{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Aspect Prediction-Deep Learning Models-New","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"V_KfS7lP6CKI","executionInfo":{"status":"ok","timestamp":1615349158749,"user_tz":-330,"elapsed":1116,"user":{"displayName":"Shanaka Chathuranga","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjyvtaGYdZLH66p14soI4ti6MLZ3PDDlHx64Gbx2A=s64","userId":"15044035539828571150"}},"outputId":"c70940ef-eff1-4c50-a6c0-46f3ead89f3d"},"source":["from google.colab import drive\r\n","drive.mount('/content/drive')"],"execution_count":13,"outputs":[{"output_type":"stream","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"MYbXOMuN6OG-","executionInfo":{"status":"ok","timestamp":1614175795065,"user_tz":-330,"elapsed":40709,"user":{"displayName":"Shanaka Chathuranga","photoUrl":"","userId":"01381725564551416324"}},"outputId":"fb60a4b0-b6fc-43eb-c597-10c37d6f58ad"},"source":["#Libraries to install \r\n","!pip install fasttext"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Collecting fasttext\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/f8/85/e2b368ab6d3528827b147fdb814f8189acc981a4bc2f99ab894650e05c40/fasttext-0.9.2.tar.gz (68kB)\n","\r\u001b[K     |████▊                           | 10kB 22.6MB/s eta 0:00:01\r\u001b[K     |█████████▌                      | 20kB 29.0MB/s eta 0:00:01\r\u001b[K     |██████████████▎                 | 30kB 22.4MB/s eta 0:00:01\r\u001b[K     |███████████████████             | 40kB 19.3MB/s eta 0:00:01\r\u001b[K     |███████████████████████▉        | 51kB 16.5MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▋   | 61kB 15.7MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 71kB 7.3MB/s \n","\u001b[?25hRequirement already satisfied: pybind11>=2.2 in /usr/local/lib/python3.7/dist-packages (from fasttext) (2.6.2)\n","Requirement already satisfied: setuptools>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from fasttext) (53.0.0)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from fasttext) (1.19.5)\n","Building wheels for collected packages: fasttext\n","  Building wheel for fasttext (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for fasttext: filename=fasttext-0.9.2-cp37-cp37m-linux_x86_64.whl size=3097872 sha256=7ddf764e4e0298729f501a156d9cbf747404c111a1ece8d4fa8be16e52db061b\n","  Stored in directory: /root/.cache/pip/wheels/98/ba/7f/b154944a1cf5a8cee91c154b75231136cc3a3321ab0e30f592\n","Successfully built fasttext\n","Installing collected packages: fasttext\n","Successfully installed fasttext-0.9.2\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"peUhowAt6SiG","executionInfo":{"status":"ok","timestamp":1615349165672,"user_tz":-330,"elapsed":1237,"user":{"displayName":"Shanaka Chathuranga","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjyvtaGYdZLH66p14soI4ti6MLZ3PDDlHx64Gbx2A=s64","userId":"15044035539828571150"}},"outputId":"f734ece6-cb62-4a33-d756-0363227cab35"},"source":["import collections\r\n","import pickle\r\n","import re\r\n","import random\r\n","import sys\r\n","import os \r\n","import time\r\n","import gensim\r\n","from gensim.models.keyedvectors import KeyedVectors\r\n","from gensim.models.fasttext import FastText\r\n","from gensim.models import word2vec\r\n","from sklearn.model_selection import train_test_split,cross_val_score, cross_val_predict, KFold, GridSearchCV\r\n","from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score, classification_report, confusion_matrix,precision_recall_fscore_support\r\n","import pandas as pd\r\n","import numpy as np\r\n","from numpy import array,asarray,zeros,cumsum\r\n","import tensorflow as tf\r\n","import keras\r\n","from keras import backend as K\r\n","from keras.models import Sequential,Model,load_model\r\n","from keras.preprocessing.text import Tokenizer\r\n","from keras.preprocessing.sequence import pad_sequences\r\n","from keras.layers import Dropout, Activation, Flatten, Embedding, Convolution1D, MaxPooling1D, AveragePooling1D,Input, Dense, merge, Add,TimeDistributed, Bidirectional,SpatialDropout1D\r\n","from keras.layers.recurrent import LSTM, GRU, SimpleRNN\r\n","from keras.regularizers import l2, l1_l2\r\n","from keras.constraints import maxnorm\r\n","from keras import callbacks\r\n","from keras.utils import generic_utils,plot_model\r\n","from keras.optimizers import Adadelta\r\n","from keras.callbacks import ModelCheckpoint,EarlyStopping\r\n","from keras.wrappers.scikit_learn import KerasClassifier\r\n","from nltk.tokenize import word_tokenize\r\n","import re\r\n","from nltk.corpus import wordnet\r\n","from sklearn.base import BaseEstimator, TransformerMixin\r\n","from nltk.corpus import wordnet\r\n","import nltk\r\n","nltk.download('punkt')\r\n","nltk.download('averaged_perceptron_tagger')\r\n","nltk.download('treebank')\r\n","from nltk.tag import UnigramTagger\r\n","from nltk.corpus import treebank\r\n","from gensim.test.utils import common_texts, get_tmpfile\r\n","from gensim.models import Word2Vec\r\n","#import fasttext\r\n","\r\n","import nltk\r\n","nltk.download('stopwords')\r\n","import re  # For preprocessing\r\n","from time import time  # To time our operations\r\n","from collections import defaultdict  # For word frequency\r\n","import spacy  # For preprocessing\r\n","import logging  # Setting up the loggings to monitor gensim\r\n","logging.basicConfig(format=\"%(levelname)s - %(asctime)s: %(message)s\", datefmt= '%H:%M:%S', level=logging.INFO)\r\n","from nltk.stem import WordNetLemmatizer\r\n","from nltk import pos_tag, word_tokenize\r\n","from nltk.corpus import stopwords\r\n","from collections import Counter\r\n","import seaborn as sns \r\n","import wordcloud\r\n","from wordcloud import WordCloud\r\n","from sklearn.feature_extraction.text import CountVectorizer\r\n","from sklearn.feature_extraction.text import TfidfTransformer\r\n","from sklearn.feature_extraction.text import TfidfVectorizer\r\n","from sklearn.ensemble import RandomForestClassifier\r\n","from sklearn.svm import SVC\r\n","import lightgbm as lgb\r\n","from sklearn.naive_bayes import MultinomialNB\r\n","import scipy.sparse\r\n","import time\r\n","import warnings\r\n","#settings\r\n","start_time=time.time()\r\n","color = sns.color_palette()\r\n","sns.set_style(\"dark\")\r\n","eng_stopwords = set(stopwords.words(\"english\"))\r\n","warnings.filterwarnings(\"ignore\")\r\n","\r\n","from wordcloud import WordCloud, STOPWORDS \r\n","import matplotlib.pyplot as plt \r\n","import pandas as pd \r\n","\r\n","\r\n","from sklearn.model_selection import cross_validate\r\n","from sklearn.metrics import recall_score\r\n","from sklearn.model_selection import KFold\r\n","from sklearn.metrics import classification_report\r\n","from sklearn.metrics import confusion_matrix\r\n","from sklearn.metrics import precision_score\r\n","from sklearn.metrics import recall_score\r\n","from sklearn.metrics import accuracy_score\r\n","from sklearn.metrics import f1_score\r\n","import os\r\n","from sklearn import model_selection, preprocessing, linear_model, naive_bayes, metrics, svm\r\n","from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\r\n","from sklearn import decomposition, ensemble\r\n","from scipy import interp\r\n","from itertools import cycle\r\n","from sklearn.preprocessing import label_binarize\r\n","from sklearn.metrics import roc_curve, auc\r\n","from sklearn.metrics import precision_recall_curve\r\n","from sklearn.metrics import average_precision_score\r\n","import nltk\r\n","from nltk.corpus import wordnet\r\n","from nltk.stem.wordnet import WordNetLemmatizer\r\n","from nltk.tokenize import sent_tokenize, word_tokenize\r\n","from sklearn.base import BaseEstimator, TransformerMixin\r\n","from sklearn.feature_extraction.text import CountVectorizer\r\n","from sklearn.feature_extraction.text import TfidfVectorizer\r\n","from sklearn.model_selection import GridSearchCV\r\n","from sklearn.model_selection import train_test_split\r\n","from sklearn.pipeline import Pipeline, FeatureUnion\r\n","from sklearn.metrics import classification_report\r\n","from sklearn.naive_bayes import MultinomialNB\r\n","from sklearn.linear_model import LogisticRegression\r\n","from nltk.corpus import stopwords\r\n","from nltk.stem import PorterStemmer\r\n","from nltk.tokenize import word_tokenize\r\n","import warnings\r\n","import multiprocessing\r\n","from gensim.models import Word2Vec\r\n","#from gensim.models import FastText\r\n","from sklearn.metrics import roc_auc_score\r\n","from numpy import asarray\r\n","\r\n","from sklearn.model_selection import cross_validate\r\n","from sklearn.metrics import recall_score\r\n","from sklearn.model_selection import KFold\r\n","from sklearn.metrics import classification_report\r\n","from sklearn.metrics import confusion_matrix\r\n","from sklearn.metrics import precision_score\r\n","from sklearn.metrics import recall_score\r\n","from sklearn.metrics import accuracy_score\r\n","from sklearn.metrics import f1_score\r\n","import os\r\n","from sklearn import model_selection, preprocessing, linear_model, naive_bayes, metrics, svm\r\n","from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\r\n","from sklearn import decomposition, ensemble\r\n","from scipy import interp\r\n","from itertools import cycle\r\n","from sklearn.preprocessing import label_binarize\r\n","from sklearn.metrics import roc_curve, auc\r\n","from sklearn.metrics import precision_recall_curve\r\n","from sklearn.metrics import average_precision_score\r\n","import nltk\r\n","from nltk.corpus import wordnet\r\n","from nltk.stem.wordnet import WordNetLemmatizer\r\n","from nltk.tokenize import sent_tokenize, word_tokenize\r\n","from sklearn.base import BaseEstimator, TransformerMixin\r\n","from sklearn.feature_extraction.text import CountVectorizer\r\n","from sklearn.feature_extraction.text import TfidfVectorizer\r\n","from sklearn.model_selection import GridSearchCV\r\n","from sklearn.model_selection import train_test_split\r\n","from sklearn.pipeline import Pipeline, FeatureUnion\r\n","from sklearn.metrics import classification_report\r\n","from sklearn.naive_bayes import MultinomialNB\r\n","from sklearn.linear_model import LogisticRegression\r\n","from nltk.corpus import stopwords\r\n","from nltk.stem import PorterStemmer\r\n","from nltk.tokenize import word_tokenize\r\n","import warnings\r\n","import multiprocessing\r\n","from gensim.models import Word2Vec\r\n","#from gensim.models import FastText\r\n","from sklearn.metrics import roc_auc_score\r\n","\r\n","\r\n","from keras.models import Sequential\r\n","from keras.layers import Dense, Input, Dropout, LSTM, Activation\r\n","from keras.layers import BatchNormalization\r\n","from keras.models import model_from_json\r\n","from keras.preprocessing import text, sequence\r\n","from keras import layers, models, optimizers\r\n","from keras.callbacks import EarlyStopping\r\n","from keras.callbacks import ModelCheckpoint\r\n","from keras.layers import BatchNormalization\r\n","from keras import backend as K\r\n","from sklearn.metrics import recall_score\r\n","from keras.models import load_model\r\n","from keras.preprocessing.text import one_hot\r\n","from keras.preprocessing.sequence import pad_sequences\r\n","from keras.models import Sequential\r\n","from keras.layers import Dense\r\n","from keras.layers import Flatten\r\n","from keras.layers.embeddings import Embedding\r\n","import matplotlib.pyplot as pyplot\r\n","\r\n","from keras.models import Sequential\r\n","from keras.layers.core import Activation, Dropout, Dense\r\n","from keras.layers import Flatten, LSTM\r\n","from keras.layers import GlobalMaxPooling1D\r\n","from keras.models import Model\r\n","from keras.layers.embeddings import Embedding\r\n","from sklearn.model_selection import train_test_split\r\n","from keras.preprocessing.text import Tokenizer\r\n","from keras.layers import Input\r\n","from keras.layers.merge import Concatenate\r\n","from keras.layers.convolutional import Conv1D\r\n","from keras.layers import GlobalMaxPooling1D\r\n","\r\n","\r\n","from keras.models import Sequential\r\n","from keras.layers import Dense, Input, Dropout, LSTM, Activation\r\n","from keras.layers import BatchNormalization\r\n","from keras.models import model_from_json\r\n","from keras.preprocessing import text, sequence\r\n","from keras import layers, models, optimizers\r\n","from keras.callbacks import EarlyStopping\r\n","from keras.callbacks import ModelCheckpoint\r\n","from keras.layers import BatchNormalization\r\n","from keras import backend as K\r\n","from sklearn.metrics import recall_score\r\n","from keras.models import load_model\r\n","import tensorflow as tf \r\n","from sklearn.model_selection import KFold\r\n","from sklearn.model_selection import StratifiedKFold\r\n","from numpy import array\r\n","from numpy import asarray\r\n","from numpy import zeros\r\n","import tensorflow as tf\r\n","\r\n","from keras import backend as K\r\n","from keras.models import Sequential,Model,load_model\r\n","from keras.preprocessing.text import Tokenizer\r\n","from keras.preprocessing.sequence import pad_sequences\r\n","from keras.layers import Dropout, Activation, Flatten, \\\r\n","    Embedding, Convolution1D, MaxPooling1D, AveragePooling1D, \\\r\n","    Input, Dense, merge, Add,TimeDistributed, Bidirectional,SpatialDropout1D\r\n","from keras.layers.recurrent import LSTM, GRU, SimpleRNN\r\n","from keras.regularizers import l2, l1_l2\r\n","from keras.constraints import maxnorm\r\n","from keras import callbacks\r\n","from keras.utils import generic_utils,plot_model\r\n","from keras.optimizers import Adadelta\r\n","from keras.callbacks import ModelCheckpoint,EarlyStopping\r\n","from keras.wrappers.scikit_learn import KerasClassifier\r\n","\r\n","import pandas as pd \r\n","import numpy as np \r\n","from sklearn.model_selection import KFold\r\n","from keras.layers.recurrent import LSTM, GRU, SimpleRNN\r\n"],"execution_count":14,"outputs":[{"output_type":"stream","text":["[nltk_data] Downloading package punkt to /root/nltk_data...\n","[nltk_data]   Package punkt is already up-to-date!\n","[nltk_data] Downloading package averaged_perceptron_tagger to\n","[nltk_data]     /root/nltk_data...\n","[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n","[nltk_data]       date!\n","[nltk_data] Downloading package treebank to /root/nltk_data...\n","[nltk_data]   Package treebank is already up-to-date!\n","[nltk_data] Downloading package stopwords to /root/nltk_data...\n","[nltk_data]   Package stopwords is already up-to-date!\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":35},"id":"EhcSOz8o6IJD","executionInfo":{"status":"ok","timestamp":1615349206679,"user_tz":-330,"elapsed":929,"user":{"displayName":"Shanaka Chathuranga","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjyvtaGYdZLH66p14soI4ti6MLZ3PDDlHx64Gbx2A=s64","userId":"15044035539828571150"}},"outputId":"ede3b23c-2aec-4a15-fc99-18e7d93e491d"},"source":["mainloc='/content/drive/My Drive/Research/ABSA_Final/'\r\n","mainloc"],"execution_count":18,"outputs":[{"output_type":"execute_result","data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["'/content/drive/My Drive/Research/ABSA_Final/'"]},"metadata":{"tags":[]},"execution_count":18}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"aCiqNyS0Rc5z","executionInfo":{"status":"ok","timestamp":1615348489602,"user_tz":-330,"elapsed":829,"user":{"displayName":"Shanaka Chathuranga","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjyvtaGYdZLH66p14soI4ti6MLZ3PDDlHx64Gbx2A=s64","userId":"15044035539828571150"}},"outputId":"5d0f2a05-8887-4249-e90e-42c263c24581"},"source":[""],"execution_count":null,"outputs":[{"output_type":"stream","text":["/content\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"lR0t1mh16YYe","executionInfo":{"status":"ok","timestamp":1615349244342,"user_tz":-330,"elapsed":1928,"user":{"displayName":"Shanaka Chathuranga","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjyvtaGYdZLH66p14soI4ti6MLZ3PDDlHx64Gbx2A=s64","userId":"15044035539828571150"}}},"source":["#Functions \r\n","\r\n","def splitdata(x,y,splitratio,valflag):\r\n","    x_train_main, x_test, y_train_main, y_test = train_test_split(x, y, test_size=splitratio, random_state=10, stratify=y)\r\n","    x_train, x_val, y_train, y_val = train_test_split(x_train_main, y_train_main, test_size=splitratio, random_state=10, \r\n","                                                      stratify=y_train_main)\r\n","    encoder = preprocessing.LabelEncoder()\r\n","    y_train_main = encoder.fit_transform(y_train_main)\r\n","    y_train = encoder.fit_transform(y_train)\r\n","    y_val = encoder.fit_transform(y_val)\r\n","    y_test = encoder.fit_transform(y_test)\r\n","    \r\n","    y_train_main_c = label_binarize(y_train_main, classes=[0,1,2])\r\n","    y_train_c = label_binarize(y_train, classes=[0,1,2])\r\n","    y_val_c = label_binarize(y_val, classes=[0,1,2])\r\n","    y_test_c = label_binarize(y_test, classes=[0,1,2])\r\n","    \r\n","    if(valflag):\r\n","        return x, y, x_train,x_val,x_test,y_train,y_val, y_test,y_train_c,y_val_c,y_test_c \r\n","    else:\r\n","        return x, y, x_train_main,x_test,y_train_main, y_test, y_train_main_c,y_test_c\r\n","            \r\n","def pred(clf, feature_vector_valid):\r\n","    predictions = clf.predict(feature_vector_valid)\r\n","    predictions_prob = clf.predict_proba(feature_vector_valid)\r\n","    return predictions, predictions_prob\r\n","\r\n","def multiclassroc(y_test,prediction_prob):\r\n","    fpr = {}\r\n","    tpr = {}\r\n","    thresh ={}\r\n","    \r\n","    n_class = 3\r\n","    for i in range(n_class):    \r\n","        fpr[i], tpr[i], thresh[i] = roc_curve(y_test, prediction_prob[:,i], pos_label=i)\r\n","        \r\n","    plt.plot(fpr[0], tpr[0], linestyle='--',color='orange', label='Passive vs Rest')\r\n","    plt.plot(fpr[1], tpr[1], linestyle='--',color='green', label='Neutral vs Rest')\r\n","    plt.plot(fpr[2], tpr[2], linestyle='--',color='blue', label='Positive vs Rest')\r\n","    plt.title('Multiclass ROC curve')\r\n","    plt.xlabel('False Positive Rate')\r\n","    plt.ylabel('True Positive rate')\r\n","    plt.legend(loc='best')\r\n","    #plt.savefig('Multiclass ROC',dpi=300)\r\n","    \r\n","def precrecallcurve(y_test_c, prediction_prob):\r\n","    precision = dict()\r\n","    recall = dict()\r\n","    for i in range(3):\r\n","        precision[i], recall[i], _ = precision_recall_curve(y_test_c[:, i],prediction_prob[:, i])\r\n","        plt.plot(recall[i], precision[i], lw=2, label='class {}'.format(i))\r\n","    \r\n","    plt.xlabel(\"recall\")\r\n","    plt.ylabel(\"precision\")\r\n","    plt.legend(loc=\"best\")\r\n","    plt.title(\"precision vs. recall curve\")\r\n","    plt.show()\r\n","    \r\n","    \r\n","#Word embeddings \r\n","\r\n","def create_txt(df,var):\r\n","    text=[]\r\n","    for i in df[var]:\r\n","        li = list(i.split())\r\n","        text.append(li)\r\n","    return text\r\n","        \r\n","def word2vec(text,min_count,size,workers,window,sg):\r\n","    model = Word2Vec(text,min_count=min_count,size=size,workers=workers,window=window,sg=sg)\r\n","    return model \r\n","\r\n","def make_feature_vec(words, model, num_features):\r\n","    \"\"\"\r\n","    Average the word vectors for a set of words\r\n","    \"\"\"\r\n","    feature_vec = np.zeros((num_features,),dtype=\"float32\")  # pre-initialize (for speed)\r\n","    nwords = 0\r\n","    index2word_set = set(model.wv.index2word)  # words known to the model\r\n","   \r\n","\r\n","    for word in words:\r\n","        if word in index2word_set: \r\n","            nwords = nwords + 1\r\n","            feature_vec = np.add(feature_vec,model[word])\r\n","    \r\n","    feature_vec = np.divide(feature_vec, nwords)\r\n","    return feature_vec\r\n","\r\n","def get_avg_feature_vecs(reviews, model, num_features):\r\n","    \"\"\"\r\n","    Calculate average feature vectors for all reviews\r\n","    \"\"\"\r\n","    counter = 0\r\n","    review_feature_vecs = np.zeros((len(reviews),num_features), dtype='float32')  # pre-initialize (for speed)\r\n","    \r\n","    for review in reviews:\r\n","        review_feature_vecs[counter] = make_feature_vec(review, model, num_features)\r\n","        counter = counter + 1\r\n","    return review_feature_vecs\r\n","\r\n","def word_embed(df,df_we,num_features,wetype,window,sg):\r\n","    text_we=create_txt(df_we,'cleanAnswer')\r\n","    text_model=create_txt(df,'cleanAnswer')\r\n","    \r\n","    if(wetype=='w2vec'):\r\n","        model=word2vec(text_we,1,num_features,7,window,sg)\r\n","        \r\n","    if(wetype=='ft'):\r\n","        model = FastText(text_we,size=num_features,window=window,sg=sg,iter=100)\r\n","\r\n","    x=get_avg_feature_vecs(text_model,model, num_features)\r\n","    return x \r\n","    \r\n","def recall_m(y_true,y_pred):\r\n","    #recall=recall_score(y_true.t.math.argmax(axis=1), y_pred.K.math.argmax(axis=1), average='macro')\r\n","    a=tf.math.argmax(y_true,axis=1)\r\n","    b=tf.math.argmax(y_pred,axis=1)\r\n","    recall=recall_score(a,b,average='macro')\r\n","    return reccall \r\n","    \r\n","def recall_m(y_true, y_pred):\r\n","    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\r\n","    possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\r\n","    recall = true_positives / (possible_positives + K.epsilon())\r\n","    return recall\r\n","\r\n","def precision_m(y_true, y_pred):\r\n","    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\r\n","    predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\r\n","    precision = true_positives / (predicted_positives + K.epsilon())\r\n","    return precision\r\n","\r\n","def f1_m(y_true, y_pred):\r\n","    precision = precision_m(y_true, y_pred)\r\n","    recall = recall_m(y_true, y_pred)\r\n","    return 2*((precision*recall)/(precision+recall+K.epsilon()))\r\n","\r\n","def emb_dictionary(filename):\r\n","    embedding_dictionary = dict()\r\n","    f = open(filename)\r\n","    for line in f:\r\n","        values = line.split()\r\n","        word = values[0]\r\n","        coefs = asarray(values[1:], dtype='float32')\r\n","        embedding_dictionary[word] = coefs\r\n","    f.close()\r\n","    return embedding_dictionary\r\n","\r\n","def emb_matrix(word_tokenizer,embeddings_dictionary,we_size):\r\n","    embedding_matrix = zeros((vocab_length, we_size))\r\n","    for word, index in word_tokenizer.word_index.items():\r\n","        embedding_vector = embeddings_dictionary.get(word)\r\n","        if embedding_vector is not None:\r\n","            embedding_matrix[index] = embedding_vector\r\n","    return  embedding_matrix\r\n","\r\n","def pred_neural(clf, feature_vector_valid):\r\n","    predictions = clf.predict(feature_vector_valid).argmax(axis=1)\r\n","    predictions_prob = clf.predict(feature_vector_valid)\r\n","    return predictions, predictions_prob\r\n","    \r\n","def accuracy_neural(y_val,y_pred,target_names):\r\n","    print(\"Accuracy Score: \",metrics.accuracy_score(y_val,y_pred))\r\n","    #print(\"AUC Score: \",metrics.accuracy_score(y_val,y_pred))\r\n","    print(\"Precision: \", metrics.precision_score(y_val,y_pred,average='micro'))\r\n","    print(\"Recall: \", metrics.recall_score(y_val,y_pred,average='micro'))\r\n","    print(\"F1 score: \", metrics.f1_score(y_val,y_pred,average='micro'))\r\n","    \r\n","    print(\"\\nClassification report\")\r\n","    print(\"---------------------\")\r\n","    print(metrics.classification_report(y_val, y_pred,target_names=target_names))\r\n","\r\n","def accuracy_scores_neural(model,x_train,y_train,y_train_c,x_test,y_test,y_test_c,target_names):\r\n","    print(\"Basic model evaluation: \")\r\n","    print(\"--------------------------------------------\")\r\n","    loss_train,acc_train,f1_train,pre_train,rec_train = model.evaluate(x_train, y_train_c, verbose=0)\r\n","    loss_test,acc_test,f1_test,pre_test,rec_test = model.evaluate(x_test, y_test_c, verbose=0)\r\n","\r\n","    print(\"Loss==>\",'Train: %.3f, Test: %.3f' % (loss_train,loss_test))\r\n","    print(\"Accuracy==>\",'Train: %.3f, Test: %.3f' % (acc_train,acc_test))\r\n","    print(\"F1==>\",'Train: %.3f, Test: %.3f' % (f1_train,f1_test))\r\n","    print(\"Precision==>\",'Train: %.3f, Test: %.3f' % (pre_train,pre_test))\r\n","    print(\"Recall==>\",'Train: %.3f, Test: %.3f' % (rec_train,rec_test))\r\n","\r\n","    print(\"Accuracy of Neural Network Model\")\r\n","    print(\"--------------------------------------------\")\r\n","\r\n","    print(\"\\nTraining accuracy\")\r\n","    print(\"--------------------------------------------\")\r\n","    predictions, predictions_prob  = pred_neural(model,x_train)\r\n","    accuracy_neural(y_train,predictions,target_names)\r\n","\r\n","    print(\"\\n Testing accuracy\")\r\n","    print(\"--------------------------------------------\")\r\n","    predictions, predictions_prob  = pred_neural(model,x_test)\r\n","    accuracy_neural(y_test,predictions,target_names)\r\n","    \r\n","         \r\n","def accuracy_curve(history,measure,title):\r\n","    print(title)\r\n","    pyplot.plot(history.history[measure], label='train')\r\n","    pyplot.plot(history.history['val_'+measure], label='val')\r\n","    pyplot.title(title)\r\n","    pyplot.legend()\r\n","    pyplot.show()\r\n","    plt.figure()\r\n","    \r\n","\r\n","def accuracy_curve(history,measure,title):\r\n","    epochs=range(len(history.history[measure]))\r\n","    plt.plot(epochs,history.history[measure], 'r')\r\n","    plt.plot(epochs,history.history['val_'+measure], 'b')\r\n","    plt.title(title)\r\n","    plt.xlabel(\"Epochs\")\r\n","    plt.ylabel(title)\r\n","    plt.legend([\"Training\", \"Validation\"])\r\n","    plt.figure()\r\n","\r\n","\r\n","def getXY(df,x,y):\r\n","    x=df[x]\r\n","    y=df[y]\r\n","    return x,y\r\n","\r\n","def encodeY(y,classes):\r\n","    encoder = preprocessing.LabelEncoder()\r\n","    y_c = encoder.fit_transform(y)\r\n","    y_c = label_binarize(y_c, classes=classes)\r\n","    return y_c\r\n","\r\n","def emb_dictionary(filename):\r\n","    embedding_dictionary = dict()\r\n","    f = open(filename)\r\n","    for line in f:\r\n","        values = line.split()\r\n","        word = values[0]\r\n","        coefs = asarray(values[1:], dtype='float32')\r\n","        embedding_dictionary[word] = coefs\r\n","    f.close()\r\n","    return embedding_dictionary\r\n","\r\n","def emb_matrix(vocab_length,word_tokenizer,embeddings_dictionary,we_size):\r\n","    embedding_matrix = zeros((vocab_length, we_size))\r\n","    for word, index in word_tokenizer.word_index.items():\r\n","        embedding_vector = embeddings_dictionary.get(word)\r\n","        if embedding_vector is not None:\r\n","            embedding_matrix[index] = embedding_vector\r\n","    return  embedding_matrix\r\n","\r\n","def get_emb_sentences(X):\r\n","    word_tokenizer = Tokenizer()\r\n","    word_tokenizer.fit_on_texts(x)\r\n","    vocab_length = len(word_tokenizer.word_index) + 1\r\n","    embedded_sentences = word_tokenizer.texts_to_sequences(x)\r\n","    return word_tokenizer,embedded_sentences,vocab_length\r\n","\r\n","def get_padded_sequence(x,embedded_sentences):\r\n","    word_count = lambda sentence: len(word_tokenize(sentence))\r\n","    longest_sentence = max(x, key=word_count)\r\n","    length_long_sentence = len(word_tokenize(longest_sentence))\r\n","    padded_sentences = pad_sequences(embedded_sentences, length_long_sentence, padding='post')\r\n","    return length_long_sentence,padded_sentences \r\n","\r\n","def crossval(padded_sentences,y,y_c,embedding_matrix,vocab_length,length_long_sentence,modeltype):\r\n","  acc_per_fold = []\r\n","  loss_per_fold = []\r\n","  f1_per_fold=[]\r\n","  precision_per_fold = []\r\n","  recall_per_fold = []\r\n","\r\n","  skf = StratifiedKFold(n_splits=n_folds,random_state=None, shuffle=False)\r\n","  fold_no = 1\r\n","  \r\n","  for train_index, test_index in skf.split(padded_sentences, y):\r\n","    if (modeltype=='cnn'):\r\n","      model=cnn_model(embedding_matrix,vocab_length,length_long_sentence)\r\n","    elif (modeltype=='rnn'):\r\n","      model=rnn_model(rnn,embedding_matrix,vocab_length,length_long_sentence,l2_reg, dropout_value_1, dropout_value_2)\r\n","     \r\n","    model,history=train_model(model,padded_sentences[train_index],y_c[train_index],True) \r\n","    scores = model.evaluate(padded_sentences[test_index], y_c[test_index], verbose=0)\r\n","    print(f'Score for fold {fold_no}: {model.metrics_names[0]} of {scores[0]};  \\\r\n","    {model.metrics_names[1]} of {scores[1]*100}% ;{model.metrics_names[2]} of {scores[2]}')\r\n","    loss_per_fold.append(scores[0])\r\n","    acc_per_fold.append(scores[1] * 100)\r\n","    precision_per_fold.append(scores[2])\r\n","    recall_per_fold.append(scores[3])\r\n","    f1_per_fold.append(scores[4])\r\n","    fold_no = fold_no + 1\r\n","        \r\n","  return acc_per_fold, loss_per_fold,precision_per_fold,recall_per_fold,f1_per_fold\r\n","\r\n","def train_model(model,x_train, y_train, cross_validation = False):\r\n","    print('Model Trainin and testing')\r\n","    es = EarlyStopping(monitor='val_f1_m', mode='max', verbose=1, patience=patience)\r\n","    mc = ModelCheckpoint(model_save_path, monitor='val_f1_m', verbose=1, save_best_only=True, mode='max')\r\n","    callbacks_list = [es,mc]\r\n","    \r\n","    if(cross_validation):\r\n","        callbacks_list=[es]\r\n","    \r\n","    history = model.fit(x_train, y_train, validation_split=validation_split, epochs=epochs, batch_size=batch_size, \r\n","                    callbacks=callbacks_list, verbose=1)\r\n","\r\n","    return model,history \r\n","          \r\n","def accuracy_crossval(acc_per_fold,loss_per_fold,f1_per_fold,precision_per_fold,recall_per_fold):\r\n","    print('------------------------------------------------------------------------')\r\n","    print('Score per fold')\r\n","    for i in range(0, len(acc_per_fold)):\r\n","        print('------------------------------------------------------------------------')\r\n","        print(f'> Fold {i+1} - Loss: {loss_per_fold[i]} - Accuracy: {acc_per_fold[i]}% - Precision: {precision_per_fold[i]} - Recall: {recall_per_fold[i]} - F1: {f1_per_fold[i]}')\r\n","    print('------------------------------------------------------------------------')\r\n","    print('Average scores for all folds:')\r\n","    print(f'> Accuracy: {np.mean(acc_per_fold)} (+- {np.std(acc_per_fold)})')\r\n","    print(f'> Precision: {np.mean(precision_per_fold)}')\r\n","    print(f'> Recall: {np.mean(recall_per_fold)}')\r\n","    print(f'> F1: {np.mean(f1_per_fold)}')\r\n","    print(f'> Loss: {np.mean(loss_per_fold)}')\r\n","    print('------------------------------------------------------------------------')\r\n","    acc=np.mean(acc_per_fold)\r\n","    precision=np.mean(precision_per_fold)\r\n","    recall=np.mean(recall_per_fold)\r\n","    f1=np.mean(f1_per_fold)\r\n","    loss=np.mean(loss_per_fold)\r\n","    return acc,precision,recall,f1,loss"],"execution_count":21,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"ls8VsrRO8Ohb"},"source":["# Extract Datasets \r\n"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":128},"id":"F7VqO0QJ8TbO","executionInfo":{"status":"ok","timestamp":1615349233301,"user_tz":-330,"elapsed":862,"user":{"displayName":"Shanaka Chathuranga","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjyvtaGYdZLH66p14soI4ti6MLZ3PDDlHx64Gbx2A=s64","userId":"15044035539828571150"}},"outputId":"470d4b2e-0e58-4864-b018-b8f2092b728f"},"source":["df=pd.read_csv(mainloc+\"df_train.csv\")\r\n","df=df[~df['cleanAnswer'].isna()]\r\n","print(\"Size of training dataset: \",df.shape)\r\n","\r\n","#df_we=pd.read_csv(mainloc+\"Data/data_clean_full_corpus.csv\")\r\n","#df_we=df_we[~df_we['cleanAnswer'].isna()]\r\n","#print(\"Size of word embedding dataset: \",df_we.shape)\r\n","\r\n","sent=df[['comment','cleanAnswer','cleanAnswer1','sentiment']]\r\n","sent.head(2)"],"execution_count":20,"outputs":[{"output_type":"stream","text":["Size of training dataset:  (10058, 15)\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>comment</th>\n","      <th>cleanAnswer</th>\n","      <th>cleanAnswer1</th>\n","      <th>sentiment</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>Munge boru math damma package eka danna kalin ...</td>\n","      <td>munge boru math damma package danna kalin 4g a...</td>\n","      <td>munge boru math damma package danna kalin 4g a...</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>Dialog Axiata night time inne it8n a tika day ...</td>\n","      <td>axiata night time inne it8n tika day time pawi...</td>\n","      <td>axiata night time inne it8n tika day time pawi...</td>\n","      <td>0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["                                             comment  ... sentiment\n","0  Munge boru math damma package eka danna kalin ...  ...         0\n","1  Dialog Axiata night time inne it8n a tika day ...  ...         0\n","\n","[2 rows x 4 columns]"]},"metadata":{"tags":[]},"execution_count":20}]},{"cell_type":"markdown","metadata":{"id":"6YyLsChf82d8"},"source":["# Get X and Y \r\n"]},{"cell_type":"code","metadata":{"id":"eBzYsSmJ2BA4"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"OnTEU4PC84qZ"},"source":["categories=['network','billing_price','package','customer_service','data','service_product']   \r\n","x=df['cleanAnswer']\r\n","y=df[categories]"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"ftUt2yqe7flH"},"source":["# Get the Embedding Matrix and Padded Sentences "]},{"cell_type":"code","metadata":{"id":"XRPLz_j87BPV"},"source":["word_tokenizer,embedded_sentences,vocab_length=get_emb_sentences(x)\r\n","length_long_sentence,padded_sentences = get_padded_sequence(x,embedded_sentences)\r\n","embeddings_dictionary=emb_dictionary(mainloc+'word_embeddings/w2v_cbow_300.txt')\r\n","embedding_matrix=emb_matrix(word_tokenizer,embeddings_dictionary,300)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"lrCQcF-R0Y-v"},"source":["def loadembedding_matrix(x,loc,emb_size):\r\n","  word_tokenizer,embedded_sentences,vocab_length=get_emb_sentences(x)\r\n","  length_long_sentence,padded_sentences = get_padded_sequence(x,embedded_sentences)\r\n","  embeddings_dictionary=emb_dictionary(loc)\r\n","  embedding_matrix=emb_matrix(vocab_length,word_tokenizer,embeddings_dictionary,emb_size)\r\n","  return vocab_length,padded_sentences,length_long_sentence,embedding_matrix\r\n","\r\n","#vocab_length,padded_sentences,length_long_sentence,embedding_matrix=loadembedding_matrix(x,mainloc+'word_embeddings/w2v_cbow_300.txt',300)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"_mUZFXXswIYK"},"source":["\r\n","def cnn_model():\r\n","    model = Sequential()\r\n","    embedding_layer = Embedding(vocab_length,EMBEDDING_SIZE,weights=[embedding_matrix],input_length=length_long_sentence, trainable=False)\r\n","    model.add(embedding_layer)\r\n","    model.add(Conv1D(256,3, activation='relu'))\r\n","    model.add(GlobalMaxPooling1D())\r\n","    model.add(Dropout(DROPOUT_VALUE_1))\r\n","    model.add(Flatten())\r\n","    model.add(Dense(NUM_CLASSES, activation='sigmoid'))\r\n","    model.compile(loss='binary_crossentropy', optimizer='adam',metrics=[\"accuracy\",precision_m,recall_m,f1_m])\r\n","    return model \r\n","\r\n","def rnn_model():\r\n","    model = Sequential()\r\n","    embedding_layer = Embedding(vocab_length,EMBEDDING_SIZE,weights=[embedding_matrix], input_length=length_long_sentence, trainable=False)\r\n","    model.add(embedding_layer)\r\n","    model.add(Dropout(DROPOUT_VALUE_1))\r\n","    model.add(RNN(HIDDEN_DIMS))\r\n","    model.add(Dense(HIDDEN_DIMS, activation='relu'))\r\n","    model.add(Dropout(DROPOUT_VALUE_2))\r\n","    model.add(Dense(NUM_CLASSES,activation='sigmoid'))\r\n","    model.compile(loss='binary_crossentropy', optimizer='adam',metrics=[\"accuracy\",precision_m,recall_m,f1_m])\r\n","    return model \r\n","\r\n","def cnn_rnn_model():\r\n","  model = Sequential()\r\n","  embedding_layer = Embedding(vocab_length,EMBEDDING_SIZE,weights=[embedding_matrix], input_length=length_long_sentence, trainable=False)\r\n","  model.add(embedding_layer)\r\n","  model.add(Conv1D(filters=NB_FILTERS,kernel_size=KERNEL_SIZE, padding='same', activation='relu'))\r\n","  model.add(MaxPooling1D(pool_size=2))\r\n","  model.add(Dropout(DROPOUT_VALUE_2))\r\n","  #model.add(RNN(HIDDEN_DIMS,return_sequences=True))\r\n","  model.add(RNN(HIDDEN_DIMS))\r\n","  model.add(Dropout(DROPOUT_VALUE_2))\r\n","  model.add(Dense(NUM_CLASSES, activation='sigmoid'))\r\n","  model.compile(loss='binary_crossentropy', optimizer='adam',metrics=[\"accuracy\",precision_m,recall_m,f1_m])\r\n","  return model \r\n","\r\n","\r\n","def bi_lstm_model():\r\n","  model = Sequential()\r\n","  embedding_layer = Embedding(vocab_length,EMBEDDING_SIZE,weights=[embedding_matrix], input_length=length_long_sentence, trainable=False)\r\n","  model.add(embedding_layer)\r\n","  model.add(Dropout(DROPOUT_VALUE_1))\r\n","  model.add(Bidirectional(LSTM(HIDDEN_DIMS,return_sequences=True)))\r\n","  model.add(Bidirectional(LSTM(HIDDEN_DIMS)))\r\n","  #model.add(RNN(HIDDEN_DIMS))\r\n","  model.add(Dense(HIDDEN_DIMS, activation='relu'))\r\n","  model.add(Dropout(DROPOUT_VALUE_2))\r\n","  model.add(Dense(NUM_CLASSES,activation='sigmoid'))\r\n","  model.compile(loss='binary_crossentropy', optimizer='adam',metrics=[\"accuracy\",precision_m,recall_m,f1_m])\r\n","  return model \r\n","\r\n","def stacked_rnn2_model():\r\n","    model = Sequential()\r\n","    embedding_layer = Embedding(vocab_length,EMBEDDING_SIZE,weights=[embedding_matrix], input_length=length_long_sentence, trainable=False)\r\n","    model.add(embedding_layer)\r\n","    model.add(Dropout(DROPOUT_VALUE_1))\r\n","    model.add(RNN(HIDDEN_DIMS,return_sequences=True))\r\n","    model.add(RNN(HIDDEN_DIMS))\r\n","    model.add(Dense(HIDDEN_DIMS, activation='relu'))\r\n","    model.add(Dropout(DROPOUT_VALUE_2))\r\n","    model.add(Dense(NUM_CLASSES,activation='sigmoid'))\r\n","    model.compile(loss='binary_crossentropy', optimizer='adam',metrics=[\"accuracy\",precision_m,recall_m,f1_m])\r\n","    return model \r\n","\r\n","def stacked_rnn3_model():\r\n","    model = Sequential()\r\n","    embedding_layer = Embedding(vocab_length,EMBEDDING_SIZE,weights=[embedding_matrix], input_length=length_long_sentence, trainable=False)\r\n","    model.add(embedding_layer)\r\n","    model.add(Dropout(DROPOUT_VALUE_1))\r\n","    model.add(RNN(HIDDEN_DIMS,return_sequences=True))\r\n","    model.add(RNN(HIDDEN_DIMS,return_sequences=True))\r\n","    model.add(RNN(HIDDEN_DIMS))\r\n","    model.add(Dense(HIDDEN_DIMS, activation='relu'))\r\n","    model.add(Dropout(DROPOUT_VALUE_2))\r\n","    model.add(Dense(NUM_CLASSES,activation='sigmoid'))\r\n","    model.compile(loss='binary_crossentropy', optimizer='adam',metrics=[\"accuracy\",precision_m,recall_m,f1_m])\r\n","    return model\r\n","\r\n","\r\n","def crossval(model_name):\r\n","\r\n","  # Define per-fold score containers <-- these are new\r\n","  acc_per_fold = []\r\n","  loss_per_fold = []\r\n","  f1_per_fold = []\r\n","  precision_per_fold =[]\r\n","  recall_per_fold=[]\r\n","\r\n","  kf = KFold(n_splits=N_FOLDS)\r\n","  fold_no = 1\r\n","  for train_index, test_index in kf.split(padded_sentences, y):\r\n","    if model_name=='cnn':\r\n","      model=cnn_model()\r\n","    elif model_name='bi_lstm':\r\n","      model=bi_lstm_model()\r\n","    elif model_name=='rnn':\r\n","      model=rnn_model()\r\n","    else:\r\n","      model=cnn_rnn_model()\r\n","\r\n","    es = EarlyStopping(monitor=MONITOR, mode=MONITOR_MODE, verbose=1,patience= PATIENCE )\r\n","    history = model.fit(padded_sentences[train_index],y.values[train_index],epochs=EPOCHS,callbacks=[es],batch_size=BATCH_SIZE,shuffle=SHUFFLE,validation_split=VALIDATION_SPLIT)\r\n","    \r\n","    # Generate generalization metrics\r\n","    scores = model.evaluate(padded_sentences[test_index], y.values[test_index], verbose=0)\r\n","    print(f'Score for fold {fold_no}: {model.metrics_names[0]} of {scores[0]}; {model.metrics_names[1]} of {scores[1]*100}% ;{model.metrics_names[2]} of {scores[2]} ;{model.metrics_names[3]} of {scores[3]} ; \\\r\n","           {model.metrics_names[4]} of {scores[4]}')\r\n","    loss_per_fold.append(scores[0])\r\n","    acc_per_fold.append(scores[1] * 100)\r\n","    precision_per_fold.append(scores[2])\r\n","    recall_per_fold.append(scores[3])\r\n","    f1_per_fold.append(scores[4])\r\n","\r\n","    # Increase fold number\r\n","    fold_no = fold_no + 1\r\n","\r\n","  acc=np.mean(acc_per_fold)\r\n","  precision=np.mean(precision_per_fold)\r\n","  recall=np.mean(recall_per_fold)\r\n","  f1=np.mean(f1_per_fold)\r\n","  loss=np.mean(loss_per_fold)\r\n","  #acc,precision,recall,f1,loss=accuracy_crossval(acc_per_fold,loss_per_fold,f1_per_fold,precision_per_fold,recall_per_fold)\r\n","\r\n","  return acc,precision,recall,f1,loss"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"U2fKS3dt2eaD"},"source":["MODELS_LIST=['cnn','bi_lstm','rnn_lstm','cnn_gru','cnn_lstm']\r\n","EMP_PATH_LIST=['cbow_100','cbow_200','cbow_300','skip_100','skip_200','skip_300','ft_100','ft_200','ft_300']\r\n","\r\n","#MODELS_LIST=['cnn','rnn_gru']\r\n","#EMP_PATH_LIST=['cbow_100','skip_300']"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"nd1B1RtE63Uo","executionInfo":{"status":"ok","timestamp":1614194393579,"user_tz":-330,"elapsed":44870,"user":{"displayName":"Shanaka Chathuranga","photoUrl":"","userId":"01381725564551416324"}},"outputId":"0faba2c9-3048-444a-8320-195e586154d0"},"source":["N_FOLDS=3 \r\n","EPOCHS=50\r\n","VALIDATION_SPLIT=0.2 \r\n","BATCH_SIZE=32 \r\n","PATIENCE=10\r\n","MONITOR='val_f1_m' \r\n","MONITOR_MODE='max' \r\n","shuffle=True \r\n","DROPOUT_VALUE_2=0.5 \r\n","DROPOUT_VALUE_1=0.5 \r\n","NUM_CLASSES=6\r\n","NB_FILTERS=200 \r\n","KERNEL_SIZE=5\r\n","SHUFFLE=True\r\n","HIDDEN_DIMS=NB_FILTERS*2\r\n","L2_REG=0.1\r\n","\r\n","acclist=[] ; prelist=[]  ; reclist=[]  ; f1list=[]  ; losslist=[] ; modelname=[] ; wename=[] ; wesize = []\r\n","\r\n","for mod in MODELS_LIST:\r\n","  for we in EMP_PATH_LIST: \r\n","    we_type=we.split('_')[0]\r\n","    EMBEDDING_SIZE=int(we.split('_')[1])\r\n","    we_path=mainloc+'word_embeddings/w2v_'+we_type+'_'+str(EMBEDDING_SIZE)+'.txt'\r\n","    vocab_length,padded_sentences,length_long_sentence,embedding_matrix=loadembedding_matrix(x,we_path,EMBEDDING_SIZE)\r\n","    if (mod=='cnn'):\r\n","      acc,precision,recall,f1,loss=crossval(mod)\r\n","    elif (mod=='bi_lstm'):\r\n","      acc,precision,recall,f1,loss=crossval(mod)\r\n","    elif (mod=='rnn_gru' or  mod=='rnn_lstm'):\r\n","      if (mod.split('_')[1]=='gru'):\r\n","        RNN=GRU\r\n","      else:\r\n","        RNN=LSTM\r\n","      acc,precision,recall,f1,loss=crossval('rnn')\r\n","    else:\r\n","      if (mod.split('_')[1]=='gru'):\r\n","        RNN=GRU\r\n","      else:\r\n","        RNN=LSTM\r\n","      acc,precision,recall,f1,loss=crossval('cnn_rnn')\r\n","    \r\n","    modelname.append(mod)\r\n","    wename.append(we_type)\r\n","    wesize.append(EMBEDDING_SIZE)\r\n","    acclist.append(acc)\r\n","    prelist.append(precision)\r\n","    reclist.append(recall)\r\n","    f1list.append(f1)\r\n","    losslist.append(loss)        \r\n","\r\n","    accdf=pd.DataFrame({'Model':modelname,'Word_Embedding':wename, 'Embedding_Size':wesize,'Accuracy':acclist,'Precision':prelist,'Recall':reclist, 'F1':f1list})\r\n","    accdf.to_csv(mainloc+\"accdf_aspect.csv\",index=False)\r\n","\r\n","accdf=pd.DataFrame({'Model':modelname,'Word_Embedding':wename, 'Embedding_Size':wesize,'Accuracy':acclist,'Precision':prelist,'Recall':reclist, 'F1':f1list})\r\n","accdf"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Epoch 1/50\n","131/131 [==============================] - 2s 8ms/step - loss: 0.5258 - accuracy: 0.3450 - precision_m: 0.5811 - recall_m: 0.3291 - f1_m: 0.4030 - val_loss: 0.3295 - val_accuracy: 0.6088 - val_precision_m: 0.7912 - val_recall_m: 0.6951 - val_f1_m: 0.7378\n","Epoch 2/50\n","131/131 [==============================] - 1s 5ms/step - loss: 0.3559 - accuracy: 0.5590 - precision_m: 0.7769 - recall_m: 0.6275 - f1_m: 0.6924 - val_loss: 0.2876 - val_accuracy: 0.6403 - val_precision_m: 0.7956 - val_recall_m: 0.7465 - val_f1_m: 0.7685\n","Epoch 3/50\n","131/131 [==============================] - 1s 5ms/step - loss: 0.3214 - accuracy: 0.5909 - precision_m: 0.7897 - recall_m: 0.6703 - f1_m: 0.7237 - val_loss: 0.2682 - val_accuracy: 0.6536 - val_precision_m: 0.8264 - val_recall_m: 0.7316 - val_f1_m: 0.7744\n","Epoch 4/50\n","131/131 [==============================] - 1s 5ms/step - loss: 0.3012 - accuracy: 0.6083 - precision_m: 0.8129 - recall_m: 0.7128 - f1_m: 0.7581 - val_loss: 0.2587 - val_accuracy: 0.6660 - val_precision_m: 0.8472 - val_recall_m: 0.7093 - val_f1_m: 0.7703\n","Epoch 5/50\n","131/131 [==============================] - 1s 5ms/step - loss: 0.2841 - accuracy: 0.6421 - precision_m: 0.8248 - recall_m: 0.7241 - f1_m: 0.7701 - val_loss: 0.2496 - val_accuracy: 0.6508 - val_precision_m: 0.8372 - val_recall_m: 0.7386 - val_f1_m: 0.7830\n","Epoch 6/50\n","131/131 [==============================] - 1s 5ms/step - loss: 0.2707 - accuracy: 0.6287 - precision_m: 0.8338 - recall_m: 0.7341 - f1_m: 0.7796 - val_loss: 0.2429 - val_accuracy: 0.6594 - val_precision_m: 0.8290 - val_recall_m: 0.7784 - val_f1_m: 0.8016\n","Epoch 7/50\n","131/131 [==============================] - 1s 5ms/step - loss: 0.2567 - accuracy: 0.6532 - precision_m: 0.8425 - recall_m: 0.7529 - f1_m: 0.7940 - val_loss: 0.2422 - val_accuracy: 0.6641 - val_precision_m: 0.8275 - val_recall_m: 0.7802 - val_f1_m: 0.8021\n","Epoch 8/50\n","131/131 [==============================] - 1s 5ms/step - loss: 0.2488 - accuracy: 0.6541 - precision_m: 0.8488 - recall_m: 0.7691 - f1_m: 0.8055 - val_loss: 0.2393 - val_accuracy: 0.6660 - val_precision_m: 0.8387 - val_recall_m: 0.7760 - val_f1_m: 0.8046\n","Epoch 9/50\n","131/131 [==============================] - 1s 5ms/step - loss: 0.2537 - accuracy: 0.6545 - precision_m: 0.8510 - recall_m: 0.7616 - f1_m: 0.8023 - val_loss: 0.2390 - val_accuracy: 0.6613 - val_precision_m: 0.8236 - val_recall_m: 0.7841 - val_f1_m: 0.8025\n","Epoch 10/50\n","131/131 [==============================] - 1s 5ms/step - loss: 0.2414 - accuracy: 0.6492 - precision_m: 0.8539 - recall_m: 0.7757 - f1_m: 0.8116 - val_loss: 0.2462 - val_accuracy: 0.6689 - val_precision_m: 0.8234 - val_recall_m: 0.7806 - val_f1_m: 0.8001\n","Epoch 11/50\n","131/131 [==============================] - 1s 5ms/step - loss: 0.2356 - accuracy: 0.6597 - precision_m: 0.8548 - recall_m: 0.7860 - f1_m: 0.8173 - val_loss: 0.2397 - val_accuracy: 0.6469 - val_precision_m: 0.8291 - val_recall_m: 0.7847 - val_f1_m: 0.8052\n","Epoch 12/50\n","131/131 [==============================] - 1s 5ms/step - loss: 0.2375 - accuracy: 0.6521 - precision_m: 0.8548 - recall_m: 0.7817 - f1_m: 0.8158 - val_loss: 0.2444 - val_accuracy: 0.6947 - val_precision_m: 0.8386 - val_recall_m: 0.7687 - val_f1_m: 0.8012\n","Epoch 13/50\n","131/131 [==============================] - 1s 5ms/step - loss: 0.2289 - accuracy: 0.6624 - precision_m: 0.8688 - recall_m: 0.7809 - f1_m: 0.8211 - val_loss: 0.2368 - val_accuracy: 0.6660 - val_precision_m: 0.8374 - val_recall_m: 0.7791 - val_f1_m: 0.8057\n","Epoch 14/50\n","131/131 [==============================] - 1s 5ms/step - loss: 0.2301 - accuracy: 0.6642 - precision_m: 0.8614 - recall_m: 0.7886 - f1_m: 0.8224 - val_loss: 0.2404 - val_accuracy: 0.6794 - val_precision_m: 0.8274 - val_recall_m: 0.7863 - val_f1_m: 0.8055\n","Epoch 15/50\n","131/131 [==============================] - 1s 5ms/step - loss: 0.2228 - accuracy: 0.6704 - precision_m: 0.8626 - recall_m: 0.7933 - f1_m: 0.8255 - val_loss: 0.2426 - val_accuracy: 0.6842 - val_precision_m: 0.8262 - val_recall_m: 0.7869 - val_f1_m: 0.8051\n","Epoch 16/50\n","131/131 [==============================] - 1s 5ms/step - loss: 0.2216 - accuracy: 0.6580 - precision_m: 0.8624 - recall_m: 0.8025 - f1_m: 0.8304 - val_loss: 0.2344 - val_accuracy: 0.6756 - val_precision_m: 0.8363 - val_recall_m: 0.7739 - val_f1_m: 0.8029\n","Epoch 17/50\n","131/131 [==============================] - 1s 5ms/step - loss: 0.2137 - accuracy: 0.6704 - precision_m: 0.8772 - recall_m: 0.8100 - f1_m: 0.8414 - val_loss: 0.2340 - val_accuracy: 0.6803 - val_precision_m: 0.8210 - val_recall_m: 0.7925 - val_f1_m: 0.8057\n","Epoch 18/50\n","131/131 [==============================] - 1s 5ms/step - loss: 0.2132 - accuracy: 0.6843 - precision_m: 0.8651 - recall_m: 0.8110 - f1_m: 0.8360 - val_loss: 0.2457 - val_accuracy: 0.6698 - val_precision_m: 0.8219 - val_recall_m: 0.7890 - val_f1_m: 0.8042\n","Epoch 19/50\n","131/131 [==============================] - 1s 5ms/step - loss: 0.2041 - accuracy: 0.6782 - precision_m: 0.8841 - recall_m: 0.8128 - f1_m: 0.8457 - val_loss: 0.2380 - val_accuracy: 0.6765 - val_precision_m: 0.8331 - val_recall_m: 0.7922 - val_f1_m: 0.8110\n","Epoch 20/50\n","131/131 [==============================] - 1s 5ms/step - loss: 0.1989 - accuracy: 0.6841 - precision_m: 0.8848 - recall_m: 0.8219 - f1_m: 0.8508 - val_loss: 0.2334 - val_accuracy: 0.6660 - val_precision_m: 0.8308 - val_recall_m: 0.7888 - val_f1_m: 0.8082\n","Epoch 21/50\n","131/131 [==============================] - 1s 5ms/step - loss: 0.1931 - accuracy: 0.6770 - precision_m: 0.8911 - recall_m: 0.8300 - f1_m: 0.8585 - val_loss: 0.2378 - val_accuracy: 0.6660 - val_precision_m: 0.8324 - val_recall_m: 0.7843 - val_f1_m: 0.8064\n","Epoch 22/50\n","131/131 [==============================] - 1s 5ms/step - loss: 0.1938 - accuracy: 0.6915 - precision_m: 0.8893 - recall_m: 0.8213 - f1_m: 0.8528 - val_loss: 0.2419 - val_accuracy: 0.6546 - val_precision_m: 0.8240 - val_recall_m: 0.7903 - val_f1_m: 0.8058\n","Epoch 23/50\n","131/131 [==============================] - 1s 5ms/step - loss: 0.1810 - accuracy: 0.6929 - precision_m: 0.8985 - recall_m: 0.8350 - f1_m: 0.8646 - val_loss: 0.2337 - val_accuracy: 0.6660 - val_precision_m: 0.8412 - val_recall_m: 0.7713 - val_f1_m: 0.8037\n","Epoch 24/50\n","131/131 [==============================] - 1s 5ms/step - loss: 0.1852 - accuracy: 0.6957 - precision_m: 0.8877 - recall_m: 0.8347 - f1_m: 0.8592 - val_loss: 0.2369 - val_accuracy: 0.6727 - val_precision_m: 0.8222 - val_recall_m: 0.7978 - val_f1_m: 0.8089\n","Epoch 25/50\n","131/131 [==============================] - 1s 5ms/step - loss: 0.1807 - accuracy: 0.7011 - precision_m: 0.8926 - recall_m: 0.8408 - f1_m: 0.8647 - val_loss: 0.2381 - val_accuracy: 0.6603 - val_precision_m: 0.8228 - val_recall_m: 0.7893 - val_f1_m: 0.8046\n","Epoch 26/50\n","131/131 [==============================] - 1s 5ms/step - loss: 0.1767 - accuracy: 0.6728 - precision_m: 0.9017 - recall_m: 0.8437 - f1_m: 0.8707 - val_loss: 0.2427 - val_accuracy: 0.6889 - val_precision_m: 0.8429 - val_recall_m: 0.7632 - val_f1_m: 0.8001\n","Epoch 27/50\n","131/131 [==============================] - 1s 5ms/step - loss: 0.1740 - accuracy: 0.6996 - precision_m: 0.9053 - recall_m: 0.8442 - f1_m: 0.8725 - val_loss: 0.2409 - val_accuracy: 0.6555 - val_precision_m: 0.8294 - val_recall_m: 0.7925 - val_f1_m: 0.8093\n","Epoch 28/50\n","131/131 [==============================] - 1s 5ms/step - loss: 0.1760 - accuracy: 0.6676 - precision_m: 0.8986 - recall_m: 0.8498 - f1_m: 0.8724 - val_loss: 0.2430 - val_accuracy: 0.6718 - val_precision_m: 0.8274 - val_recall_m: 0.7836 - val_f1_m: 0.8037\n","Epoch 29/50\n","131/131 [==============================] - 1s 5ms/step - loss: 0.1672 - accuracy: 0.6928 - precision_m: 0.9055 - recall_m: 0.8482 - f1_m: 0.8750 - val_loss: 0.2396 - val_accuracy: 0.6756 - val_precision_m: 0.8346 - val_recall_m: 0.7925 - val_f1_m: 0.8118\n","Epoch 30/50\n","131/131 [==============================] - 1s 5ms/step - loss: 0.1629 - accuracy: 0.6996 - precision_m: 0.9068 - recall_m: 0.8657 - f1_m: 0.8849 - val_loss: 0.2375 - val_accuracy: 0.6651 - val_precision_m: 0.8370 - val_recall_m: 0.7900 - val_f1_m: 0.8116\n","Epoch 31/50\n","131/131 [==============================] - 1s 5ms/step - loss: 0.1607 - accuracy: 0.6922 - precision_m: 0.9077 - recall_m: 0.8626 - f1_m: 0.8835 - val_loss: 0.2439 - val_accuracy: 0.6918 - val_precision_m: 0.8216 - val_recall_m: 0.7879 - val_f1_m: 0.8036\n","Epoch 32/50\n","131/131 [==============================] - 1s 5ms/step - loss: 0.1684 - accuracy: 0.7069 - precision_m: 0.9052 - recall_m: 0.8456 - f1_m: 0.8735 - val_loss: 0.2398 - val_accuracy: 0.6737 - val_precision_m: 0.8360 - val_recall_m: 0.7895 - val_f1_m: 0.8109\n","Epoch 33/50\n","131/131 [==============================] - 1s 5ms/step - loss: 0.1515 - accuracy: 0.6909 - precision_m: 0.9143 - recall_m: 0.8682 - f1_m: 0.8898 - val_loss: 0.2427 - val_accuracy: 0.6746 - val_precision_m: 0.8409 - val_recall_m: 0.7680 - val_f1_m: 0.8017\n","Epoch 34/50\n","131/131 [==============================] - 1s 5ms/step - loss: 0.1564 - accuracy: 0.6967 - precision_m: 0.9075 - recall_m: 0.8583 - f1_m: 0.8807 - val_loss: 0.2550 - val_accuracy: 0.6565 - val_precision_m: 0.8053 - val_recall_m: 0.8187 - val_f1_m: 0.8111\n","Epoch 35/50\n","131/131 [==============================] - 1s 5ms/step - loss: 0.1515 - accuracy: 0.6962 - precision_m: 0.9100 - recall_m: 0.8746 - f1_m: 0.8910 - val_loss: 0.2477 - val_accuracy: 0.6899 - val_precision_m: 0.8403 - val_recall_m: 0.7746 - val_f1_m: 0.8050\n","Epoch 36/50\n","131/131 [==============================] - 1s 5ms/step - loss: 0.1455 - accuracy: 0.7053 - precision_m: 0.9163 - recall_m: 0.8722 - f1_m: 0.8928 - val_loss: 0.2465 - val_accuracy: 0.6632 - val_precision_m: 0.8250 - val_recall_m: 0.8041 - val_f1_m: 0.8134\n","Epoch 37/50\n","131/131 [==============================] - 1s 5ms/step - loss: 0.1482 - accuracy: 0.7031 - precision_m: 0.9105 - recall_m: 0.8733 - f1_m: 0.8908 - val_loss: 0.2450 - val_accuracy: 0.6756 - val_precision_m: 0.8428 - val_recall_m: 0.7816 - val_f1_m: 0.8099\n","Epoch 38/50\n","131/131 [==============================] - 1s 5ms/step - loss: 0.1471 - accuracy: 0.7120 - precision_m: 0.9153 - recall_m: 0.8709 - f1_m: 0.8917 - val_loss: 0.2463 - val_accuracy: 0.6775 - val_precision_m: 0.8295 - val_recall_m: 0.7913 - val_f1_m: 0.8087\n","Epoch 39/50\n","131/131 [==============================] - 1s 5ms/step - loss: 0.1370 - accuracy: 0.7066 - precision_m: 0.9174 - recall_m: 0.8860 - f1_m: 0.9008 - val_loss: 0.2449 - val_accuracy: 0.6756 - val_precision_m: 0.8493 - val_recall_m: 0.7629 - val_f1_m: 0.8028\n","Epoch 40/50\n","131/131 [==============================] - 1s 6ms/step - loss: 0.1392 - accuracy: 0.7195 - precision_m: 0.9236 - recall_m: 0.8779 - f1_m: 0.8994 - val_loss: 0.2468 - val_accuracy: 0.6727 - val_precision_m: 0.8363 - val_recall_m: 0.7736 - val_f1_m: 0.8025\n","Epoch 41/50\n","131/131 [==============================] - 1s 5ms/step - loss: 0.1418 - accuracy: 0.7035 - precision_m: 0.9208 - recall_m: 0.8744 - f1_m: 0.8963 - val_loss: 0.2464 - val_accuracy: 0.6803 - val_precision_m: 0.8349 - val_recall_m: 0.7886 - val_f1_m: 0.8100\n","Epoch 42/50\n","131/131 [==============================] - 1s 5ms/step - loss: 0.1383 - accuracy: 0.7166 - precision_m: 0.9265 - recall_m: 0.8842 - f1_m: 0.9042 - val_loss: 0.2504 - val_accuracy: 0.6966 - val_precision_m: 0.8292 - val_recall_m: 0.7895 - val_f1_m: 0.8079\n","Epoch 43/50\n","131/131 [==============================] - 1s 5ms/step - loss: 0.1364 - accuracy: 0.7136 - precision_m: 0.9177 - recall_m: 0.8850 - f1_m: 0.9003 - val_loss: 0.2517 - val_accuracy: 0.6708 - val_precision_m: 0.8276 - val_recall_m: 0.7920 - val_f1_m: 0.8084\n","Epoch 44/50\n","131/131 [==============================] - 1s 6ms/step - loss: 0.1314 - accuracy: 0.7150 - precision_m: 0.9241 - recall_m: 0.8845 - f1_m: 0.9033 - val_loss: 0.2526 - val_accuracy: 0.6613 - val_precision_m: 0.8302 - val_recall_m: 0.7981 - val_f1_m: 0.8129\n","Epoch 45/50\n","131/131 [==============================] - 1s 5ms/step - loss: 0.1238 - accuracy: 0.7199 - precision_m: 0.9307 - recall_m: 0.9018 - f1_m: 0.9154 - val_loss: 0.2461 - val_accuracy: 0.6689 - val_precision_m: 0.8358 - val_recall_m: 0.7941 - val_f1_m: 0.8133\n","Epoch 46/50\n","131/131 [==============================] - 1s 5ms/step - loss: 0.1310 - accuracy: 0.7154 - precision_m: 0.9269 - recall_m: 0.8838 - f1_m: 0.9040 - val_loss: 0.2538 - val_accuracy: 0.6756 - val_precision_m: 0.8413 - val_recall_m: 0.7765 - val_f1_m: 0.8064\n","Epoch 00046: early stopping\n","Score for fold 1: loss of 0.45449697971343994; accuracy of 54.21594977378845% ;precision_m of 0.8613422513008118 ;recall_m of 0.6733155846595764 ;            f1_m of 0.7526277899742126\n","Epoch 1/50\n","131/131 [==============================] - 1s 7ms/step - loss: 0.5817 - accuracy: 0.3170 - precision_m: 0.5764 - recall_m: 0.3313 - f1_m: 0.4058 - val_loss: 0.3391 - val_accuracy: 0.6501 - val_precision_m: 0.8039 - val_recall_m: 0.6959 - val_f1_m: 0.7440\n","Epoch 2/50\n","131/131 [==============================] - 1s 5ms/step - loss: 0.3894 - accuracy: 0.5514 - precision_m: 0.7751 - recall_m: 0.6503 - f1_m: 0.7053 - val_loss: 0.2899 - val_accuracy: 0.6635 - val_precision_m: 0.8007 - val_recall_m: 0.7583 - val_f1_m: 0.7771\n","Epoch 3/50\n","131/131 [==============================] - 1s 5ms/step - loss: 0.3353 - accuracy: 0.5840 - precision_m: 0.8048 - recall_m: 0.7104 - f1_m: 0.7535 - val_loss: 0.2680 - val_accuracy: 0.6644 - val_precision_m: 0.8052 - val_recall_m: 0.7649 - val_f1_m: 0.7831\n","Epoch 4/50\n","131/131 [==============================] - 1s 5ms/step - loss: 0.3077 - accuracy: 0.5826 - precision_m: 0.8221 - recall_m: 0.7519 - f1_m: 0.7842 - val_loss: 0.2658 - val_accuracy: 0.6864 - val_precision_m: 0.8250 - val_recall_m: 0.7522 - val_f1_m: 0.7852\n","Epoch 5/50\n","131/131 [==============================] - 1s 5ms/step - loss: 0.3071 - accuracy: 0.5946 - precision_m: 0.8160 - recall_m: 0.7394 - f1_m: 0.7746 - val_loss: 0.2506 - val_accuracy: 0.6759 - val_precision_m: 0.8471 - val_recall_m: 0.7425 - val_f1_m: 0.7897\n","Epoch 6/50\n","131/131 [==============================] - 1s 6ms/step - loss: 0.2918 - accuracy: 0.5854 - precision_m: 0.8325 - recall_m: 0.7587 - f1_m: 0.7925 - val_loss: 0.2529 - val_accuracy: 0.6892 - val_precision_m: 0.8356 - val_recall_m: 0.7635 - val_f1_m: 0.7967\n","Epoch 7/50\n","131/131 [==============================] - 1s 5ms/step - loss: 0.2841 - accuracy: 0.6116 - precision_m: 0.8362 - recall_m: 0.7683 - f1_m: 0.7996 - val_loss: 0.2442 - val_accuracy: 0.6826 - val_precision_m: 0.8513 - val_recall_m: 0.7555 - val_f1_m: 0.7988\n","Epoch 8/50\n","131/131 [==============================] - 1s 5ms/step - loss: 0.2775 - accuracy: 0.6145 - precision_m: 0.8428 - recall_m: 0.7665 - f1_m: 0.8019 - val_loss: 0.2442 - val_accuracy: 0.6654 - val_precision_m: 0.8498 - val_recall_m: 0.7643 - val_f1_m: 0.8035\n","Epoch 9/50\n","131/131 [==============================] - 1s 5ms/step - loss: 0.2701 - accuracy: 0.6157 - precision_m: 0.8567 - recall_m: 0.7772 - f1_m: 0.8138 - val_loss: 0.2444 - val_accuracy: 0.6778 - val_precision_m: 0.8346 - val_recall_m: 0.7795 - val_f1_m: 0.8050\n","Epoch 10/50\n","131/131 [==============================] - 1s 5ms/step - loss: 0.2594 - accuracy: 0.6199 - precision_m: 0.8577 - recall_m: 0.7959 - f1_m: 0.8247 - val_loss: 0.2433 - val_accuracy: 0.7073 - val_precision_m: 0.8517 - val_recall_m: 0.7438 - val_f1_m: 0.7921\n","Epoch 11/50\n","131/131 [==============================] - 1s 5ms/step - loss: 0.2531 - accuracy: 0.6318 - precision_m: 0.8684 - recall_m: 0.7944 - f1_m: 0.8288 - val_loss: 0.2416 - val_accuracy: 0.6949 - val_precision_m: 0.8385 - val_recall_m: 0.7847 - val_f1_m: 0.8095\n","Epoch 12/50\n","131/131 [==============================] - 1s 5ms/step - loss: 0.2494 - accuracy: 0.6240 - precision_m: 0.8639 - recall_m: 0.8014 - f1_m: 0.8305 - val_loss: 0.2394 - val_accuracy: 0.6864 - val_precision_m: 0.8279 - val_recall_m: 0.7926 - val_f1_m: 0.8086\n","Epoch 13/50\n","131/131 [==============================] - 1s 5ms/step - loss: 0.2394 - accuracy: 0.6198 - precision_m: 0.8723 - recall_m: 0.8081 - f1_m: 0.8380 - val_loss: 0.2373 - val_accuracy: 0.6921 - val_precision_m: 0.8348 - val_recall_m: 0.7864 - val_f1_m: 0.8085\n","Epoch 14/50\n","131/131 [==============================] - 1s 5ms/step - loss: 0.2384 - accuracy: 0.6252 - precision_m: 0.8694 - recall_m: 0.8149 - f1_m: 0.8401 - val_loss: 0.2338 - val_accuracy: 0.6949 - val_precision_m: 0.8485 - val_recall_m: 0.7768 - val_f1_m: 0.8099\n","Epoch 15/50\n","131/131 [==============================] - 1s 5ms/step - loss: 0.2354 - accuracy: 0.6293 - precision_m: 0.8721 - recall_m: 0.8178 - f1_m: 0.8431 - val_loss: 0.2491 - val_accuracy: 0.7102 - val_precision_m: 0.8474 - val_recall_m: 0.7725 - val_f1_m: 0.8066\n","Epoch 16/50\n","131/131 [==============================] - 1s 5ms/step - loss: 0.2367 - accuracy: 0.6262 - precision_m: 0.8688 - recall_m: 0.8149 - f1_m: 0.8399 - val_loss: 0.2387 - val_accuracy: 0.6949 - val_precision_m: 0.8465 - val_recall_m: 0.7603 - val_f1_m: 0.7997\n","Epoch 17/50\n","131/131 [==============================] - 1s 5ms/step - loss: 0.2248 - accuracy: 0.6461 - precision_m: 0.8757 - recall_m: 0.8178 - f1_m: 0.8449 - val_loss: 0.2434 - val_accuracy: 0.7035 - val_precision_m: 0.8560 - val_recall_m: 0.7643 - val_f1_m: 0.8061\n","Epoch 18/50\n","131/131 [==============================] - 1s 5ms/step - loss: 0.2257 - accuracy: 0.6441 - precision_m: 0.8841 - recall_m: 0.8166 - f1_m: 0.8481 - val_loss: 0.2323 - val_accuracy: 0.6988 - val_precision_m: 0.8451 - val_recall_m: 0.7624 - val_f1_m: 0.8005\n","Epoch 19/50\n","131/131 [==============================] - 1s 5ms/step - loss: 0.2178 - accuracy: 0.6258 - precision_m: 0.8827 - recall_m: 0.8268 - f1_m: 0.8528 - val_loss: 0.2364 - val_accuracy: 0.7026 - val_precision_m: 0.8339 - val_recall_m: 0.7875 - val_f1_m: 0.8089\n","Epoch 20/50\n","131/131 [==============================] - 1s 5ms/step - loss: 0.2142 - accuracy: 0.6397 - precision_m: 0.8906 - recall_m: 0.8426 - f1_m: 0.8649 - val_loss: 0.2362 - val_accuracy: 0.7007 - val_precision_m: 0.8513 - val_recall_m: 0.7493 - val_f1_m: 0.7957\n","Epoch 21/50\n","131/131 [==============================] - 1s 5ms/step - loss: 0.2148 - accuracy: 0.6481 - precision_m: 0.8869 - recall_m: 0.8299 - f1_m: 0.8564 - val_loss: 0.2387 - val_accuracy: 0.7064 - val_precision_m: 0.8327 - val_recall_m: 0.7897 - val_f1_m: 0.8093\n","Epoch 22/50\n","131/131 [==============================] - 1s 5ms/step - loss: 0.2087 - accuracy: 0.6547 - precision_m: 0.8873 - recall_m: 0.8323 - f1_m: 0.8579 - val_loss: 0.2336 - val_accuracy: 0.6988 - val_precision_m: 0.8415 - val_recall_m: 0.7864 - val_f1_m: 0.8117\n","Epoch 23/50\n","131/131 [==============================] - 1s 5ms/step - loss: 0.2044 - accuracy: 0.6362 - precision_m: 0.8933 - recall_m: 0.8367 - f1_m: 0.8630 - val_loss: 0.2375 - val_accuracy: 0.6949 - val_precision_m: 0.8343 - val_recall_m: 0.7934 - val_f1_m: 0.8121\n","Epoch 24/50\n","131/131 [==============================] - 1s 5ms/step - loss: 0.2037 - accuracy: 0.6622 - precision_m: 0.8908 - recall_m: 0.8436 - f1_m: 0.8655 - val_loss: 0.2346 - val_accuracy: 0.6940 - val_precision_m: 0.8522 - val_recall_m: 0.7543 - val_f1_m: 0.7990\n","Epoch 25/50\n","131/131 [==============================] - 1s 5ms/step - loss: 0.1992 - accuracy: 0.6368 - precision_m: 0.8961 - recall_m: 0.8475 - f1_m: 0.8701 - val_loss: 0.2356 - val_accuracy: 0.7007 - val_precision_m: 0.8446 - val_recall_m: 0.7771 - val_f1_m: 0.8083\n","Epoch 26/50\n","131/131 [==============================] - 1s 5ms/step - loss: 0.1920 - accuracy: 0.6652 - precision_m: 0.8984 - recall_m: 0.8505 - f1_m: 0.8731 - val_loss: 0.2357 - val_accuracy: 0.7035 - val_precision_m: 0.8459 - val_recall_m: 0.7669 - val_f1_m: 0.8031\n","Epoch 27/50\n","131/131 [==============================] - 1s 5ms/step - loss: 0.1851 - accuracy: 0.6524 - precision_m: 0.9014 - recall_m: 0.8588 - f1_m: 0.8786 - val_loss: 0.2407 - val_accuracy: 0.7064 - val_precision_m: 0.8428 - val_recall_m: 0.7826 - val_f1_m: 0.8101\n","Epoch 28/50\n","131/131 [==============================] - 1s 5ms/step - loss: 0.1906 - accuracy: 0.6560 - precision_m: 0.9012 - recall_m: 0.8540 - f1_m: 0.8763 - val_loss: 0.2396 - val_accuracy: 0.6873 - val_precision_m: 0.8313 - val_recall_m: 0.7787 - val_f1_m: 0.8026\n","Epoch 29/50\n","131/131 [==============================] - 1s 5ms/step - loss: 0.1895 - accuracy: 0.6640 - precision_m: 0.9011 - recall_m: 0.8537 - f1_m: 0.8758 - val_loss: 0.2408 - val_accuracy: 0.6864 - val_precision_m: 0.8347 - val_recall_m: 0.7829 - val_f1_m: 0.8063\n","Epoch 30/50\n","131/131 [==============================] - 1s 5ms/step - loss: 0.1885 - accuracy: 0.6499 - precision_m: 0.9033 - recall_m: 0.8634 - f1_m: 0.8820 - val_loss: 0.2430 - val_accuracy: 0.7121 - val_precision_m: 0.8262 - val_recall_m: 0.7975 - val_f1_m: 0.8099\n","Epoch 31/50\n","131/131 [==============================] - 1s 5ms/step - loss: 0.1825 - accuracy: 0.6752 - precision_m: 0.9041 - recall_m: 0.8568 - f1_m: 0.8788 - val_loss: 0.2416 - val_accuracy: 0.7073 - val_precision_m: 0.8376 - val_recall_m: 0.7899 - val_f1_m: 0.8118\n","Epoch 32/50\n","131/131 [==============================] - 1s 5ms/step - loss: 0.1779 - accuracy: 0.6483 - precision_m: 0.9099 - recall_m: 0.8673 - f1_m: 0.8874 - val_loss: 0.2424 - val_accuracy: 0.7035 - val_precision_m: 0.8293 - val_recall_m: 0.7972 - val_f1_m: 0.8120\n","Epoch 33/50\n","131/131 [==============================] - 1s 5ms/step - loss: 0.1838 - accuracy: 0.6770 - precision_m: 0.9010 - recall_m: 0.8608 - f1_m: 0.8798 - val_loss: 0.2390 - val_accuracy: 0.7159 - val_precision_m: 0.8361 - val_recall_m: 0.7965 - val_f1_m: 0.8147\n","Epoch 34/50\n","131/131 [==============================] - 1s 5ms/step - loss: 0.1743 - accuracy: 0.6646 - precision_m: 0.9101 - recall_m: 0.8749 - f1_m: 0.8912 - val_loss: 0.2411 - val_accuracy: 0.7035 - val_precision_m: 0.8380 - val_recall_m: 0.7856 - val_f1_m: 0.8097\n","Epoch 35/50\n","131/131 [==============================] - 1s 5ms/step - loss: 0.1708 - accuracy: 0.6636 - precision_m: 0.9140 - recall_m: 0.8679 - f1_m: 0.8895 - val_loss: 0.2403 - val_accuracy: 0.7112 - val_precision_m: 0.8421 - val_recall_m: 0.7866 - val_f1_m: 0.8120\n","Epoch 36/50\n","131/131 [==============================] - 1s 5ms/step - loss: 0.1675 - accuracy: 0.6649 - precision_m: 0.9219 - recall_m: 0.8761 - f1_m: 0.8976 - val_loss: 0.2377 - val_accuracy: 0.7064 - val_precision_m: 0.8490 - val_recall_m: 0.7677 - val_f1_m: 0.8050\n","Epoch 37/50\n","131/131 [==============================] - 1s 5ms/step - loss: 0.1673 - accuracy: 0.6812 - precision_m: 0.9143 - recall_m: 0.8772 - f1_m: 0.8946 - val_loss: 0.2400 - val_accuracy: 0.7207 - val_precision_m: 0.8389 - val_recall_m: 0.7910 - val_f1_m: 0.8131\n","Epoch 38/50\n","131/131 [==============================] - 1s 5ms/step - loss: 0.1656 - accuracy: 0.6789 - precision_m: 0.9166 - recall_m: 0.8756 - f1_m: 0.8947 - val_loss: 0.2428 - val_accuracy: 0.7064 - val_precision_m: 0.8335 - val_recall_m: 0.7920 - val_f1_m: 0.8107\n","Epoch 39/50\n","131/131 [==============================] - 1s 5ms/step - loss: 0.1521 - accuracy: 0.6689 - precision_m: 0.9251 - recall_m: 0.8818 - f1_m: 0.9024 - val_loss: 0.2456 - val_accuracy: 0.7216 - val_precision_m: 0.8271 - val_recall_m: 0.7967 - val_f1_m: 0.8104\n","Epoch 40/50\n","131/131 [==============================] - 1s 5ms/step - loss: 0.1594 - accuracy: 0.6669 - precision_m: 0.9145 - recall_m: 0.8827 - f1_m: 0.8976 - val_loss: 0.2418 - val_accuracy: 0.7073 - val_precision_m: 0.8410 - val_recall_m: 0.7916 - val_f1_m: 0.8146\n","Epoch 41/50\n","131/131 [==============================] - 1s 5ms/step - loss: 0.1553 - accuracy: 0.6770 - precision_m: 0.9201 - recall_m: 0.8883 - f1_m: 0.9033 - val_loss: 0.2447 - val_accuracy: 0.7102 - val_precision_m: 0.8252 - val_recall_m: 0.7955 - val_f1_m: 0.8086\n","Epoch 42/50\n","131/131 [==============================] - 1s 5ms/step - loss: 0.1525 - accuracy: 0.6727 - precision_m: 0.9221 - recall_m: 0.8857 - f1_m: 0.9027 - val_loss: 0.2461 - val_accuracy: 0.7140 - val_precision_m: 0.8200 - val_recall_m: 0.8138 - val_f1_m: 0.8157\n","Epoch 43/50\n","131/131 [==============================] - 1s 5ms/step - loss: 0.1486 - accuracy: 0.6641 - precision_m: 0.9252 - recall_m: 0.8897 - f1_m: 0.9062 - val_loss: 0.2406 - val_accuracy: 0.7178 - val_precision_m: 0.8464 - val_recall_m: 0.7791 - val_f1_m: 0.8100\n","Epoch 44/50\n","131/131 [==============================] - 1s 5ms/step - loss: 0.1516 - accuracy: 0.6702 - precision_m: 0.9232 - recall_m: 0.8880 - f1_m: 0.9046 - val_loss: 0.2460 - val_accuracy: 0.6969 - val_precision_m: 0.8405 - val_recall_m: 0.7865 - val_f1_m: 0.8111\n","Epoch 45/50\n","131/131 [==============================] - 1s 5ms/step - loss: 0.1441 - accuracy: 0.6548 - precision_m: 0.9269 - recall_m: 0.8950 - f1_m: 0.9099 - val_loss: 0.2464 - val_accuracy: 0.7045 - val_precision_m: 0.8498 - val_recall_m: 0.7815 - val_f1_m: 0.8129\n","Epoch 46/50\n","131/131 [==============================] - 1s 5ms/step - loss: 0.1413 - accuracy: 0.6766 - precision_m: 0.9309 - recall_m: 0.8950 - f1_m: 0.9120 - val_loss: 0.2494 - val_accuracy: 0.6959 - val_precision_m: 0.8304 - val_recall_m: 0.7851 - val_f1_m: 0.8055\n","Epoch 47/50\n","131/131 [==============================] - 1s 5ms/step - loss: 0.1461 - accuracy: 0.6578 - precision_m: 0.9234 - recall_m: 0.8979 - f1_m: 0.9100 - val_loss: 0.2486 - val_accuracy: 0.6978 - val_precision_m: 0.8380 - val_recall_m: 0.7778 - val_f1_m: 0.8058\n","Epoch 48/50\n","131/131 [==============================] - 1s 5ms/step - loss: 0.1505 - accuracy: 0.6594 - precision_m: 0.9241 - recall_m: 0.8919 - f1_m: 0.9066 - val_loss: 0.2501 - val_accuracy: 0.7207 - val_precision_m: 0.8246 - val_recall_m: 0.8007 - val_f1_m: 0.8108\n","Epoch 49/50\n","131/131 [==============================] - 1s 5ms/step - loss: 0.1412 - accuracy: 0.6603 - precision_m: 0.9247 - recall_m: 0.8950 - f1_m: 0.9091 - val_loss: 0.2477 - val_accuracy: 0.7064 - val_precision_m: 0.8386 - val_recall_m: 0.7967 - val_f1_m: 0.8159\n","Epoch 50/50\n","131/131 [==============================] - 1s 5ms/step - loss: 0.1467 - accuracy: 0.6578 - precision_m: 0.9277 - recall_m: 0.8872 - f1_m: 0.9063 - val_loss: 0.2531 - val_accuracy: 0.7016 - val_precision_m: 0.8309 - val_recall_m: 0.7895 - val_f1_m: 0.8085\n","Score for fold 2: loss of 0.3243308365345001; accuracy of 66.52671694755554% ;precision_m of 0.8155048489570618 ;recall_m of 0.7785707712173462 ;            f1_m of 0.7947401404380798\n","Epoch 1/50\n","131/131 [==============================] - 1s 7ms/step - loss: 0.5976 - accuracy: 0.3084 - precision_m: 0.5491 - recall_m: 0.3161 - f1_m: 0.3895 - val_loss: 0.3736 - val_accuracy: 0.6101 - val_precision_m: 0.7484 - val_recall_m: 0.6953 - val_f1_m: 0.7193\n","Epoch 2/50\n","131/131 [==============================] - 1s 6ms/step - loss: 0.4072 - accuracy: 0.5518 - precision_m: 0.7661 - recall_m: 0.6308 - f1_m: 0.6894 - val_loss: 0.3282 - val_accuracy: 0.6454 - val_precision_m: 0.7721 - val_recall_m: 0.7108 - val_f1_m: 0.7384\n","Epoch 3/50\n","131/131 [==============================] - 1s 5ms/step - loss: 0.3548 - accuracy: 0.5805 - precision_m: 0.7991 - recall_m: 0.6979 - f1_m: 0.7437 - val_loss: 0.3034 - val_accuracy: 0.6597 - val_precision_m: 0.7903 - val_recall_m: 0.7592 - val_f1_m: 0.7726\n","Epoch 4/50\n","131/131 [==============================] - 1s 5ms/step - loss: 0.3191 - accuracy: 0.5691 - precision_m: 0.8231 - recall_m: 0.7519 - f1_m: 0.7842 - val_loss: 0.3073 - val_accuracy: 0.6597 - val_precision_m: 0.7905 - val_recall_m: 0.7487 - val_f1_m: 0.7673\n","Epoch 5/50\n","131/131 [==============================] - 1s 5ms/step - loss: 0.3096 - accuracy: 0.5858 - precision_m: 0.8298 - recall_m: 0.7446 - f1_m: 0.7840 - val_loss: 0.2958 - val_accuracy: 0.6654 - val_precision_m: 0.7861 - val_recall_m: 0.7689 - val_f1_m: 0.7758\n","Epoch 6/50\n","131/131 [==============================] - 1s 5ms/step - loss: 0.2993 - accuracy: 0.5919 - precision_m: 0.8362 - recall_m: 0.7649 - f1_m: 0.7967 - val_loss: 0.2987 - val_accuracy: 0.6940 - val_precision_m: 0.8083 - val_recall_m: 0.7427 - val_f1_m: 0.7727\n","Epoch 7/50\n","131/131 [==============================] - 1s 5ms/step - loss: 0.2917 - accuracy: 0.5922 - precision_m: 0.8442 - recall_m: 0.7769 - f1_m: 0.8084 - val_loss: 0.2887 - val_accuracy: 0.6721 - val_precision_m: 0.8169 - val_recall_m: 0.7271 - val_f1_m: 0.7679\n","Epoch 8/50\n","131/131 [==============================] - 1s 5ms/step - loss: 0.2844 - accuracy: 0.5939 - precision_m: 0.8511 - recall_m: 0.7741 - f1_m: 0.8096 - val_loss: 0.2944 - val_accuracy: 0.6940 - val_precision_m: 0.8197 - val_recall_m: 0.7448 - val_f1_m: 0.7787\n","Epoch 9/50\n","131/131 [==============================] - 1s 5ms/step - loss: 0.2743 - accuracy: 0.6126 - precision_m: 0.8585 - recall_m: 0.7868 - f1_m: 0.8196 - val_loss: 0.2807 - val_accuracy: 0.6797 - val_precision_m: 0.8259 - val_recall_m: 0.7452 - val_f1_m: 0.7817\n","Epoch 10/50\n","131/131 [==============================] - 1s 5ms/step - loss: 0.2654 - accuracy: 0.5941 - precision_m: 0.8573 - recall_m: 0.7916 - f1_m: 0.8219 - val_loss: 0.2807 - val_accuracy: 0.6759 - val_precision_m: 0.8227 - val_recall_m: 0.7587 - val_f1_m: 0.7876\n","Epoch 11/50\n","131/131 [==============================] - 1s 5ms/step - loss: 0.2639 - accuracy: 0.6005 - precision_m: 0.8618 - recall_m: 0.7976 - f1_m: 0.8273 - val_loss: 0.2797 - val_accuracy: 0.6826 - val_precision_m: 0.8244 - val_recall_m: 0.7644 - val_f1_m: 0.7916\n","Epoch 12/50\n","131/131 [==============================] - 1s 5ms/step - loss: 0.2590 - accuracy: 0.6173 - precision_m: 0.8610 - recall_m: 0.8057 - f1_m: 0.8311 - val_loss: 0.2899 - val_accuracy: 0.6835 - val_precision_m: 0.8088 - val_recall_m: 0.7443 - val_f1_m: 0.7735\n","Epoch 13/50\n","131/131 [==============================] - 1s 6ms/step - loss: 0.2534 - accuracy: 0.6209 - precision_m: 0.8743 - recall_m: 0.8096 - f1_m: 0.8396 - val_loss: 0.2842 - val_accuracy: 0.6911 - val_precision_m: 0.8190 - val_recall_m: 0.7580 - val_f1_m: 0.7856\n","Epoch 14/50\n","131/131 [==============================] - 1s 5ms/step - loss: 0.2496 - accuracy: 0.6143 - precision_m: 0.8618 - recall_m: 0.8050 - f1_m: 0.8314 - val_loss: 0.2826 - val_accuracy: 0.6921 - val_precision_m: 0.8227 - val_recall_m: 0.7552 - val_f1_m: 0.7858\n","Epoch 15/50\n","131/131 [==============================] - 1s 5ms/step - loss: 0.2407 - accuracy: 0.6161 - precision_m: 0.8746 - recall_m: 0.8076 - f1_m: 0.8381 - val_loss: 0.2736 - val_accuracy: 0.6826 - val_precision_m: 0.8345 - val_recall_m: 0.7519 - val_f1_m: 0.7892\n","Epoch 16/50\n","131/131 [==============================] - 1s 5ms/step - loss: 0.2426 - accuracy: 0.6086 - precision_m: 0.8780 - recall_m: 0.8080 - f1_m: 0.8406 - val_loss: 0.2940 - val_accuracy: 0.6997 - val_precision_m: 0.8106 - val_recall_m: 0.7701 - val_f1_m: 0.7882\n","Epoch 17/50\n","131/131 [==============================] - 1s 5ms/step - loss: 0.2339 - accuracy: 0.6322 - precision_m: 0.8833 - recall_m: 0.8234 - f1_m: 0.8512 - val_loss: 0.2846 - val_accuracy: 0.6969 - val_precision_m: 0.8179 - val_recall_m: 0.7568 - val_f1_m: 0.7844\n","Epoch 18/50\n","131/131 [==============================] - 1s 5ms/step - loss: 0.2344 - accuracy: 0.6163 - precision_m: 0.8777 - recall_m: 0.8217 - f1_m: 0.8476 - val_loss: 0.2913 - val_accuracy: 0.7016 - val_precision_m: 0.8209 - val_recall_m: 0.7516 - val_f1_m: 0.7829\n","Epoch 19/50\n","131/131 [==============================] - 1s 5ms/step - loss: 0.2282 - accuracy: 0.6297 - precision_m: 0.8773 - recall_m: 0.8294 - f1_m: 0.8514 - val_loss: 0.2805 - val_accuracy: 0.6978 - val_precision_m: 0.8304 - val_recall_m: 0.7557 - val_f1_m: 0.7896\n","Epoch 20/50\n","131/131 [==============================] - 1s 5ms/step - loss: 0.2259 - accuracy: 0.6243 - precision_m: 0.8850 - recall_m: 0.8313 - f1_m: 0.8565 - val_loss: 0.2845 - val_accuracy: 0.6940 - val_precision_m: 0.8197 - val_recall_m: 0.7664 - val_f1_m: 0.7903\n","Epoch 21/50\n","131/131 [==============================] - 1s 5ms/step - loss: 0.2234 - accuracy: 0.6265 - precision_m: 0.8817 - recall_m: 0.8314 - f1_m: 0.8549 - val_loss: 0.2825 - val_accuracy: 0.6940 - val_precision_m: 0.8174 - val_recall_m: 0.7659 - val_f1_m: 0.7892\n","Epoch 00021: early stopping\n","Score for fold 3: loss of 0.2687307894229889; accuracy of 68.12977194786072% ;precision_m of 0.8249310851097107 ;recall_m of 0.7583205699920654 ;            f1_m of 0.78887939453125\n","Epoch 1/50\n","131/131 [==============================] - 2s 9ms/step - loss: 0.5072 - accuracy: 0.3730 - precision_m: 0.6342 - recall_m: 0.3548 - f1_m: 0.4374 - val_loss: 0.3091 - val_accuracy: 0.6059 - val_precision_m: 0.7990 - val_recall_m: 0.6915 - val_f1_m: 0.7391\n","Epoch 2/50\n","131/131 [==============================] - 1s 7ms/step - loss: 0.3419 - accuracy: 0.5759 - precision_m: 0.7890 - recall_m: 0.6505 - f1_m: 0.7111 - val_loss: 0.2721 - val_accuracy: 0.6517 - val_precision_m: 0.8259 - val_recall_m: 0.7325 - val_f1_m: 0.7744\n","Epoch 3/50\n","131/131 [==============================] - 1s 7ms/step - loss: 0.3050 - accuracy: 0.6056 - precision_m: 0.8122 - recall_m: 0.7035 - f1_m: 0.7523 - val_loss: 0.2601 - val_accuracy: 0.6651 - val_precision_m: 0.8147 - val_recall_m: 0.7691 - val_f1_m: 0.7897\n","Epoch 4/50\n","131/131 [==============================] - 1s 7ms/step - loss: 0.2916 - accuracy: 0.6171 - precision_m: 0.8163 - recall_m: 0.7188 - f1_m: 0.7633 - val_loss: 0.2519 - val_accuracy: 0.6670 - val_precision_m: 0.8291 - val_recall_m: 0.7674 - val_f1_m: 0.7959\n","Epoch 5/50\n","131/131 [==============================] - 1s 7ms/step - loss: 0.2686 - accuracy: 0.6370 - precision_m: 0.8283 - recall_m: 0.7499 - f1_m: 0.7858 - val_loss: 0.2471 - val_accuracy: 0.6842 - val_precision_m: 0.8441 - val_recall_m: 0.7433 - val_f1_m: 0.7890\n","Epoch 6/50\n","131/131 [==============================] - 1s 7ms/step - loss: 0.2739 - accuracy: 0.6325 - precision_m: 0.8281 - recall_m: 0.7370 - f1_m: 0.7779 - val_loss: 0.2450 - val_accuracy: 0.6574 - val_precision_m: 0.8366 - val_recall_m: 0.7735 - val_f1_m: 0.8023\n","Epoch 7/50\n","131/131 [==============================] - 1s 7ms/step - loss: 0.2600 - accuracy: 0.6499 - precision_m: 0.8440 - recall_m: 0.7634 - f1_m: 0.8001 - val_loss: 0.2386 - val_accuracy: 0.6746 - val_precision_m: 0.8410 - val_recall_m: 0.7617 - val_f1_m: 0.7984\n","Epoch 8/50\n","131/131 [==============================] - 1s 7ms/step - loss: 0.2421 - accuracy: 0.6528 - precision_m: 0.8450 - recall_m: 0.7740 - f1_m: 0.8068 - val_loss: 0.2398 - val_accuracy: 0.6489 - val_precision_m: 0.8258 - val_recall_m: 0.7777 - val_f1_m: 0.8001\n","Epoch 9/50\n","131/131 [==============================] - 1s 7ms/step - loss: 0.2390 - accuracy: 0.6321 - precision_m: 0.8574 - recall_m: 0.7851 - f1_m: 0.8184 - val_loss: 0.2362 - val_accuracy: 0.6622 - val_precision_m: 0.8293 - val_recall_m: 0.7795 - val_f1_m: 0.8023\n","Epoch 10/50\n","131/131 [==============================] - 1s 7ms/step - loss: 0.2387 - accuracy: 0.6540 - precision_m: 0.8498 - recall_m: 0.7770 - f1_m: 0.8106 - val_loss: 0.2411 - val_accuracy: 0.6746 - val_precision_m: 0.8385 - val_recall_m: 0.7738 - val_f1_m: 0.8037\n","Epoch 11/50\n","131/131 [==============================] - 1s 7ms/step - loss: 0.2391 - accuracy: 0.6528 - precision_m: 0.8491 - recall_m: 0.7805 - f1_m: 0.8121 - val_loss: 0.2378 - val_accuracy: 0.6670 - val_precision_m: 0.8309 - val_recall_m: 0.7783 - val_f1_m: 0.8027\n","Epoch 12/50\n","131/131 [==============================] - 1s 7ms/step - loss: 0.2218 - accuracy: 0.6654 - precision_m: 0.8673 - recall_m: 0.8011 - f1_m: 0.8319 - val_loss: 0.2385 - val_accuracy: 0.6527 - val_precision_m: 0.8267 - val_recall_m: 0.7860 - val_f1_m: 0.8048\n","Epoch 13/50\n","131/131 [==============================] - 1s 7ms/step - loss: 0.2217 - accuracy: 0.6696 - precision_m: 0.8659 - recall_m: 0.8027 - f1_m: 0.8322 - val_loss: 0.2370 - val_accuracy: 0.6660 - val_precision_m: 0.8479 - val_recall_m: 0.7538 - val_f1_m: 0.7966\n","Epoch 14/50\n","131/131 [==============================] - 1s 7ms/step - loss: 0.2139 - accuracy: 0.6788 - precision_m: 0.8783 - recall_m: 0.8114 - f1_m: 0.8423 - val_loss: 0.2426 - val_accuracy: 0.6784 - val_precision_m: 0.8409 - val_recall_m: 0.7686 - val_f1_m: 0.8021\n","Epoch 15/50\n","131/131 [==============================] - 1s 7ms/step - loss: 0.2112 - accuracy: 0.6702 - precision_m: 0.8759 - recall_m: 0.8069 - f1_m: 0.8388 - val_loss: 0.2349 - val_accuracy: 0.6737 - val_precision_m: 0.8221 - val_recall_m: 0.8113 - val_f1_m: 0.8158\n","Epoch 16/50\n","131/131 [==============================] - 1s 7ms/step - loss: 0.2007 - accuracy: 0.6783 - precision_m: 0.8768 - recall_m: 0.8188 - f1_m: 0.8457 - val_loss: 0.2375 - val_accuracy: 0.6842 - val_precision_m: 0.8365 - val_recall_m: 0.7816 - val_f1_m: 0.8070\n","Epoch 17/50\n","131/131 [==============================] - 1s 7ms/step - loss: 0.2000 - accuracy: 0.6900 - precision_m: 0.8734 - recall_m: 0.8251 - f1_m: 0.8475 - val_loss: 0.2394 - val_accuracy: 0.6947 - val_precision_m: 0.8234 - val_recall_m: 0.8087 - val_f1_m: 0.8151\n","Epoch 18/50\n","131/131 [==============================] - 1s 7ms/step - loss: 0.1973 - accuracy: 0.6861 - precision_m: 0.8795 - recall_m: 0.8286 - f1_m: 0.8521 - val_loss: 0.2388 - val_accuracy: 0.6584 - val_precision_m: 0.8396 - val_recall_m: 0.7867 - val_f1_m: 0.8112\n","Epoch 19/50\n","131/131 [==============================] - 1s 7ms/step - loss: 0.1858 - accuracy: 0.6722 - precision_m: 0.8930 - recall_m: 0.8365 - f1_m: 0.8628 - val_loss: 0.2321 - val_accuracy: 0.6718 - val_precision_m: 0.8421 - val_recall_m: 0.7913 - val_f1_m: 0.8148\n","Epoch 20/50\n","131/131 [==============================] - 1s 7ms/step - loss: 0.1897 - accuracy: 0.6948 - precision_m: 0.8820 - recall_m: 0.8287 - f1_m: 0.8535 - val_loss: 0.2362 - val_accuracy: 0.6842 - val_precision_m: 0.8430 - val_recall_m: 0.7720 - val_f1_m: 0.8045\n","Epoch 21/50\n","131/131 [==============================] - 1s 7ms/step - loss: 0.1887 - accuracy: 0.6939 - precision_m: 0.8952 - recall_m: 0.8325 - f1_m: 0.8615 - val_loss: 0.2445 - val_accuracy: 0.7004 - val_precision_m: 0.8204 - val_recall_m: 0.8056 - val_f1_m: 0.8118\n","Epoch 22/50\n","131/131 [==============================] - 1s 7ms/step - loss: 0.1868 - accuracy: 0.6899 - precision_m: 0.8885 - recall_m: 0.8362 - f1_m: 0.8603 - val_loss: 0.2475 - val_accuracy: 0.6813 - val_precision_m: 0.8293 - val_recall_m: 0.7953 - val_f1_m: 0.8111\n","Epoch 23/50\n","131/131 [==============================] - 1s 7ms/step - loss: 0.1864 - accuracy: 0.6793 - precision_m: 0.8909 - recall_m: 0.8349 - f1_m: 0.8611 - val_loss: 0.2374 - val_accuracy: 0.6803 - val_precision_m: 0.8215 - val_recall_m: 0.8139 - val_f1_m: 0.8167\n","Epoch 24/50\n","131/131 [==============================] - 1s 7ms/step - loss: 0.1816 - accuracy: 0.6872 - precision_m: 0.8869 - recall_m: 0.8433 - f1_m: 0.8630 - val_loss: 0.2413 - val_accuracy: 0.6823 - val_precision_m: 0.8324 - val_recall_m: 0.7940 - val_f1_m: 0.8118\n","Epoch 25/50\n","131/131 [==============================] - 1s 7ms/step - loss: 0.1714 - accuracy: 0.7005 - precision_m: 0.9005 - recall_m: 0.8504 - f1_m: 0.8736 - val_loss: 0.2348 - val_accuracy: 0.6861 - val_precision_m: 0.8399 - val_recall_m: 0.7925 - val_f1_m: 0.8145\n","Epoch 26/50\n","131/131 [==============================] - 1s 7ms/step - loss: 0.1623 - accuracy: 0.6843 - precision_m: 0.9103 - recall_m: 0.8522 - f1_m: 0.8792 - val_loss: 0.2393 - val_accuracy: 0.6670 - val_precision_m: 0.8340 - val_recall_m: 0.7841 - val_f1_m: 0.8073\n","Epoch 27/50\n","131/131 [==============================] - 1s 7ms/step - loss: 0.1651 - accuracy: 0.6912 - precision_m: 0.9036 - recall_m: 0.8570 - f1_m: 0.8787 - val_loss: 0.2480 - val_accuracy: 0.6947 - val_precision_m: 0.8229 - val_recall_m: 0.8026 - val_f1_m: 0.8119\n","Epoch 28/50\n","131/131 [==============================] - 1s 7ms/step - loss: 0.1652 - accuracy: 0.7062 - precision_m: 0.9036 - recall_m: 0.8552 - f1_m: 0.8778 - val_loss: 0.2408 - val_accuracy: 0.6937 - val_precision_m: 0.8435 - val_recall_m: 0.7728 - val_f1_m: 0.8054\n","Epoch 29/50\n","131/131 [==============================] - 1s 7ms/step - loss: 0.1549 - accuracy: 0.7148 - precision_m: 0.9141 - recall_m: 0.8622 - f1_m: 0.8865 - val_loss: 0.2387 - val_accuracy: 0.6737 - val_precision_m: 0.8401 - val_recall_m: 0.7878 - val_f1_m: 0.8121\n","Epoch 30/50\n","131/131 [==============================] - 1s 7ms/step - loss: 0.1551 - accuracy: 0.7014 - precision_m: 0.9058 - recall_m: 0.8636 - f1_m: 0.8836 - val_loss: 0.2450 - val_accuracy: 0.6842 - val_precision_m: 0.8299 - val_recall_m: 0.7859 - val_f1_m: 0.8063\n","Epoch 31/50\n","131/131 [==============================] - 1s 7ms/step - loss: 0.1534 - accuracy: 0.7082 - precision_m: 0.9104 - recall_m: 0.8685 - f1_m: 0.8881 - val_loss: 0.2467 - val_accuracy: 0.6594 - val_precision_m: 0.8426 - val_recall_m: 0.7773 - val_f1_m: 0.8074\n","Epoch 32/50\n","131/131 [==============================] - 1s 7ms/step - loss: 0.1531 - accuracy: 0.6996 - precision_m: 0.9104 - recall_m: 0.8706 - f1_m: 0.8891 - val_loss: 0.2406 - val_accuracy: 0.6870 - val_precision_m: 0.8433 - val_recall_m: 0.7852 - val_f1_m: 0.8124\n","Epoch 33/50\n","131/131 [==============================] - 1s 7ms/step - loss: 0.1471 - accuracy: 0.6992 - precision_m: 0.9137 - recall_m: 0.8735 - f1_m: 0.8922 - val_loss: 0.2461 - val_accuracy: 0.6956 - val_precision_m: 0.8425 - val_recall_m: 0.7796 - val_f1_m: 0.8086\n","Epoch 00033: early stopping\n","Score for fold 1: loss of 0.4122806787490845; accuracy of 54.21594977378845% ;precision_m of 0.8601517081260681 ;recall_m of 0.6873178482055664 ;            f1_m of 0.7611193060874939\n","Epoch 1/50\n","131/131 [==============================] - 2s 14ms/step - loss: 0.5690 - accuracy: 0.3490 - precision_m: 0.5750 - recall_m: 0.3285 - f1_m: 0.4038 - val_loss: 0.3221 - val_accuracy: 0.6282 - val_precision_m: 0.7577 - val_recall_m: 0.7531 - val_f1_m: 0.7530\n","Epoch 2/50\n","131/131 [==============================] - 1s 7ms/step - loss: 0.3742 - accuracy: 0.5522 - precision_m: 0.7797 - recall_m: 0.6697 - f1_m: 0.7187 - val_loss: 0.2812 - val_accuracy: 0.6759 - val_precision_m: 0.8248 - val_recall_m: 0.7323 - val_f1_m: 0.7740\n","Epoch 3/50\n","131/131 [==============================] - 1s 7ms/step - loss: 0.3305 - accuracy: 0.5884 - precision_m: 0.8034 - recall_m: 0.7179 - f1_m: 0.7562 - val_loss: 0.2691 - val_accuracy: 0.6663 - val_precision_m: 0.8167 - val_recall_m: 0.7582 - val_f1_m: 0.7847\n","Epoch 4/50\n","131/131 [==============================] - 1s 7ms/step - loss: 0.3145 - accuracy: 0.5917 - precision_m: 0.8181 - recall_m: 0.7444 - f1_m: 0.7783 - val_loss: 0.2607 - val_accuracy: 0.6969 - val_precision_m: 0.8152 - val_recall_m: 0.7768 - val_f1_m: 0.7941\n","Epoch 5/50\n","131/131 [==============================] - 1s 7ms/step - loss: 0.2815 - accuracy: 0.6054 - precision_m: 0.8377 - recall_m: 0.7765 - f1_m: 0.8047 - val_loss: 0.2548 - val_accuracy: 0.6625 - val_precision_m: 0.8162 - val_recall_m: 0.7711 - val_f1_m: 0.7912\n","Epoch 6/50\n","131/131 [==============================] - 1s 7ms/step - loss: 0.2827 - accuracy: 0.6084 - precision_m: 0.8307 - recall_m: 0.7719 - f1_m: 0.7995 - val_loss: 0.2443 - val_accuracy: 0.6835 - val_precision_m: 0.8376 - val_recall_m: 0.7629 - val_f1_m: 0.7968\n","Epoch 7/50\n","131/131 [==============================] - 1s 7ms/step - loss: 0.2778 - accuracy: 0.6218 - precision_m: 0.8422 - recall_m: 0.7681 - f1_m: 0.8024 - val_loss: 0.2477 - val_accuracy: 0.6663 - val_precision_m: 0.8058 - val_recall_m: 0.8011 - val_f1_m: 0.8020\n","Epoch 8/50\n","131/131 [==============================] - 1s 7ms/step - loss: 0.2681 - accuracy: 0.6147 - precision_m: 0.8435 - recall_m: 0.7936 - f1_m: 0.8168 - val_loss: 0.2432 - val_accuracy: 0.6826 - val_precision_m: 0.8261 - val_recall_m: 0.7947 - val_f1_m: 0.8086\n","Epoch 9/50\n","131/131 [==============================] - 1s 7ms/step - loss: 0.2531 - accuracy: 0.6310 - precision_m: 0.8537 - recall_m: 0.8009 - f1_m: 0.8252 - val_loss: 0.2462 - val_accuracy: 0.6835 - val_precision_m: 0.8181 - val_recall_m: 0.7888 - val_f1_m: 0.8019\n","Epoch 10/50\n","131/131 [==============================] - 1s 7ms/step - loss: 0.2575 - accuracy: 0.6003 - precision_m: 0.8534 - recall_m: 0.7949 - f1_m: 0.8220 - val_loss: 0.2414 - val_accuracy: 0.6911 - val_precision_m: 0.8246 - val_recall_m: 0.7974 - val_f1_m: 0.8096\n","Epoch 11/50\n","131/131 [==============================] - 1s 7ms/step - loss: 0.2524 - accuracy: 0.6213 - precision_m: 0.8580 - recall_m: 0.8005 - f1_m: 0.8273 - val_loss: 0.2390 - val_accuracy: 0.6883 - val_precision_m: 0.8395 - val_recall_m: 0.7861 - val_f1_m: 0.8107\n","Epoch 12/50\n","131/131 [==============================] - 1s 7ms/step - loss: 0.2414 - accuracy: 0.6216 - precision_m: 0.8684 - recall_m: 0.8059 - f1_m: 0.8351 - val_loss: 0.2414 - val_accuracy: 0.7045 - val_precision_m: 0.8323 - val_recall_m: 0.7749 - val_f1_m: 0.8009\n","Epoch 13/50\n","131/131 [==============================] - 1s 7ms/step - loss: 0.2419 - accuracy: 0.6273 - precision_m: 0.8628 - recall_m: 0.8030 - f1_m: 0.8309 - val_loss: 0.2417 - val_accuracy: 0.7007 - val_precision_m: 0.8336 - val_recall_m: 0.7926 - val_f1_m: 0.8114\n","Epoch 14/50\n","131/131 [==============================] - 1s 7ms/step - loss: 0.2368 - accuracy: 0.6307 - precision_m: 0.8663 - recall_m: 0.8074 - f1_m: 0.8348 - val_loss: 0.2440 - val_accuracy: 0.7083 - val_precision_m: 0.8405 - val_recall_m: 0.7870 - val_f1_m: 0.8113\n","Epoch 15/50\n","131/131 [==============================] - 1s 7ms/step - loss: 0.2266 - accuracy: 0.6309 - precision_m: 0.8762 - recall_m: 0.8236 - f1_m: 0.8479 - val_loss: 0.2451 - val_accuracy: 0.7035 - val_precision_m: 0.8306 - val_recall_m: 0.7825 - val_f1_m: 0.8046\n","Epoch 16/50\n","131/131 [==============================] - 1s 8ms/step - loss: 0.2306 - accuracy: 0.6375 - precision_m: 0.8767 - recall_m: 0.8197 - f1_m: 0.8461 - val_loss: 0.2396 - val_accuracy: 0.7035 - val_precision_m: 0.8257 - val_recall_m: 0.8036 - val_f1_m: 0.8134\n","Epoch 17/50\n","131/131 [==============================] - 1s 7ms/step - loss: 0.2229 - accuracy: 0.6395 - precision_m: 0.8750 - recall_m: 0.8281 - f1_m: 0.8495 - val_loss: 0.2358 - val_accuracy: 0.7045 - val_precision_m: 0.8378 - val_recall_m: 0.7779 - val_f1_m: 0.8054\n","Epoch 18/50\n","131/131 [==============================] - 1s 7ms/step - loss: 0.2174 - accuracy: 0.6445 - precision_m: 0.8844 - recall_m: 0.8352 - f1_m: 0.8583 - val_loss: 0.2392 - val_accuracy: 0.7092 - val_precision_m: 0.8309 - val_recall_m: 0.7900 - val_f1_m: 0.8085\n","Epoch 19/50\n","131/131 [==============================] - 1s 8ms/step - loss: 0.2119 - accuracy: 0.6469 - precision_m: 0.8840 - recall_m: 0.8357 - f1_m: 0.8580 - val_loss: 0.2433 - val_accuracy: 0.7007 - val_precision_m: 0.8486 - val_recall_m: 0.7813 - val_f1_m: 0.8123\n","Epoch 20/50\n","131/131 [==============================] - 1s 7ms/step - loss: 0.2119 - accuracy: 0.6500 - precision_m: 0.8896 - recall_m: 0.8371 - f1_m: 0.8616 - val_loss: 0.2443 - val_accuracy: 0.7054 - val_precision_m: 0.8152 - val_recall_m: 0.8121 - val_f1_m: 0.8123\n","Epoch 21/50\n","131/131 [==============================] - 1s 7ms/step - loss: 0.2068 - accuracy: 0.6633 - precision_m: 0.8875 - recall_m: 0.8428 - f1_m: 0.8632 - val_loss: 0.2383 - val_accuracy: 0.6997 - val_precision_m: 0.8378 - val_recall_m: 0.7906 - val_f1_m: 0.8120\n","Epoch 22/50\n","131/131 [==============================] - 1s 7ms/step - loss: 0.1989 - accuracy: 0.6444 - precision_m: 0.9001 - recall_m: 0.8489 - f1_m: 0.8729 - val_loss: 0.2393 - val_accuracy: 0.7035 - val_precision_m: 0.8537 - val_recall_m: 0.7775 - val_f1_m: 0.8124\n","Epoch 23/50\n","131/131 [==============================] - 1s 7ms/step - loss: 0.1986 - accuracy: 0.6555 - precision_m: 0.8940 - recall_m: 0.8440 - f1_m: 0.8674 - val_loss: 0.2417 - val_accuracy: 0.6997 - val_precision_m: 0.8299 - val_recall_m: 0.7783 - val_f1_m: 0.8017\n","Epoch 24/50\n","131/131 [==============================] - 1s 7ms/step - loss: 0.2009 - accuracy: 0.6640 - precision_m: 0.8924 - recall_m: 0.8428 - f1_m: 0.8657 - val_loss: 0.2417 - val_accuracy: 0.7007 - val_precision_m: 0.8295 - val_recall_m: 0.7943 - val_f1_m: 0.8102\n","Epoch 25/50\n","131/131 [==============================] - 1s 7ms/step - loss: 0.1890 - accuracy: 0.6445 - precision_m: 0.8988 - recall_m: 0.8567 - f1_m: 0.8764 - val_loss: 0.2423 - val_accuracy: 0.7112 - val_precision_m: 0.8311 - val_recall_m: 0.7966 - val_f1_m: 0.8123\n","Epoch 26/50\n","131/131 [==============================] - 1s 8ms/step - loss: 0.1817 - accuracy: 0.6625 - precision_m: 0.9127 - recall_m: 0.8633 - f1_m: 0.8863 - val_loss: 0.2442 - val_accuracy: 0.7226 - val_precision_m: 0.8288 - val_recall_m: 0.7821 - val_f1_m: 0.8037\n","Epoch 00026: early stopping\n","Score for fold 2: loss of 0.3115154802799225; accuracy of 69.04579997062683% ;precision_m of 0.806212842464447 ;recall_m of 0.7727561593055725 ;            f1_m of 0.7873302698135376\n","Epoch 1/50\n","131/131 [==============================] - 2s 9ms/step - loss: 0.5705 - accuracy: 0.3448 - precision_m: 0.6017 - recall_m: 0.3575 - f1_m: 0.4345 - val_loss: 0.3640 - val_accuracy: 0.6368 - val_precision_m: 0.7535 - val_recall_m: 0.7037 - val_f1_m: 0.7258\n","Epoch 2/50\n","131/131 [==============================] - 1s 7ms/step - loss: 0.3831 - accuracy: 0.5481 - precision_m: 0.7874 - recall_m: 0.6658 - f1_m: 0.7195 - val_loss: 0.3090 - val_accuracy: 0.6625 - val_precision_m: 0.8171 - val_recall_m: 0.7181 - val_f1_m: 0.7627\n","Epoch 3/50\n","131/131 [==============================] - 1s 7ms/step - loss: 0.3454 - accuracy: 0.5728 - precision_m: 0.8071 - recall_m: 0.7183 - f1_m: 0.7579 - val_loss: 0.3152 - val_accuracy: 0.6806 - val_precision_m: 0.7835 - val_recall_m: 0.7594 - val_f1_m: 0.7694\n","Epoch 4/50\n","131/131 [==============================] - 1s 7ms/step - loss: 0.3214 - accuracy: 0.5651 - precision_m: 0.8250 - recall_m: 0.7431 - f1_m: 0.7800 - val_loss: 0.3032 - val_accuracy: 0.6625 - val_precision_m: 0.7930 - val_recall_m: 0.7375 - val_f1_m: 0.7621\n","Epoch 5/50\n","131/131 [==============================] - 1s 7ms/step - loss: 0.2976 - accuracy: 0.5916 - precision_m: 0.8416 - recall_m: 0.7620 - f1_m: 0.7987 - val_loss: 0.3025 - val_accuracy: 0.6864 - val_precision_m: 0.8047 - val_recall_m: 0.7333 - val_f1_m: 0.7655\n","Epoch 6/50\n","131/131 [==============================] - 1s 7ms/step - loss: 0.2902 - accuracy: 0.5960 - precision_m: 0.8369 - recall_m: 0.7664 - f1_m: 0.7985 - val_loss: 0.2847 - val_accuracy: 0.6597 - val_precision_m: 0.8089 - val_recall_m: 0.7476 - val_f1_m: 0.7753\n","Epoch 7/50\n","131/131 [==============================] - 1s 7ms/step - loss: 0.2885 - accuracy: 0.5871 - precision_m: 0.8457 - recall_m: 0.7745 - f1_m: 0.8075 - val_loss: 0.2885 - val_accuracy: 0.6949 - val_precision_m: 0.8234 - val_recall_m: 0.7505 - val_f1_m: 0.7834\n","Epoch 8/50\n","131/131 [==============================] - 1s 7ms/step - loss: 0.2741 - accuracy: 0.5849 - precision_m: 0.8608 - recall_m: 0.7921 - f1_m: 0.8239 - val_loss: 0.2775 - val_accuracy: 0.6759 - val_precision_m: 0.8440 - val_recall_m: 0.7306 - val_f1_m: 0.7816\n","Epoch 9/50\n","131/131 [==============================] - 1s 7ms/step - loss: 0.2723 - accuracy: 0.6048 - precision_m: 0.8571 - recall_m: 0.7795 - f1_m: 0.8153 - val_loss: 0.2830 - val_accuracy: 0.6864 - val_precision_m: 0.8070 - val_recall_m: 0.7620 - val_f1_m: 0.7821\n","Epoch 10/50\n","131/131 [==============================] - 1s 7ms/step - loss: 0.2561 - accuracy: 0.6078 - precision_m: 0.8650 - recall_m: 0.8052 - f1_m: 0.8327 - val_loss: 0.2906 - val_accuracy: 0.6835 - val_precision_m: 0.8029 - val_recall_m: 0.7768 - val_f1_m: 0.7874\n","Epoch 11/50\n","131/131 [==============================] - 1s 7ms/step - loss: 0.2642 - accuracy: 0.6092 - precision_m: 0.8574 - recall_m: 0.8022 - f1_m: 0.8278 - val_loss: 0.2831 - val_accuracy: 0.6921 - val_precision_m: 0.8272 - val_recall_m: 0.7549 - val_f1_m: 0.7873\n","Epoch 12/50\n","131/131 [==============================] - 1s 7ms/step - loss: 0.2481 - accuracy: 0.6015 - precision_m: 0.8724 - recall_m: 0.8082 - f1_m: 0.8382 - val_loss: 0.2830 - val_accuracy: 0.6845 - val_precision_m: 0.8266 - val_recall_m: 0.7501 - val_f1_m: 0.7846\n","Epoch 13/50\n","131/131 [==============================] - 1s 7ms/step - loss: 0.2484 - accuracy: 0.6284 - precision_m: 0.8729 - recall_m: 0.8128 - f1_m: 0.8406 - val_loss: 0.2879 - val_accuracy: 0.6797 - val_precision_m: 0.8223 - val_recall_m: 0.7182 - val_f1_m: 0.7649\n","Epoch 14/50\n","131/131 [==============================] - 1s 8ms/step - loss: 0.2354 - accuracy: 0.6154 - precision_m: 0.8717 - recall_m: 0.8164 - f1_m: 0.8421 - val_loss: 0.2861 - val_accuracy: 0.6883 - val_precision_m: 0.8071 - val_recall_m: 0.7669 - val_f1_m: 0.7846\n","Epoch 15/50\n","131/131 [==============================] - 1s 7ms/step - loss: 0.2401 - accuracy: 0.5953 - precision_m: 0.8761 - recall_m: 0.8208 - f1_m: 0.8466 - val_loss: 0.2748 - val_accuracy: 0.6806 - val_precision_m: 0.8386 - val_recall_m: 0.7594 - val_f1_m: 0.7954\n","Epoch 16/50\n","131/131 [==============================] - 1s 7ms/step - loss: 0.2404 - accuracy: 0.6117 - precision_m: 0.8743 - recall_m: 0.8177 - f1_m: 0.8439 - val_loss: 0.2859 - val_accuracy: 0.6787 - val_precision_m: 0.8122 - val_recall_m: 0.7499 - val_f1_m: 0.7778\n","Epoch 17/50\n","131/131 [==============================] - 1s 7ms/step - loss: 0.2361 - accuracy: 0.6167 - precision_m: 0.8677 - recall_m: 0.8156 - f1_m: 0.8396 - val_loss: 0.2879 - val_accuracy: 0.6978 - val_precision_m: 0.8219 - val_recall_m: 0.7506 - val_f1_m: 0.7827\n","Epoch 18/50\n","131/131 [==============================] - 1s 7ms/step - loss: 0.2329 - accuracy: 0.6192 - precision_m: 0.8867 - recall_m: 0.8208 - f1_m: 0.8514 - val_loss: 0.2870 - val_accuracy: 0.7007 - val_precision_m: 0.8180 - val_recall_m: 0.7627 - val_f1_m: 0.7874\n","Epoch 19/50\n","131/131 [==============================] - 1s 8ms/step - loss: 0.2205 - accuracy: 0.6240 - precision_m: 0.8815 - recall_m: 0.8356 - f1_m: 0.8569 - val_loss: 0.2845 - val_accuracy: 0.6826 - val_precision_m: 0.8183 - val_recall_m: 0.7602 - val_f1_m: 0.7863\n","Epoch 20/50\n","131/131 [==============================] - 1s 7ms/step - loss: 0.2171 - accuracy: 0.6340 - precision_m: 0.8911 - recall_m: 0.8428 - f1_m: 0.8652 - val_loss: 0.2783 - val_accuracy: 0.6969 - val_precision_m: 0.8199 - val_recall_m: 0.7687 - val_f1_m: 0.7918\n","Epoch 21/50\n","131/131 [==============================] - 1s 7ms/step - loss: 0.2079 - accuracy: 0.6292 - precision_m: 0.8968 - recall_m: 0.8441 - f1_m: 0.8685 - val_loss: 0.2826 - val_accuracy: 0.6949 - val_precision_m: 0.8252 - val_recall_m: 0.7475 - val_f1_m: 0.7825\n","Epoch 22/50\n","131/131 [==============================] - 1s 7ms/step - loss: 0.2121 - accuracy: 0.6254 - precision_m: 0.8912 - recall_m: 0.8377 - f1_m: 0.8627 - val_loss: 0.2789 - val_accuracy: 0.6921 - val_precision_m: 0.8137 - val_recall_m: 0.7715 - val_f1_m: 0.7905\n","Epoch 23/50\n","131/131 [==============================] - 1s 7ms/step - loss: 0.2046 - accuracy: 0.6226 - precision_m: 0.8891 - recall_m: 0.8477 - f1_m: 0.8670 - val_loss: 0.2836 - val_accuracy: 0.6911 - val_precision_m: 0.8316 - val_recall_m: 0.7581 - val_f1_m: 0.7915\n","Epoch 24/50\n","131/131 [==============================] - 1s 7ms/step - loss: 0.1964 - accuracy: 0.6255 - precision_m: 0.8993 - recall_m: 0.8567 - f1_m: 0.8767 - val_loss: 0.2812 - val_accuracy: 0.6892 - val_precision_m: 0.8311 - val_recall_m: 0.7522 - val_f1_m: 0.7879\n","Epoch 25/50\n","131/131 [==============================] - 1s 7ms/step - loss: 0.2044 - accuracy: 0.6228 - precision_m: 0.8966 - recall_m: 0.8511 - f1_m: 0.8722 - val_loss: 0.2874 - val_accuracy: 0.7016 - val_precision_m: 0.8239 - val_recall_m: 0.7396 - val_f1_m: 0.7778\n","Epoch 00025: early stopping\n","Score for fold 3: loss of 0.27317288517951965; accuracy of 66.94656610488892% ;precision_m of 0.8321382403373718 ;recall_m of 0.7300665974617004 ;            f1_m of 0.7763451933860779\n","Epoch 1/50\n","131/131 [==============================] - 2s 12ms/step - loss: 0.5016 - accuracy: 0.3846 - precision_m: 0.6224 - recall_m: 0.3776 - f1_m: 0.4469 - val_loss: 0.3044 - val_accuracy: 0.6116 - val_precision_m: 0.7956 - val_recall_m: 0.7188 - val_f1_m: 0.7531\n","Epoch 2/50\n","131/131 [==============================] - 1s 9ms/step - loss: 0.3444 - accuracy: 0.5732 - precision_m: 0.7786 - recall_m: 0.6448 - f1_m: 0.7032 - val_loss: 0.2735 - val_accuracy: 0.6441 - val_precision_m: 0.8195 - val_recall_m: 0.7264 - val_f1_m: 0.7683\n","Epoch 3/50\n","131/131 [==============================] - 1s 9ms/step - loss: 0.3146 - accuracy: 0.6043 - precision_m: 0.8017 - recall_m: 0.6852 - f1_m: 0.7369 - val_loss: 0.2558 - val_accuracy: 0.6555 - val_precision_m: 0.8302 - val_recall_m: 0.7559 - val_f1_m: 0.7899\n","Epoch 4/50\n","131/131 [==============================] - 1s 9ms/step - loss: 0.2923 - accuracy: 0.6186 - precision_m: 0.8154 - recall_m: 0.7193 - f1_m: 0.7631 - val_loss: 0.2453 - val_accuracy: 0.6460 - val_precision_m: 0.8266 - val_recall_m: 0.7819 - val_f1_m: 0.8026\n","Epoch 5/50\n","131/131 [==============================] - 1s 9ms/step - loss: 0.2832 - accuracy: 0.6180 - precision_m: 0.8310 - recall_m: 0.7315 - f1_m: 0.7764 - val_loss: 0.2517 - val_accuracy: 0.6565 - val_precision_m: 0.8271 - val_recall_m: 0.7744 - val_f1_m: 0.7985\n","Epoch 6/50\n","131/131 [==============================] - 1s 9ms/step - loss: 0.2738 - accuracy: 0.6355 - precision_m: 0.8281 - recall_m: 0.7476 - f1_m: 0.7844 - val_loss: 0.2476 - val_accuracy: 0.6660 - val_precision_m: 0.8379 - val_recall_m: 0.7692 - val_f1_m: 0.8006\n","Epoch 7/50\n","131/131 [==============================] - 1s 9ms/step - loss: 0.2649 - accuracy: 0.6430 - precision_m: 0.8321 - recall_m: 0.7507 - f1_m: 0.7884 - val_loss: 0.2422 - val_accuracy: 0.6498 - val_precision_m: 0.8312 - val_recall_m: 0.7723 - val_f1_m: 0.7992\n","Epoch 8/50\n","131/131 [==============================] - 1s 9ms/step - loss: 0.2561 - accuracy: 0.6502 - precision_m: 0.8445 - recall_m: 0.7638 - f1_m: 0.8005 - val_loss: 0.2384 - val_accuracy: 0.6651 - val_precision_m: 0.8231 - val_recall_m: 0.7902 - val_f1_m: 0.8049\n","Epoch 9/50\n","131/131 [==============================] - 1s 9ms/step - loss: 0.2524 - accuracy: 0.6522 - precision_m: 0.8413 - recall_m: 0.7666 - f1_m: 0.8006 - val_loss: 0.2329 - val_accuracy: 0.6698 - val_precision_m: 0.8351 - val_recall_m: 0.7814 - val_f1_m: 0.8062\n","Epoch 10/50\n","131/131 [==============================] - 1s 9ms/step - loss: 0.2537 - accuracy: 0.6443 - precision_m: 0.8509 - recall_m: 0.7640 - f1_m: 0.8039 - val_loss: 0.2353 - val_accuracy: 0.6813 - val_precision_m: 0.8411 - val_recall_m: 0.7779 - val_f1_m: 0.8070\n","Epoch 11/50\n","131/131 [==============================] - 1s 9ms/step - loss: 0.2395 - accuracy: 0.6483 - precision_m: 0.8547 - recall_m: 0.7866 - f1_m: 0.8181 - val_loss: 0.2326 - val_accuracy: 0.6660 - val_precision_m: 0.8325 - val_recall_m: 0.7909 - val_f1_m: 0.8101\n","Epoch 12/50\n","131/131 [==============================] - 1s 9ms/step - loss: 0.2335 - accuracy: 0.6662 - precision_m: 0.8577 - recall_m: 0.7804 - f1_m: 0.8157 - val_loss: 0.2370 - val_accuracy: 0.6832 - val_precision_m: 0.8254 - val_recall_m: 0.8044 - val_f1_m: 0.8135\n","Epoch 13/50\n","131/131 [==============================] - 1s 9ms/step - loss: 0.2262 - accuracy: 0.6698 - precision_m: 0.8589 - recall_m: 0.7980 - f1_m: 0.8261 - val_loss: 0.2381 - val_accuracy: 0.6622 - val_precision_m: 0.8258 - val_recall_m: 0.8028 - val_f1_m: 0.8130\n","Epoch 14/50\n","131/131 [==============================] - 1s 9ms/step - loss: 0.2237 - accuracy: 0.6650 - precision_m: 0.8658 - recall_m: 0.8027 - f1_m: 0.8320 - val_loss: 0.2363 - val_accuracy: 0.6899 - val_precision_m: 0.8340 - val_recall_m: 0.7860 - val_f1_m: 0.8081\n","Epoch 15/50\n","131/131 [==============================] - 1s 9ms/step - loss: 0.2186 - accuracy: 0.6764 - precision_m: 0.8737 - recall_m: 0.7962 - f1_m: 0.8320 - val_loss: 0.2355 - val_accuracy: 0.6889 - val_precision_m: 0.8321 - val_recall_m: 0.7969 - val_f1_m: 0.8133\n","Epoch 16/50\n","131/131 [==============================] - 1s 9ms/step - loss: 0.2145 - accuracy: 0.6785 - precision_m: 0.8812 - recall_m: 0.8064 - f1_m: 0.8410 - val_loss: 0.2338 - val_accuracy: 0.6546 - val_precision_m: 0.8357 - val_recall_m: 0.7858 - val_f1_m: 0.8090\n","Epoch 17/50\n","131/131 [==============================] - 1s 9ms/step - loss: 0.2082 - accuracy: 0.6654 - precision_m: 0.8786 - recall_m: 0.8150 - f1_m: 0.8444 - val_loss: 0.2407 - val_accuracy: 0.6861 - val_precision_m: 0.8265 - val_recall_m: 0.8126 - val_f1_m: 0.8184\n","Epoch 18/50\n","131/131 [==============================] - 1s 9ms/step - loss: 0.2076 - accuracy: 0.6698 - precision_m: 0.8723 - recall_m: 0.8224 - f1_m: 0.8455 - val_loss: 0.2326 - val_accuracy: 0.6727 - val_precision_m: 0.8413 - val_recall_m: 0.7865 - val_f1_m: 0.8120\n","Epoch 19/50\n","131/131 [==============================] - 1s 9ms/step - loss: 0.2013 - accuracy: 0.6853 - precision_m: 0.8843 - recall_m: 0.8184 - f1_m: 0.8489 - val_loss: 0.2415 - val_accuracy: 0.7061 - val_precision_m: 0.8263 - val_recall_m: 0.7843 - val_f1_m: 0.8036\n","Epoch 20/50\n","131/131 [==============================] - 1s 9ms/step - loss: 0.2017 - accuracy: 0.6945 - precision_m: 0.8865 - recall_m: 0.8265 - f1_m: 0.8542 - val_loss: 0.2414 - val_accuracy: 0.6698 - val_precision_m: 0.8413 - val_recall_m: 0.7817 - val_f1_m: 0.8089\n","Epoch 21/50\n","131/131 [==============================] - 1s 9ms/step - loss: 0.1987 - accuracy: 0.6906 - precision_m: 0.8820 - recall_m: 0.8221 - f1_m: 0.8497 - val_loss: 0.2361 - val_accuracy: 0.6746 - val_precision_m: 0.8387 - val_recall_m: 0.7920 - val_f1_m: 0.8134\n","Epoch 22/50\n","131/131 [==============================] - 1s 9ms/step - loss: 0.1851 - accuracy: 0.6948 - precision_m: 0.8828 - recall_m: 0.8354 - f1_m: 0.8573 - val_loss: 0.2343 - val_accuracy: 0.6613 - val_precision_m: 0.8274 - val_recall_m: 0.8048 - val_f1_m: 0.8149\n","Epoch 23/50\n","131/131 [==============================] - 1s 9ms/step - loss: 0.1916 - accuracy: 0.6852 - precision_m: 0.8925 - recall_m: 0.8300 - f1_m: 0.8591 - val_loss: 0.2382 - val_accuracy: 0.6775 - val_precision_m: 0.8264 - val_recall_m: 0.8157 - val_f1_m: 0.8204\n","Epoch 24/50\n","131/131 [==============================] - 1s 9ms/step - loss: 0.1811 - accuracy: 0.6914 - precision_m: 0.9001 - recall_m: 0.8463 - f1_m: 0.8716 - val_loss: 0.2497 - val_accuracy: 0.6813 - val_precision_m: 0.8128 - val_recall_m: 0.8166 - val_f1_m: 0.8135\n","Epoch 25/50\n","131/131 [==============================] - 1s 9ms/step - loss: 0.1762 - accuracy: 0.7013 - precision_m: 0.8995 - recall_m: 0.8470 - f1_m: 0.8711 - val_loss: 0.2375 - val_accuracy: 0.6603 - val_precision_m: 0.8239 - val_recall_m: 0.8086 - val_f1_m: 0.8151\n","Epoch 26/50\n","131/131 [==============================] - 1s 9ms/step - loss: 0.1828 - accuracy: 0.6838 - precision_m: 0.8950 - recall_m: 0.8409 - f1_m: 0.8662 - val_loss: 0.2449 - val_accuracy: 0.6908 - val_precision_m: 0.8269 - val_recall_m: 0.8058 - val_f1_m: 0.8150\n","Epoch 27/50\n","131/131 [==============================] - 1s 9ms/step - loss: 0.1712 - accuracy: 0.6942 - precision_m: 0.9012 - recall_m: 0.8572 - f1_m: 0.8777 - val_loss: 0.2367 - val_accuracy: 0.6870 - val_precision_m: 0.8327 - val_recall_m: 0.7977 - val_f1_m: 0.8137\n","Epoch 28/50\n","131/131 [==============================] - 1s 9ms/step - loss: 0.1696 - accuracy: 0.7232 - precision_m: 0.9033 - recall_m: 0.8562 - f1_m: 0.8782 - val_loss: 0.2415 - val_accuracy: 0.6689 - val_precision_m: 0.8298 - val_recall_m: 0.7976 - val_f1_m: 0.8122\n","Epoch 29/50\n","131/131 [==============================] - 1s 9ms/step - loss: 0.1764 - accuracy: 0.6962 - precision_m: 0.8992 - recall_m: 0.8437 - f1_m: 0.8698 - val_loss: 0.2418 - val_accuracy: 0.6536 - val_precision_m: 0.8238 - val_recall_m: 0.8093 - val_f1_m: 0.8151\n","Epoch 30/50\n","131/131 [==============================] - 1s 9ms/step - loss: 0.1706 - accuracy: 0.6867 - precision_m: 0.8996 - recall_m: 0.8560 - f1_m: 0.8765 - val_loss: 0.2443 - val_accuracy: 0.6794 - val_precision_m: 0.8243 - val_recall_m: 0.8027 - val_f1_m: 0.8123\n","Epoch 31/50\n","131/131 [==============================] - 1s 9ms/step - loss: 0.1623 - accuracy: 0.6926 - precision_m: 0.9032 - recall_m: 0.8591 - f1_m: 0.8794 - val_loss: 0.2436 - val_accuracy: 0.6660 - val_precision_m: 0.8240 - val_recall_m: 0.8068 - val_f1_m: 0.8141\n","Epoch 32/50\n","131/131 [==============================] - 1s 9ms/step - loss: 0.1584 - accuracy: 0.6880 - precision_m: 0.9105 - recall_m: 0.8652 - f1_m: 0.8866 - val_loss: 0.2423 - val_accuracy: 0.6823 - val_precision_m: 0.8257 - val_recall_m: 0.8076 - val_f1_m: 0.8155\n","Epoch 33/50\n","131/131 [==============================] - 1s 9ms/step - loss: 0.1521 - accuracy: 0.7016 - precision_m: 0.9176 - recall_m: 0.8661 - f1_m: 0.8902 - val_loss: 0.2434 - val_accuracy: 0.6708 - val_precision_m: 0.8184 - val_recall_m: 0.8148 - val_f1_m: 0.8155\n","Epoch 00033: early stopping\n","Score for fold 1: loss of 0.43100228905677795; accuracy of 53.18580865859985% ;precision_m of 0.8370445966720581 ;recall_m of 0.7001758217811584 ;            f1_m of 0.7592286467552185\n","Epoch 1/50\n","131/131 [==============================] - 2s 11ms/step - loss: 0.5416 - accuracy: 0.3732 - precision_m: 0.6124 - recall_m: 0.3731 - f1_m: 0.4490 - val_loss: 0.2997 - val_accuracy: 0.6454 - val_precision_m: 0.8183 - val_recall_m: 0.6942 - val_f1_m: 0.7489\n","Epoch 2/50\n","131/131 [==============================] - 1s 9ms/step - loss: 0.3622 - accuracy: 0.5595 - precision_m: 0.7937 - recall_m: 0.6846 - f1_m: 0.7333 - val_loss: 0.2746 - val_accuracy: 0.6740 - val_precision_m: 0.8080 - val_recall_m: 0.7592 - val_f1_m: 0.7814\n","Epoch 3/50\n","131/131 [==============================] - 1s 9ms/step - loss: 0.3229 - accuracy: 0.5887 - precision_m: 0.8112 - recall_m: 0.7376 - f1_m: 0.7710 - val_loss: 0.2643 - val_accuracy: 0.6902 - val_precision_m: 0.8223 - val_recall_m: 0.7402 - val_f1_m: 0.7771\n","Epoch 4/50\n","131/131 [==============================] - 1s 9ms/step - loss: 0.3077 - accuracy: 0.6010 - precision_m: 0.8187 - recall_m: 0.7419 - f1_m: 0.7769 - val_loss: 0.2526 - val_accuracy: 0.6826 - val_precision_m: 0.8259 - val_recall_m: 0.7853 - val_f1_m: 0.8037\n","Epoch 5/50\n","131/131 [==============================] - 1s 9ms/step - loss: 0.2919 - accuracy: 0.6081 - precision_m: 0.8343 - recall_m: 0.7617 - f1_m: 0.7954 - val_loss: 0.2589 - val_accuracy: 0.6864 - val_precision_m: 0.7921 - val_recall_m: 0.8234 - val_f1_m: 0.8062\n","Epoch 6/50\n","131/131 [==============================] - 1s 9ms/step - loss: 0.2853 - accuracy: 0.5910 - precision_m: 0.8343 - recall_m: 0.7725 - f1_m: 0.8004 - val_loss: 0.2430 - val_accuracy: 0.6921 - val_precision_m: 0.8305 - val_recall_m: 0.7854 - val_f1_m: 0.8058\n","Epoch 7/50\n","131/131 [==============================] - 1s 9ms/step - loss: 0.2706 - accuracy: 0.6259 - precision_m: 0.8440 - recall_m: 0.7815 - f1_m: 0.8106 - val_loss: 0.2447 - val_accuracy: 0.7092 - val_precision_m: 0.8369 - val_recall_m: 0.7634 - val_f1_m: 0.7969\n","Epoch 8/50\n","131/131 [==============================] - 1s 9ms/step - loss: 0.2659 - accuracy: 0.6148 - precision_m: 0.8558 - recall_m: 0.7870 - f1_m: 0.8185 - val_loss: 0.2403 - val_accuracy: 0.6787 - val_precision_m: 0.8392 - val_recall_m: 0.7850 - val_f1_m: 0.8098\n","Epoch 9/50\n","131/131 [==============================] - 1s 9ms/step - loss: 0.2547 - accuracy: 0.6240 - precision_m: 0.8592 - recall_m: 0.7968 - f1_m: 0.8257 - val_loss: 0.2407 - val_accuracy: 0.6959 - val_precision_m: 0.8348 - val_recall_m: 0.7993 - val_f1_m: 0.8155\n","Epoch 10/50\n","131/131 [==============================] - 1s 10ms/step - loss: 0.2512 - accuracy: 0.6229 - precision_m: 0.8582 - recall_m: 0.7998 - f1_m: 0.8269 - val_loss: 0.2396 - val_accuracy: 0.7007 - val_precision_m: 0.8324 - val_recall_m: 0.7912 - val_f1_m: 0.8100\n","Epoch 11/50\n","131/131 [==============================] - 1s 9ms/step - loss: 0.2391 - accuracy: 0.6389 - precision_m: 0.8642 - recall_m: 0.8119 - f1_m: 0.8363 - val_loss: 0.2368 - val_accuracy: 0.6845 - val_precision_m: 0.8414 - val_recall_m: 0.7713 - val_f1_m: 0.8035\n","Epoch 12/50\n","131/131 [==============================] - 1s 9ms/step - loss: 0.2411 - accuracy: 0.6452 - precision_m: 0.8671 - recall_m: 0.8087 - f1_m: 0.8356 - val_loss: 0.2359 - val_accuracy: 0.6864 - val_precision_m: 0.8340 - val_recall_m: 0.7957 - val_f1_m: 0.8130\n","Epoch 13/50\n","131/131 [==============================] - 1s 9ms/step - loss: 0.2314 - accuracy: 0.6353 - precision_m: 0.8757 - recall_m: 0.8102 - f1_m: 0.8402 - val_loss: 0.2394 - val_accuracy: 0.6797 - val_precision_m: 0.8301 - val_recall_m: 0.7960 - val_f1_m: 0.8111\n","Epoch 14/50\n","131/131 [==============================] - 1s 9ms/step - loss: 0.2317 - accuracy: 0.6520 - precision_m: 0.8701 - recall_m: 0.8186 - f1_m: 0.8423 - val_loss: 0.2378 - val_accuracy: 0.6826 - val_precision_m: 0.8453 - val_recall_m: 0.7848 - val_f1_m: 0.8127\n","Epoch 15/50\n","131/131 [==============================] - 1s 9ms/step - loss: 0.2259 - accuracy: 0.6323 - precision_m: 0.8776 - recall_m: 0.8237 - f1_m: 0.8488 - val_loss: 0.2389 - val_accuracy: 0.6988 - val_precision_m: 0.8296 - val_recall_m: 0.8010 - val_f1_m: 0.8136\n","Epoch 16/50\n","131/131 [==============================] - 1s 9ms/step - loss: 0.2212 - accuracy: 0.6442 - precision_m: 0.8772 - recall_m: 0.8315 - f1_m: 0.8526 - val_loss: 0.2396 - val_accuracy: 0.7073 - val_precision_m: 0.8297 - val_recall_m: 0.8075 - val_f1_m: 0.8172\n","Epoch 17/50\n","131/131 [==============================] - 1s 9ms/step - loss: 0.2158 - accuracy: 0.6478 - precision_m: 0.8792 - recall_m: 0.8322 - f1_m: 0.8541 - val_loss: 0.2399 - val_accuracy: 0.6997 - val_precision_m: 0.8343 - val_recall_m: 0.8076 - val_f1_m: 0.8194\n","Epoch 18/50\n","131/131 [==============================] - 1s 9ms/step - loss: 0.2092 - accuracy: 0.6694 - precision_m: 0.8885 - recall_m: 0.8311 - f1_m: 0.8579 - val_loss: 0.2452 - val_accuracy: 0.7083 - val_precision_m: 0.8335 - val_recall_m: 0.8044 - val_f1_m: 0.8175\n","Epoch 19/50\n","131/131 [==============================] - 1s 9ms/step - loss: 0.2140 - accuracy: 0.6490 - precision_m: 0.8807 - recall_m: 0.8372 - f1_m: 0.8575 - val_loss: 0.2361 - val_accuracy: 0.6911 - val_precision_m: 0.8527 - val_recall_m: 0.7832 - val_f1_m: 0.8152\n","Epoch 20/50\n","131/131 [==============================] - 1s 9ms/step - loss: 0.2056 - accuracy: 0.6556 - precision_m: 0.8850 - recall_m: 0.8408 - f1_m: 0.8615 - val_loss: 0.2337 - val_accuracy: 0.6949 - val_precision_m: 0.8492 - val_recall_m: 0.7837 - val_f1_m: 0.8140\n","Epoch 21/50\n","131/131 [==============================] - 1s 9ms/step - loss: 0.2075 - accuracy: 0.6496 - precision_m: 0.8893 - recall_m: 0.8371 - f1_m: 0.8615 - val_loss: 0.2367 - val_accuracy: 0.7131 - val_precision_m: 0.8370 - val_recall_m: 0.7976 - val_f1_m: 0.8155\n","Epoch 22/50\n","131/131 [==============================] - 1s 10ms/step - loss: 0.2010 - accuracy: 0.6580 - precision_m: 0.8933 - recall_m: 0.8416 - f1_m: 0.8655 - val_loss: 0.2412 - val_accuracy: 0.7140 - val_precision_m: 0.8402 - val_recall_m: 0.7929 - val_f1_m: 0.8146\n","Epoch 23/50\n","131/131 [==============================] - 1s 9ms/step - loss: 0.1953 - accuracy: 0.6532 - precision_m: 0.8993 - recall_m: 0.8438 - f1_m: 0.8696 - val_loss: 0.2443 - val_accuracy: 0.7064 - val_precision_m: 0.8324 - val_recall_m: 0.7962 - val_f1_m: 0.8123\n","Epoch 24/50\n","131/131 [==============================] - 1s 9ms/step - loss: 0.2004 - accuracy: 0.6523 - precision_m: 0.8976 - recall_m: 0.8481 - f1_m: 0.8714 - val_loss: 0.2378 - val_accuracy: 0.7007 - val_precision_m: 0.8362 - val_recall_m: 0.7990 - val_f1_m: 0.8154\n","Epoch 25/50\n","131/131 [==============================] - 1s 10ms/step - loss: 0.1865 - accuracy: 0.6470 - precision_m: 0.9024 - recall_m: 0.8607 - f1_m: 0.8802 - val_loss: 0.2374 - val_accuracy: 0.6911 - val_precision_m: 0.8474 - val_recall_m: 0.7807 - val_f1_m: 0.8111\n","Epoch 26/50\n","131/131 [==============================] - 1s 9ms/step - loss: 0.1914 - accuracy: 0.6427 - precision_m: 0.8963 - recall_m: 0.8551 - f1_m: 0.8746 - val_loss: 0.2372 - val_accuracy: 0.7016 - val_precision_m: 0.8424 - val_recall_m: 0.7895 - val_f1_m: 0.8136\n","Epoch 27/50\n","131/131 [==============================] - 1s 9ms/step - loss: 0.1704 - accuracy: 0.6730 - precision_m: 0.9100 - recall_m: 0.8782 - f1_m: 0.8933 - val_loss: 0.2434 - val_accuracy: 0.6816 - val_precision_m: 0.8230 - val_recall_m: 0.8017 - val_f1_m: 0.8105\n","Epoch 00027: early stopping\n","Score for fold 2: loss of 0.31089967489242554; accuracy of 65.83969593048096% ;precision_m of 0.7949449419975281 ;recall_m of 0.7859727144241333 ;            f1_m of 0.7889469265937805\n","Epoch 1/50\n","131/131 [==============================] - 2s 11ms/step - loss: 0.5472 - accuracy: 0.3815 - precision_m: 0.6159 - recall_m: 0.3893 - f1_m: 0.4669 - val_loss: 0.3479 - val_accuracy: 0.6301 - val_precision_m: 0.7774 - val_recall_m: 0.6980 - val_f1_m: 0.7340\n","Epoch 2/50\n","131/131 [==============================] - 1s 9ms/step - loss: 0.3734 - accuracy: 0.5673 - precision_m: 0.7792 - recall_m: 0.6783 - f1_m: 0.7231 - val_loss: 0.3231 - val_accuracy: 0.6768 - val_precision_m: 0.7791 - val_recall_m: 0.7614 - val_f1_m: 0.7683\n","Epoch 3/50\n","131/131 [==============================] - 1s 9ms/step - loss: 0.3249 - accuracy: 0.5906 - precision_m: 0.8159 - recall_m: 0.7387 - f1_m: 0.7740 - val_loss: 0.3086 - val_accuracy: 0.6673 - val_precision_m: 0.7813 - val_recall_m: 0.7528 - val_f1_m: 0.7647\n","Epoch 4/50\n","131/131 [==============================] - 1s 9ms/step - loss: 0.3248 - accuracy: 0.5804 - precision_m: 0.8191 - recall_m: 0.7382 - f1_m: 0.7749 - val_loss: 0.2891 - val_accuracy: 0.6806 - val_precision_m: 0.8177 - val_recall_m: 0.7342 - val_f1_m: 0.7718\n","Epoch 5/50\n","131/131 [==============================] - 1s 9ms/step - loss: 0.3004 - accuracy: 0.5881 - precision_m: 0.8366 - recall_m: 0.7659 - f1_m: 0.7982 - val_loss: 0.2891 - val_accuracy: 0.6721 - val_precision_m: 0.8183 - val_recall_m: 0.7451 - val_f1_m: 0.7778\n","Epoch 6/50\n","131/131 [==============================] - 1s 9ms/step - loss: 0.2965 - accuracy: 0.5844 - precision_m: 0.8443 - recall_m: 0.7728 - f1_m: 0.8057 - val_loss: 0.2892 - val_accuracy: 0.6845 - val_precision_m: 0.8104 - val_recall_m: 0.7627 - val_f1_m: 0.7835\n","Epoch 7/50\n","131/131 [==============================] - 1s 9ms/step - loss: 0.2857 - accuracy: 0.6020 - precision_m: 0.8454 - recall_m: 0.7765 - f1_m: 0.8081 - val_loss: 0.2973 - val_accuracy: 0.6930 - val_precision_m: 0.8076 - val_recall_m: 0.7554 - val_f1_m: 0.7788\n","Epoch 8/50\n","131/131 [==============================] - 1s 10ms/step - loss: 0.2862 - accuracy: 0.6073 - precision_m: 0.8390 - recall_m: 0.7786 - f1_m: 0.8063 - val_loss: 0.2928 - val_accuracy: 0.6921 - val_precision_m: 0.8109 - val_recall_m: 0.7417 - val_f1_m: 0.7727\n","Epoch 9/50\n","131/131 [==============================] - 1s 9ms/step - loss: 0.2723 - accuracy: 0.5981 - precision_m: 0.8498 - recall_m: 0.7893 - f1_m: 0.8173 - val_loss: 0.2954 - val_accuracy: 0.6892 - val_precision_m: 0.7855 - val_recall_m: 0.7771 - val_f1_m: 0.7793\n","Epoch 10/50\n","131/131 [==============================] - 1s 9ms/step - loss: 0.2685 - accuracy: 0.6005 - precision_m: 0.8531 - recall_m: 0.8009 - f1_m: 0.8248 - val_loss: 0.2822 - val_accuracy: 0.6883 - val_precision_m: 0.8311 - val_recall_m: 0.7312 - val_f1_m: 0.7761\n","Epoch 11/50\n","131/131 [==============================] - 1s 9ms/step - loss: 0.2632 - accuracy: 0.6143 - precision_m: 0.8653 - recall_m: 0.7857 - f1_m: 0.8225 - val_loss: 0.2771 - val_accuracy: 0.6854 - val_precision_m: 0.8367 - val_recall_m: 0.7491 - val_f1_m: 0.7884\n","Epoch 12/50\n","131/131 [==============================] - 1s 9ms/step - loss: 0.2495 - accuracy: 0.6271 - precision_m: 0.8731 - recall_m: 0.8111 - f1_m: 0.8398 - val_loss: 0.2937 - val_accuracy: 0.6759 - val_precision_m: 0.8167 - val_recall_m: 0.7320 - val_f1_m: 0.7699\n","Epoch 13/50\n","131/131 [==============================] - 1s 9ms/step - loss: 0.2517 - accuracy: 0.6266 - precision_m: 0.8699 - recall_m: 0.8040 - f1_m: 0.8348 - val_loss: 0.2819 - val_accuracy: 0.6873 - val_precision_m: 0.8171 - val_recall_m: 0.7623 - val_f1_m: 0.7868\n","Epoch 14/50\n","131/131 [==============================] - 1s 9ms/step - loss: 0.2494 - accuracy: 0.5947 - precision_m: 0.8740 - recall_m: 0.8109 - f1_m: 0.8401 - val_loss: 0.2868 - val_accuracy: 0.7007 - val_precision_m: 0.8150 - val_recall_m: 0.7494 - val_f1_m: 0.7791\n","Epoch 15/50\n","131/131 [==============================] - 1s 9ms/step - loss: 0.2373 - accuracy: 0.6120 - precision_m: 0.8748 - recall_m: 0.8154 - f1_m: 0.8430 - val_loss: 0.2917 - val_accuracy: 0.6892 - val_precision_m: 0.8334 - val_recall_m: 0.7210 - val_f1_m: 0.7709\n","Epoch 16/50\n","131/131 [==============================] - 1s 9ms/step - loss: 0.2373 - accuracy: 0.6163 - precision_m: 0.8836 - recall_m: 0.8192 - f1_m: 0.8492 - val_loss: 0.2883 - val_accuracy: 0.7102 - val_precision_m: 0.8169 - val_recall_m: 0.7519 - val_f1_m: 0.7810\n","Epoch 17/50\n","131/131 [==============================] - 1s 9ms/step - loss: 0.2282 - accuracy: 0.6315 - precision_m: 0.8851 - recall_m: 0.8309 - f1_m: 0.8561 - val_loss: 0.2837 - val_accuracy: 0.6911 - val_precision_m: 0.8304 - val_recall_m: 0.7505 - val_f1_m: 0.7866\n","Epoch 18/50\n","131/131 [==============================] - 1s 9ms/step - loss: 0.2243 - accuracy: 0.6185 - precision_m: 0.8849 - recall_m: 0.8225 - f1_m: 0.8518 - val_loss: 0.2893 - val_accuracy: 0.7073 - val_precision_m: 0.8193 - val_recall_m: 0.7589 - val_f1_m: 0.7855\n","Epoch 19/50\n","131/131 [==============================] - 1s 9ms/step - loss: 0.2171 - accuracy: 0.6318 - precision_m: 0.8850 - recall_m: 0.8392 - f1_m: 0.8605 - val_loss: 0.2885 - val_accuracy: 0.6978 - val_precision_m: 0.8026 - val_recall_m: 0.7790 - val_f1_m: 0.7887\n","Epoch 20/50\n","131/131 [==============================] - 1s 9ms/step - loss: 0.2120 - accuracy: 0.6206 - precision_m: 0.8866 - recall_m: 0.8334 - f1_m: 0.8582 - val_loss: 0.2831 - val_accuracy: 0.6911 - val_precision_m: 0.8220 - val_recall_m: 0.7504 - val_f1_m: 0.7827\n","Epoch 21/50\n","131/131 [==============================] - 1s 9ms/step - loss: 0.2137 - accuracy: 0.6295 - precision_m: 0.8908 - recall_m: 0.8386 - f1_m: 0.8629 - val_loss: 0.2860 - val_accuracy: 0.7092 - val_precision_m: 0.8242 - val_recall_m: 0.7529 - val_f1_m: 0.7849\n","Epoch 22/50\n","131/131 [==============================] - 1s 9ms/step - loss: 0.2051 - accuracy: 0.6394 - precision_m: 0.9016 - recall_m: 0.8402 - f1_m: 0.8691 - val_loss: 0.2839 - val_accuracy: 0.7140 - val_precision_m: 0.8356 - val_recall_m: 0.7505 - val_f1_m: 0.7890\n","Epoch 23/50\n","131/131 [==============================] - 1s 9ms/step - loss: 0.2062 - accuracy: 0.6298 - precision_m: 0.8968 - recall_m: 0.8477 - f1_m: 0.8709 - val_loss: 0.2947 - val_accuracy: 0.7007 - val_precision_m: 0.8022 - val_recall_m: 0.7725 - val_f1_m: 0.7855\n","Epoch 24/50\n","131/131 [==============================] - 1s 9ms/step - loss: 0.2067 - accuracy: 0.6346 - precision_m: 0.8967 - recall_m: 0.8486 - f1_m: 0.8709 - val_loss: 0.2849 - val_accuracy: 0.7188 - val_precision_m: 0.8294 - val_recall_m: 0.7652 - val_f1_m: 0.7940\n","Epoch 25/50\n","131/131 [==============================] - 1s 9ms/step - loss: 0.1985 - accuracy: 0.6374 - precision_m: 0.9000 - recall_m: 0.8514 - f1_m: 0.8742 - val_loss: 0.2883 - val_accuracy: 0.7121 - val_precision_m: 0.8249 - val_recall_m: 0.7519 - val_f1_m: 0.7849\n","Epoch 26/50\n","131/131 [==============================] - 1s 9ms/step - loss: 0.2010 - accuracy: 0.6317 - precision_m: 0.8984 - recall_m: 0.8476 - f1_m: 0.8714 - val_loss: 0.2897 - val_accuracy: 0.7102 - val_precision_m: 0.8187 - val_recall_m: 0.7676 - val_f1_m: 0.7904\n","Epoch 27/50\n","131/131 [==============================] - 1s 9ms/step - loss: 0.1933 - accuracy: 0.6373 - precision_m: 0.8956 - recall_m: 0.8511 - f1_m: 0.8721 - val_loss: 0.2823 - val_accuracy: 0.7026 - val_precision_m: 0.8260 - val_recall_m: 0.7578 - val_f1_m: 0.7884\n","Epoch 28/50\n","131/131 [==============================] - 1s 9ms/step - loss: 0.1842 - accuracy: 0.6461 - precision_m: 0.9050 - recall_m: 0.8615 - f1_m: 0.8819 - val_loss: 0.2896 - val_accuracy: 0.6940 - val_precision_m: 0.8223 - val_recall_m: 0.7565 - val_f1_m: 0.7863\n","Epoch 29/50\n","131/131 [==============================] - 1s 9ms/step - loss: 0.1910 - accuracy: 0.6480 - precision_m: 0.9036 - recall_m: 0.8630 - f1_m: 0.8819 - val_loss: 0.2858 - val_accuracy: 0.7073 - val_precision_m: 0.8196 - val_recall_m: 0.7824 - val_f1_m: 0.7988\n","Epoch 30/50\n","131/131 [==============================] - 1s 9ms/step - loss: 0.1849 - accuracy: 0.6587 - precision_m: 0.8998 - recall_m: 0.8644 - f1_m: 0.8805 - val_loss: 0.2891 - val_accuracy: 0.7083 - val_precision_m: 0.8334 - val_recall_m: 0.7384 - val_f1_m: 0.7811\n","Epoch 31/50\n","131/131 [==============================] - 1s 9ms/step - loss: 0.1791 - accuracy: 0.6291 - precision_m: 0.9132 - recall_m: 0.8700 - f1_m: 0.8901 - val_loss: 0.3002 - val_accuracy: 0.7121 - val_precision_m: 0.8126 - val_recall_m: 0.7540 - val_f1_m: 0.7801\n","Epoch 32/50\n","131/131 [==============================] - 1s 9ms/step - loss: 0.1741 - accuracy: 0.6473 - precision_m: 0.9201 - recall_m: 0.8745 - f1_m: 0.8957 - val_loss: 0.2860 - val_accuracy: 0.7092 - val_precision_m: 0.8170 - val_recall_m: 0.7632 - val_f1_m: 0.7873\n","Epoch 33/50\n","131/131 [==============================] - 1s 9ms/step - loss: 0.1824 - accuracy: 0.6434 - precision_m: 0.9103 - recall_m: 0.8663 - f1_m: 0.8871 - val_loss: 0.3006 - val_accuracy: 0.7178 - val_precision_m: 0.8023 - val_recall_m: 0.7752 - val_f1_m: 0.7861\n","Epoch 34/50\n","131/131 [==============================] - 1s 9ms/step - loss: 0.1668 - accuracy: 0.6547 - precision_m: 0.9112 - recall_m: 0.8822 - f1_m: 0.8957 - val_loss: 0.2972 - val_accuracy: 0.7083 - val_precision_m: 0.8131 - val_recall_m: 0.7632 - val_f1_m: 0.7859\n","Epoch 35/50\n","131/131 [==============================] - 1s 9ms/step - loss: 0.1673 - accuracy: 0.6448 - precision_m: 0.9219 - recall_m: 0.8815 - f1_m: 0.9007 - val_loss: 0.2883 - val_accuracy: 0.7102 - val_precision_m: 0.8278 - val_recall_m: 0.7570 - val_f1_m: 0.7894\n","Epoch 36/50\n","131/131 [==============================] - 1s 9ms/step - loss: 0.1611 - accuracy: 0.6644 - precision_m: 0.9222 - recall_m: 0.8803 - f1_m: 0.8999 - val_loss: 0.2939 - val_accuracy: 0.7092 - val_precision_m: 0.8207 - val_recall_m: 0.7497 - val_f1_m: 0.7822\n","Epoch 37/50\n","131/131 [==============================] - 1s 9ms/step - loss: 0.1585 - accuracy: 0.6475 - precision_m: 0.9220 - recall_m: 0.8882 - f1_m: 0.9042 - val_loss: 0.2909 - val_accuracy: 0.6997 - val_precision_m: 0.8138 - val_recall_m: 0.7576 - val_f1_m: 0.7831\n","Epoch 38/50\n","131/131 [==============================] - 1s 9ms/step - loss: 0.1607 - accuracy: 0.6425 - precision_m: 0.9233 - recall_m: 0.8858 - f1_m: 0.9036 - val_loss: 0.3093 - val_accuracy: 0.7216 - val_precision_m: 0.8015 - val_recall_m: 0.7564 - val_f1_m: 0.7764\n","Epoch 39/50\n","131/131 [==============================] - 1s 9ms/step - loss: 0.1587 - accuracy: 0.6688 - precision_m: 0.9247 - recall_m: 0.8871 - f1_m: 0.9049 - val_loss: 0.2888 - val_accuracy: 0.7035 - val_precision_m: 0.8191 - val_recall_m: 0.7561 - val_f1_m: 0.7848\n","Epoch 00039: early stopping\n","Score for fold 3: loss of 0.2760048806667328; accuracy of 67.21373796463013% ;precision_m of 0.8222029805183411 ;recall_m of 0.7454102039337158 ;            f1_m of 0.7801487445831299\n","Epoch 1/50\n","131/131 [==============================] - 2s 8ms/step - loss: 0.5623 - accuracy: 0.3956 - precision_m: 0.5613 - recall_m: 0.4612 - f1_m: 0.4983 - val_loss: 0.3112 - val_accuracy: 0.6059 - val_precision_m: 0.7845 - val_recall_m: 0.6821 - val_f1_m: 0.7276\n","Epoch 2/50\n","131/131 [==============================] - 1s 6ms/step - loss: 0.3707 - accuracy: 0.5507 - precision_m: 0.7498 - recall_m: 0.6390 - f1_m: 0.6879 - val_loss: 0.2982 - val_accuracy: 0.6422 - val_precision_m: 0.8113 - val_recall_m: 0.7001 - val_f1_m: 0.7497\n","Epoch 3/50\n","131/131 [==============================] - 1s 6ms/step - loss: 0.3362 - accuracy: 0.5792 - precision_m: 0.7854 - recall_m: 0.6712 - f1_m: 0.7218 - val_loss: 0.2800 - val_accuracy: 0.6441 - val_precision_m: 0.8012 - val_recall_m: 0.7306 - val_f1_m: 0.7627\n","Epoch 4/50\n","131/131 [==============================] - 1s 5ms/step - loss: 0.3291 - accuracy: 0.5778 - precision_m: 0.7825 - recall_m: 0.6901 - f1_m: 0.7320 - val_loss: 0.2841 - val_accuracy: 0.6307 - val_precision_m: 0.8057 - val_recall_m: 0.7351 - val_f1_m: 0.7671\n","Epoch 5/50\n","131/131 [==============================] - 1s 6ms/step - loss: 0.3089 - accuracy: 0.6029 - precision_m: 0.7974 - recall_m: 0.7089 - f1_m: 0.7485 - val_loss: 0.2728 - val_accuracy: 0.6288 - val_precision_m: 0.8099 - val_recall_m: 0.7342 - val_f1_m: 0.7685\n","Epoch 6/50\n","131/131 [==============================] - 1s 6ms/step - loss: 0.3104 - accuracy: 0.5912 - precision_m: 0.8005 - recall_m: 0.7005 - f1_m: 0.7456 - val_loss: 0.2769 - val_accuracy: 0.6469 - val_precision_m: 0.8047 - val_recall_m: 0.7380 - val_f1_m: 0.7684\n","Epoch 7/50\n","131/131 [==============================] - 1s 6ms/step - loss: 0.2998 - accuracy: 0.6051 - precision_m: 0.8039 - recall_m: 0.7172 - f1_m: 0.7564 - val_loss: 0.2691 - val_accuracy: 0.6489 - val_precision_m: 0.8191 - val_recall_m: 0.7359 - val_f1_m: 0.7736\n","Epoch 8/50\n","131/131 [==============================] - 1s 6ms/step - loss: 0.2943 - accuracy: 0.6119 - precision_m: 0.8215 - recall_m: 0.7203 - f1_m: 0.7664 - val_loss: 0.2758 - val_accuracy: 0.6479 - val_precision_m: 0.8092 - val_recall_m: 0.7583 - val_f1_m: 0.7816\n","Epoch 9/50\n","131/131 [==============================] - 1s 6ms/step - loss: 0.2890 - accuracy: 0.6062 - precision_m: 0.8231 - recall_m: 0.7288 - f1_m: 0.7707 - val_loss: 0.2688 - val_accuracy: 0.6393 - val_precision_m: 0.8085 - val_recall_m: 0.7574 - val_f1_m: 0.7805\n","Epoch 10/50\n","131/131 [==============================] - 1s 6ms/step - loss: 0.2820 - accuracy: 0.6200 - precision_m: 0.8228 - recall_m: 0.7356 - f1_m: 0.7753 - val_loss: 0.2736 - val_accuracy: 0.6708 - val_precision_m: 0.8038 - val_recall_m: 0.7563 - val_f1_m: 0.7779\n","Epoch 11/50\n","131/131 [==============================] - 1s 6ms/step - loss: 0.2727 - accuracy: 0.6211 - precision_m: 0.8313 - recall_m: 0.7389 - f1_m: 0.7808 - val_loss: 0.2688 - val_accuracy: 0.6508 - val_precision_m: 0.8218 - val_recall_m: 0.7259 - val_f1_m: 0.7693\n","Epoch 12/50\n","131/131 [==============================] - 1s 6ms/step - loss: 0.2770 - accuracy: 0.6293 - precision_m: 0.8327 - recall_m: 0.7444 - f1_m: 0.7846 - val_loss: 0.2649 - val_accuracy: 0.6613 - val_precision_m: 0.8155 - val_recall_m: 0.7434 - val_f1_m: 0.7762\n","Epoch 13/50\n","131/131 [==============================] - 1s 6ms/step - loss: 0.2693 - accuracy: 0.6290 - precision_m: 0.8351 - recall_m: 0.7541 - f1_m: 0.7912 - val_loss: 0.2642 - val_accuracy: 0.6689 - val_precision_m: 0.8219 - val_recall_m: 0.7562 - val_f1_m: 0.7864\n","Epoch 14/50\n","131/131 [==============================] - 1s 6ms/step - loss: 0.2634 - accuracy: 0.6408 - precision_m: 0.8365 - recall_m: 0.7549 - f1_m: 0.7924 - val_loss: 0.2673 - val_accuracy: 0.6651 - val_precision_m: 0.8325 - val_recall_m: 0.7415 - val_f1_m: 0.7832\n","Epoch 15/50\n","131/131 [==============================] - 1s 6ms/step - loss: 0.2708 - accuracy: 0.6340 - precision_m: 0.8386 - recall_m: 0.7431 - f1_m: 0.7866 - val_loss: 0.2614 - val_accuracy: 0.6498 - val_precision_m: 0.8164 - val_recall_m: 0.7517 - val_f1_m: 0.7817\n","Epoch 16/50\n","131/131 [==============================] - 1s 6ms/step - loss: 0.2560 - accuracy: 0.6334 - precision_m: 0.8472 - recall_m: 0.7618 - f1_m: 0.8012 - val_loss: 0.2641 - val_accuracy: 0.6765 - val_precision_m: 0.8040 - val_recall_m: 0.7813 - val_f1_m: 0.7913\n","Epoch 17/50\n","131/131 [==============================] - 1s 6ms/step - loss: 0.2587 - accuracy: 0.6332 - precision_m: 0.8373 - recall_m: 0.7606 - f1_m: 0.7962 - val_loss: 0.2606 - val_accuracy: 0.6594 - val_precision_m: 0.8328 - val_recall_m: 0.7461 - val_f1_m: 0.7858\n","Epoch 18/50\n","131/131 [==============================] - 1s 6ms/step - loss: 0.2515 - accuracy: 0.6355 - precision_m: 0.8537 - recall_m: 0.7712 - f1_m: 0.8095 - val_loss: 0.2650 - val_accuracy: 0.6517 - val_precision_m: 0.8074 - val_recall_m: 0.7704 - val_f1_m: 0.7870\n","Epoch 19/50\n","131/131 [==============================] - 1s 6ms/step - loss: 0.2549 - accuracy: 0.6390 - precision_m: 0.8343 - recall_m: 0.7680 - f1_m: 0.7979 - val_loss: 0.2633 - val_accuracy: 0.6594 - val_precision_m: 0.8093 - val_recall_m: 0.7736 - val_f1_m: 0.7899\n","Epoch 20/50\n","131/131 [==============================] - 1s 6ms/step - loss: 0.2473 - accuracy: 0.6536 - precision_m: 0.8517 - recall_m: 0.7741 - f1_m: 0.8100 - val_loss: 0.2614 - val_accuracy: 0.6622 - val_precision_m: 0.8223 - val_recall_m: 0.7522 - val_f1_m: 0.7843\n","Epoch 21/50\n","131/131 [==============================] - 1s 6ms/step - loss: 0.2427 - accuracy: 0.6493 - precision_m: 0.8584 - recall_m: 0.7774 - f1_m: 0.8148 - val_loss: 0.2636 - val_accuracy: 0.6737 - val_precision_m: 0.8163 - val_recall_m: 0.7442 - val_f1_m: 0.7770\n","Epoch 22/50\n","131/131 [==============================] - 1s 6ms/step - loss: 0.2386 - accuracy: 0.6398 - precision_m: 0.8595 - recall_m: 0.7816 - f1_m: 0.8174 - val_loss: 0.2642 - val_accuracy: 0.6632 - val_precision_m: 0.8134 - val_recall_m: 0.7570 - val_f1_m: 0.7831\n","Epoch 23/50\n","131/131 [==============================] - 1s 6ms/step - loss: 0.2411 - accuracy: 0.6368 - precision_m: 0.8487 - recall_m: 0.7733 - f1_m: 0.8081 - val_loss: 0.2669 - val_accuracy: 0.6708 - val_precision_m: 0.8159 - val_recall_m: 0.7512 - val_f1_m: 0.7808\n","Epoch 24/50\n","131/131 [==============================] - 1s 6ms/step - loss: 0.2350 - accuracy: 0.6514 - precision_m: 0.8610 - recall_m: 0.7825 - f1_m: 0.8187 - val_loss: 0.2618 - val_accuracy: 0.6679 - val_precision_m: 0.8119 - val_recall_m: 0.7618 - val_f1_m: 0.7848\n","Epoch 25/50\n","131/131 [==============================] - 1s 6ms/step - loss: 0.2328 - accuracy: 0.6410 - precision_m: 0.8584 - recall_m: 0.7864 - f1_m: 0.8193 - val_loss: 0.2626 - val_accuracy: 0.6412 - val_precision_m: 0.8122 - val_recall_m: 0.7581 - val_f1_m: 0.7826\n","Epoch 26/50\n","131/131 [==============================] - 1s 6ms/step - loss: 0.2330 - accuracy: 0.6393 - precision_m: 0.8570 - recall_m: 0.7799 - f1_m: 0.8154 - val_loss: 0.2647 - val_accuracy: 0.6365 - val_precision_m: 0.8055 - val_recall_m: 0.7667 - val_f1_m: 0.7844\n","Epoch 00026: early stopping\n","Score for fold 1: loss of 0.4286119341850281; accuracy of 48.721861839294434% ;precision_m of 0.8319126963615417 ;recall_m of 0.6588261127471924 ;            f1_m of 0.7322672009468079\n","Epoch 1/50\n","131/131 [==============================] - 2s 8ms/step - loss: 0.6053 - accuracy: 0.4151 - precision_m: 0.5735 - recall_m: 0.4800 - f1_m: 0.5178 - val_loss: 0.3334 - val_accuracy: 0.6559 - val_precision_m: 0.7673 - val_recall_m: 0.7175 - val_f1_m: 0.7393\n","Epoch 2/50\n","131/131 [==============================] - 1s 6ms/step - loss: 0.3907 - accuracy: 0.5468 - precision_m: 0.7597 - recall_m: 0.6663 - f1_m: 0.7083 - val_loss: 0.3097 - val_accuracy: 0.6616 - val_precision_m: 0.7744 - val_recall_m: 0.7460 - val_f1_m: 0.7586\n","Epoch 3/50\n","131/131 [==============================] - 1s 6ms/step - loss: 0.3519 - accuracy: 0.5840 - precision_m: 0.7887 - recall_m: 0.7067 - f1_m: 0.7440 - val_loss: 0.2936 - val_accuracy: 0.6692 - val_precision_m: 0.7964 - val_recall_m: 0.7263 - val_f1_m: 0.7581\n","Epoch 4/50\n","131/131 [==============================] - 1s 6ms/step - loss: 0.3359 - accuracy: 0.5754 - precision_m: 0.7993 - recall_m: 0.7196 - f1_m: 0.7559 - val_loss: 0.2897 - val_accuracy: 0.6654 - val_precision_m: 0.7891 - val_recall_m: 0.7512 - val_f1_m: 0.7672\n","Epoch 5/50\n","131/131 [==============================] - 1s 6ms/step - loss: 0.3307 - accuracy: 0.5689 - precision_m: 0.8049 - recall_m: 0.7207 - f1_m: 0.7594 - val_loss: 0.2898 - val_accuracy: 0.6683 - val_precision_m: 0.7847 - val_recall_m: 0.7622 - val_f1_m: 0.7714\n","Epoch 6/50\n","131/131 [==============================] - 1s 6ms/step - loss: 0.3249 - accuracy: 0.5747 - precision_m: 0.8079 - recall_m: 0.7350 - f1_m: 0.7680 - val_loss: 0.2764 - val_accuracy: 0.6759 - val_precision_m: 0.8107 - val_recall_m: 0.7416 - val_f1_m: 0.7731\n","Epoch 7/50\n","131/131 [==============================] - 1s 6ms/step - loss: 0.3147 - accuracy: 0.5680 - precision_m: 0.8165 - recall_m: 0.7388 - f1_m: 0.7742 - val_loss: 0.2743 - val_accuracy: 0.6826 - val_precision_m: 0.8009 - val_recall_m: 0.7543 - val_f1_m: 0.7750\n","Epoch 8/50\n","131/131 [==============================] - 1s 6ms/step - loss: 0.3068 - accuracy: 0.5832 - precision_m: 0.8243 - recall_m: 0.7557 - f1_m: 0.7872 - val_loss: 0.2692 - val_accuracy: 0.6559 - val_precision_m: 0.8109 - val_recall_m: 0.7386 - val_f1_m: 0.7712\n","Epoch 9/50\n","131/131 [==============================] - 1s 6ms/step - loss: 0.3069 - accuracy: 0.5904 - precision_m: 0.8239 - recall_m: 0.7542 - f1_m: 0.7864 - val_loss: 0.2706 - val_accuracy: 0.6683 - val_precision_m: 0.8218 - val_recall_m: 0.7212 - val_f1_m: 0.7665\n","Epoch 10/50\n","131/131 [==============================] - 1s 6ms/step - loss: 0.3080 - accuracy: 0.5766 - precision_m: 0.8258 - recall_m: 0.7401 - f1_m: 0.7790 - val_loss: 0.2703 - val_accuracy: 0.6806 - val_precision_m: 0.8108 - val_recall_m: 0.7635 - val_f1_m: 0.7850\n","Epoch 11/50\n","131/131 [==============================] - 1s 6ms/step - loss: 0.2925 - accuracy: 0.5848 - precision_m: 0.8278 - recall_m: 0.7658 - f1_m: 0.7942 - val_loss: 0.2648 - val_accuracy: 0.6911 - val_precision_m: 0.8223 - val_recall_m: 0.7578 - val_f1_m: 0.7872\n","Epoch 12/50\n","131/131 [==============================] - 1s 6ms/step - loss: 0.2909 - accuracy: 0.5846 - precision_m: 0.8370 - recall_m: 0.7580 - f1_m: 0.7941 - val_loss: 0.2677 - val_accuracy: 0.6673 - val_precision_m: 0.8216 - val_recall_m: 0.7425 - val_f1_m: 0.7789\n","Epoch 13/50\n","131/131 [==============================] - 1s 6ms/step - loss: 0.2943 - accuracy: 0.5970 - precision_m: 0.8343 - recall_m: 0.7659 - f1_m: 0.7976 - val_loss: 0.2688 - val_accuracy: 0.6740 - val_precision_m: 0.8309 - val_recall_m: 0.7353 - val_f1_m: 0.7786\n","Epoch 14/50\n","131/131 [==============================] - 1s 6ms/step - loss: 0.2739 - accuracy: 0.6058 - precision_m: 0.8498 - recall_m: 0.7708 - f1_m: 0.8072 - val_loss: 0.2705 - val_accuracy: 0.6911 - val_precision_m: 0.8147 - val_recall_m: 0.7498 - val_f1_m: 0.7793\n","Epoch 15/50\n","131/131 [==============================] - 1s 6ms/step - loss: 0.2851 - accuracy: 0.6040 - precision_m: 0.8472 - recall_m: 0.7673 - f1_m: 0.8039 - val_loss: 0.2758 - val_accuracy: 0.6845 - val_precision_m: 0.8108 - val_recall_m: 0.7661 - val_f1_m: 0.7861\n","Epoch 16/50\n","131/131 [==============================] - 1s 6ms/step - loss: 0.2765 - accuracy: 0.5944 - precision_m: 0.8486 - recall_m: 0.7814 - f1_m: 0.8128 - val_loss: 0.2643 - val_accuracy: 0.6749 - val_precision_m: 0.8158 - val_recall_m: 0.7339 - val_f1_m: 0.7712\n","Epoch 17/50\n","131/131 [==============================] - 1s 6ms/step - loss: 0.2729 - accuracy: 0.5952 - precision_m: 0.8528 - recall_m: 0.7716 - f1_m: 0.8093 - val_loss: 0.2624 - val_accuracy: 0.6797 - val_precision_m: 0.8165 - val_recall_m: 0.7708 - val_f1_m: 0.7914\n","Epoch 18/50\n","131/131 [==============================] - 1s 6ms/step - loss: 0.2644 - accuracy: 0.6099 - precision_m: 0.8505 - recall_m: 0.7857 - f1_m: 0.8158 - val_loss: 0.2678 - val_accuracy: 0.6873 - val_precision_m: 0.8246 - val_recall_m: 0.7581 - val_f1_m: 0.7884\n","Epoch 19/50\n","131/131 [==============================] - 1s 6ms/step - loss: 0.2673 - accuracy: 0.6113 - precision_m: 0.8523 - recall_m: 0.7801 - f1_m: 0.8137 - val_loss: 0.2591 - val_accuracy: 0.6883 - val_precision_m: 0.8190 - val_recall_m: 0.7528 - val_f1_m: 0.7833\n","Epoch 20/50\n","131/131 [==============================] - 1s 6ms/step - loss: 0.2627 - accuracy: 0.6133 - precision_m: 0.8569 - recall_m: 0.7918 - f1_m: 0.8221 - val_loss: 0.2598 - val_accuracy: 0.6892 - val_precision_m: 0.8322 - val_recall_m: 0.7421 - val_f1_m: 0.7829\n","Epoch 21/50\n","131/131 [==============================] - 1s 6ms/step - loss: 0.2622 - accuracy: 0.5879 - precision_m: 0.8510 - recall_m: 0.7858 - f1_m: 0.8160 - val_loss: 0.2586 - val_accuracy: 0.6721 - val_precision_m: 0.8183 - val_recall_m: 0.7587 - val_f1_m: 0.7861\n","Epoch 22/50\n","131/131 [==============================] - 1s 6ms/step - loss: 0.2655 - accuracy: 0.6079 - precision_m: 0.8552 - recall_m: 0.7928 - f1_m: 0.8216 - val_loss: 0.2663 - val_accuracy: 0.6969 - val_precision_m: 0.8110 - val_recall_m: 0.7857 - val_f1_m: 0.7968\n","Epoch 23/50\n","131/131 [==============================] - 1s 6ms/step - loss: 0.2606 - accuracy: 0.6214 - precision_m: 0.8615 - recall_m: 0.7931 - f1_m: 0.8251 - val_loss: 0.2584 - val_accuracy: 0.6759 - val_precision_m: 0.8343 - val_recall_m: 0.7475 - val_f1_m: 0.7875\n","Epoch 24/50\n","131/131 [==============================] - 1s 6ms/step - loss: 0.2596 - accuracy: 0.5944 - precision_m: 0.8585 - recall_m: 0.7937 - f1_m: 0.8237 - val_loss: 0.2591 - val_accuracy: 0.6873 - val_precision_m: 0.8388 - val_recall_m: 0.7329 - val_f1_m: 0.7812\n","Epoch 25/50\n","131/131 [==============================] - 1s 6ms/step - loss: 0.2552 - accuracy: 0.5977 - precision_m: 0.8612 - recall_m: 0.7950 - f1_m: 0.8258 - val_loss: 0.2579 - val_accuracy: 0.6768 - val_precision_m: 0.8230 - val_recall_m: 0.7485 - val_f1_m: 0.7828\n","Epoch 26/50\n","131/131 [==============================] - 1s 6ms/step - loss: 0.2496 - accuracy: 0.6220 - precision_m: 0.8644 - recall_m: 0.7943 - f1_m: 0.8268 - val_loss: 0.2595 - val_accuracy: 0.6902 - val_precision_m: 0.8197 - val_recall_m: 0.7646 - val_f1_m: 0.7896\n","Epoch 27/50\n","131/131 [==============================] - 1s 6ms/step - loss: 0.2477 - accuracy: 0.6144 - precision_m: 0.8626 - recall_m: 0.8026 - f1_m: 0.8307 - val_loss: 0.2580 - val_accuracy: 0.6902 - val_precision_m: 0.8359 - val_recall_m: 0.7523 - val_f1_m: 0.7906\n","Epoch 28/50\n","131/131 [==============================] - 1s 6ms/step - loss: 0.2399 - accuracy: 0.6135 - precision_m: 0.8704 - recall_m: 0.8104 - f1_m: 0.8382 - val_loss: 0.2605 - val_accuracy: 0.6730 - val_precision_m: 0.8205 - val_recall_m: 0.7592 - val_f1_m: 0.7874\n","Epoch 29/50\n","131/131 [==============================] - 1s 6ms/step - loss: 0.2450 - accuracy: 0.6208 - precision_m: 0.8600 - recall_m: 0.8009 - f1_m: 0.8284 - val_loss: 0.2565 - val_accuracy: 0.6873 - val_precision_m: 0.8366 - val_recall_m: 0.7340 - val_f1_m: 0.7805\n","Epoch 30/50\n","131/131 [==============================] - 1s 6ms/step - loss: 0.2523 - accuracy: 0.6043 - precision_m: 0.8568 - recall_m: 0.8016 - f1_m: 0.8272 - val_loss: 0.2611 - val_accuracy: 0.6835 - val_precision_m: 0.8099 - val_recall_m: 0.7776 - val_f1_m: 0.7920\n","Epoch 31/50\n","131/131 [==============================] - 1s 6ms/step - loss: 0.2474 - accuracy: 0.6119 - precision_m: 0.8657 - recall_m: 0.8074 - f1_m: 0.8348 - val_loss: 0.2712 - val_accuracy: 0.6902 - val_precision_m: 0.8041 - val_recall_m: 0.7702 - val_f1_m: 0.7856\n","Epoch 32/50\n","131/131 [==============================] - 1s 6ms/step - loss: 0.2482 - accuracy: 0.6243 - precision_m: 0.8642 - recall_m: 0.8039 - f1_m: 0.8316 - val_loss: 0.2600 - val_accuracy: 0.6749 - val_precision_m: 0.8229 - val_recall_m: 0.7561 - val_f1_m: 0.7867\n","Epoch 00032: early stopping\n","Score for fold 2: loss of 0.3276568055152893; accuracy of 63.43511343002319% ;precision_m of 0.7955363392829895 ;recall_m of 0.7422977089881897 ;            f1_m of 0.7659164071083069\n","Epoch 1/50\n","131/131 [==============================] - 2s 8ms/step - loss: 0.6535 - accuracy: 0.3560 - precision_m: 0.5450 - recall_m: 0.4771 - f1_m: 0.5020 - val_loss: 0.3644 - val_accuracy: 0.6177 - val_precision_m: 0.7331 - val_recall_m: 0.6968 - val_f1_m: 0.7125\n","Epoch 2/50\n","131/131 [==============================] - 1s 6ms/step - loss: 0.3961 - accuracy: 0.5397 - precision_m: 0.7621 - recall_m: 0.6730 - f1_m: 0.7134 - val_loss: 0.3480 - val_accuracy: 0.6635 - val_precision_m: 0.7600 - val_recall_m: 0.6985 - val_f1_m: 0.7265\n","Epoch 3/50\n","131/131 [==============================] - 1s 6ms/step - loss: 0.3727 - accuracy: 0.5475 - precision_m: 0.7911 - recall_m: 0.6881 - f1_m: 0.7346 - val_loss: 0.3307 - val_accuracy: 0.6330 - val_precision_m: 0.7671 - val_recall_m: 0.7333 - val_f1_m: 0.7485\n","Epoch 4/50\n","131/131 [==============================] - 1s 6ms/step - loss: 0.3599 - accuracy: 0.5503 - precision_m: 0.7950 - recall_m: 0.7083 - f1_m: 0.7476 - val_loss: 0.3218 - val_accuracy: 0.6482 - val_precision_m: 0.7861 - val_recall_m: 0.7196 - val_f1_m: 0.7499\n","Epoch 5/50\n","131/131 [==============================] - 1s 6ms/step - loss: 0.3486 - accuracy: 0.5631 - precision_m: 0.7999 - recall_m: 0.7176 - f1_m: 0.7553 - val_loss: 0.3192 - val_accuracy: 0.6482 - val_precision_m: 0.7812 - val_recall_m: 0.7297 - val_f1_m: 0.7529\n","Epoch 6/50\n","131/131 [==============================] - 1s 6ms/step - loss: 0.3393 - accuracy: 0.5540 - precision_m: 0.8074 - recall_m: 0.7205 - f1_m: 0.7601 - val_loss: 0.3271 - val_accuracy: 0.6673 - val_precision_m: 0.7801 - val_recall_m: 0.7322 - val_f1_m: 0.7538\n","Epoch 7/50\n","131/131 [==============================] - 1s 6ms/step - loss: 0.3271 - accuracy: 0.5637 - precision_m: 0.8203 - recall_m: 0.7318 - f1_m: 0.7722 - val_loss: 0.3279 - val_accuracy: 0.6778 - val_precision_m: 0.7716 - val_recall_m: 0.7275 - val_f1_m: 0.7472\n","Epoch 8/50\n","131/131 [==============================] - 1s 6ms/step - loss: 0.3237 - accuracy: 0.5674 - precision_m: 0.8221 - recall_m: 0.7386 - f1_m: 0.7767 - val_loss: 0.3150 - val_accuracy: 0.6454 - val_precision_m: 0.7876 - val_recall_m: 0.7332 - val_f1_m: 0.7576\n","Epoch 9/50\n","131/131 [==============================] - 1s 6ms/step - loss: 0.3183 - accuracy: 0.5662 - precision_m: 0.8225 - recall_m: 0.7419 - f1_m: 0.7786 - val_loss: 0.3198 - val_accuracy: 0.6463 - val_precision_m: 0.7911 - val_recall_m: 0.7429 - val_f1_m: 0.7643\n","Epoch 10/50\n","131/131 [==============================] - 1s 6ms/step - loss: 0.3168 - accuracy: 0.5498 - precision_m: 0.8278 - recall_m: 0.7437 - f1_m: 0.7820 - val_loss: 0.3122 - val_accuracy: 0.6520 - val_precision_m: 0.7999 - val_recall_m: 0.7339 - val_f1_m: 0.7639\n","Epoch 11/50\n","131/131 [==============================] - 1s 6ms/step - loss: 0.3071 - accuracy: 0.5516 - precision_m: 0.8281 - recall_m: 0.7498 - f1_m: 0.7858 - val_loss: 0.3138 - val_accuracy: 0.6444 - val_precision_m: 0.7954 - val_recall_m: 0.7434 - val_f1_m: 0.7668\n","Epoch 12/50\n","131/131 [==============================] - 1s 6ms/step - loss: 0.3035 - accuracy: 0.5683 - precision_m: 0.8344 - recall_m: 0.7597 - f1_m: 0.7940 - val_loss: 0.3210 - val_accuracy: 0.6702 - val_precision_m: 0.8008 - val_recall_m: 0.7187 - val_f1_m: 0.7556\n","Epoch 13/50\n","131/131 [==============================] - 1s 6ms/step - loss: 0.3044 - accuracy: 0.5813 - precision_m: 0.8312 - recall_m: 0.7505 - f1_m: 0.7877 - val_loss: 0.3145 - val_accuracy: 0.6482 - val_precision_m: 0.7980 - val_recall_m: 0.7492 - val_f1_m: 0.7715\n","Epoch 14/50\n","131/131 [==============================] - 1s 6ms/step - loss: 0.2863 - accuracy: 0.5962 - precision_m: 0.8462 - recall_m: 0.7780 - f1_m: 0.8094 - val_loss: 0.3153 - val_accuracy: 0.6511 - val_precision_m: 0.7992 - val_recall_m: 0.7207 - val_f1_m: 0.7562\n","Epoch 15/50\n","131/131 [==============================] - 1s 6ms/step - loss: 0.2911 - accuracy: 0.5822 - precision_m: 0.8421 - recall_m: 0.7645 - f1_m: 0.8004 - val_loss: 0.3203 - val_accuracy: 0.6616 - val_precision_m: 0.8031 - val_recall_m: 0.7264 - val_f1_m: 0.7611\n","Epoch 16/50\n","131/131 [==============================] - 1s 6ms/step - loss: 0.2902 - accuracy: 0.5791 - precision_m: 0.8396 - recall_m: 0.7687 - f1_m: 0.8015 - val_loss: 0.3134 - val_accuracy: 0.6663 - val_precision_m: 0.7987 - val_recall_m: 0.7440 - val_f1_m: 0.7691\n","Epoch 17/50\n","131/131 [==============================] - 1s 6ms/step - loss: 0.2803 - accuracy: 0.5743 - precision_m: 0.8510 - recall_m: 0.7788 - f1_m: 0.8123 - val_loss: 0.3216 - val_accuracy: 0.6568 - val_precision_m: 0.7806 - val_recall_m: 0.7357 - val_f1_m: 0.7555\n","Epoch 18/50\n","131/131 [==============================] - 1s 6ms/step - loss: 0.2881 - accuracy: 0.5789 - precision_m: 0.8419 - recall_m: 0.7681 - f1_m: 0.8022 - val_loss: 0.3090 - val_accuracy: 0.6578 - val_precision_m: 0.8040 - val_recall_m: 0.7368 - val_f1_m: 0.7674\n","Epoch 19/50\n","131/131 [==============================] - 1s 6ms/step - loss: 0.2832 - accuracy: 0.5787 - precision_m: 0.8509 - recall_m: 0.7717 - f1_m: 0.8083 - val_loss: 0.3194 - val_accuracy: 0.6549 - val_precision_m: 0.7838 - val_recall_m: 0.7400 - val_f1_m: 0.7598\n","Epoch 20/50\n","131/131 [==============================] - 1s 6ms/step - loss: 0.2779 - accuracy: 0.5892 - precision_m: 0.8579 - recall_m: 0.7823 - f1_m: 0.8170 - val_loss: 0.3243 - val_accuracy: 0.6673 - val_precision_m: 0.7583 - val_recall_m: 0.7683 - val_f1_m: 0.7617\n","Epoch 21/50\n","131/131 [==============================] - 1s 6ms/step - loss: 0.2751 - accuracy: 0.5818 - precision_m: 0.8461 - recall_m: 0.7961 - f1_m: 0.8192 - val_loss: 0.3150 - val_accuracy: 0.6644 - val_precision_m: 0.8096 - val_recall_m: 0.7131 - val_f1_m: 0.7566\n","Epoch 22/50\n","131/131 [==============================] - 1s 6ms/step - loss: 0.2698 - accuracy: 0.5997 - precision_m: 0.8603 - recall_m: 0.7794 - f1_m: 0.8167 - val_loss: 0.3131 - val_accuracy: 0.6683 - val_precision_m: 0.7905 - val_recall_m: 0.7440 - val_f1_m: 0.7650\n","Epoch 23/50\n","131/131 [==============================] - 1s 6ms/step - loss: 0.2696 - accuracy: 0.5910 - precision_m: 0.8564 - recall_m: 0.7978 - f1_m: 0.8248 - val_loss: 0.3093 - val_accuracy: 0.6597 - val_precision_m: 0.7970 - val_recall_m: 0.7498 - val_f1_m: 0.7713\n","Epoch 00023: early stopping\n","Score for fold 3: loss of 0.29682058095932007; accuracy of 65.07633328437805% ;precision_m of 0.8064160943031311 ;recall_m of 0.7363831996917725 ;            f1_m of 0.7680891156196594\n","Epoch 1/50\n","131/131 [==============================] - 2s 10ms/step - loss: 0.5209 - accuracy: 0.4273 - precision_m: 0.5983 - recall_m: 0.4841 - f1_m: 0.5324 - val_loss: 0.3070 - val_accuracy: 0.6260 - val_precision_m: 0.7918 - val_recall_m: 0.7049 - val_f1_m: 0.7441\n","Epoch 2/50\n","131/131 [==============================] - 1s 7ms/step - loss: 0.3533 - accuracy: 0.5689 - precision_m: 0.7695 - recall_m: 0.6599 - f1_m: 0.7094 - val_loss: 0.2952 - val_accuracy: 0.6355 - val_precision_m: 0.7907 - val_recall_m: 0.7357 - val_f1_m: 0.7605\n","Epoch 3/50\n","131/131 [==============================] - 1s 7ms/step - loss: 0.3328 - accuracy: 0.5989 - precision_m: 0.7894 - recall_m: 0.6843 - f1_m: 0.7316 - val_loss: 0.2805 - val_accuracy: 0.6536 - val_precision_m: 0.8187 - val_recall_m: 0.7134 - val_f1_m: 0.7610\n","Epoch 4/50\n","131/131 [==============================] - 1s 7ms/step - loss: 0.3225 - accuracy: 0.6018 - precision_m: 0.7963 - recall_m: 0.6863 - f1_m: 0.7351 - val_loss: 0.2771 - val_accuracy: 0.6489 - val_precision_m: 0.8026 - val_recall_m: 0.7684 - val_f1_m: 0.7830\n","Epoch 5/50\n","131/131 [==============================] - 1s 7ms/step - loss: 0.3105 - accuracy: 0.5998 - precision_m: 0.8077 - recall_m: 0.7206 - f1_m: 0.7598 - val_loss: 0.2718 - val_accuracy: 0.6498 - val_precision_m: 0.8173 - val_recall_m: 0.7471 - val_f1_m: 0.7791\n","Epoch 6/50\n","131/131 [==============================] - 1s 7ms/step - loss: 0.3040 - accuracy: 0.6215 - precision_m: 0.8137 - recall_m: 0.7081 - f1_m: 0.7559 - val_loss: 0.2746 - val_accuracy: 0.6374 - val_precision_m: 0.8094 - val_recall_m: 0.7667 - val_f1_m: 0.7862\n","Epoch 7/50\n","131/131 [==============================] - 1s 7ms/step - loss: 0.2967 - accuracy: 0.6169 - precision_m: 0.8125 - recall_m: 0.7245 - f1_m: 0.7635 - val_loss: 0.2706 - val_accuracy: 0.6460 - val_precision_m: 0.8359 - val_recall_m: 0.7238 - val_f1_m: 0.7741\n","Epoch 8/50\n","131/131 [==============================] - 1s 7ms/step - loss: 0.2957 - accuracy: 0.6205 - precision_m: 0.8213 - recall_m: 0.7234 - f1_m: 0.7679 - val_loss: 0.2678 - val_accuracy: 0.6527 - val_precision_m: 0.8161 - val_recall_m: 0.7521 - val_f1_m: 0.7812\n","Epoch 9/50\n","131/131 [==============================] - 1s 7ms/step - loss: 0.2826 - accuracy: 0.6126 - precision_m: 0.8219 - recall_m: 0.7307 - f1_m: 0.7721 - val_loss: 0.2613 - val_accuracy: 0.6555 - val_precision_m: 0.8189 - val_recall_m: 0.7526 - val_f1_m: 0.7833\n","Epoch 10/50\n","131/131 [==============================] - 1s 7ms/step - loss: 0.2847 - accuracy: 0.6205 - precision_m: 0.8182 - recall_m: 0.7328 - f1_m: 0.7717 - val_loss: 0.2715 - val_accuracy: 0.6508 - val_precision_m: 0.8154 - val_recall_m: 0.7571 - val_f1_m: 0.7835\n","Epoch 11/50\n","131/131 [==============================] - 1s 7ms/step - loss: 0.2757 - accuracy: 0.6168 - precision_m: 0.8255 - recall_m: 0.7434 - f1_m: 0.7812 - val_loss: 0.2669 - val_accuracy: 0.6641 - val_precision_m: 0.8250 - val_recall_m: 0.7440 - val_f1_m: 0.7808\n","Epoch 12/50\n","131/131 [==============================] - 1s 7ms/step - loss: 0.2767 - accuracy: 0.6403 - precision_m: 0.8279 - recall_m: 0.7385 - f1_m: 0.7792 - val_loss: 0.2683 - val_accuracy: 0.6565 - val_precision_m: 0.8052 - val_recall_m: 0.7598 - val_f1_m: 0.7804\n","Epoch 13/50\n","131/131 [==============================] - 1s 7ms/step - loss: 0.2653 - accuracy: 0.6214 - precision_m: 0.8392 - recall_m: 0.7535 - f1_m: 0.7927 - val_loss: 0.2684 - val_accuracy: 0.6527 - val_precision_m: 0.8180 - val_recall_m: 0.7485 - val_f1_m: 0.7800\n","Epoch 14/50\n","131/131 [==============================] - 1s 7ms/step - loss: 0.2634 - accuracy: 0.6183 - precision_m: 0.8405 - recall_m: 0.7602 - f1_m: 0.7972 - val_loss: 0.2687 - val_accuracy: 0.6670 - val_precision_m: 0.7965 - val_recall_m: 0.7858 - val_f1_m: 0.7896\n","Epoch 15/50\n","131/131 [==============================] - 1s 7ms/step - loss: 0.2706 - accuracy: 0.6333 - precision_m: 0.8339 - recall_m: 0.7532 - f1_m: 0.7899 - val_loss: 0.2628 - val_accuracy: 0.6555 - val_precision_m: 0.8020 - val_recall_m: 0.7819 - val_f1_m: 0.7907\n","Epoch 16/50\n","131/131 [==============================] - 1s 7ms/step - loss: 0.2537 - accuracy: 0.6368 - precision_m: 0.8405 - recall_m: 0.7718 - f1_m: 0.8034 - val_loss: 0.2637 - val_accuracy: 0.6565 - val_precision_m: 0.8198 - val_recall_m: 0.7472 - val_f1_m: 0.7806\n","Epoch 17/50\n","131/131 [==============================] - 1s 7ms/step - loss: 0.2627 - accuracy: 0.6362 - precision_m: 0.8464 - recall_m: 0.7581 - f1_m: 0.7977 - val_loss: 0.2745 - val_accuracy: 0.6489 - val_precision_m: 0.8080 - val_recall_m: 0.7451 - val_f1_m: 0.7735\n","Epoch 18/50\n","131/131 [==============================] - 1s 7ms/step - loss: 0.2573 - accuracy: 0.6391 - precision_m: 0.8413 - recall_m: 0.7624 - f1_m: 0.7985 - val_loss: 0.2616 - val_accuracy: 0.6546 - val_precision_m: 0.8183 - val_recall_m: 0.7580 - val_f1_m: 0.7858\n","Epoch 19/50\n","131/131 [==============================] - 1s 7ms/step - loss: 0.2536 - accuracy: 0.6480 - precision_m: 0.8475 - recall_m: 0.7597 - f1_m: 0.7999 - val_loss: 0.2616 - val_accuracy: 0.6565 - val_precision_m: 0.8156 - val_recall_m: 0.7488 - val_f1_m: 0.7793\n","Epoch 20/50\n","131/131 [==============================] - 1s 7ms/step - loss: 0.2426 - accuracy: 0.6494 - precision_m: 0.8566 - recall_m: 0.7825 - f1_m: 0.8171 - val_loss: 0.2640 - val_accuracy: 0.6613 - val_precision_m: 0.8189 - val_recall_m: 0.7409 - val_f1_m: 0.7767\n","Epoch 21/50\n","131/131 [==============================] - 1s 7ms/step - loss: 0.2503 - accuracy: 0.6505 - precision_m: 0.8532 - recall_m: 0.7675 - f1_m: 0.8066 - val_loss: 0.2616 - val_accuracy: 0.6574 - val_precision_m: 0.8073 - val_recall_m: 0.7661 - val_f1_m: 0.7848\n","Epoch 22/50\n","131/131 [==============================] - 1s 7ms/step - loss: 0.2419 - accuracy: 0.6432 - precision_m: 0.8580 - recall_m: 0.7899 - f1_m: 0.8212 - val_loss: 0.2648 - val_accuracy: 0.6422 - val_precision_m: 0.8188 - val_recall_m: 0.7487 - val_f1_m: 0.7806\n","Epoch 23/50\n","131/131 [==============================] - 1s 7ms/step - loss: 0.2413 - accuracy: 0.6558 - precision_m: 0.8574 - recall_m: 0.7807 - f1_m: 0.8159 - val_loss: 0.2696 - val_accuracy: 0.6527 - val_precision_m: 0.8023 - val_recall_m: 0.7561 - val_f1_m: 0.7767\n","Epoch 24/50\n","131/131 [==============================] - 1s 7ms/step - loss: 0.2406 - accuracy: 0.6434 - precision_m: 0.8560 - recall_m: 0.7820 - f1_m: 0.8163 - val_loss: 0.2632 - val_accuracy: 0.6431 - val_precision_m: 0.8139 - val_recall_m: 0.7568 - val_f1_m: 0.7823\n","Epoch 25/50\n","131/131 [==============================] - 1s 7ms/step - loss: 0.2381 - accuracy: 0.6569 - precision_m: 0.8573 - recall_m: 0.7859 - f1_m: 0.8190 - val_loss: 0.2620 - val_accuracy: 0.6603 - val_precision_m: 0.8105 - val_recall_m: 0.7548 - val_f1_m: 0.7802\n","Epoch 00025: early stopping\n","Score for fold 1: loss of 0.415201336145401; accuracy of 52.8042733669281% ;precision_m of 0.8464977145195007 ;recall_m of 0.6624542474746704 ;            f1_m of 0.7403586506843567\n","Epoch 1/50\n","131/131 [==============================] - 2s 9ms/step - loss: 0.5826 - accuracy: 0.4023 - precision_m: 0.5977 - recall_m: 0.5007 - f1_m: 0.5372 - val_loss: 0.3175 - val_accuracy: 0.6425 - val_precision_m: 0.7775 - val_recall_m: 0.7081 - val_f1_m: 0.7388\n","Epoch 2/50\n","131/131 [==============================] - 1s 7ms/step - loss: 0.3903 - accuracy: 0.5460 - precision_m: 0.7769 - recall_m: 0.6692 - f1_m: 0.7168 - val_loss: 0.3015 - val_accuracy: 0.6578 - val_precision_m: 0.7590 - val_recall_m: 0.7506 - val_f1_m: 0.7531\n","Epoch 3/50\n","131/131 [==============================] - 1s 7ms/step - loss: 0.3583 - accuracy: 0.5692 - precision_m: 0.7829 - recall_m: 0.6990 - f1_m: 0.7374 - val_loss: 0.2898 - val_accuracy: 0.6616 - val_precision_m: 0.8164 - val_recall_m: 0.7094 - val_f1_m: 0.7568\n","Epoch 4/50\n","131/131 [==============================] - 1s 7ms/step - loss: 0.3399 - accuracy: 0.5795 - precision_m: 0.8015 - recall_m: 0.7197 - f1_m: 0.7571 - val_loss: 0.2851 - val_accuracy: 0.6501 - val_precision_m: 0.7867 - val_recall_m: 0.7428 - val_f1_m: 0.7629\n","Epoch 5/50\n","131/131 [==============================] - 1s 7ms/step - loss: 0.3351 - accuracy: 0.5795 - precision_m: 0.7982 - recall_m: 0.7133 - f1_m: 0.7523 - val_loss: 0.2777 - val_accuracy: 0.6673 - val_precision_m: 0.8126 - val_recall_m: 0.7268 - val_f1_m: 0.7655\n","Epoch 6/50\n","131/131 [==============================] - 1s 8ms/step - loss: 0.3219 - accuracy: 0.5710 - precision_m: 0.8195 - recall_m: 0.7360 - f1_m: 0.7738 - val_loss: 0.2862 - val_accuracy: 0.6787 - val_precision_m: 0.7930 - val_recall_m: 0.7453 - val_f1_m: 0.7667\n","Epoch 7/50\n","131/131 [==============================] - 1s 8ms/step - loss: 0.3239 - accuracy: 0.5686 - precision_m: 0.8132 - recall_m: 0.7287 - f1_m: 0.7671 - val_loss: 0.2742 - val_accuracy: 0.6711 - val_precision_m: 0.8036 - val_recall_m: 0.7396 - val_f1_m: 0.7687\n","Epoch 8/50\n","131/131 [==============================] - 1s 7ms/step - loss: 0.3162 - accuracy: 0.5702 - precision_m: 0.8220 - recall_m: 0.7478 - f1_m: 0.7815 - val_loss: 0.2755 - val_accuracy: 0.6730 - val_precision_m: 0.7980 - val_recall_m: 0.7686 - val_f1_m: 0.7814\n","Epoch 9/50\n","131/131 [==============================] - 1s 7ms/step - loss: 0.3108 - accuracy: 0.5763 - precision_m: 0.8167 - recall_m: 0.7476 - f1_m: 0.7793 - val_loss: 0.2671 - val_accuracy: 0.6740 - val_precision_m: 0.8189 - val_recall_m: 0.7452 - val_f1_m: 0.7786\n","Epoch 10/50\n","131/131 [==============================] - 1s 7ms/step - loss: 0.3049 - accuracy: 0.5826 - precision_m: 0.8233 - recall_m: 0.7544 - f1_m: 0.7859 - val_loss: 0.2749 - val_accuracy: 0.6873 - val_precision_m: 0.8095 - val_recall_m: 0.7457 - val_f1_m: 0.7742\n","Epoch 11/50\n","131/131 [==============================] - 1s 7ms/step - loss: 0.3020 - accuracy: 0.5837 - precision_m: 0.8310 - recall_m: 0.7602 - f1_m: 0.7927 - val_loss: 0.2736 - val_accuracy: 0.6911 - val_precision_m: 0.8116 - val_recall_m: 0.7472 - val_f1_m: 0.7764\n","Epoch 12/50\n","131/131 [==============================] - 1s 8ms/step - loss: 0.3022 - accuracy: 0.5949 - precision_m: 0.8270 - recall_m: 0.7503 - f1_m: 0.7853 - val_loss: 0.2744 - val_accuracy: 0.6749 - val_precision_m: 0.8177 - val_recall_m: 0.7464 - val_f1_m: 0.7787\n","Epoch 13/50\n","131/131 [==============================] - 1s 7ms/step - loss: 0.2892 - accuracy: 0.6006 - precision_m: 0.8425 - recall_m: 0.7711 - f1_m: 0.8042 - val_loss: 0.2764 - val_accuracy: 0.6873 - val_precision_m: 0.8070 - val_recall_m: 0.7428 - val_f1_m: 0.7717\n","Epoch 14/50\n","131/131 [==============================] - 1s 8ms/step - loss: 0.2933 - accuracy: 0.5902 - precision_m: 0.8360 - recall_m: 0.7670 - f1_m: 0.7991 - val_loss: 0.2672 - val_accuracy: 0.6740 - val_precision_m: 0.8144 - val_recall_m: 0.7522 - val_f1_m: 0.7806\n","Epoch 15/50\n","131/131 [==============================] - 1s 7ms/step - loss: 0.2791 - accuracy: 0.5863 - precision_m: 0.8457 - recall_m: 0.7761 - f1_m: 0.8079 - val_loss: 0.2670 - val_accuracy: 0.6683 - val_precision_m: 0.8251 - val_recall_m: 0.7364 - val_f1_m: 0.7769\n","Epoch 16/50\n","131/131 [==============================] - 1s 8ms/step - loss: 0.2789 - accuracy: 0.6055 - precision_m: 0.8432 - recall_m: 0.7717 - f1_m: 0.8050 - val_loss: 0.2665 - val_accuracy: 0.6702 - val_precision_m: 0.8092 - val_recall_m: 0.7517 - val_f1_m: 0.7782\n","Epoch 17/50\n","131/131 [==============================] - 1s 8ms/step - loss: 0.2756 - accuracy: 0.5880 - precision_m: 0.8514 - recall_m: 0.7852 - f1_m: 0.8158 - val_loss: 0.2744 - val_accuracy: 0.6759 - val_precision_m: 0.8159 - val_recall_m: 0.7546 - val_f1_m: 0.7826\n","Epoch 18/50\n","131/131 [==============================] - 1s 7ms/step - loss: 0.2713 - accuracy: 0.5992 - precision_m: 0.8467 - recall_m: 0.7810 - f1_m: 0.8115 - val_loss: 0.2687 - val_accuracy: 0.6740 - val_precision_m: 0.8069 - val_recall_m: 0.7583 - val_f1_m: 0.7802\n","Epoch 19/50\n","131/131 [==============================] - 1s 7ms/step - loss: 0.2652 - accuracy: 0.6079 - precision_m: 0.8528 - recall_m: 0.7879 - f1_m: 0.8178 - val_loss: 0.2709 - val_accuracy: 0.6768 - val_precision_m: 0.8231 - val_recall_m: 0.7295 - val_f1_m: 0.7722\n","Epoch 20/50\n","131/131 [==============================] - 1s 7ms/step - loss: 0.2661 - accuracy: 0.6014 - precision_m: 0.8550 - recall_m: 0.7865 - f1_m: 0.8179 - val_loss: 0.2647 - val_accuracy: 0.6892 - val_precision_m: 0.8142 - val_recall_m: 0.7613 - val_f1_m: 0.7855\n","Epoch 21/50\n","131/131 [==============================] - 1s 7ms/step - loss: 0.2736 - accuracy: 0.5981 - precision_m: 0.8546 - recall_m: 0.7843 - f1_m: 0.8169 - val_loss: 0.2669 - val_accuracy: 0.6921 - val_precision_m: 0.8115 - val_recall_m: 0.7580 - val_f1_m: 0.7824\n","Epoch 22/50\n","131/131 [==============================] - 1s 7ms/step - loss: 0.2649 - accuracy: 0.6030 - precision_m: 0.8510 - recall_m: 0.7892 - f1_m: 0.8175 - val_loss: 0.2641 - val_accuracy: 0.6768 - val_precision_m: 0.8238 - val_recall_m: 0.7406 - val_f1_m: 0.7785\n","Epoch 23/50\n","131/131 [==============================] - 1s 7ms/step - loss: 0.2594 - accuracy: 0.6089 - precision_m: 0.8560 - recall_m: 0.7882 - f1_m: 0.8197 - val_loss: 0.2653 - val_accuracy: 0.6806 - val_precision_m: 0.8156 - val_recall_m: 0.7614 - val_f1_m: 0.7863\n","Epoch 24/50\n","131/131 [==============================] - 1s 7ms/step - loss: 0.2649 - accuracy: 0.5957 - precision_m: 0.8491 - recall_m: 0.7949 - f1_m: 0.8199 - val_loss: 0.2639 - val_accuracy: 0.6625 - val_precision_m: 0.8246 - val_recall_m: 0.7387 - val_f1_m: 0.7778\n","Epoch 25/50\n","131/131 [==============================] - 1s 7ms/step - loss: 0.2631 - accuracy: 0.6098 - precision_m: 0.8560 - recall_m: 0.7857 - f1_m: 0.8180 - val_loss: 0.2639 - val_accuracy: 0.6597 - val_precision_m: 0.8155 - val_recall_m: 0.7456 - val_f1_m: 0.7777\n","Epoch 26/50\n","131/131 [==============================] - 1s 7ms/step - loss: 0.2587 - accuracy: 0.5989 - precision_m: 0.8621 - recall_m: 0.7906 - f1_m: 0.8239 - val_loss: 0.2699 - val_accuracy: 0.6864 - val_precision_m: 0.8230 - val_recall_m: 0.7503 - val_f1_m: 0.7833\n","Epoch 27/50\n","131/131 [==============================] - 1s 7ms/step - loss: 0.2504 - accuracy: 0.6170 - precision_m: 0.8594 - recall_m: 0.7984 - f1_m: 0.8265 - val_loss: 0.2674 - val_accuracy: 0.6778 - val_precision_m: 0.8123 - val_recall_m: 0.7514 - val_f1_m: 0.7792\n","Epoch 28/50\n","131/131 [==============================] - 1s 7ms/step - loss: 0.2460 - accuracy: 0.6259 - precision_m: 0.8674 - recall_m: 0.8083 - f1_m: 0.8357 - val_loss: 0.2654 - val_accuracy: 0.6721 - val_precision_m: 0.8231 - val_recall_m: 0.7410 - val_f1_m: 0.7782\n","Epoch 29/50\n","131/131 [==============================] - 1s 7ms/step - loss: 0.2485 - accuracy: 0.6104 - precision_m: 0.8655 - recall_m: 0.8072 - f1_m: 0.8342 - val_loss: 0.2628 - val_accuracy: 0.6911 - val_precision_m: 0.8325 - val_recall_m: 0.7586 - val_f1_m: 0.7924\n","Epoch 30/50\n","131/131 [==============================] - 1s 7ms/step - loss: 0.2463 - accuracy: 0.6084 - precision_m: 0.8616 - recall_m: 0.8020 - f1_m: 0.8299 - val_loss: 0.2689 - val_accuracy: 0.6835 - val_precision_m: 0.8202 - val_recall_m: 0.7546 - val_f1_m: 0.7841\n","Epoch 31/50\n","131/131 [==============================] - 1s 7ms/step - loss: 0.2463 - accuracy: 0.6032 - precision_m: 0.8660 - recall_m: 0.8111 - f1_m: 0.8365 - val_loss: 0.2671 - val_accuracy: 0.6864 - val_precision_m: 0.8198 - val_recall_m: 0.7566 - val_f1_m: 0.7847\n","Epoch 32/50\n","131/131 [==============================] - 1s 7ms/step - loss: 0.2468 - accuracy: 0.6104 - precision_m: 0.8709 - recall_m: 0.8047 - f1_m: 0.8357 - val_loss: 0.2644 - val_accuracy: 0.6940 - val_precision_m: 0.8234 - val_recall_m: 0.7593 - val_f1_m: 0.7884\n","Epoch 33/50\n","131/131 [==============================] - 1s 7ms/step - loss: 0.2464 - accuracy: 0.6072 - precision_m: 0.8675 - recall_m: 0.8031 - f1_m: 0.8333 - val_loss: 0.2646 - val_accuracy: 0.6683 - val_precision_m: 0.8123 - val_recall_m: 0.7572 - val_f1_m: 0.7823\n","Epoch 34/50\n","131/131 [==============================] - 1s 7ms/step - loss: 0.2305 - accuracy: 0.6208 - precision_m: 0.8725 - recall_m: 0.8190 - f1_m: 0.8440 - val_loss: 0.2643 - val_accuracy: 0.6654 - val_precision_m: 0.8188 - val_recall_m: 0.7491 - val_f1_m: 0.7810\n","Epoch 35/50\n","131/131 [==============================] - 1s 7ms/step - loss: 0.2353 - accuracy: 0.6142 - precision_m: 0.8749 - recall_m: 0.8121 - f1_m: 0.8413 - val_loss: 0.2681 - val_accuracy: 0.6873 - val_precision_m: 0.8182 - val_recall_m: 0.7591 - val_f1_m: 0.7859\n","Epoch 36/50\n","131/131 [==============================] - 1s 7ms/step - loss: 0.2401 - accuracy: 0.6175 - precision_m: 0.8710 - recall_m: 0.8074 - f1_m: 0.8373 - val_loss: 0.2732 - val_accuracy: 0.6578 - val_precision_m: 0.8050 - val_recall_m: 0.7579 - val_f1_m: 0.7794\n","Epoch 37/50\n","131/131 [==============================] - 1s 8ms/step - loss: 0.2475 - accuracy: 0.6120 - precision_m: 0.8648 - recall_m: 0.8034 - f1_m: 0.8318 - val_loss: 0.2678 - val_accuracy: 0.6749 - val_precision_m: 0.8223 - val_recall_m: 0.7503 - val_f1_m: 0.7831\n","Epoch 38/50\n","131/131 [==============================] - 1s 7ms/step - loss: 0.2326 - accuracy: 0.6273 - precision_m: 0.8777 - recall_m: 0.8164 - f1_m: 0.8452 - val_loss: 0.2638 - val_accuracy: 0.6787 - val_precision_m: 0.8118 - val_recall_m: 0.7761 - val_f1_m: 0.7918\n","Epoch 39/50\n","131/131 [==============================] - 1s 7ms/step - loss: 0.2341 - accuracy: 0.6120 - precision_m: 0.8694 - recall_m: 0.8194 - f1_m: 0.8428 - val_loss: 0.2677 - val_accuracy: 0.6768 - val_precision_m: 0.8143 - val_recall_m: 0.7712 - val_f1_m: 0.7906\n","Epoch 00039: early stopping\n","Score for fold 2: loss of 0.3341359794139862; accuracy of 62.25190758705139% ;precision_m of 0.7925072908401489 ;recall_m of 0.7654057741165161 ;            f1_m of 0.7766426205635071\n","Epoch 1/50\n","131/131 [==============================] - 2s 9ms/step - loss: 0.5792 - accuracy: 0.3798 - precision_m: 0.5952 - recall_m: 0.4944 - f1_m: 0.5338 - val_loss: 0.3715 - val_accuracy: 0.6625 - val_precision_m: 0.7493 - val_recall_m: 0.6776 - val_f1_m: 0.7099\n","Epoch 2/50\n","131/131 [==============================] - 1s 7ms/step - loss: 0.3929 - accuracy: 0.5433 - precision_m: 0.7681 - recall_m: 0.6764 - f1_m: 0.7175 - val_loss: 0.3396 - val_accuracy: 0.6301 - val_precision_m: 0.7452 - val_recall_m: 0.7398 - val_f1_m: 0.7409\n","Epoch 3/50\n","131/131 [==============================] - 1s 7ms/step - loss: 0.3659 - accuracy: 0.5404 - precision_m: 0.7895 - recall_m: 0.7054 - f1_m: 0.7439 - val_loss: 0.3480 - val_accuracy: 0.6559 - val_precision_m: 0.7526 - val_recall_m: 0.7293 - val_f1_m: 0.7392\n","Epoch 4/50\n","131/131 [==============================] - 1s 7ms/step - loss: 0.3519 - accuracy: 0.5560 - precision_m: 0.8069 - recall_m: 0.7141 - f1_m: 0.7562 - val_loss: 0.3239 - val_accuracy: 0.6559 - val_precision_m: 0.7943 - val_recall_m: 0.7251 - val_f1_m: 0.7565\n","Epoch 5/50\n","131/131 [==============================] - 1s 7ms/step - loss: 0.3365 - accuracy: 0.5739 - precision_m: 0.8181 - recall_m: 0.7287 - f1_m: 0.7688 - val_loss: 0.3201 - val_accuracy: 0.6520 - val_precision_m: 0.7999 - val_recall_m: 0.7278 - val_f1_m: 0.7605\n","Epoch 6/50\n","131/131 [==============================] - 1s 7ms/step - loss: 0.3379 - accuracy: 0.5595 - precision_m: 0.8061 - recall_m: 0.7310 - f1_m: 0.7652 - val_loss: 0.3178 - val_accuracy: 0.6473 - val_precision_m: 0.7780 - val_recall_m: 0.7443 - val_f1_m: 0.7591\n","Epoch 7/50\n","131/131 [==============================] - 1s 8ms/step - loss: 0.3360 - accuracy: 0.5534 - precision_m: 0.8223 - recall_m: 0.7435 - f1_m: 0.7792 - val_loss: 0.3298 - val_accuracy: 0.6721 - val_precision_m: 0.7895 - val_recall_m: 0.7150 - val_f1_m: 0.7485\n","Epoch 8/50\n","131/131 [==============================] - 1s 7ms/step - loss: 0.3314 - accuracy: 0.5684 - precision_m: 0.8254 - recall_m: 0.7377 - f1_m: 0.7776 - val_loss: 0.3242 - val_accuracy: 0.6625 - val_precision_m: 0.8078 - val_recall_m: 0.7041 - val_f1_m: 0.7505\n","Epoch 9/50\n","131/131 [==============================] - 1s 7ms/step - loss: 0.3199 - accuracy: 0.5726 - precision_m: 0.8344 - recall_m: 0.7371 - f1_m: 0.7816 - val_loss: 0.3194 - val_accuracy: 0.6578 - val_precision_m: 0.8032 - val_recall_m: 0.7214 - val_f1_m: 0.7586\n","Epoch 10/50\n","131/131 [==============================] - 1s 7ms/step - loss: 0.3186 - accuracy: 0.5823 - precision_m: 0.8277 - recall_m: 0.7478 - f1_m: 0.7845 - val_loss: 0.3229 - val_accuracy: 0.6597 - val_precision_m: 0.7781 - val_recall_m: 0.7318 - val_f1_m: 0.7523\n","Epoch 11/50\n","131/131 [==============================] - 1s 7ms/step - loss: 0.3160 - accuracy: 0.5791 - precision_m: 0.8264 - recall_m: 0.7506 - f1_m: 0.7854 - val_loss: 0.3253 - val_accuracy: 0.6568 - val_precision_m: 0.7741 - val_recall_m: 0.7406 - val_f1_m: 0.7555\n","Epoch 12/50\n","131/131 [==============================] - 1s 7ms/step - loss: 0.3111 - accuracy: 0.5557 - precision_m: 0.8348 - recall_m: 0.7611 - f1_m: 0.7951 - val_loss: 0.3226 - val_accuracy: 0.6625 - val_precision_m: 0.7883 - val_recall_m: 0.7200 - val_f1_m: 0.7511\n","Epoch 13/50\n","131/131 [==============================] - 1s 7ms/step - loss: 0.3088 - accuracy: 0.5805 - precision_m: 0.8295 - recall_m: 0.7525 - f1_m: 0.7876 - val_loss: 0.3182 - val_accuracy: 0.6663 - val_precision_m: 0.7970 - val_recall_m: 0.7224 - val_f1_m: 0.7563\n","Epoch 14/50\n","131/131 [==============================] - 1s 7ms/step - loss: 0.3022 - accuracy: 0.5782 - precision_m: 0.8418 - recall_m: 0.7502 - f1_m: 0.7918 - val_loss: 0.3206 - val_accuracy: 0.6625 - val_precision_m: 0.7880 - val_recall_m: 0.7342 - val_f1_m: 0.7587\n","Epoch 15/50\n","131/131 [==============================] - 1s 7ms/step - loss: 0.2945 - accuracy: 0.5740 - precision_m: 0.8431 - recall_m: 0.7708 - f1_m: 0.8042 - val_loss: 0.3236 - val_accuracy: 0.6644 - val_precision_m: 0.8058 - val_recall_m: 0.7186 - val_f1_m: 0.7584\n","Epoch 00015: early stopping\n","Score for fold 3: loss of 0.3060165047645569; accuracy of 65.95419645309448% ;precision_m of 0.8135871887207031 ;recall_m of 0.710429847240448 ;            f1_m of 0.7570096254348755\n","Epoch 1/50\n","131/131 [==============================] - 2s 12ms/step - loss: 0.5163 - accuracy: 0.4396 - precision_m: 0.6172 - recall_m: 0.4959 - f1_m: 0.5440 - val_loss: 0.3078 - val_accuracy: 0.6317 - val_precision_m: 0.8215 - val_recall_m: 0.6671 - val_f1_m: 0.7341\n","Epoch 2/50\n","131/131 [==============================] - 1s 9ms/step - loss: 0.3542 - accuracy: 0.5734 - precision_m: 0.7687 - recall_m: 0.6505 - f1_m: 0.7021 - val_loss: 0.3069 - val_accuracy: 0.6479 - val_precision_m: 0.8085 - val_recall_m: 0.6896 - val_f1_m: 0.7420\n","Epoch 3/50\n","131/131 [==============================] - 1s 9ms/step - loss: 0.3445 - accuracy: 0.5827 - precision_m: 0.7787 - recall_m: 0.6691 - f1_m: 0.7178 - val_loss: 0.2802 - val_accuracy: 0.6450 - val_precision_m: 0.8172 - val_recall_m: 0.7208 - val_f1_m: 0.7649\n","Epoch 4/50\n","131/131 [==============================] - 1s 9ms/step - loss: 0.3318 - accuracy: 0.5846 - precision_m: 0.7839 - recall_m: 0.6813 - f1_m: 0.7274 - val_loss: 0.2831 - val_accuracy: 0.6450 - val_precision_m: 0.8081 - val_recall_m: 0.7411 - val_f1_m: 0.7711\n","Epoch 5/50\n","131/131 [==============================] - 1s 9ms/step - loss: 0.3130 - accuracy: 0.6132 - precision_m: 0.8029 - recall_m: 0.7020 - f1_m: 0.7477 - val_loss: 0.2749 - val_accuracy: 0.6345 - val_precision_m: 0.8159 - val_recall_m: 0.7155 - val_f1_m: 0.7610\n","Epoch 6/50\n","131/131 [==============================] - 1s 9ms/step - loss: 0.3145 - accuracy: 0.5893 - precision_m: 0.7985 - recall_m: 0.6933 - f1_m: 0.7410 - val_loss: 0.2709 - val_accuracy: 0.6393 - val_precision_m: 0.8218 - val_recall_m: 0.7467 - val_f1_m: 0.7807\n","Epoch 7/50\n","131/131 [==============================] - 1s 9ms/step - loss: 0.2995 - accuracy: 0.6080 - precision_m: 0.8107 - recall_m: 0.7209 - f1_m: 0.7617 - val_loss: 0.2704 - val_accuracy: 0.6489 - val_precision_m: 0.8302 - val_recall_m: 0.7222 - val_f1_m: 0.7709\n","Epoch 8/50\n","131/131 [==============================] - 1s 9ms/step - loss: 0.2967 - accuracy: 0.5994 - precision_m: 0.8102 - recall_m: 0.7296 - f1_m: 0.7666 - val_loss: 0.2811 - val_accuracy: 0.6660 - val_precision_m: 0.8055 - val_recall_m: 0.7527 - val_f1_m: 0.7765\n","Epoch 9/50\n","131/131 [==============================] - 1s 9ms/step - loss: 0.3029 - accuracy: 0.6122 - precision_m: 0.8089 - recall_m: 0.7147 - f1_m: 0.7576 - val_loss: 0.2719 - val_accuracy: 0.6517 - val_precision_m: 0.8383 - val_recall_m: 0.7182 - val_f1_m: 0.7718\n","Epoch 10/50\n","131/131 [==============================] - 1s 9ms/step - loss: 0.2846 - accuracy: 0.6047 - precision_m: 0.8277 - recall_m: 0.7289 - f1_m: 0.7737 - val_loss: 0.2658 - val_accuracy: 0.6460 - val_precision_m: 0.8080 - val_recall_m: 0.7626 - val_f1_m: 0.7834\n","Epoch 11/50\n","131/131 [==============================] - 1s 9ms/step - loss: 0.2809 - accuracy: 0.6232 - precision_m: 0.8251 - recall_m: 0.7398 - f1_m: 0.7786 - val_loss: 0.2791 - val_accuracy: 0.6565 - val_precision_m: 0.8029 - val_recall_m: 0.7341 - val_f1_m: 0.7653\n","Epoch 12/50\n","131/131 [==============================] - 1s 9ms/step - loss: 0.2829 - accuracy: 0.6380 - precision_m: 0.8219 - recall_m: 0.7332 - f1_m: 0.7738 - val_loss: 0.2746 - val_accuracy: 0.6613 - val_precision_m: 0.8051 - val_recall_m: 0.7463 - val_f1_m: 0.7732\n","Epoch 13/50\n","131/131 [==============================] - 1s 9ms/step - loss: 0.2843 - accuracy: 0.6163 - precision_m: 0.8173 - recall_m: 0.7348 - f1_m: 0.7727 - val_loss: 0.2728 - val_accuracy: 0.6641 - val_precision_m: 0.8164 - val_recall_m: 0.7455 - val_f1_m: 0.7778\n","Epoch 14/50\n","131/131 [==============================] - 1s 9ms/step - loss: 0.2756 - accuracy: 0.6121 - precision_m: 0.8273 - recall_m: 0.7367 - f1_m: 0.7782 - val_loss: 0.2749 - val_accuracy: 0.6546 - val_precision_m: 0.8068 - val_recall_m: 0.7581 - val_f1_m: 0.7798\n","Epoch 15/50\n","131/131 [==============================] - 1s 9ms/step - loss: 0.2812 - accuracy: 0.6159 - precision_m: 0.8227 - recall_m: 0.7401 - f1_m: 0.7775 - val_loss: 0.2719 - val_accuracy: 0.6737 - val_precision_m: 0.8200 - val_recall_m: 0.7479 - val_f1_m: 0.7809\n","Epoch 16/50\n","131/131 [==============================] - 1s 9ms/step - loss: 0.2671 - accuracy: 0.6277 - precision_m: 0.8374 - recall_m: 0.7547 - f1_m: 0.7925 - val_loss: 0.2726 - val_accuracy: 0.6594 - val_precision_m: 0.7996 - val_recall_m: 0.7779 - val_f1_m: 0.7870\n","Epoch 17/50\n","131/131 [==============================] - 1s 9ms/step - loss: 0.2639 - accuracy: 0.6372 - precision_m: 0.8275 - recall_m: 0.7529 - f1_m: 0.7867 - val_loss: 0.2710 - val_accuracy: 0.6479 - val_precision_m: 0.8373 - val_recall_m: 0.7037 - val_f1_m: 0.7630\n","Epoch 18/50\n","131/131 [==============================] - 1s 9ms/step - loss: 0.2568 - accuracy: 0.6066 - precision_m: 0.8347 - recall_m: 0.7554 - f1_m: 0.7915 - val_loss: 0.2686 - val_accuracy: 0.6632 - val_precision_m: 0.8226 - val_recall_m: 0.7430 - val_f1_m: 0.7791\n","Epoch 19/50\n","131/131 [==============================] - 1s 10ms/step - loss: 0.2657 - accuracy: 0.6194 - precision_m: 0.8322 - recall_m: 0.7546 - f1_m: 0.7905 - val_loss: 0.2698 - val_accuracy: 0.6527 - val_precision_m: 0.8113 - val_recall_m: 0.7529 - val_f1_m: 0.7797\n","Epoch 20/50\n","131/131 [==============================] - 1s 9ms/step - loss: 0.2517 - accuracy: 0.6392 - precision_m: 0.8494 - recall_m: 0.7723 - f1_m: 0.8081 - val_loss: 0.2670 - val_accuracy: 0.6632 - val_precision_m: 0.8207 - val_recall_m: 0.7532 - val_f1_m: 0.7840\n","Epoch 21/50\n","131/131 [==============================] - 1s 9ms/step - loss: 0.2580 - accuracy: 0.6304 - precision_m: 0.8367 - recall_m: 0.7579 - f1_m: 0.7943 - val_loss: 0.2670 - val_accuracy: 0.6670 - val_precision_m: 0.8181 - val_recall_m: 0.7580 - val_f1_m: 0.7854\n","Epoch 22/50\n","131/131 [==============================] - 1s 9ms/step - loss: 0.2524 - accuracy: 0.6470 - precision_m: 0.8448 - recall_m: 0.7752 - f1_m: 0.8072 - val_loss: 0.2716 - val_accuracy: 0.6632 - val_precision_m: 0.8230 - val_recall_m: 0.7285 - val_f1_m: 0.7711\n","Epoch 23/50\n","131/131 [==============================] - 1s 9ms/step - loss: 0.2464 - accuracy: 0.6346 - precision_m: 0.8443 - recall_m: 0.7608 - f1_m: 0.7989 - val_loss: 0.2696 - val_accuracy: 0.6670 - val_precision_m: 0.8303 - val_recall_m: 0.7437 - val_f1_m: 0.7827\n","Epoch 24/50\n","131/131 [==============================] - 1s 9ms/step - loss: 0.2470 - accuracy: 0.6394 - precision_m: 0.8519 - recall_m: 0.7712 - f1_m: 0.8081 - val_loss: 0.2647 - val_accuracy: 0.6727 - val_precision_m: 0.8320 - val_recall_m: 0.7285 - val_f1_m: 0.7750\n","Epoch 25/50\n","131/131 [==============================] - 1s 9ms/step - loss: 0.2544 - accuracy: 0.6422 - precision_m: 0.8454 - recall_m: 0.7647 - f1_m: 0.8020 - val_loss: 0.2633 - val_accuracy: 0.6574 - val_precision_m: 0.8263 - val_recall_m: 0.7471 - val_f1_m: 0.7832\n","Epoch 26/50\n","131/131 [==============================] - 1s 9ms/step - loss: 0.2406 - accuracy: 0.6378 - precision_m: 0.8565 - recall_m: 0.7711 - f1_m: 0.8107 - val_loss: 0.2636 - val_accuracy: 0.6613 - val_precision_m: 0.8311 - val_recall_m: 0.7460 - val_f1_m: 0.7849\n","Epoch 00026: early stopping\n","Score for fold 1: loss of 0.4289538264274597; accuracy of 51.278138160705566% ;precision_m of 0.8524366021156311 ;recall_m of 0.6396523714065552 ;            f1_m of 0.7277462482452393\n","Epoch 1/50\n","131/131 [==============================] - 2s 11ms/step - loss: 0.5778 - accuracy: 0.4104 - precision_m: 0.5941 - recall_m: 0.5023 - f1_m: 0.5399 - val_loss: 0.3333 - val_accuracy: 0.6597 - val_precision_m: 0.7511 - val_recall_m: 0.7336 - val_f1_m: 0.7402\n","Epoch 2/50\n","131/131 [==============================] - 1s 9ms/step - loss: 0.3837 - accuracy: 0.5676 - precision_m: 0.7656 - recall_m: 0.6760 - f1_m: 0.7163 - val_loss: 0.3011 - val_accuracy: 0.6520 - val_precision_m: 0.8100 - val_recall_m: 0.7078 - val_f1_m: 0.7539\n","Epoch 3/50\n","131/131 [==============================] - 1s 9ms/step - loss: 0.3655 - accuracy: 0.5659 - precision_m: 0.7980 - recall_m: 0.6968 - f1_m: 0.7425 - val_loss: 0.2978 - val_accuracy: 0.6673 - val_precision_m: 0.7880 - val_recall_m: 0.7398 - val_f1_m: 0.7614\n","Epoch 4/50\n","131/131 [==============================] - 1s 9ms/step - loss: 0.3481 - accuracy: 0.5749 - precision_m: 0.7997 - recall_m: 0.7180 - f1_m: 0.7553 - val_loss: 0.2862 - val_accuracy: 0.6492 - val_precision_m: 0.8002 - val_recall_m: 0.7175 - val_f1_m: 0.7550\n","Epoch 5/50\n","131/131 [==============================] - 1s 9ms/step - loss: 0.3408 - accuracy: 0.5787 - precision_m: 0.8093 - recall_m: 0.7287 - f1_m: 0.7651 - val_loss: 0.2794 - val_accuracy: 0.6663 - val_precision_m: 0.8089 - val_recall_m: 0.7372 - val_f1_m: 0.7700\n","Epoch 6/50\n","131/131 [==============================] - 1s 9ms/step - loss: 0.3296 - accuracy: 0.5771 - precision_m: 0.8133 - recall_m: 0.7262 - f1_m: 0.7661 - val_loss: 0.2774 - val_accuracy: 0.6644 - val_precision_m: 0.8095 - val_recall_m: 0.7219 - val_f1_m: 0.7611\n","Epoch 7/50\n","131/131 [==============================] - 1s 9ms/step - loss: 0.3252 - accuracy: 0.5891 - precision_m: 0.8092 - recall_m: 0.7330 - f1_m: 0.7676 - val_loss: 0.2881 - val_accuracy: 0.6787 - val_precision_m: 0.8088 - val_recall_m: 0.7419 - val_f1_m: 0.7726\n","Epoch 8/50\n","131/131 [==============================] - 1s 9ms/step - loss: 0.3224 - accuracy: 0.5882 - precision_m: 0.8203 - recall_m: 0.7290 - f1_m: 0.7708 - val_loss: 0.2854 - val_accuracy: 0.6816 - val_precision_m: 0.8148 - val_recall_m: 0.6982 - val_f1_m: 0.7503\n","Epoch 9/50\n","131/131 [==============================] - 1s 9ms/step - loss: 0.3172 - accuracy: 0.5915 - precision_m: 0.8212 - recall_m: 0.7341 - f1_m: 0.7737 - val_loss: 0.2775 - val_accuracy: 0.6740 - val_precision_m: 0.8007 - val_recall_m: 0.7491 - val_f1_m: 0.7726\n","Epoch 10/50\n","131/131 [==============================] - 1s 9ms/step - loss: 0.3112 - accuracy: 0.5868 - precision_m: 0.8198 - recall_m: 0.7391 - f1_m: 0.7760 - val_loss: 0.2769 - val_accuracy: 0.6787 - val_precision_m: 0.8076 - val_recall_m: 0.7698 - val_f1_m: 0.7871\n","Epoch 11/50\n","131/131 [==============================] - 1s 9ms/step - loss: 0.2995 - accuracy: 0.5896 - precision_m: 0.8233 - recall_m: 0.7640 - f1_m: 0.7912 - val_loss: 0.2753 - val_accuracy: 0.6778 - val_precision_m: 0.8180 - val_recall_m: 0.7544 - val_f1_m: 0.7840\n","Epoch 12/50\n","131/131 [==============================] - 1s 9ms/step - loss: 0.3045 - accuracy: 0.6026 - precision_m: 0.8292 - recall_m: 0.7618 - f1_m: 0.7931 - val_loss: 0.2747 - val_accuracy: 0.6644 - val_precision_m: 0.8145 - val_recall_m: 0.7644 - val_f1_m: 0.7872\n","Epoch 13/50\n","131/131 [==============================] - 1s 9ms/step - loss: 0.2944 - accuracy: 0.5864 - precision_m: 0.8361 - recall_m: 0.7621 - f1_m: 0.7965 - val_loss: 0.2730 - val_accuracy: 0.6787 - val_precision_m: 0.8170 - val_recall_m: 0.7657 - val_f1_m: 0.7890\n","Epoch 14/50\n","131/131 [==============================] - 1s 9ms/step - loss: 0.2981 - accuracy: 0.5927 - precision_m: 0.8291 - recall_m: 0.7596 - f1_m: 0.7910 - val_loss: 0.2748 - val_accuracy: 0.6797 - val_precision_m: 0.8167 - val_recall_m: 0.7566 - val_f1_m: 0.7840\n","Epoch 15/50\n","131/131 [==============================] - 1s 9ms/step - loss: 0.2921 - accuracy: 0.6043 - precision_m: 0.8320 - recall_m: 0.7676 - f1_m: 0.7970 - val_loss: 0.2755 - val_accuracy: 0.6787 - val_precision_m: 0.8164 - val_recall_m: 0.7537 - val_f1_m: 0.7823\n","Epoch 16/50\n","131/131 [==============================] - 1s 9ms/step - loss: 0.2936 - accuracy: 0.6030 - precision_m: 0.8400 - recall_m: 0.7602 - f1_m: 0.7970 - val_loss: 0.2760 - val_accuracy: 0.6949 - val_precision_m: 0.8249 - val_recall_m: 0.7405 - val_f1_m: 0.7793\n","Epoch 17/50\n","131/131 [==============================] - 1s 9ms/step - loss: 0.2876 - accuracy: 0.6100 - precision_m: 0.8418 - recall_m: 0.7633 - f1_m: 0.7997 - val_loss: 0.2680 - val_accuracy: 0.6778 - val_precision_m: 0.8276 - val_recall_m: 0.7473 - val_f1_m: 0.7839\n","Epoch 18/50\n","131/131 [==============================] - 1s 9ms/step - loss: 0.2883 - accuracy: 0.5952 - precision_m: 0.8342 - recall_m: 0.7663 - f1_m: 0.7978 - val_loss: 0.2754 - val_accuracy: 0.6864 - val_precision_m: 0.8068 - val_recall_m: 0.7741 - val_f1_m: 0.7886\n","Epoch 19/50\n","131/131 [==============================] - 1s 9ms/step - loss: 0.2845 - accuracy: 0.5911 - precision_m: 0.8356 - recall_m: 0.7757 - f1_m: 0.8031 - val_loss: 0.2663 - val_accuracy: 0.6768 - val_precision_m: 0.8168 - val_recall_m: 0.7615 - val_f1_m: 0.7869\n","Epoch 20/50\n","131/131 [==============================] - 1s 9ms/step - loss: 0.2814 - accuracy: 0.6046 - precision_m: 0.8419 - recall_m: 0.7741 - f1_m: 0.8053 - val_loss: 0.2697 - val_accuracy: 0.6692 - val_precision_m: 0.8116 - val_recall_m: 0.7682 - val_f1_m: 0.7878\n","Epoch 21/50\n","131/131 [==============================] - 1s 9ms/step - loss: 0.2739 - accuracy: 0.6037 - precision_m: 0.8403 - recall_m: 0.7834 - f1_m: 0.8098 - val_loss: 0.2739 - val_accuracy: 0.6854 - val_precision_m: 0.8027 - val_recall_m: 0.7679 - val_f1_m: 0.7836\n","Epoch 22/50\n","131/131 [==============================] - 1s 9ms/step - loss: 0.2660 - accuracy: 0.6159 - precision_m: 0.8563 - recall_m: 0.7834 - f1_m: 0.8170 - val_loss: 0.2711 - val_accuracy: 0.6730 - val_precision_m: 0.8222 - val_recall_m: 0.7461 - val_f1_m: 0.7808\n","Epoch 23/50\n","131/131 [==============================] - 1s 9ms/step - loss: 0.2654 - accuracy: 0.6118 - precision_m: 0.8607 - recall_m: 0.7868 - f1_m: 0.8206 - val_loss: 0.2685 - val_accuracy: 0.6711 - val_precision_m: 0.8083 - val_recall_m: 0.7485 - val_f1_m: 0.7753\n","Epoch 00023: early stopping\n","Score for fold 2: loss of 0.333236962556839; accuracy of 61.94656491279602% ;precision_m of 0.7834933996200562 ;recall_m of 0.7325789928436279 ;            f1_m of 0.7549492120742798\n","Epoch 1/50\n","131/131 [==============================] - 2s 11ms/step - loss: 0.5736 - accuracy: 0.4325 - precision_m: 0.6067 - recall_m: 0.5145 - f1_m: 0.5452 - val_loss: 0.3478 - val_accuracy: 0.6330 - val_precision_m: 0.7646 - val_recall_m: 0.7095 - val_f1_m: 0.7344\n","Epoch 2/50\n","131/131 [==============================] - 1s 9ms/step - loss: 0.3874 - accuracy: 0.5425 - precision_m: 0.7749 - recall_m: 0.6885 - f1_m: 0.7279 - val_loss: 0.3256 - val_accuracy: 0.6444 - val_precision_m: 0.7983 - val_recall_m: 0.6974 - val_f1_m: 0.7423\n","Epoch 3/50\n","131/131 [==============================] - 1s 9ms/step - loss: 0.3698 - accuracy: 0.5423 - precision_m: 0.7848 - recall_m: 0.6929 - f1_m: 0.7340 - val_loss: 0.3292 - val_accuracy: 0.6358 - val_precision_m: 0.7891 - val_recall_m: 0.7109 - val_f1_m: 0.7460\n","Epoch 4/50\n","131/131 [==============================] - 1s 9ms/step - loss: 0.3651 - accuracy: 0.5612 - precision_m: 0.8030 - recall_m: 0.7045 - f1_m: 0.7491 - val_loss: 0.3233 - val_accuracy: 0.6492 - val_precision_m: 0.8049 - val_recall_m: 0.7207 - val_f1_m: 0.7587\n","Epoch 5/50\n","131/131 [==============================] - 1s 9ms/step - loss: 0.3483 - accuracy: 0.5680 - precision_m: 0.8071 - recall_m: 0.7205 - f1_m: 0.7602 - val_loss: 0.3208 - val_accuracy: 0.6311 - val_precision_m: 0.7791 - val_recall_m: 0.7122 - val_f1_m: 0.7423\n","Epoch 6/50\n","131/131 [==============================] - 1s 9ms/step - loss: 0.3416 - accuracy: 0.5678 - precision_m: 0.8187 - recall_m: 0.7283 - f1_m: 0.7696 - val_loss: 0.3179 - val_accuracy: 0.6425 - val_precision_m: 0.7908 - val_recall_m: 0.7285 - val_f1_m: 0.7562\n","Epoch 7/50\n","131/131 [==============================] - 1s 9ms/step - loss: 0.3360 - accuracy: 0.5574 - precision_m: 0.8195 - recall_m: 0.7329 - f1_m: 0.7723 - val_loss: 0.3223 - val_accuracy: 0.6454 - val_precision_m: 0.7682 - val_recall_m: 0.7408 - val_f1_m: 0.7526\n","Epoch 8/50\n","131/131 [==============================] - 1s 9ms/step - loss: 0.3356 - accuracy: 0.5544 - precision_m: 0.8080 - recall_m: 0.7342 - f1_m: 0.7678 - val_loss: 0.3112 - val_accuracy: 0.6406 - val_precision_m: 0.7991 - val_recall_m: 0.7165 - val_f1_m: 0.7538\n","Epoch 9/50\n","131/131 [==============================] - 1s 9ms/step - loss: 0.3324 - accuracy: 0.5611 - precision_m: 0.8296 - recall_m: 0.7343 - f1_m: 0.7774 - val_loss: 0.3067 - val_accuracy: 0.6368 - val_precision_m: 0.8027 - val_recall_m: 0.7332 - val_f1_m: 0.7652\n","Epoch 10/50\n","131/131 [==============================] - 1s 9ms/step - loss: 0.3227 - accuracy: 0.5641 - precision_m: 0.8316 - recall_m: 0.7494 - f1_m: 0.7870 - val_loss: 0.3176 - val_accuracy: 0.6530 - val_precision_m: 0.8050 - val_recall_m: 0.7286 - val_f1_m: 0.7634\n","Epoch 11/50\n","131/131 [==============================] - 1s 9ms/step - loss: 0.3075 - accuracy: 0.5719 - precision_m: 0.8341 - recall_m: 0.7566 - f1_m: 0.7926 - val_loss: 0.3152 - val_accuracy: 0.6292 - val_precision_m: 0.7904 - val_recall_m: 0.7302 - val_f1_m: 0.7578\n","Epoch 12/50\n","131/131 [==============================] - 1s 9ms/step - loss: 0.3085 - accuracy: 0.5710 - precision_m: 0.8358 - recall_m: 0.7546 - f1_m: 0.7921 - val_loss: 0.3385 - val_accuracy: 0.6806 - val_precision_m: 0.7793 - val_recall_m: 0.7310 - val_f1_m: 0.7527\n","Epoch 13/50\n","131/131 [==============================] - 1s 9ms/step - loss: 0.3103 - accuracy: 0.5797 - precision_m: 0.8265 - recall_m: 0.7594 - f1_m: 0.7903 - val_loss: 0.3253 - val_accuracy: 0.6482 - val_precision_m: 0.7832 - val_recall_m: 0.7406 - val_f1_m: 0.7597\n","Epoch 14/50\n","131/131 [==============================] - 1s 9ms/step - loss: 0.3048 - accuracy: 0.5769 - precision_m: 0.8267 - recall_m: 0.7660 - f1_m: 0.7938 - val_loss: 0.3290 - val_accuracy: 0.6616 - val_precision_m: 0.7759 - val_recall_m: 0.7385 - val_f1_m: 0.7547\n","Epoch 15/50\n","131/131 [==============================] - 1s 9ms/step - loss: 0.3018 - accuracy: 0.5672 - precision_m: 0.8349 - recall_m: 0.7612 - f1_m: 0.7948 - val_loss: 0.3149 - val_accuracy: 0.6673 - val_precision_m: 0.8008 - val_recall_m: 0.7398 - val_f1_m: 0.7675\n","Epoch 16/50\n","131/131 [==============================] - 1s 9ms/step - loss: 0.2947 - accuracy: 0.5696 - precision_m: 0.8440 - recall_m: 0.7710 - f1_m: 0.8048 - val_loss: 0.3186 - val_accuracy: 0.6616 - val_precision_m: 0.7864 - val_recall_m: 0.7420 - val_f1_m: 0.7617\n","Epoch 17/50\n","131/131 [==============================] - 1s 9ms/step - loss: 0.2932 - accuracy: 0.5687 - precision_m: 0.8447 - recall_m: 0.7742 - f1_m: 0.8066 - val_loss: 0.3180 - val_accuracy: 0.6606 - val_precision_m: 0.8169 - val_recall_m: 0.7176 - val_f1_m: 0.7626\n","Epoch 18/50\n","131/131 [==============================] - 1s 9ms/step - loss: 0.2989 - accuracy: 0.5960 - precision_m: 0.8368 - recall_m: 0.7606 - f1_m: 0.7957 - val_loss: 0.3182 - val_accuracy: 0.6568 - val_precision_m: 0.7931 - val_recall_m: 0.7286 - val_f1_m: 0.7579\n","Epoch 19/50\n","131/131 [==============================] - 1s 9ms/step - loss: 0.2856 - accuracy: 0.5899 - precision_m: 0.8453 - recall_m: 0.7739 - f1_m: 0.8068 - val_loss: 0.3080 - val_accuracy: 0.6416 - val_precision_m: 0.7942 - val_recall_m: 0.7388 - val_f1_m: 0.7640\n","Epoch 20/50\n","131/131 [==============================] - 1s 9ms/step - loss: 0.2884 - accuracy: 0.5748 - precision_m: 0.8402 - recall_m: 0.7688 - f1_m: 0.8015 - val_loss: 0.3226 - val_accuracy: 0.6597 - val_precision_m: 0.7862 - val_recall_m: 0.7353 - val_f1_m: 0.7581\n","Epoch 21/50\n","131/131 [==============================] - 1s 9ms/step - loss: 0.2850 - accuracy: 0.5904 - precision_m: 0.8491 - recall_m: 0.7779 - f1_m: 0.8111 - val_loss: 0.3138 - val_accuracy: 0.6435 - val_precision_m: 0.7884 - val_recall_m: 0.7392 - val_f1_m: 0.7612\n","Epoch 22/50\n","131/131 [==============================] - 1s 9ms/step - loss: 0.2895 - accuracy: 0.5835 - precision_m: 0.8460 - recall_m: 0.7760 - f1_m: 0.8082 - val_loss: 0.3091 - val_accuracy: 0.6683 - val_precision_m: 0.8165 - val_recall_m: 0.7143 - val_f1_m: 0.7604\n","Epoch 23/50\n","131/131 [==============================] - 1s 9ms/step - loss: 0.2780 - accuracy: 0.5873 - precision_m: 0.8541 - recall_m: 0.7788 - f1_m: 0.8137 - val_loss: 0.3138 - val_accuracy: 0.6540 - val_precision_m: 0.7925 - val_recall_m: 0.7257 - val_f1_m: 0.7558\n","Epoch 24/50\n","131/131 [==============================] - 1s 9ms/step - loss: 0.2795 - accuracy: 0.5976 - precision_m: 0.8544 - recall_m: 0.7855 - f1_m: 0.8173 - val_loss: 0.3460 - val_accuracy: 0.6787 - val_precision_m: 0.7656 - val_recall_m: 0.7440 - val_f1_m: 0.7526\n","Epoch 25/50\n","131/131 [==============================] - 1s 9ms/step - loss: 0.2758 - accuracy: 0.5877 - precision_m: 0.8562 - recall_m: 0.7920 - f1_m: 0.8214 - val_loss: 0.3156 - val_accuracy: 0.6654 - val_precision_m: 0.7925 - val_recall_m: 0.7300 - val_f1_m: 0.7581\n","Epoch 00025: early stopping\n","Score for fold 3: loss of 0.2979499399662018; accuracy of 65.1526689529419% ;precision_m of 0.8097653985023499 ;recall_m of 0.7311171889305115 ;            f1_m of 0.7668278217315674\n","Epoch 1/50\n","131/131 [==============================] - 2s 8ms/step - loss: 1.2345 - accuracy: 0.3094 - precision_m: 0.4361 - recall_m: 0.4249 - f1_m: 0.4279 - val_loss: 0.3718 - val_accuracy: 0.5630 - val_precision_m: 0.7368 - val_recall_m: 0.6340 - val_f1_m: 0.6796\n","Epoch 2/50\n","131/131 [==============================] - 1s 6ms/step - loss: 0.5110 - accuracy: 0.5169 - precision_m: 0.6744 - recall_m: 0.6168 - f1_m: 0.6422 - val_loss: 0.3318 - val_accuracy: 0.6011 - val_precision_m: 0.7489 - val_recall_m: 0.7050 - val_f1_m: 0.7243\n","Epoch 3/50\n","131/131 [==============================] - 1s 6ms/step - loss: 0.4035 - accuracy: 0.5679 - precision_m: 0.7374 - recall_m: 0.6657 - f1_m: 0.6983 - val_loss: 0.3135 - val_accuracy: 0.6116 - val_precision_m: 0.7866 - val_recall_m: 0.6931 - val_f1_m: 0.7351\n","Epoch 4/50\n","131/131 [==============================] - 1s 6ms/step - loss: 0.3434 - accuracy: 0.5950 - precision_m: 0.7807 - recall_m: 0.7042 - f1_m: 0.7391 - val_loss: 0.3028 - val_accuracy: 0.6489 - val_precision_m: 0.7907 - val_recall_m: 0.7288 - val_f1_m: 0.7570\n","Epoch 5/50\n","131/131 [==============================] - 1s 6ms/step - loss: 0.3095 - accuracy: 0.6173 - precision_m: 0.7934 - recall_m: 0.7244 - f1_m: 0.7559 - val_loss: 0.2924 - val_accuracy: 0.6345 - val_precision_m: 0.8174 - val_recall_m: 0.7224 - val_f1_m: 0.7652\n","Epoch 6/50\n","131/131 [==============================] - 1s 6ms/step - loss: 0.2998 - accuracy: 0.6164 - precision_m: 0.8082 - recall_m: 0.7382 - f1_m: 0.7700 - val_loss: 0.2920 - val_accuracy: 0.6613 - val_precision_m: 0.8090 - val_recall_m: 0.7278 - val_f1_m: 0.7641\n","Epoch 7/50\n","131/131 [==============================] - 1s 6ms/step - loss: 0.2742 - accuracy: 0.6347 - precision_m: 0.8241 - recall_m: 0.7602 - f1_m: 0.7895 - val_loss: 0.2765 - val_accuracy: 0.6517 - val_precision_m: 0.8137 - val_recall_m: 0.7512 - val_f1_m: 0.7794\n","Epoch 8/50\n","131/131 [==============================] - 1s 6ms/step - loss: 0.2645 - accuracy: 0.6530 - precision_m: 0.8367 - recall_m: 0.7750 - f1_m: 0.8034 - val_loss: 0.2852 - val_accuracy: 0.6613 - val_precision_m: 0.8124 - val_recall_m: 0.7378 - val_f1_m: 0.7721\n","Epoch 9/50\n","131/131 [==============================] - 1s 6ms/step - loss: 0.2547 - accuracy: 0.6494 - precision_m: 0.8376 - recall_m: 0.7726 - f1_m: 0.8025 - val_loss: 0.2780 - val_accuracy: 0.6632 - val_precision_m: 0.8196 - val_recall_m: 0.7418 - val_f1_m: 0.7775\n","Epoch 10/50\n","131/131 [==============================] - 1s 6ms/step - loss: 0.2353 - accuracy: 0.6593 - precision_m: 0.8566 - recall_m: 0.8046 - f1_m: 0.8286 - val_loss: 0.2797 - val_accuracy: 0.6613 - val_precision_m: 0.8054 - val_recall_m: 0.7493 - val_f1_m: 0.7755\n","Epoch 11/50\n","131/131 [==============================] - 1s 6ms/step - loss: 0.2281 - accuracy: 0.6627 - precision_m: 0.8608 - recall_m: 0.8058 - f1_m: 0.8314 - val_loss: 0.2785 - val_accuracy: 0.6460 - val_precision_m: 0.8217 - val_recall_m: 0.7574 - val_f1_m: 0.7870\n","Epoch 12/50\n","131/131 [==============================] - 1s 6ms/step - loss: 0.2165 - accuracy: 0.6523 - precision_m: 0.8699 - recall_m: 0.8203 - f1_m: 0.8432 - val_loss: 0.2783 - val_accuracy: 0.6546 - val_precision_m: 0.8183 - val_recall_m: 0.7482 - val_f1_m: 0.7805\n","Epoch 13/50\n","131/131 [==============================] - 1s 6ms/step - loss: 0.2050 - accuracy: 0.6734 - precision_m: 0.8736 - recall_m: 0.8227 - f1_m: 0.8462 - val_loss: 0.2730 - val_accuracy: 0.6555 - val_precision_m: 0.8097 - val_recall_m: 0.7617 - val_f1_m: 0.7839\n","Epoch 14/50\n","131/131 [==============================] - 1s 6ms/step - loss: 0.2003 - accuracy: 0.7011 - precision_m: 0.8745 - recall_m: 0.8282 - f1_m: 0.8498 - val_loss: 0.2724 - val_accuracy: 0.6689 - val_precision_m: 0.8132 - val_recall_m: 0.7679 - val_f1_m: 0.7890\n","Epoch 15/50\n","131/131 [==============================] - 1s 6ms/step - loss: 0.2009 - accuracy: 0.6735 - precision_m: 0.8810 - recall_m: 0.8292 - f1_m: 0.8537 - val_loss: 0.2713 - val_accuracy: 0.6708 - val_precision_m: 0.8176 - val_recall_m: 0.7600 - val_f1_m: 0.7862\n","Epoch 16/50\n","131/131 [==============================] - 1s 6ms/step - loss: 0.2017 - accuracy: 0.6746 - precision_m: 0.8817 - recall_m: 0.8282 - f1_m: 0.8531 - val_loss: 0.2750 - val_accuracy: 0.6594 - val_precision_m: 0.8243 - val_recall_m: 0.7523 - val_f1_m: 0.7857\n","Epoch 17/50\n","131/131 [==============================] - 1s 6ms/step - loss: 0.1838 - accuracy: 0.6878 - precision_m: 0.8965 - recall_m: 0.8424 - f1_m: 0.8675 - val_loss: 0.2805 - val_accuracy: 0.6632 - val_precision_m: 0.8162 - val_recall_m: 0.7586 - val_f1_m: 0.7853\n","Epoch 18/50\n","131/131 [==============================] - 1s 6ms/step - loss: 0.1758 - accuracy: 0.6921 - precision_m: 0.8963 - recall_m: 0.8563 - f1_m: 0.8749 - val_loss: 0.2782 - val_accuracy: 0.6718 - val_precision_m: 0.8091 - val_recall_m: 0.7658 - val_f1_m: 0.7857\n","Epoch 19/50\n","131/131 [==============================] - 1s 6ms/step - loss: 0.1762 - accuracy: 0.6994 - precision_m: 0.8909 - recall_m: 0.8501 - f1_m: 0.8689 - val_loss: 0.2813 - val_accuracy: 0.6794 - val_precision_m: 0.8074 - val_recall_m: 0.7540 - val_f1_m: 0.7789\n","Epoch 20/50\n","131/131 [==============================] - 1s 6ms/step - loss: 0.1745 - accuracy: 0.7034 - precision_m: 0.8993 - recall_m: 0.8556 - f1_m: 0.8760 - val_loss: 0.2826 - val_accuracy: 0.6660 - val_precision_m: 0.8028 - val_recall_m: 0.7739 - val_f1_m: 0.7869\n","Epoch 21/50\n","131/131 [==============================] - 1s 6ms/step - loss: 0.1688 - accuracy: 0.7001 - precision_m: 0.9009 - recall_m: 0.8657 - f1_m: 0.8821 - val_loss: 0.2845 - val_accuracy: 0.6641 - val_precision_m: 0.8235 - val_recall_m: 0.7630 - val_f1_m: 0.7906\n","Epoch 22/50\n","131/131 [==============================] - 1s 6ms/step - loss: 0.1619 - accuracy: 0.7024 - precision_m: 0.9027 - recall_m: 0.8723 - f1_m: 0.8865 - val_loss: 0.2825 - val_accuracy: 0.6641 - val_precision_m: 0.8261 - val_recall_m: 0.7549 - val_f1_m: 0.7878\n","Epoch 23/50\n","131/131 [==============================] - 1s 6ms/step - loss: 0.1651 - accuracy: 0.7039 - precision_m: 0.8966 - recall_m: 0.8572 - f1_m: 0.8755 - val_loss: 0.2834 - val_accuracy: 0.6708 - val_precision_m: 0.8155 - val_recall_m: 0.7745 - val_f1_m: 0.7934\n","Epoch 24/50\n","131/131 [==============================] - 1s 6ms/step - loss: 0.1605 - accuracy: 0.6939 - precision_m: 0.9042 - recall_m: 0.8707 - f1_m: 0.8861 - val_loss: 0.2830 - val_accuracy: 0.6727 - val_precision_m: 0.8210 - val_recall_m: 0.7706 - val_f1_m: 0.7936\n","Epoch 25/50\n","131/131 [==============================] - 1s 6ms/step - loss: 0.1578 - accuracy: 0.6944 - precision_m: 0.9066 - recall_m: 0.8801 - f1_m: 0.8925 - val_loss: 0.2897 - val_accuracy: 0.6737 - val_precision_m: 0.8317 - val_recall_m: 0.7389 - val_f1_m: 0.7813\n","Epoch 26/50\n","131/131 [==============================] - 1s 6ms/step - loss: 0.1494 - accuracy: 0.7267 - precision_m: 0.9155 - recall_m: 0.8720 - f1_m: 0.8921 - val_loss: 0.2900 - val_accuracy: 0.6574 - val_precision_m: 0.8153 - val_recall_m: 0.7671 - val_f1_m: 0.7892\n","Epoch 27/50\n","131/131 [==============================] - 1s 6ms/step - loss: 0.1483 - accuracy: 0.7126 - precision_m: 0.9122 - recall_m: 0.8861 - f1_m: 0.8977 - val_loss: 0.2895 - val_accuracy: 0.6641 - val_precision_m: 0.8084 - val_recall_m: 0.7705 - val_f1_m: 0.7878\n","Epoch 28/50\n","131/131 [==============================] - 1s 6ms/step - loss: 0.1459 - accuracy: 0.6984 - precision_m: 0.9141 - recall_m: 0.8818 - f1_m: 0.8971 - val_loss: 0.2966 - val_accuracy: 0.6689 - val_precision_m: 0.8276 - val_recall_m: 0.7495 - val_f1_m: 0.7855\n","Epoch 29/50\n","131/131 [==============================] - 1s 6ms/step - loss: 0.1425 - accuracy: 0.7042 - precision_m: 0.9176 - recall_m: 0.8898 - f1_m: 0.9027 - val_loss: 0.3073 - val_accuracy: 0.6412 - val_precision_m: 0.8008 - val_recall_m: 0.7869 - val_f1_m: 0.7924\n","Epoch 30/50\n","131/131 [==============================] - 1s 6ms/step - loss: 0.1349 - accuracy: 0.7161 - precision_m: 0.9152 - recall_m: 0.8966 - f1_m: 0.9052 - val_loss: 0.2988 - val_accuracy: 0.6603 - val_precision_m: 0.8224 - val_recall_m: 0.7593 - val_f1_m: 0.7881\n","Epoch 31/50\n","131/131 [==============================] - 1s 6ms/step - loss: 0.1371 - accuracy: 0.7336 - precision_m: 0.9219 - recall_m: 0.8887 - f1_m: 0.9042 - val_loss: 0.3010 - val_accuracy: 0.6479 - val_precision_m: 0.8155 - val_recall_m: 0.7605 - val_f1_m: 0.7857\n","Epoch 32/50\n","131/131 [==============================] - 1s 6ms/step - loss: 0.1349 - accuracy: 0.7201 - precision_m: 0.9189 - recall_m: 0.8899 - f1_m: 0.9034 - val_loss: 0.3029 - val_accuracy: 0.6517 - val_precision_m: 0.8119 - val_recall_m: 0.7550 - val_f1_m: 0.7814\n","Epoch 33/50\n","131/131 [==============================] - 1s 6ms/step - loss: 0.1330 - accuracy: 0.7143 - precision_m: 0.9176 - recall_m: 0.8968 - f1_m: 0.9060 - val_loss: 0.3110 - val_accuracy: 0.6489 - val_precision_m: 0.8049 - val_recall_m: 0.7571 - val_f1_m: 0.7788\n","Epoch 34/50\n","131/131 [==============================] - 1s 6ms/step - loss: 0.1277 - accuracy: 0.7209 - precision_m: 0.9244 - recall_m: 0.9009 - f1_m: 0.9119 - val_loss: 0.3069 - val_accuracy: 0.6498 - val_precision_m: 0.8039 - val_recall_m: 0.7581 - val_f1_m: 0.7793\n","Epoch 00034: early stopping\n","Score for fold 1: loss of 0.7127891778945923; accuracy of 49.713850021362305% ;precision_m of 0.8372265696525574 ;recall_m of 0.592262327671051 ;            f1_m of 0.6882032752037048\n","Epoch 1/50\n","131/131 [==============================] - 2s 8ms/step - loss: 1.4639 - accuracy: 0.2822 - precision_m: 0.4343 - recall_m: 0.4357 - f1_m: 0.4318 - val_loss: 0.3984 - val_accuracy: 0.5806 - val_precision_m: 0.6691 - val_recall_m: 0.6491 - val_f1_m: 0.6562\n","Epoch 2/50\n","131/131 [==============================] - 1s 6ms/step - loss: 0.6467 - accuracy: 0.4667 - precision_m: 0.6141 - recall_m: 0.5863 - f1_m: 0.5978 - val_loss: 0.3644 - val_accuracy: 0.5939 - val_precision_m: 0.7001 - val_recall_m: 0.7448 - val_f1_m: 0.7201\n","Epoch 3/50\n","131/131 [==============================] - 1s 6ms/step - loss: 0.5122 - accuracy: 0.5300 - precision_m: 0.6796 - recall_m: 0.6352 - f1_m: 0.6550 - val_loss: 0.3367 - val_accuracy: 0.6463 - val_precision_m: 0.7366 - val_recall_m: 0.7385 - val_f1_m: 0.7362\n","Epoch 4/50\n","131/131 [==============================] - 1s 6ms/step - loss: 0.4276 - accuracy: 0.5498 - precision_m: 0.7398 - recall_m: 0.6905 - f1_m: 0.7128 - val_loss: 0.3194 - val_accuracy: 0.6616 - val_precision_m: 0.7504 - val_recall_m: 0.7632 - val_f1_m: 0.7549\n","Epoch 5/50\n","131/131 [==============================] - 1s 6ms/step - loss: 0.3923 - accuracy: 0.5675 - precision_m: 0.7622 - recall_m: 0.7032 - f1_m: 0.7300 - val_loss: 0.3100 - val_accuracy: 0.6892 - val_precision_m: 0.7790 - val_recall_m: 0.7329 - val_f1_m: 0.7538\n","Epoch 6/50\n","131/131 [==============================] - 1s 6ms/step - loss: 0.3419 - accuracy: 0.6000 - precision_m: 0.8007 - recall_m: 0.7396 - f1_m: 0.7672 - val_loss: 0.2905 - val_accuracy: 0.6768 - val_precision_m: 0.8010 - val_recall_m: 0.7553 - val_f1_m: 0.7758\n","Epoch 7/50\n","131/131 [==============================] - 1s 6ms/step - loss: 0.3272 - accuracy: 0.6136 - precision_m: 0.8074 - recall_m: 0.7513 - f1_m: 0.7768 - val_loss: 0.2851 - val_accuracy: 0.6816 - val_precision_m: 0.7859 - val_recall_m: 0.7751 - val_f1_m: 0.7793\n","Epoch 8/50\n","131/131 [==============================] - 1s 6ms/step - loss: 0.3130 - accuracy: 0.5999 - precision_m: 0.8155 - recall_m: 0.7767 - f1_m: 0.7942 - val_loss: 0.2872 - val_accuracy: 0.6854 - val_precision_m: 0.7995 - val_recall_m: 0.7616 - val_f1_m: 0.7785\n","Epoch 9/50\n","131/131 [==============================] - 1s 6ms/step - loss: 0.2952 - accuracy: 0.6076 - precision_m: 0.8340 - recall_m: 0.7727 - f1_m: 0.8011 - val_loss: 0.2754 - val_accuracy: 0.6997 - val_precision_m: 0.8156 - val_recall_m: 0.7520 - val_f1_m: 0.7811\n","Epoch 10/50\n","131/131 [==============================] - 1s 6ms/step - loss: 0.2727 - accuracy: 0.6146 - precision_m: 0.8462 - recall_m: 0.7877 - f1_m: 0.8148 - val_loss: 0.2748 - val_accuracy: 0.6902 - val_precision_m: 0.8101 - val_recall_m: 0.7663 - val_f1_m: 0.7861\n","Epoch 11/50\n","131/131 [==============================] - 1s 6ms/step - loss: 0.2614 - accuracy: 0.6234 - precision_m: 0.8570 - recall_m: 0.7976 - f1_m: 0.8249 - val_loss: 0.2745 - val_accuracy: 0.6845 - val_precision_m: 0.8022 - val_recall_m: 0.7657 - val_f1_m: 0.7819\n","Epoch 12/50\n","131/131 [==============================] - 1s 6ms/step - loss: 0.2530 - accuracy: 0.6252 - precision_m: 0.8646 - recall_m: 0.8109 - f1_m: 0.8359 - val_loss: 0.2734 - val_accuracy: 0.6873 - val_precision_m: 0.8086 - val_recall_m: 0.7757 - val_f1_m: 0.7906\n","Epoch 13/50\n","131/131 [==============================] - 1s 6ms/step - loss: 0.2490 - accuracy: 0.6327 - precision_m: 0.8678 - recall_m: 0.8096 - f1_m: 0.8368 - val_loss: 0.2748 - val_accuracy: 0.6997 - val_precision_m: 0.7995 - val_recall_m: 0.7663 - val_f1_m: 0.7809\n","Epoch 14/50\n","131/131 [==============================] - 1s 6ms/step - loss: 0.2418 - accuracy: 0.6422 - precision_m: 0.8636 - recall_m: 0.8177 - f1_m: 0.8390 - val_loss: 0.2711 - val_accuracy: 0.6806 - val_precision_m: 0.8135 - val_recall_m: 0.7703 - val_f1_m: 0.7892\n","Epoch 15/50\n","131/131 [==============================] - 1s 6ms/step - loss: 0.2426 - accuracy: 0.6361 - precision_m: 0.8728 - recall_m: 0.8107 - f1_m: 0.8395 - val_loss: 0.2697 - val_accuracy: 0.6778 - val_precision_m: 0.8156 - val_recall_m: 0.7628 - val_f1_m: 0.7866\n","Epoch 16/50\n","131/131 [==============================] - 1s 6ms/step - loss: 0.2347 - accuracy: 0.6373 - precision_m: 0.8724 - recall_m: 0.8192 - f1_m: 0.8437 - val_loss: 0.2726 - val_accuracy: 0.6930 - val_precision_m: 0.8201 - val_recall_m: 0.7663 - val_f1_m: 0.7906\n","Epoch 17/50\n","131/131 [==============================] - 1s 6ms/step - loss: 0.2363 - accuracy: 0.6419 - precision_m: 0.8754 - recall_m: 0.8246 - f1_m: 0.8480 - val_loss: 0.2677 - val_accuracy: 0.7035 - val_precision_m: 0.8194 - val_recall_m: 0.7600 - val_f1_m: 0.7871\n","Epoch 18/50\n","131/131 [==============================] - 1s 6ms/step - loss: 0.2290 - accuracy: 0.6444 - precision_m: 0.8755 - recall_m: 0.8274 - f1_m: 0.8497 - val_loss: 0.2666 - val_accuracy: 0.6826 - val_precision_m: 0.8217 - val_recall_m: 0.7560 - val_f1_m: 0.7858\n","Epoch 19/50\n","131/131 [==============================] - 1s 6ms/step - loss: 0.2229 - accuracy: 0.6495 - precision_m: 0.8752 - recall_m: 0.8271 - f1_m: 0.8491 - val_loss: 0.2730 - val_accuracy: 0.6892 - val_precision_m: 0.8179 - val_recall_m: 0.7673 - val_f1_m: 0.7899\n","Epoch 20/50\n","131/131 [==============================] - 1s 6ms/step - loss: 0.2167 - accuracy: 0.6380 - precision_m: 0.8865 - recall_m: 0.8406 - f1_m: 0.8620 - val_loss: 0.2752 - val_accuracy: 0.6930 - val_precision_m: 0.8200 - val_recall_m: 0.7829 - val_f1_m: 0.7995\n","Epoch 21/50\n","131/131 [==============================] - 1s 6ms/step - loss: 0.2034 - accuracy: 0.6521 - precision_m: 0.8964 - recall_m: 0.8554 - f1_m: 0.8746 - val_loss: 0.2710 - val_accuracy: 0.6997 - val_precision_m: 0.8155 - val_recall_m: 0.7880 - val_f1_m: 0.7995\n","Epoch 22/50\n","131/131 [==============================] - 1s 6ms/step - loss: 0.1968 - accuracy: 0.6453 - precision_m: 0.8969 - recall_m: 0.8621 - f1_m: 0.8778 - val_loss: 0.2709 - val_accuracy: 0.7007 - val_precision_m: 0.8169 - val_recall_m: 0.7908 - val_f1_m: 0.8023\n","Epoch 23/50\n","131/131 [==============================] - 1s 6ms/step - loss: 0.2064 - accuracy: 0.6441 - precision_m: 0.8910 - recall_m: 0.8503 - f1_m: 0.8694 - val_loss: 0.2735 - val_accuracy: 0.6988 - val_precision_m: 0.8216 - val_recall_m: 0.7795 - val_f1_m: 0.7987\n","Epoch 24/50\n","131/131 [==============================] - 1s 6ms/step - loss: 0.1954 - accuracy: 0.6558 - precision_m: 0.8959 - recall_m: 0.8531 - f1_m: 0.8733 - val_loss: 0.2727 - val_accuracy: 0.6921 - val_precision_m: 0.8273 - val_recall_m: 0.7727 - val_f1_m: 0.7974\n","Epoch 25/50\n","131/131 [==============================] - 1s 6ms/step - loss: 0.1961 - accuracy: 0.6448 - precision_m: 0.8980 - recall_m: 0.8530 - f1_m: 0.8741 - val_loss: 0.2809 - val_accuracy: 0.7026 - val_precision_m: 0.8199 - val_recall_m: 0.7610 - val_f1_m: 0.7874\n","Epoch 26/50\n","131/131 [==============================] - 1s 6ms/step - loss: 0.1885 - accuracy: 0.6542 - precision_m: 0.9052 - recall_m: 0.8648 - f1_m: 0.8838 - val_loss: 0.2712 - val_accuracy: 0.6959 - val_precision_m: 0.8163 - val_recall_m: 0.7798 - val_f1_m: 0.7958\n","Epoch 27/50\n","131/131 [==============================] - 1s 6ms/step - loss: 0.1861 - accuracy: 0.6485 - precision_m: 0.9012 - recall_m: 0.8655 - f1_m: 0.8820 - val_loss: 0.2742 - val_accuracy: 0.6854 - val_precision_m: 0.8155 - val_recall_m: 0.7784 - val_f1_m: 0.7949\n","Epoch 28/50\n","131/131 [==============================] - 1s 6ms/step - loss: 0.1916 - accuracy: 0.6410 - precision_m: 0.8943 - recall_m: 0.8591 - f1_m: 0.8756 - val_loss: 0.2843 - val_accuracy: 0.6921 - val_precision_m: 0.8188 - val_recall_m: 0.7609 - val_f1_m: 0.7872\n","Epoch 29/50\n","131/131 [==============================] - 1s 6ms/step - loss: 0.1736 - accuracy: 0.6564 - precision_m: 0.9116 - recall_m: 0.8704 - f1_m: 0.8896 - val_loss: 0.2833 - val_accuracy: 0.7092 - val_precision_m: 0.8139 - val_recall_m: 0.7741 - val_f1_m: 0.7921\n","Epoch 30/50\n","131/131 [==============================] - 1s 6ms/step - loss: 0.1823 - accuracy: 0.6632 - precision_m: 0.9097 - recall_m: 0.8686 - f1_m: 0.8880 - val_loss: 0.2842 - val_accuracy: 0.6969 - val_precision_m: 0.8222 - val_recall_m: 0.7555 - val_f1_m: 0.7858\n","Epoch 31/50\n","131/131 [==============================] - 1s 6ms/step - loss: 0.1801 - accuracy: 0.6564 - precision_m: 0.9090 - recall_m: 0.8734 - f1_m: 0.8901 - val_loss: 0.2806 - val_accuracy: 0.6949 - val_precision_m: 0.8139 - val_recall_m: 0.7737 - val_f1_m: 0.7921\n","Epoch 32/50\n","131/131 [==============================] - 1s 6ms/step - loss: 0.1672 - accuracy: 0.6635 - precision_m: 0.9122 - recall_m: 0.8859 - f1_m: 0.8981 - val_loss: 0.2824 - val_accuracy: 0.7045 - val_precision_m: 0.8217 - val_recall_m: 0.7631 - val_f1_m: 0.7896\n","Epoch 00032: early stopping\n","Score for fold 2: loss of 0.35961833596229553; accuracy of 64.88549709320068% ;precision_m of 0.7974687814712524 ;recall_m of 0.7494150400161743 ;            f1_m of 0.7710337042808533\n","Epoch 1/50\n","131/131 [==============================] - 1s 7ms/step - loss: 1.6626 - accuracy: 0.2670 - precision_m: 0.4270 - recall_m: 0.4330 - f1_m: 0.4252 - val_loss: 0.4171 - val_accuracy: 0.5615 - val_precision_m: 0.6624 - val_recall_m: 0.7099 - val_f1_m: 0.6833\n","Epoch 2/50\n","131/131 [==============================] - 1s 6ms/step - loss: 0.6745 - accuracy: 0.4292 - precision_m: 0.6130 - recall_m: 0.5813 - f1_m: 0.5946 - val_loss: 0.3752 - val_accuracy: 0.5758 - val_precision_m: 0.7116 - val_recall_m: 0.7240 - val_f1_m: 0.7156\n","Epoch 3/50\n","131/131 [==============================] - 1s 6ms/step - loss: 0.5107 - accuracy: 0.4954 - precision_m: 0.6963 - recall_m: 0.6409 - f1_m: 0.6654 - val_loss: 0.3630 - val_accuracy: 0.6235 - val_precision_m: 0.7412 - val_recall_m: 0.7188 - val_f1_m: 0.7273\n","Epoch 4/50\n","131/131 [==============================] - 1s 6ms/step - loss: 0.4371 - accuracy: 0.5423 - precision_m: 0.7350 - recall_m: 0.6708 - f1_m: 0.6998 - val_loss: 0.3566 - val_accuracy: 0.6463 - val_precision_m: 0.7470 - val_recall_m: 0.7509 - val_f1_m: 0.7467\n","Epoch 5/50\n","131/131 [==============================] - 1s 6ms/step - loss: 0.3920 - accuracy: 0.5547 - precision_m: 0.7779 - recall_m: 0.7125 - f1_m: 0.7421 - val_loss: 0.3396 - val_accuracy: 0.6482 - val_precision_m: 0.7730 - val_recall_m: 0.7276 - val_f1_m: 0.7473\n","Epoch 6/50\n","131/131 [==============================] - 1s 6ms/step - loss: 0.3690 - accuracy: 0.5640 - precision_m: 0.7886 - recall_m: 0.7187 - f1_m: 0.7504 - val_loss: 0.3323 - val_accuracy: 0.6568 - val_precision_m: 0.7468 - val_recall_m: 0.7798 - val_f1_m: 0.7614\n","Epoch 7/50\n","131/131 [==============================] - 1s 6ms/step - loss: 0.3435 - accuracy: 0.5544 - precision_m: 0.7960 - recall_m: 0.7479 - f1_m: 0.7696 - val_loss: 0.3264 - val_accuracy: 0.6540 - val_precision_m: 0.7672 - val_recall_m: 0.7526 - val_f1_m: 0.7583\n","Epoch 8/50\n","131/131 [==============================] - 1s 6ms/step - loss: 0.3185 - accuracy: 0.5788 - precision_m: 0.8278 - recall_m: 0.7608 - f1_m: 0.7907 - val_loss: 0.3173 - val_accuracy: 0.6625 - val_precision_m: 0.7778 - val_recall_m: 0.7670 - val_f1_m: 0.7711\n","Epoch 9/50\n","131/131 [==============================] - 1s 6ms/step - loss: 0.3095 - accuracy: 0.5907 - precision_m: 0.8311 - recall_m: 0.7704 - f1_m: 0.7984 - val_loss: 0.3219 - val_accuracy: 0.6501 - val_precision_m: 0.7785 - val_recall_m: 0.7588 - val_f1_m: 0.7671\n","Epoch 10/50\n","131/131 [==============================] - 1s 6ms/step - loss: 0.2970 - accuracy: 0.5962 - precision_m: 0.8370 - recall_m: 0.7772 - f1_m: 0.8044 - val_loss: 0.3176 - val_accuracy: 0.6616 - val_precision_m: 0.7988 - val_recall_m: 0.7505 - val_f1_m: 0.7724\n","Epoch 11/50\n","131/131 [==============================] - 1s 6ms/step - loss: 0.2858 - accuracy: 0.6297 - precision_m: 0.8487 - recall_m: 0.7797 - f1_m: 0.8115 - val_loss: 0.3132 - val_accuracy: 0.6711 - val_precision_m: 0.7726 - val_recall_m: 0.7675 - val_f1_m: 0.7688\n","Epoch 12/50\n","131/131 [==============================] - 1s 6ms/step - loss: 0.2624 - accuracy: 0.6062 - precision_m: 0.8629 - recall_m: 0.8091 - f1_m: 0.8341 - val_loss: 0.3146 - val_accuracy: 0.6616 - val_precision_m: 0.7870 - val_recall_m: 0.7564 - val_f1_m: 0.7700\n","Epoch 13/50\n","131/131 [==============================] - 1s 6ms/step - loss: 0.2710 - accuracy: 0.5911 - precision_m: 0.8639 - recall_m: 0.7961 - f1_m: 0.8272 - val_loss: 0.3238 - val_accuracy: 0.6673 - val_precision_m: 0.7686 - val_recall_m: 0.7841 - val_f1_m: 0.7750\n","Epoch 14/50\n","131/131 [==============================] - 1s 6ms/step - loss: 0.2581 - accuracy: 0.6211 - precision_m: 0.8634 - recall_m: 0.8176 - f1_m: 0.8388 - val_loss: 0.3156 - val_accuracy: 0.6692 - val_precision_m: 0.7937 - val_recall_m: 0.7592 - val_f1_m: 0.7738\n","Epoch 15/50\n","131/131 [==============================] - 1s 6ms/step - loss: 0.2554 - accuracy: 0.6017 - precision_m: 0.8639 - recall_m: 0.8184 - f1_m: 0.8395 - val_loss: 0.3194 - val_accuracy: 0.6835 - val_precision_m: 0.7907 - val_recall_m: 0.7400 - val_f1_m: 0.7630\n","Epoch 16/50\n","131/131 [==============================] - 1s 6ms/step - loss: 0.2495 - accuracy: 0.6141 - precision_m: 0.8677 - recall_m: 0.8142 - f1_m: 0.8389 - val_loss: 0.3049 - val_accuracy: 0.6730 - val_precision_m: 0.8084 - val_recall_m: 0.7583 - val_f1_m: 0.7807\n","Epoch 17/50\n","131/131 [==============================] - 1s 6ms/step - loss: 0.2327 - accuracy: 0.6224 - precision_m: 0.8850 - recall_m: 0.8260 - f1_m: 0.8536 - val_loss: 0.3063 - val_accuracy: 0.6778 - val_precision_m: 0.7861 - val_recall_m: 0.7619 - val_f1_m: 0.7718\n","Epoch 18/50\n","131/131 [==============================] - 1s 6ms/step - loss: 0.2412 - accuracy: 0.6233 - precision_m: 0.8756 - recall_m: 0.8280 - f1_m: 0.8503 - val_loss: 0.3098 - val_accuracy: 0.6740 - val_precision_m: 0.7913 - val_recall_m: 0.7699 - val_f1_m: 0.7789\n","Epoch 19/50\n","131/131 [==============================] - 1s 6ms/step - loss: 0.2301 - accuracy: 0.6206 - precision_m: 0.8764 - recall_m: 0.8345 - f1_m: 0.8537 - val_loss: 0.3235 - val_accuracy: 0.6835 - val_precision_m: 0.7748 - val_recall_m: 0.7811 - val_f1_m: 0.7762\n","Epoch 20/50\n","131/131 [==============================] - 1s 6ms/step - loss: 0.2247 - accuracy: 0.6164 - precision_m: 0.8839 - recall_m: 0.8398 - f1_m: 0.8602 - val_loss: 0.3194 - val_accuracy: 0.6845 - val_precision_m: 0.7786 - val_recall_m: 0.7612 - val_f1_m: 0.7679\n","Epoch 21/50\n","131/131 [==============================] - 1s 6ms/step - loss: 0.2235 - accuracy: 0.6223 - precision_m: 0.8817 - recall_m: 0.8426 - f1_m: 0.8607 - val_loss: 0.3205 - val_accuracy: 0.6864 - val_precision_m: 0.7792 - val_recall_m: 0.7687 - val_f1_m: 0.7722\n","Epoch 22/50\n","131/131 [==============================] - 1s 6ms/step - loss: 0.2129 - accuracy: 0.6372 - precision_m: 0.8835 - recall_m: 0.8476 - f1_m: 0.8643 - val_loss: 0.3189 - val_accuracy: 0.6911 - val_precision_m: 0.7855 - val_recall_m: 0.7611 - val_f1_m: 0.7717\n","Epoch 23/50\n","131/131 [==============================] - 1s 6ms/step - loss: 0.2220 - accuracy: 0.6385 - precision_m: 0.8756 - recall_m: 0.8437 - f1_m: 0.8583 - val_loss: 0.3151 - val_accuracy: 0.6949 - val_precision_m: 0.7987 - val_recall_m: 0.7764 - val_f1_m: 0.7860\n","Epoch 24/50\n","131/131 [==============================] - 1s 6ms/step - loss: 0.2076 - accuracy: 0.6121 - precision_m: 0.8877 - recall_m: 0.8581 - f1_m: 0.8716 - val_loss: 0.3215 - val_accuracy: 0.6911 - val_precision_m: 0.7936 - val_recall_m: 0.7627 - val_f1_m: 0.7763\n","Epoch 25/50\n","131/131 [==============================] - 1s 6ms/step - loss: 0.2027 - accuracy: 0.6306 - precision_m: 0.8936 - recall_m: 0.8523 - f1_m: 0.8717 - val_loss: 0.3221 - val_accuracy: 0.6826 - val_precision_m: 0.7921 - val_recall_m: 0.7670 - val_f1_m: 0.7780\n","Epoch 26/50\n","131/131 [==============================] - 1s 6ms/step - loss: 0.1966 - accuracy: 0.6242 - precision_m: 0.8970 - recall_m: 0.8626 - f1_m: 0.8786 - val_loss: 0.3180 - val_accuracy: 0.6902 - val_precision_m: 0.7970 - val_recall_m: 0.7622 - val_f1_m: 0.7777\n","Epoch 27/50\n","131/131 [==============================] - 1s 6ms/step - loss: 0.2085 - accuracy: 0.6223 - precision_m: 0.8886 - recall_m: 0.8446 - f1_m: 0.8655 - val_loss: 0.3166 - val_accuracy: 0.6768 - val_precision_m: 0.8044 - val_recall_m: 0.7574 - val_f1_m: 0.7788\n","Epoch 28/50\n","131/131 [==============================] - 1s 6ms/step - loss: 0.1937 - accuracy: 0.6279 - precision_m: 0.9003 - recall_m: 0.8582 - f1_m: 0.8777 - val_loss: 0.3255 - val_accuracy: 0.6959 - val_precision_m: 0.7816 - val_recall_m: 0.7703 - val_f1_m: 0.7744\n","Epoch 29/50\n","131/131 [==============================] - 1s 6ms/step - loss: 0.1861 - accuracy: 0.6417 - precision_m: 0.9004 - recall_m: 0.8732 - f1_m: 0.8856 - val_loss: 0.3236 - val_accuracy: 0.6873 - val_precision_m: 0.7982 - val_recall_m: 0.7497 - val_f1_m: 0.7715\n","Epoch 30/50\n","131/131 [==============================] - 1s 6ms/step - loss: 0.1894 - accuracy: 0.6399 - precision_m: 0.9006 - recall_m: 0.8645 - f1_m: 0.8815 - val_loss: 0.3254 - val_accuracy: 0.6892 - val_precision_m: 0.7884 - val_recall_m: 0.7643 - val_f1_m: 0.7745\n","Epoch 31/50\n","131/131 [==============================] - 1s 6ms/step - loss: 0.1944 - accuracy: 0.6241 - precision_m: 0.9003 - recall_m: 0.8651 - f1_m: 0.8814 - val_loss: 0.3368 - val_accuracy: 0.6883 - val_precision_m: 0.7839 - val_recall_m: 0.7546 - val_f1_m: 0.7675\n","Epoch 32/50\n","131/131 [==============================] - 1s 6ms/step - loss: 0.1895 - accuracy: 0.6394 - precision_m: 0.9040 - recall_m: 0.8718 - f1_m: 0.8868 - val_loss: 0.3277 - val_accuracy: 0.6826 - val_precision_m: 0.7834 - val_recall_m: 0.7678 - val_f1_m: 0.7738\n","Epoch 33/50\n","131/131 [==============================] - 1s 6ms/step - loss: 0.1808 - accuracy: 0.6248 - precision_m: 0.9080 - recall_m: 0.8724 - f1_m: 0.8888 - val_loss: 0.3243 - val_accuracy: 0.6959 - val_precision_m: 0.8074 - val_recall_m: 0.7527 - val_f1_m: 0.7775\n","Epoch 00033: early stopping\n","Score for fold 3: loss of 0.30677834153175354; accuracy of 66.29770994186401% ;precision_m of 0.804779052734375 ;recall_m of 0.7360309362411499 ;            f1_m of 0.7672140598297119\n","Epoch 1/50\n","131/131 [==============================] - 2s 10ms/step - loss: 1.1153 - accuracy: 0.3252 - precision_m: 0.4611 - recall_m: 0.4482 - f1_m: 0.4515 - val_loss: 0.3697 - val_accuracy: 0.5878 - val_precision_m: 0.7451 - val_recall_m: 0.6282 - val_f1_m: 0.6787\n","Epoch 2/50\n","131/131 [==============================] - 1s 7ms/step - loss: 0.4733 - accuracy: 0.5219 - precision_m: 0.7023 - recall_m: 0.6328 - f1_m: 0.6641 - val_loss: 0.3182 - val_accuracy: 0.6040 - val_precision_m: 0.7582 - val_recall_m: 0.7176 - val_f1_m: 0.7356\n","Epoch 3/50\n","131/131 [==============================] - 1s 7ms/step - loss: 0.3738 - accuracy: 0.5787 - precision_m: 0.7546 - recall_m: 0.6945 - f1_m: 0.7221 - val_loss: 0.3078 - val_accuracy: 0.6336 - val_precision_m: 0.7921 - val_recall_m: 0.7233 - val_f1_m: 0.7542\n","Epoch 4/50\n","131/131 [==============================] - 1s 7ms/step - loss: 0.3119 - accuracy: 0.6136 - precision_m: 0.8002 - recall_m: 0.7444 - f1_m: 0.7699 - val_loss: 0.2898 - val_accuracy: 0.6594 - val_precision_m: 0.8019 - val_recall_m: 0.7357 - val_f1_m: 0.7655\n","Epoch 5/50\n","131/131 [==============================] - 1s 7ms/step - loss: 0.2748 - accuracy: 0.6411 - precision_m: 0.8267 - recall_m: 0.7605 - f1_m: 0.7903 - val_loss: 0.2830 - val_accuracy: 0.6508 - val_precision_m: 0.8170 - val_recall_m: 0.7289 - val_f1_m: 0.7683\n","Epoch 6/50\n","131/131 [==============================] - 1s 7ms/step - loss: 0.2586 - accuracy: 0.6393 - precision_m: 0.8448 - recall_m: 0.7833 - f1_m: 0.8112 - val_loss: 0.2870 - val_accuracy: 0.6718 - val_precision_m: 0.8037 - val_recall_m: 0.7470 - val_f1_m: 0.7716\n","Epoch 7/50\n","131/131 [==============================] - 1s 7ms/step - loss: 0.2397 - accuracy: 0.6639 - precision_m: 0.8519 - recall_m: 0.7982 - f1_m: 0.8225 - val_loss: 0.2803 - val_accuracy: 0.6746 - val_precision_m: 0.8165 - val_recall_m: 0.7422 - val_f1_m: 0.7754\n","Epoch 8/50\n","131/131 [==============================] - 1s 7ms/step - loss: 0.2144 - accuracy: 0.6470 - precision_m: 0.8725 - recall_m: 0.8229 - f1_m: 0.8459 - val_loss: 0.2801 - val_accuracy: 0.6613 - val_precision_m: 0.8163 - val_recall_m: 0.7532 - val_f1_m: 0.7817\n","Epoch 9/50\n","131/131 [==============================] - 1s 7ms/step - loss: 0.2001 - accuracy: 0.6906 - precision_m: 0.8787 - recall_m: 0.8369 - f1_m: 0.8561 - val_loss: 0.2726 - val_accuracy: 0.6679 - val_precision_m: 0.8119 - val_recall_m: 0.7467 - val_f1_m: 0.7762\n","Epoch 10/50\n","131/131 [==============================] - 1s 8ms/step - loss: 0.1903 - accuracy: 0.6775 - precision_m: 0.8917 - recall_m: 0.8450 - f1_m: 0.8669 - val_loss: 0.2752 - val_accuracy: 0.6613 - val_precision_m: 0.8168 - val_recall_m: 0.7326 - val_f1_m: 0.7707\n","Epoch 11/50\n","131/131 [==============================] - 1s 7ms/step - loss: 0.1834 - accuracy: 0.6809 - precision_m: 0.8928 - recall_m: 0.8391 - f1_m: 0.8640 - val_loss: 0.2840 - val_accuracy: 0.6746 - val_precision_m: 0.8219 - val_recall_m: 0.7340 - val_f1_m: 0.7734\n","Epoch 12/50\n","131/131 [==============================] - 1s 7ms/step - loss: 0.1762 - accuracy: 0.7001 - precision_m: 0.8931 - recall_m: 0.8530 - f1_m: 0.8716 - val_loss: 0.2811 - val_accuracy: 0.6584 - val_precision_m: 0.8193 - val_recall_m: 0.7602 - val_f1_m: 0.7871\n","Epoch 13/50\n","131/131 [==============================] - 1s 7ms/step - loss: 0.1628 - accuracy: 0.7017 - precision_m: 0.8995 - recall_m: 0.8722 - f1_m: 0.8848 - val_loss: 0.2808 - val_accuracy: 0.6594 - val_precision_m: 0.8111 - val_recall_m: 0.7595 - val_f1_m: 0.7824\n","Epoch 14/50\n","131/131 [==============================] - 1s 7ms/step - loss: 0.1655 - accuracy: 0.6768 - precision_m: 0.9038 - recall_m: 0.8703 - f1_m: 0.8859 - val_loss: 0.2811 - val_accuracy: 0.6546 - val_precision_m: 0.8223 - val_recall_m: 0.7573 - val_f1_m: 0.7867\n","Epoch 15/50\n","131/131 [==============================] - 1s 7ms/step - loss: 0.1557 - accuracy: 0.6965 - precision_m: 0.9091 - recall_m: 0.8758 - f1_m: 0.8912 - val_loss: 0.2882 - val_accuracy: 0.6689 - val_precision_m: 0.8126 - val_recall_m: 0.7484 - val_f1_m: 0.7779\n","Epoch 16/50\n","131/131 [==============================] - 1s 7ms/step - loss: 0.1511 - accuracy: 0.7100 - precision_m: 0.9075 - recall_m: 0.8853 - f1_m: 0.8954 - val_loss: 0.2931 - val_accuracy: 0.6823 - val_precision_m: 0.8160 - val_recall_m: 0.7342 - val_f1_m: 0.7718\n","Epoch 17/50\n","131/131 [==============================] - 1s 7ms/step - loss: 0.1409 - accuracy: 0.6949 - precision_m: 0.9193 - recall_m: 0.8876 - f1_m: 0.9022 - val_loss: 0.2943 - val_accuracy: 0.6632 - val_precision_m: 0.8062 - val_recall_m: 0.7571 - val_f1_m: 0.7793\n","Epoch 18/50\n","131/131 [==============================] - 1s 7ms/step - loss: 0.1338 - accuracy: 0.7073 - precision_m: 0.9208 - recall_m: 0.8958 - f1_m: 0.9074 - val_loss: 0.3136 - val_accuracy: 0.6746 - val_precision_m: 0.7999 - val_recall_m: 0.7389 - val_f1_m: 0.7660\n","Epoch 19/50\n","131/131 [==============================] - 1s 7ms/step - loss: 0.1316 - accuracy: 0.7059 - precision_m: 0.9247 - recall_m: 0.8971 - f1_m: 0.9101 - val_loss: 0.3011 - val_accuracy: 0.6698 - val_precision_m: 0.8010 - val_recall_m: 0.7556 - val_f1_m: 0.7764\n","Epoch 20/50\n","131/131 [==============================] - 1s 7ms/step - loss: 0.1300 - accuracy: 0.7098 - precision_m: 0.9212 - recall_m: 0.9037 - f1_m: 0.9115 - val_loss: 0.3043 - val_accuracy: 0.6718 - val_precision_m: 0.8070 - val_recall_m: 0.7575 - val_f1_m: 0.7802\n","Epoch 21/50\n","131/131 [==============================] - 1s 7ms/step - loss: 0.1247 - accuracy: 0.7144 - precision_m: 0.9289 - recall_m: 0.9037 - f1_m: 0.9154 - val_loss: 0.3137 - val_accuracy: 0.6679 - val_precision_m: 0.8084 - val_recall_m: 0.7523 - val_f1_m: 0.7780\n","Epoch 22/50\n","131/131 [==============================] - 1s 7ms/step - loss: 0.1257 - accuracy: 0.7151 - precision_m: 0.9308 - recall_m: 0.9037 - f1_m: 0.9164 - val_loss: 0.3125 - val_accuracy: 0.6670 - val_precision_m: 0.8162 - val_recall_m: 0.7500 - val_f1_m: 0.7803\n","Epoch 00022: early stopping\n","Score for fold 1: loss of 0.7441516518592834; accuracy of 47.15757369995117% ;precision_m of 0.8275898098945618 ;recall_m of 0.5752400755882263 ;            f1_m of 0.6730021238327026\n","Epoch 1/50\n","131/131 [==============================] - 2s 9ms/step - loss: 1.5236 - accuracy: 0.2878 - precision_m: 0.4395 - recall_m: 0.4485 - f1_m: 0.4396 - val_loss: 0.3907 - val_accuracy: 0.5968 - val_precision_m: 0.6910 - val_recall_m: 0.6825 - val_f1_m: 0.6853\n","Epoch 2/50\n","131/131 [==============================] - 1s 7ms/step - loss: 0.6040 - accuracy: 0.4889 - precision_m: 0.6444 - recall_m: 0.6188 - f1_m: 0.6290 - val_loss: 0.3575 - val_accuracy: 0.6406 - val_precision_m: 0.7432 - val_recall_m: 0.6892 - val_f1_m: 0.7133\n","Epoch 3/50\n","131/131 [==============================] - 1s 7ms/step - loss: 0.4505 - accuracy: 0.5492 - precision_m: 0.7303 - recall_m: 0.6831 - f1_m: 0.7044 - val_loss: 0.3249 - val_accuracy: 0.6549 - val_precision_m: 0.7601 - val_recall_m: 0.7236 - val_f1_m: 0.7395\n","Epoch 4/50\n","131/131 [==============================] - 1s 7ms/step - loss: 0.4054 - accuracy: 0.5551 - precision_m: 0.7582 - recall_m: 0.7106 - f1_m: 0.7316 - val_loss: 0.3152 - val_accuracy: 0.6845 - val_precision_m: 0.7657 - val_recall_m: 0.7404 - val_f1_m: 0.7506\n","Epoch 5/50\n","131/131 [==============================] - 1s 7ms/step - loss: 0.3417 - accuracy: 0.5939 - precision_m: 0.7956 - recall_m: 0.7524 - f1_m: 0.7723 - val_loss: 0.3046 - val_accuracy: 0.6768 - val_precision_m: 0.7750 - val_recall_m: 0.7294 - val_f1_m: 0.7493\n","Epoch 6/50\n","131/131 [==============================] - 1s 8ms/step - loss: 0.3156 - accuracy: 0.6143 - precision_m: 0.8202 - recall_m: 0.7683 - f1_m: 0.7912 - val_loss: 0.2831 - val_accuracy: 0.6883 - val_precision_m: 0.7842 - val_recall_m: 0.7764 - val_f1_m: 0.7787\n","Epoch 7/50\n","131/131 [==============================] - 1s 7ms/step - loss: 0.2783 - accuracy: 0.6160 - precision_m: 0.8367 - recall_m: 0.7859 - f1_m: 0.8094 - val_loss: 0.2889 - val_accuracy: 0.6940 - val_precision_m: 0.7846 - val_recall_m: 0.7909 - val_f1_m: 0.7865\n","Epoch 8/50\n","131/131 [==============================] - 1s 7ms/step - loss: 0.2623 - accuracy: 0.6252 - precision_m: 0.8527 - recall_m: 0.8114 - f1_m: 0.8301 - val_loss: 0.2792 - val_accuracy: 0.6930 - val_precision_m: 0.7929 - val_recall_m: 0.7606 - val_f1_m: 0.7748\n","Epoch 9/50\n","131/131 [==============================] - 1s 7ms/step - loss: 0.2511 - accuracy: 0.6280 - precision_m: 0.8589 - recall_m: 0.8154 - f1_m: 0.8355 - val_loss: 0.2794 - val_accuracy: 0.6949 - val_precision_m: 0.8132 - val_recall_m: 0.7506 - val_f1_m: 0.7787\n","Epoch 10/50\n","131/131 [==============================] - 1s 7ms/step - loss: 0.2395 - accuracy: 0.6436 - precision_m: 0.8675 - recall_m: 0.8304 - f1_m: 0.8475 - val_loss: 0.2719 - val_accuracy: 0.6978 - val_precision_m: 0.7995 - val_recall_m: 0.7772 - val_f1_m: 0.7868\n","Epoch 11/50\n","131/131 [==============================] - 1s 7ms/step - loss: 0.2262 - accuracy: 0.6375 - precision_m: 0.8768 - recall_m: 0.8381 - f1_m: 0.8561 - val_loss: 0.2729 - val_accuracy: 0.7035 - val_precision_m: 0.8135 - val_recall_m: 0.7642 - val_f1_m: 0.7862\n","Epoch 12/50\n","131/131 [==============================] - 1s 7ms/step - loss: 0.2201 - accuracy: 0.6532 - precision_m: 0.8783 - recall_m: 0.8344 - f1_m: 0.8547 - val_loss: 0.2719 - val_accuracy: 0.6921 - val_precision_m: 0.7907 - val_recall_m: 0.7918 - val_f1_m: 0.7898\n","Epoch 13/50\n","131/131 [==============================] - 1s 7ms/step - loss: 0.2122 - accuracy: 0.6367 - precision_m: 0.8841 - recall_m: 0.8534 - f1_m: 0.8676 - val_loss: 0.2711 - val_accuracy: 0.6940 - val_precision_m: 0.8040 - val_recall_m: 0.7832 - val_f1_m: 0.7920\n","Epoch 14/50\n","131/131 [==============================] - 1s 7ms/step - loss: 0.2025 - accuracy: 0.6372 - precision_m: 0.8925 - recall_m: 0.8539 - f1_m: 0.8720 - val_loss: 0.2815 - val_accuracy: 0.7016 - val_precision_m: 0.7855 - val_recall_m: 0.7988 - val_f1_m: 0.7904\n","Epoch 15/50\n","131/131 [==============================] - 1s 7ms/step - loss: 0.1937 - accuracy: 0.6655 - precision_m: 0.8928 - recall_m: 0.8636 - f1_m: 0.8771 - val_loss: 0.2762 - val_accuracy: 0.7054 - val_precision_m: 0.8009 - val_recall_m: 0.7820 - val_f1_m: 0.7897\n","Epoch 16/50\n","131/131 [==============================] - 1s 7ms/step - loss: 0.1811 - accuracy: 0.6678 - precision_m: 0.9038 - recall_m: 0.8733 - f1_m: 0.8873 - val_loss: 0.2699 - val_accuracy: 0.7007 - val_precision_m: 0.8097 - val_recall_m: 0.7783 - val_f1_m: 0.7915\n","Epoch 17/50\n","131/131 [==============================] - 1s 7ms/step - loss: 0.1722 - accuracy: 0.6505 - precision_m: 0.9097 - recall_m: 0.8811 - f1_m: 0.8946 - val_loss: 0.2696 - val_accuracy: 0.6997 - val_precision_m: 0.8089 - val_recall_m: 0.7775 - val_f1_m: 0.7913\n","Epoch 18/50\n","131/131 [==============================] - 1s 7ms/step - loss: 0.1709 - accuracy: 0.6644 - precision_m: 0.9136 - recall_m: 0.8763 - f1_m: 0.8937 - val_loss: 0.2817 - val_accuracy: 0.6969 - val_precision_m: 0.8001 - val_recall_m: 0.7908 - val_f1_m: 0.7937\n","Epoch 19/50\n","131/131 [==============================] - 1s 7ms/step - loss: 0.1629 - accuracy: 0.6541 - precision_m: 0.9134 - recall_m: 0.8861 - f1_m: 0.8988 - val_loss: 0.2779 - val_accuracy: 0.7092 - val_precision_m: 0.8101 - val_recall_m: 0.7726 - val_f1_m: 0.7895\n","Epoch 20/50\n","131/131 [==============================] - 1s 8ms/step - loss: 0.1618 - accuracy: 0.6759 - precision_m: 0.9194 - recall_m: 0.8914 - f1_m: 0.9045 - val_loss: 0.2870 - val_accuracy: 0.7054 - val_precision_m: 0.7946 - val_recall_m: 0.7686 - val_f1_m: 0.7797\n","Epoch 21/50\n","131/131 [==============================] - 1s 7ms/step - loss: 0.1608 - accuracy: 0.6630 - precision_m: 0.9203 - recall_m: 0.8844 - f1_m: 0.9012 - val_loss: 0.2882 - val_accuracy: 0.7035 - val_precision_m: 0.8067 - val_recall_m: 0.7549 - val_f1_m: 0.7782\n","Epoch 22/50\n","131/131 [==============================] - 1s 7ms/step - loss: 0.1571 - accuracy: 0.6599 - precision_m: 0.9213 - recall_m: 0.8941 - f1_m: 0.9069 - val_loss: 0.2781 - val_accuracy: 0.7083 - val_precision_m: 0.8156 - val_recall_m: 0.7652 - val_f1_m: 0.7877\n","Epoch 23/50\n","131/131 [==============================] - 1s 7ms/step - loss: 0.1486 - accuracy: 0.6676 - precision_m: 0.9236 - recall_m: 0.8918 - f1_m: 0.9069 - val_loss: 0.2836 - val_accuracy: 0.7045 - val_precision_m: 0.8006 - val_recall_m: 0.7758 - val_f1_m: 0.7862\n","Epoch 24/50\n","131/131 [==============================] - 1s 7ms/step - loss: 0.1503 - accuracy: 0.6581 - precision_m: 0.9222 - recall_m: 0.8953 - f1_m: 0.9080 - val_loss: 0.2844 - val_accuracy: 0.7178 - val_precision_m: 0.8007 - val_recall_m: 0.7817 - val_f1_m: 0.7896\n","Epoch 25/50\n","131/131 [==============================] - 1s 7ms/step - loss: 0.1443 - accuracy: 0.6628 - precision_m: 0.9300 - recall_m: 0.9007 - f1_m: 0.9145 - val_loss: 0.2902 - val_accuracy: 0.7092 - val_precision_m: 0.7927 - val_recall_m: 0.7875 - val_f1_m: 0.7886\n","Epoch 26/50\n","131/131 [==============================] - 1s 7ms/step - loss: 0.1428 - accuracy: 0.6603 - precision_m: 0.9269 - recall_m: 0.9076 - f1_m: 0.9165 - val_loss: 0.2923 - val_accuracy: 0.7102 - val_precision_m: 0.7962 - val_recall_m: 0.7725 - val_f1_m: 0.7822\n","Epoch 27/50\n","131/131 [==============================] - 1s 7ms/step - loss: 0.1423 - accuracy: 0.6800 - precision_m: 0.9297 - recall_m: 0.8989 - f1_m: 0.9132 - val_loss: 0.2844 - val_accuracy: 0.7045 - val_precision_m: 0.8090 - val_recall_m: 0.7724 - val_f1_m: 0.7888\n","Epoch 28/50\n","131/131 [==============================] - 1s 7ms/step - loss: 0.1433 - accuracy: 0.6773 - precision_m: 0.9321 - recall_m: 0.9019 - f1_m: 0.9161 - val_loss: 0.2873 - val_accuracy: 0.7121 - val_precision_m: 0.8092 - val_recall_m: 0.7647 - val_f1_m: 0.7845\n","Epoch 00028: early stopping\n","Score for fold 2: loss of 0.38265207409858704; accuracy of 66.37404561042786% ;precision_m of 0.8030974268913269 ;recall_m of 0.74785315990448 ;            f1_m of 0.7724283337593079\n","Epoch 1/50\n","131/131 [==============================] - 2s 9ms/step - loss: 1.5225 - accuracy: 0.2826 - precision_m: 0.4487 - recall_m: 0.4565 - f1_m: 0.4443 - val_loss: 0.4177 - val_accuracy: 0.5891 - val_precision_m: 0.6766 - val_recall_m: 0.6938 - val_f1_m: 0.6826\n","Epoch 2/50\n","131/131 [==============================] - 1s 7ms/step - loss: 0.6117 - accuracy: 0.4714 - precision_m: 0.6457 - recall_m: 0.6068 - f1_m: 0.6245 - val_loss: 0.3915 - val_accuracy: 0.6206 - val_precision_m: 0.6989 - val_recall_m: 0.7243 - val_f1_m: 0.7095\n","Epoch 3/50\n","131/131 [==============================] - 1s 7ms/step - loss: 0.4675 - accuracy: 0.5268 - precision_m: 0.7144 - recall_m: 0.6738 - f1_m: 0.6914 - val_loss: 0.3668 - val_accuracy: 0.6320 - val_precision_m: 0.7113 - val_recall_m: 0.7364 - val_f1_m: 0.7218\n","Epoch 4/50\n","131/131 [==============================] - 1s 7ms/step - loss: 0.4009 - accuracy: 0.5456 - precision_m: 0.7679 - recall_m: 0.7151 - f1_m: 0.7393 - val_loss: 0.3647 - val_accuracy: 0.6520 - val_precision_m: 0.7189 - val_recall_m: 0.7558 - val_f1_m: 0.7347\n","Epoch 5/50\n","131/131 [==============================] - 1s 7ms/step - loss: 0.3615 - accuracy: 0.5676 - precision_m: 0.8025 - recall_m: 0.7452 - f1_m: 0.7710 - val_loss: 0.3439 - val_accuracy: 0.6492 - val_precision_m: 0.7501 - val_recall_m: 0.7347 - val_f1_m: 0.7406\n","Epoch 6/50\n","131/131 [==============================] - 1s 7ms/step - loss: 0.3081 - accuracy: 0.6000 - precision_m: 0.8312 - recall_m: 0.7730 - f1_m: 0.7996 - val_loss: 0.3433 - val_accuracy: 0.6663 - val_precision_m: 0.7431 - val_recall_m: 0.7791 - val_f1_m: 0.7591\n","Epoch 7/50\n","131/131 [==============================] - 1s 7ms/step - loss: 0.2952 - accuracy: 0.5966 - precision_m: 0.8338 - recall_m: 0.7940 - f1_m: 0.8123 - val_loss: 0.3250 - val_accuracy: 0.6673 - val_precision_m: 0.7798 - val_recall_m: 0.7344 - val_f1_m: 0.7551\n","Epoch 8/50\n","131/131 [==============================] - 1s 7ms/step - loss: 0.2778 - accuracy: 0.5956 - precision_m: 0.8467 - recall_m: 0.7939 - f1_m: 0.8178 - val_loss: 0.3397 - val_accuracy: 0.6797 - val_precision_m: 0.7447 - val_recall_m: 0.7793 - val_f1_m: 0.7601\n","Epoch 9/50\n","131/131 [==============================] - 1s 7ms/step - loss: 0.2570 - accuracy: 0.6044 - precision_m: 0.8617 - recall_m: 0.8179 - f1_m: 0.8382 - val_loss: 0.3230 - val_accuracy: 0.6759 - val_precision_m: 0.7768 - val_recall_m: 0.7530 - val_f1_m: 0.7628\n","Epoch 10/50\n","131/131 [==============================] - 1s 7ms/step - loss: 0.2377 - accuracy: 0.6191 - precision_m: 0.8773 - recall_m: 0.8250 - f1_m: 0.8495 - val_loss: 0.3246 - val_accuracy: 0.6673 - val_precision_m: 0.7641 - val_recall_m: 0.7701 - val_f1_m: 0.7655\n","Epoch 11/50\n","131/131 [==============================] - 1s 7ms/step - loss: 0.2253 - accuracy: 0.6025 - precision_m: 0.8858 - recall_m: 0.8410 - f1_m: 0.8619 - val_loss: 0.3354 - val_accuracy: 0.6892 - val_precision_m: 0.7687 - val_recall_m: 0.7550 - val_f1_m: 0.7604\n","Epoch 12/50\n","131/131 [==============================] - 1s 7ms/step - loss: 0.2233 - accuracy: 0.6415 - precision_m: 0.8839 - recall_m: 0.8425 - f1_m: 0.8616 - val_loss: 0.3294 - val_accuracy: 0.6683 - val_precision_m: 0.7693 - val_recall_m: 0.7520 - val_f1_m: 0.7593\n","Epoch 13/50\n","131/131 [==============================] - 1s 7ms/step - loss: 0.2239 - accuracy: 0.6109 - precision_m: 0.8837 - recall_m: 0.8458 - f1_m: 0.8633 - val_loss: 0.3343 - val_accuracy: 0.6644 - val_precision_m: 0.7585 - val_recall_m: 0.7569 - val_f1_m: 0.7563\n","Epoch 14/50\n","131/131 [==============================] - 1s 7ms/step - loss: 0.2074 - accuracy: 0.6408 - precision_m: 0.8964 - recall_m: 0.8524 - f1_m: 0.8727 - val_loss: 0.3320 - val_accuracy: 0.6721 - val_precision_m: 0.7680 - val_recall_m: 0.7662 - val_f1_m: 0.7659\n","Epoch 15/50\n","131/131 [==============================] - 1s 7ms/step - loss: 0.1943 - accuracy: 0.6455 - precision_m: 0.9048 - recall_m: 0.8603 - f1_m: 0.8811 - val_loss: 0.3397 - val_accuracy: 0.6692 - val_precision_m: 0.7549 - val_recall_m: 0.7692 - val_f1_m: 0.7606\n","Epoch 16/50\n","131/131 [==============================] - 1s 7ms/step - loss: 0.1987 - accuracy: 0.6301 - precision_m: 0.8952 - recall_m: 0.8640 - f1_m: 0.8787 - val_loss: 0.3467 - val_accuracy: 0.6797 - val_precision_m: 0.7497 - val_recall_m: 0.7908 - val_f1_m: 0.7684\n","Epoch 17/50\n","131/131 [==============================] - 1s 7ms/step - loss: 0.1930 - accuracy: 0.6207 - precision_m: 0.8935 - recall_m: 0.8693 - f1_m: 0.8803 - val_loss: 0.3395 - val_accuracy: 0.6730 - val_precision_m: 0.7613 - val_recall_m: 0.7730 - val_f1_m: 0.7659\n","Epoch 18/50\n","131/131 [==============================] - 1s 7ms/step - loss: 0.1870 - accuracy: 0.6123 - precision_m: 0.9010 - recall_m: 0.8703 - f1_m: 0.8845 - val_loss: 0.3349 - val_accuracy: 0.6721 - val_precision_m: 0.7842 - val_recall_m: 0.7592 - val_f1_m: 0.7701\n","Epoch 19/50\n","131/131 [==============================] - 1s 7ms/step - loss: 0.1774 - accuracy: 0.6353 - precision_m: 0.9074 - recall_m: 0.8794 - f1_m: 0.8922 - val_loss: 0.3454 - val_accuracy: 0.6721 - val_precision_m: 0.7499 - val_recall_m: 0.7825 - val_f1_m: 0.7641\n","Epoch 20/50\n","131/131 [==============================] - 1s 7ms/step - loss: 0.1692 - accuracy: 0.6316 - precision_m: 0.9134 - recall_m: 0.8862 - f1_m: 0.8990 - val_loss: 0.3373 - val_accuracy: 0.6873 - val_precision_m: 0.7736 - val_recall_m: 0.7497 - val_f1_m: 0.7602\n","Epoch 21/50\n","131/131 [==============================] - 1s 7ms/step - loss: 0.1626 - accuracy: 0.6505 - precision_m: 0.9196 - recall_m: 0.8888 - f1_m: 0.9033 - val_loss: 0.3472 - val_accuracy: 0.6787 - val_precision_m: 0.7709 - val_recall_m: 0.7569 - val_f1_m: 0.7624\n","Epoch 22/50\n","131/131 [==============================] - 1s 7ms/step - loss: 0.1664 - accuracy: 0.6398 - precision_m: 0.9243 - recall_m: 0.8867 - f1_m: 0.9042 - val_loss: 0.3425 - val_accuracy: 0.6702 - val_precision_m: 0.7762 - val_recall_m: 0.7631 - val_f1_m: 0.7685\n","Epoch 23/50\n","131/131 [==============================] - 1s 7ms/step - loss: 0.1649 - accuracy: 0.6371 - precision_m: 0.9227 - recall_m: 0.8911 - f1_m: 0.9062 - val_loss: 0.3492 - val_accuracy: 0.6835 - val_precision_m: 0.7716 - val_recall_m: 0.7638 - val_f1_m: 0.7664\n","Epoch 24/50\n","131/131 [==============================] - 1s 7ms/step - loss: 0.1433 - accuracy: 0.6512 - precision_m: 0.9257 - recall_m: 0.9074 - f1_m: 0.9158 - val_loss: 0.3465 - val_accuracy: 0.6683 - val_precision_m: 0.7809 - val_recall_m: 0.7572 - val_f1_m: 0.7676\n","Epoch 25/50\n","131/131 [==============================] - 1s 7ms/step - loss: 0.1536 - accuracy: 0.6319 - precision_m: 0.9198 - recall_m: 0.9008 - f1_m: 0.9094 - val_loss: 0.3530 - val_accuracy: 0.6749 - val_precision_m: 0.7822 - val_recall_m: 0.7440 - val_f1_m: 0.7612\n","Epoch 26/50\n","131/131 [==============================] - 1s 7ms/step - loss: 0.1464 - accuracy: 0.6263 - precision_m: 0.9284 - recall_m: 0.9021 - f1_m: 0.9144 - val_loss: 0.3556 - val_accuracy: 0.6797 - val_precision_m: 0.7750 - val_recall_m: 0.7413 - val_f1_m: 0.7564\n","Epoch 27/50\n","131/131 [==============================] - 1s 7ms/step - loss: 0.1477 - accuracy: 0.6520 - precision_m: 0.9305 - recall_m: 0.9024 - f1_m: 0.9155 - val_loss: 0.3663 - val_accuracy: 0.6835 - val_precision_m: 0.7603 - val_recall_m: 0.7670 - val_f1_m: 0.7624\n","Epoch 28/50\n","131/131 [==============================] - 1s 8ms/step - loss: 0.1396 - accuracy: 0.6404 - precision_m: 0.9288 - recall_m: 0.9044 - f1_m: 0.9159 - val_loss: 0.3595 - val_accuracy: 0.6759 - val_precision_m: 0.7767 - val_recall_m: 0.7382 - val_f1_m: 0.7557\n","Epoch 00028: early stopping\n","Score for fold 3: loss of 0.32479244470596313; accuracy of 67.93892979621887% ;precision_m of 0.788960874080658 ;recall_m of 0.7406190633773804 ;            f1_m of 0.762672483921051\n","Epoch 1/50\n","131/131 [==============================] - 2s 12ms/step - loss: 1.0734 - accuracy: 0.3406 - precision_m: 0.4704 - recall_m: 0.4682 - f1_m: 0.4647 - val_loss: 0.3740 - val_accuracy: 0.5897 - val_precision_m: 0.7433 - val_recall_m: 0.6234 - val_f1_m: 0.6762\n","Epoch 2/50\n","131/131 [==============================] - 1s 9ms/step - loss: 0.4423 - accuracy: 0.5462 - precision_m: 0.7102 - recall_m: 0.6516 - f1_m: 0.6781 - val_loss: 0.3212 - val_accuracy: 0.5983 - val_precision_m: 0.7742 - val_recall_m: 0.7191 - val_f1_m: 0.7448\n","Epoch 3/50\n","131/131 [==============================] - 1s 9ms/step - loss: 0.3521 - accuracy: 0.5768 - precision_m: 0.7769 - recall_m: 0.7108 - f1_m: 0.7408 - val_loss: 0.3015 - val_accuracy: 0.6317 - val_precision_m: 0.8258 - val_recall_m: 0.6807 - val_f1_m: 0.7448\n","Epoch 4/50\n","131/131 [==============================] - 1s 9ms/step - loss: 0.2942 - accuracy: 0.6233 - precision_m: 0.8187 - recall_m: 0.7437 - f1_m: 0.7773 - val_loss: 0.2994 - val_accuracy: 0.6489 - val_precision_m: 0.7927 - val_recall_m: 0.7357 - val_f1_m: 0.7617\n","Epoch 5/50\n","131/131 [==============================] - 1s 9ms/step - loss: 0.2594 - accuracy: 0.6442 - precision_m: 0.8348 - recall_m: 0.7881 - f1_m: 0.8095 - val_loss: 0.2894 - val_accuracy: 0.6403 - val_precision_m: 0.8016 - val_recall_m: 0.7524 - val_f1_m: 0.7751\n","Epoch 6/50\n","131/131 [==============================] - 1s 9ms/step - loss: 0.2345 - accuracy: 0.6481 - precision_m: 0.8543 - recall_m: 0.7999 - f1_m: 0.8252 - val_loss: 0.2848 - val_accuracy: 0.6489 - val_precision_m: 0.8060 - val_recall_m: 0.7371 - val_f1_m: 0.7683\n","Epoch 7/50\n","131/131 [==============================] - 1s 9ms/step - loss: 0.2049 - accuracy: 0.6757 - precision_m: 0.8763 - recall_m: 0.8296 - f1_m: 0.8511 - val_loss: 0.2839 - val_accuracy: 0.6508 - val_precision_m: 0.8065 - val_recall_m: 0.7527 - val_f1_m: 0.7774\n","Epoch 8/50\n","131/131 [==============================] - 1s 9ms/step - loss: 0.1989 - accuracy: 0.6745 - precision_m: 0.8760 - recall_m: 0.8387 - f1_m: 0.8560 - val_loss: 0.2873 - val_accuracy: 0.6479 - val_precision_m: 0.7956 - val_recall_m: 0.7656 - val_f1_m: 0.7789\n","Epoch 9/50\n","131/131 [==============================] - 1s 9ms/step - loss: 0.1875 - accuracy: 0.6723 - precision_m: 0.8786 - recall_m: 0.8507 - f1_m: 0.8628 - val_loss: 0.2934 - val_accuracy: 0.6441 - val_precision_m: 0.8021 - val_recall_m: 0.7571 - val_f1_m: 0.7776\n","Epoch 10/50\n","131/131 [==============================] - 1s 9ms/step - loss: 0.1777 - accuracy: 0.6882 - precision_m: 0.8944 - recall_m: 0.8558 - f1_m: 0.8736 - val_loss: 0.2886 - val_accuracy: 0.6584 - val_precision_m: 0.8131 - val_recall_m: 0.7522 - val_f1_m: 0.7803\n","Epoch 11/50\n","131/131 [==============================] - 1s 9ms/step - loss: 0.1655 - accuracy: 0.7008 - precision_m: 0.9013 - recall_m: 0.8640 - f1_m: 0.8814 - val_loss: 0.2869 - val_accuracy: 0.6622 - val_precision_m: 0.8097 - val_recall_m: 0.7557 - val_f1_m: 0.7808\n","Epoch 12/50\n","131/131 [==============================] - 1s 9ms/step - loss: 0.1508 - accuracy: 0.7010 - precision_m: 0.9100 - recall_m: 0.8806 - f1_m: 0.8943 - val_loss: 0.2889 - val_accuracy: 0.6651 - val_precision_m: 0.8057 - val_recall_m: 0.7656 - val_f1_m: 0.7840\n","Epoch 13/50\n","131/131 [==============================] - 1s 9ms/step - loss: 0.1448 - accuracy: 0.7134 - precision_m: 0.9130 - recall_m: 0.8814 - f1_m: 0.8961 - val_loss: 0.3067 - val_accuracy: 0.6498 - val_precision_m: 0.8103 - val_recall_m: 0.7355 - val_f1_m: 0.7699\n","Epoch 14/50\n","131/131 [==============================] - 1s 9ms/step - loss: 0.1425 - accuracy: 0.7175 - precision_m: 0.9196 - recall_m: 0.8917 - f1_m: 0.9047 - val_loss: 0.2972 - val_accuracy: 0.6775 - val_precision_m: 0.8034 - val_recall_m: 0.7720 - val_f1_m: 0.7861\n","Epoch 15/50\n","131/131 [==============================] - 1s 9ms/step - loss: 0.1346 - accuracy: 0.7201 - precision_m: 0.9163 - recall_m: 0.9006 - f1_m: 0.9077 - val_loss: 0.2988 - val_accuracy: 0.6660 - val_precision_m: 0.8356 - val_recall_m: 0.7403 - val_f1_m: 0.7837\n","Epoch 16/50\n","131/131 [==============================] - 1s 9ms/step - loss: 0.1313 - accuracy: 0.6946 - precision_m: 0.9277 - recall_m: 0.9004 - f1_m: 0.9133 - val_loss: 0.3117 - val_accuracy: 0.6584 - val_precision_m: 0.8078 - val_recall_m: 0.7572 - val_f1_m: 0.7800\n","Epoch 17/50\n","131/131 [==============================] - 1s 9ms/step - loss: 0.1242 - accuracy: 0.7144 - precision_m: 0.9282 - recall_m: 0.9028 - f1_m: 0.9146 - val_loss: 0.3134 - val_accuracy: 0.6632 - val_precision_m: 0.7946 - val_recall_m: 0.7763 - val_f1_m: 0.7838\n","Epoch 18/50\n","131/131 [==============================] - 1s 9ms/step - loss: 0.1190 - accuracy: 0.7178 - precision_m: 0.9305 - recall_m: 0.9159 - f1_m: 0.9225 - val_loss: 0.3151 - val_accuracy: 0.6594 - val_precision_m: 0.8199 - val_recall_m: 0.7402 - val_f1_m: 0.7765\n","Epoch 19/50\n","131/131 [==============================] - 1s 9ms/step - loss: 0.1143 - accuracy: 0.7172 - precision_m: 0.9329 - recall_m: 0.9138 - f1_m: 0.9226 - val_loss: 0.3201 - val_accuracy: 0.6555 - val_precision_m: 0.8096 - val_recall_m: 0.7463 - val_f1_m: 0.7748\n","Epoch 20/50\n","131/131 [==============================] - 1s 9ms/step - loss: 0.1175 - accuracy: 0.7105 - precision_m: 0.9338 - recall_m: 0.9113 - f1_m: 0.9218 - val_loss: 0.3333 - val_accuracy: 0.6679 - val_precision_m: 0.7917 - val_recall_m: 0.7564 - val_f1_m: 0.7721\n","Epoch 21/50\n","131/131 [==============================] - 1s 9ms/step - loss: 0.1111 - accuracy: 0.7065 - precision_m: 0.9397 - recall_m: 0.9216 - f1_m: 0.9298 - val_loss: 0.3281 - val_accuracy: 0.6670 - val_precision_m: 0.8045 - val_recall_m: 0.7573 - val_f1_m: 0.7787\n","Epoch 22/50\n","131/131 [==============================] - 1s 9ms/step - loss: 0.1106 - accuracy: 0.7112 - precision_m: 0.9364 - recall_m: 0.9213 - f1_m: 0.9282 - val_loss: 0.3353 - val_accuracy: 0.6622 - val_precision_m: 0.7968 - val_recall_m: 0.7832 - val_f1_m: 0.7884\n","Epoch 23/50\n","131/131 [==============================] - 1s 9ms/step - loss: 0.1017 - accuracy: 0.7228 - precision_m: 0.9404 - recall_m: 0.9233 - f1_m: 0.9312 - val_loss: 0.3416 - val_accuracy: 0.6508 - val_precision_m: 0.7948 - val_recall_m: 0.7541 - val_f1_m: 0.7723\n","Epoch 24/50\n","131/131 [==============================] - 1s 9ms/step - loss: 0.1012 - accuracy: 0.7241 - precision_m: 0.9359 - recall_m: 0.9228 - f1_m: 0.9287 - val_loss: 0.3406 - val_accuracy: 0.6565 - val_precision_m: 0.8017 - val_recall_m: 0.7561 - val_f1_m: 0.7770\n","Epoch 25/50\n","131/131 [==============================] - 1s 9ms/step - loss: 0.0979 - accuracy: 0.7260 - precision_m: 0.9414 - recall_m: 0.9313 - f1_m: 0.9359 - val_loss: 0.3514 - val_accuracy: 0.6555 - val_precision_m: 0.8075 - val_recall_m: 0.7397 - val_f1_m: 0.7705\n","Epoch 26/50\n","131/131 [==============================] - 1s 9ms/step - loss: 0.0991 - accuracy: 0.7333 - precision_m: 0.9425 - recall_m: 0.9239 - f1_m: 0.9326 - val_loss: 0.3545 - val_accuracy: 0.6565 - val_precision_m: 0.8054 - val_recall_m: 0.7569 - val_f1_m: 0.7791\n","Epoch 27/50\n","131/131 [==============================] - 1s 9ms/step - loss: 0.0869 - accuracy: 0.7359 - precision_m: 0.9505 - recall_m: 0.9360 - f1_m: 0.9427 - val_loss: 0.3524 - val_accuracy: 0.6536 - val_precision_m: 0.7969 - val_recall_m: 0.7579 - val_f1_m: 0.7757\n","Epoch 28/50\n","131/131 [==============================] - 1s 9ms/step - loss: 0.0859 - accuracy: 0.7370 - precision_m: 0.9499 - recall_m: 0.9317 - f1_m: 0.9401 - val_loss: 0.3633 - val_accuracy: 0.6622 - val_precision_m: 0.8040 - val_recall_m: 0.7592 - val_f1_m: 0.7793\n","Epoch 29/50\n","131/131 [==============================] - 1s 9ms/step - loss: 0.0888 - accuracy: 0.7334 - precision_m: 0.9456 - recall_m: 0.9352 - f1_m: 0.9398 - val_loss: 0.3620 - val_accuracy: 0.6737 - val_precision_m: 0.7998 - val_recall_m: 0.7594 - val_f1_m: 0.7775\n","Epoch 30/50\n","131/131 [==============================] - 1s 9ms/step - loss: 0.0898 - accuracy: 0.7435 - precision_m: 0.9511 - recall_m: 0.9385 - f1_m: 0.9443 - val_loss: 0.3606 - val_accuracy: 0.6536 - val_precision_m: 0.8028 - val_recall_m: 0.7675 - val_f1_m: 0.7832\n","Epoch 31/50\n","131/131 [==============================] - 1s 9ms/step - loss: 0.0891 - accuracy: 0.7337 - precision_m: 0.9478 - recall_m: 0.9352 - f1_m: 0.9410 - val_loss: 0.3596 - val_accuracy: 0.6546 - val_precision_m: 0.8194 - val_recall_m: 0.7398 - val_f1_m: 0.7762\n","Epoch 32/50\n","131/131 [==============================] - 1s 9ms/step - loss: 0.0840 - accuracy: 0.7308 - precision_m: 0.9551 - recall_m: 0.9399 - f1_m: 0.9469 - val_loss: 0.3660 - val_accuracy: 0.6641 - val_precision_m: 0.8128 - val_recall_m: 0.7492 - val_f1_m: 0.7787\n","Epoch 00032: early stopping\n","Score for fold 1: loss of 0.9932554364204407; accuracy of 48.95078241825104% ;precision_m of 0.8457445502281189 ;recall_m of 0.5713915824890137 ;            f1_m of 0.6743208169937134\n","Epoch 1/50\n","131/131 [==============================] - 2s 11ms/step - loss: 1.3069 - accuracy: 0.2990 - precision_m: 0.4536 - recall_m: 0.4541 - f1_m: 0.4507 - val_loss: 0.3971 - val_accuracy: 0.6025 - val_precision_m: 0.6590 - val_recall_m: 0.7195 - val_f1_m: 0.6860\n","Epoch 2/50\n","131/131 [==============================] - 1s 9ms/step - loss: 0.5611 - accuracy: 0.5114 - precision_m: 0.6751 - recall_m: 0.6419 - f1_m: 0.6567 - val_loss: 0.3484 - val_accuracy: 0.6578 - val_precision_m: 0.7212 - val_recall_m: 0.7440 - val_f1_m: 0.7304\n","Epoch 3/50\n","131/131 [==============================] - 1s 9ms/step - loss: 0.4101 - accuracy: 0.5611 - precision_m: 0.7495 - recall_m: 0.7182 - f1_m: 0.7322 - val_loss: 0.3199 - val_accuracy: 0.6663 - val_precision_m: 0.7591 - val_recall_m: 0.7617 - val_f1_m: 0.7582\n","Epoch 4/50\n","131/131 [==============================] - 1s 9ms/step - loss: 0.3609 - accuracy: 0.5829 - precision_m: 0.7880 - recall_m: 0.7495 - f1_m: 0.7670 - val_loss: 0.2932 - val_accuracy: 0.6816 - val_precision_m: 0.7794 - val_recall_m: 0.7619 - val_f1_m: 0.7688\n","Epoch 5/50\n","131/131 [==============================] - 1s 9ms/step - loss: 0.3153 - accuracy: 0.6077 - precision_m: 0.8141 - recall_m: 0.7672 - f1_m: 0.7888 - val_loss: 0.2933 - val_accuracy: 0.6768 - val_precision_m: 0.7849 - val_recall_m: 0.7575 - val_f1_m: 0.7691\n","Epoch 6/50\n","131/131 [==============================] - 1s 9ms/step - loss: 0.2844 - accuracy: 0.6111 - precision_m: 0.8382 - recall_m: 0.7970 - f1_m: 0.8162 - val_loss: 0.2905 - val_accuracy: 0.6949 - val_precision_m: 0.7987 - val_recall_m: 0.7445 - val_f1_m: 0.7684\n","Epoch 7/50\n","131/131 [==============================] - 1s 9ms/step - loss: 0.2641 - accuracy: 0.6230 - precision_m: 0.8522 - recall_m: 0.8119 - f1_m: 0.8302 - val_loss: 0.2821 - val_accuracy: 0.7026 - val_precision_m: 0.7998 - val_recall_m: 0.7603 - val_f1_m: 0.7777\n","Epoch 8/50\n","131/131 [==============================] - 1s 9ms/step - loss: 0.2411 - accuracy: 0.6353 - precision_m: 0.8661 - recall_m: 0.8296 - f1_m: 0.8465 - val_loss: 0.2839 - val_accuracy: 0.6978 - val_precision_m: 0.7849 - val_recall_m: 0.7829 - val_f1_m: 0.7823\n","Epoch 9/50\n","131/131 [==============================] - 1s 9ms/step - loss: 0.2292 - accuracy: 0.6493 - precision_m: 0.8715 - recall_m: 0.8413 - f1_m: 0.8551 - val_loss: 0.2770 - val_accuracy: 0.7054 - val_precision_m: 0.8056 - val_recall_m: 0.7627 - val_f1_m: 0.7820\n","Epoch 10/50\n","131/131 [==============================] - 1s 9ms/step - loss: 0.2170 - accuracy: 0.6430 - precision_m: 0.8844 - recall_m: 0.8420 - f1_m: 0.8615 - val_loss: 0.2834 - val_accuracy: 0.6978 - val_precision_m: 0.7993 - val_recall_m: 0.7786 - val_f1_m: 0.7874\n","Epoch 11/50\n","131/131 [==============================] - 1s 9ms/step - loss: 0.2085 - accuracy: 0.6508 - precision_m: 0.8839 - recall_m: 0.8547 - f1_m: 0.8685 - val_loss: 0.2800 - val_accuracy: 0.6921 - val_precision_m: 0.8053 - val_recall_m: 0.7588 - val_f1_m: 0.7798\n","Epoch 12/50\n","131/131 [==============================] - 1s 9ms/step - loss: 0.1843 - accuracy: 0.6564 - precision_m: 0.9029 - recall_m: 0.8663 - f1_m: 0.8834 - val_loss: 0.2761 - val_accuracy: 0.6988 - val_precision_m: 0.8139 - val_recall_m: 0.7739 - val_f1_m: 0.7920\n","Epoch 13/50\n","131/131 [==============================] - 1s 9ms/step - loss: 0.1898 - accuracy: 0.6613 - precision_m: 0.8989 - recall_m: 0.8609 - f1_m: 0.8786 - val_loss: 0.2803 - val_accuracy: 0.6988 - val_precision_m: 0.8004 - val_recall_m: 0.7802 - val_f1_m: 0.7885\n","Epoch 14/50\n","131/131 [==============================] - 1s 9ms/step - loss: 0.1823 - accuracy: 0.6480 - precision_m: 0.9052 - recall_m: 0.8778 - f1_m: 0.8905 - val_loss: 0.2750 - val_accuracy: 0.7073 - val_precision_m: 0.8029 - val_recall_m: 0.7743 - val_f1_m: 0.7870\n","Epoch 15/50\n","131/131 [==============================] - 1s 9ms/step - loss: 0.1738 - accuracy: 0.6393 - precision_m: 0.9133 - recall_m: 0.8855 - f1_m: 0.8984 - val_loss: 0.2818 - val_accuracy: 0.6911 - val_precision_m: 0.8121 - val_recall_m: 0.7599 - val_f1_m: 0.7833\n","Epoch 16/50\n","131/131 [==============================] - 1s 9ms/step - loss: 0.1678 - accuracy: 0.6448 - precision_m: 0.9184 - recall_m: 0.8827 - f1_m: 0.8994 - val_loss: 0.2829 - val_accuracy: 0.7016 - val_precision_m: 0.8036 - val_recall_m: 0.7963 - val_f1_m: 0.7987\n","Epoch 17/50\n","131/131 [==============================] - 1s 9ms/step - loss: 0.1633 - accuracy: 0.6542 - precision_m: 0.9157 - recall_m: 0.8915 - f1_m: 0.9026 - val_loss: 0.2889 - val_accuracy: 0.7112 - val_precision_m: 0.7947 - val_recall_m: 0.7893 - val_f1_m: 0.7904\n","Epoch 18/50\n","131/131 [==============================] - 1s 9ms/step - loss: 0.1521 - accuracy: 0.6725 - precision_m: 0.9212 - recall_m: 0.9011 - f1_m: 0.9102 - val_loss: 0.2851 - val_accuracy: 0.7035 - val_precision_m: 0.8293 - val_recall_m: 0.7631 - val_f1_m: 0.7931\n","Epoch 19/50\n","131/131 [==============================] - 1s 9ms/step - loss: 0.1494 - accuracy: 0.6643 - precision_m: 0.9270 - recall_m: 0.8956 - f1_m: 0.9100 - val_loss: 0.2884 - val_accuracy: 0.6997 - val_precision_m: 0.8109 - val_recall_m: 0.7721 - val_f1_m: 0.7893\n","Epoch 20/50\n","131/131 [==============================] - 1s 9ms/step - loss: 0.1435 - accuracy: 0.6697 - precision_m: 0.9300 - recall_m: 0.9010 - f1_m: 0.9146 - val_loss: 0.2915 - val_accuracy: 0.6930 - val_precision_m: 0.8106 - val_recall_m: 0.7695 - val_f1_m: 0.7873\n","Epoch 21/50\n","131/131 [==============================] - 1s 9ms/step - loss: 0.1424 - accuracy: 0.6533 - precision_m: 0.9319 - recall_m: 0.9069 - f1_m: 0.9187 - val_loss: 0.2994 - val_accuracy: 0.6969 - val_precision_m: 0.7968 - val_recall_m: 0.7803 - val_f1_m: 0.7870\n","Epoch 22/50\n","131/131 [==============================] - 1s 9ms/step - loss: 0.1302 - accuracy: 0.6743 - precision_m: 0.9351 - recall_m: 0.9152 - f1_m: 0.9241 - val_loss: 0.3079 - val_accuracy: 0.6988 - val_precision_m: 0.7839 - val_recall_m: 0.7837 - val_f1_m: 0.7818\n","Epoch 23/50\n","131/131 [==============================] - 1s 9ms/step - loss: 0.1327 - accuracy: 0.6795 - precision_m: 0.9309 - recall_m: 0.9096 - f1_m: 0.9193 - val_loss: 0.3041 - val_accuracy: 0.7026 - val_precision_m: 0.8006 - val_recall_m: 0.7579 - val_f1_m: 0.7773\n","Epoch 24/50\n","131/131 [==============================] - 1s 9ms/step - loss: 0.1307 - accuracy: 0.6687 - precision_m: 0.9328 - recall_m: 0.9153 - f1_m: 0.9235 - val_loss: 0.3002 - val_accuracy: 0.7064 - val_precision_m: 0.8079 - val_recall_m: 0.7608 - val_f1_m: 0.7822\n","Epoch 25/50\n","131/131 [==============================] - 1s 9ms/step - loss: 0.1264 - accuracy: 0.6754 - precision_m: 0.9373 - recall_m: 0.9174 - f1_m: 0.9265 - val_loss: 0.3081 - val_accuracy: 0.6997 - val_precision_m: 0.8161 - val_recall_m: 0.7612 - val_f1_m: 0.7862\n","Epoch 26/50\n","131/131 [==============================] - 1s 9ms/step - loss: 0.1241 - accuracy: 0.6712 - precision_m: 0.9315 - recall_m: 0.9177 - f1_m: 0.9240 - val_loss: 0.3044 - val_accuracy: 0.6921 - val_precision_m: 0.8117 - val_recall_m: 0.7764 - val_f1_m: 0.7919\n","Epoch 00026: early stopping\n","Score for fold 2: loss of 0.399277001619339; accuracy of 64.35114741325378% ;precision_m of 0.792168378829956 ;recall_m of 0.7720839977264404 ;            f1_m of 0.7802561521530151\n","Epoch 1/50\n","131/131 [==============================] - 2s 11ms/step - loss: 1.3527 - accuracy: 0.3011 - precision_m: 0.4612 - recall_m: 0.4532 - f1_m: 0.4544 - val_loss: 0.3924 - val_accuracy: 0.5891 - val_precision_m: 0.7005 - val_recall_m: 0.6964 - val_f1_m: 0.6957\n","Epoch 2/50\n","131/131 [==============================] - 1s 9ms/step - loss: 0.5773 - accuracy: 0.4779 - precision_m: 0.6719 - recall_m: 0.6368 - f1_m: 0.6518 - val_loss: 0.3694 - val_accuracy: 0.6292 - val_precision_m: 0.7171 - val_recall_m: 0.7373 - val_f1_m: 0.7251\n","Epoch 3/50\n","131/131 [==============================] - 1s 9ms/step - loss: 0.4470 - accuracy: 0.5426 - precision_m: 0.7410 - recall_m: 0.6925 - f1_m: 0.7140 - val_loss: 0.3494 - val_accuracy: 0.6463 - val_precision_m: 0.7316 - val_recall_m: 0.7665 - val_f1_m: 0.7466\n","Epoch 4/50\n","131/131 [==============================] - 1s 9ms/step - loss: 0.3603 - accuracy: 0.5583 - precision_m: 0.7910 - recall_m: 0.7510 - f1_m: 0.7690 - val_loss: 0.3489 - val_accuracy: 0.6540 - val_precision_m: 0.7170 - val_recall_m: 0.7754 - val_f1_m: 0.7433\n","Epoch 5/50\n","131/131 [==============================] - 1s 9ms/step - loss: 0.3101 - accuracy: 0.5809 - precision_m: 0.8232 - recall_m: 0.7751 - f1_m: 0.7972 - val_loss: 0.3460 - val_accuracy: 0.6683 - val_precision_m: 0.7454 - val_recall_m: 0.7476 - val_f1_m: 0.7450\n","Epoch 6/50\n","131/131 [==============================] - 1s 9ms/step - loss: 0.2976 - accuracy: 0.6057 - precision_m: 0.8393 - recall_m: 0.7917 - f1_m: 0.8137 - val_loss: 0.3358 - val_accuracy: 0.6721 - val_precision_m: 0.7570 - val_recall_m: 0.7735 - val_f1_m: 0.7631\n","Epoch 7/50\n","131/131 [==============================] - 1s 9ms/step - loss: 0.2654 - accuracy: 0.6094 - precision_m: 0.8518 - recall_m: 0.8118 - f1_m: 0.8302 - val_loss: 0.3490 - val_accuracy: 0.6797 - val_precision_m: 0.7524 - val_recall_m: 0.7605 - val_f1_m: 0.7546\n","Epoch 8/50\n","131/131 [==============================] - 1s 9ms/step - loss: 0.2504 - accuracy: 0.6161 - precision_m: 0.8644 - recall_m: 0.8242 - f1_m: 0.8428 - val_loss: 0.3309 - val_accuracy: 0.6806 - val_precision_m: 0.7670 - val_recall_m: 0.7668 - val_f1_m: 0.7646\n","Epoch 9/50\n","131/131 [==============================] - 1s 9ms/step - loss: 0.2332 - accuracy: 0.5917 - precision_m: 0.8809 - recall_m: 0.8377 - f1_m: 0.8578 - val_loss: 0.3288 - val_accuracy: 0.6845 - val_precision_m: 0.7853 - val_recall_m: 0.7512 - val_f1_m: 0.7664\n","Epoch 10/50\n","131/131 [==============================] - 1s 9ms/step - loss: 0.2190 - accuracy: 0.6161 - precision_m: 0.8895 - recall_m: 0.8413 - f1_m: 0.8638 - val_loss: 0.3323 - val_accuracy: 0.6845 - val_precision_m: 0.7708 - val_recall_m: 0.7588 - val_f1_m: 0.7629\n","Epoch 11/50\n","131/131 [==============================] - 1s 9ms/step - loss: 0.2137 - accuracy: 0.6294 - precision_m: 0.8834 - recall_m: 0.8512 - f1_m: 0.8660 - val_loss: 0.3368 - val_accuracy: 0.6949 - val_precision_m: 0.7581 - val_recall_m: 0.7659 - val_f1_m: 0.7607\n","Epoch 12/50\n","131/131 [==============================] - 1s 9ms/step - loss: 0.2014 - accuracy: 0.6301 - precision_m: 0.8933 - recall_m: 0.8709 - f1_m: 0.8811 - val_loss: 0.3345 - val_accuracy: 0.6988 - val_precision_m: 0.7709 - val_recall_m: 0.7680 - val_f1_m: 0.7682\n","Epoch 13/50\n","131/131 [==============================] - 1s 9ms/step - loss: 0.2040 - accuracy: 0.6401 - precision_m: 0.8959 - recall_m: 0.8560 - f1_m: 0.8744 - val_loss: 0.3305 - val_accuracy: 0.6854 - val_precision_m: 0.7752 - val_recall_m: 0.7655 - val_f1_m: 0.7686\n","Epoch 14/50\n","131/131 [==============================] - 1s 9ms/step - loss: 0.1777 - accuracy: 0.6365 - precision_m: 0.9125 - recall_m: 0.8737 - f1_m: 0.8918 - val_loss: 0.3414 - val_accuracy: 0.6911 - val_precision_m: 0.7651 - val_recall_m: 0.7783 - val_f1_m: 0.7699\n","Epoch 15/50\n","131/131 [==============================] - 1s 9ms/step - loss: 0.1751 - accuracy: 0.6342 - precision_m: 0.9114 - recall_m: 0.8821 - f1_m: 0.8959 - val_loss: 0.3291 - val_accuracy: 0.6787 - val_precision_m: 0.7833 - val_recall_m: 0.7597 - val_f1_m: 0.7703\n","Epoch 16/50\n","131/131 [==============================] - 1s 9ms/step - loss: 0.1650 - accuracy: 0.6219 - precision_m: 0.9226 - recall_m: 0.8833 - f1_m: 0.9017 - val_loss: 0.3480 - val_accuracy: 0.6778 - val_precision_m: 0.7564 - val_recall_m: 0.7811 - val_f1_m: 0.7671\n","Epoch 17/50\n","131/131 [==============================] - 1s 9ms/step - loss: 0.1657 - accuracy: 0.6459 - precision_m: 0.9154 - recall_m: 0.8874 - f1_m: 0.9004 - val_loss: 0.3334 - val_accuracy: 0.6797 - val_precision_m: 0.7736 - val_recall_m: 0.7823 - val_f1_m: 0.7762\n","Epoch 18/50\n","131/131 [==============================] - 1s 9ms/step - loss: 0.1586 - accuracy: 0.6362 - precision_m: 0.9254 - recall_m: 0.8960 - f1_m: 0.9100 - val_loss: 0.3325 - val_accuracy: 0.6826 - val_precision_m: 0.7889 - val_recall_m: 0.7599 - val_f1_m: 0.7724\n","Epoch 19/50\n","131/131 [==============================] - 1s 9ms/step - loss: 0.1498 - accuracy: 0.6299 - precision_m: 0.9262 - recall_m: 0.8989 - f1_m: 0.9119 - val_loss: 0.3451 - val_accuracy: 0.6759 - val_precision_m: 0.7797 - val_recall_m: 0.7634 - val_f1_m: 0.7697\n","Epoch 20/50\n","131/131 [==============================] - 1s 9ms/step - loss: 0.1433 - accuracy: 0.6361 - precision_m: 0.9303 - recall_m: 0.9081 - f1_m: 0.9186 - val_loss: 0.3502 - val_accuracy: 0.6787 - val_precision_m: 0.7712 - val_recall_m: 0.7751 - val_f1_m: 0.7717\n","Epoch 21/50\n","131/131 [==============================] - 1s 9ms/step - loss: 0.1575 - accuracy: 0.6408 - precision_m: 0.9233 - recall_m: 0.8988 - f1_m: 0.9102 - val_loss: 0.3439 - val_accuracy: 0.6740 - val_precision_m: 0.7792 - val_recall_m: 0.7672 - val_f1_m: 0.7715\n","Epoch 22/50\n","131/131 [==============================] - 1s 9ms/step - loss: 0.1389 - accuracy: 0.6594 - precision_m: 0.9298 - recall_m: 0.9050 - f1_m: 0.9167 - val_loss: 0.3668 - val_accuracy: 0.6806 - val_precision_m: 0.7521 - val_recall_m: 0.7833 - val_f1_m: 0.7662\n","Epoch 23/50\n","131/131 [==============================] - 1s 9ms/step - loss: 0.1437 - accuracy: 0.6496 - precision_m: 0.9288 - recall_m: 0.9095 - f1_m: 0.9184 - val_loss: 0.3596 - val_accuracy: 0.6787 - val_precision_m: 0.7777 - val_recall_m: 0.7613 - val_f1_m: 0.7678\n","Epoch 24/50\n","131/131 [==============================] - 1s 9ms/step - loss: 0.1363 - accuracy: 0.6539 - precision_m: 0.9290 - recall_m: 0.9104 - f1_m: 0.9192 - val_loss: 0.3738 - val_accuracy: 0.6797 - val_precision_m: 0.7574 - val_recall_m: 0.7708 - val_f1_m: 0.7624\n","Epoch 25/50\n","131/131 [==============================] - 1s 9ms/step - loss: 0.1329 - accuracy: 0.6484 - precision_m: 0.9370 - recall_m: 0.9165 - f1_m: 0.9262 - val_loss: 0.3712 - val_accuracy: 0.6816 - val_precision_m: 0.7596 - val_recall_m: 0.7678 - val_f1_m: 0.7618\n","Epoch 26/50\n","131/131 [==============================] - 1s 9ms/step - loss: 0.1221 - accuracy: 0.6591 - precision_m: 0.9385 - recall_m: 0.9190 - f1_m: 0.9281 - val_loss: 0.3706 - val_accuracy: 0.6826 - val_precision_m: 0.7709 - val_recall_m: 0.7653 - val_f1_m: 0.7662\n","Epoch 27/50\n","131/131 [==============================] - 1s 9ms/step - loss: 0.1236 - accuracy: 0.6451 - precision_m: 0.9385 - recall_m: 0.9225 - f1_m: 0.9298 - val_loss: 0.3694 - val_accuracy: 0.6740 - val_precision_m: 0.7843 - val_recall_m: 0.7636 - val_f1_m: 0.7720\n","Epoch 00027: early stopping\n","Score for fold 3: loss of 0.3452378511428833; accuracy of 66.75572395324707% ;precision_m of 0.7817964553833008 ;recall_m of 0.7400619983673096 ;            f1_m of 0.758732259273529\n","Epoch 1/50\n","131/131 [==============================] - 9s 50ms/step - loss: 0.6175 - accuracy: 0.2565 - precision_m: 0.4588 - recall_m: 0.1946 - f1_m: 0.2453 - val_loss: 0.5008 - val_accuracy: 0.3273 - val_precision_m: 0.5824 - val_recall_m: 0.3934 - val_f1_m: 0.4681\n","Epoch 2/50\n","131/131 [==============================] - 6s 45ms/step - loss: 0.5480 - accuracy: 0.2781 - precision_m: 0.5267 - recall_m: 0.2386 - f1_m: 0.3247 - val_loss: 0.5100 - val_accuracy: 0.3273 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00 - val_f1_m: 0.0000e+00\n","Epoch 3/50\n","131/131 [==============================] - 6s 44ms/step - loss: 0.5512 - accuracy: 0.2658 - precision_m: 0.5370 - recall_m: 0.1803 - f1_m: 0.2548 - val_loss: 0.5103 - val_accuracy: 0.3273 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00 - val_f1_m: 0.0000e+00\n","Epoch 4/50\n","131/131 [==============================] - 6s 45ms/step - loss: 0.5505 - accuracy: 0.2682 - precision_m: 0.5224 - recall_m: 0.1981 - f1_m: 0.2795 - val_loss: 0.5046 - val_accuracy: 0.3273 - val_precision_m: 0.5824 - val_recall_m: 0.3934 - val_f1_m: 0.4681\n","Epoch 5/50\n","131/131 [==============================] - 6s 44ms/step - loss: 0.5508 - accuracy: 0.2598 - precision_m: 0.4878 - recall_m: 0.1560 - f1_m: 0.2266 - val_loss: 0.4990 - val_accuracy: 0.3273 - val_precision_m: 0.5824 - val_recall_m: 0.3934 - val_f1_m: 0.4681\n","Epoch 6/50\n","131/131 [==============================] - 6s 44ms/step - loss: 0.5479 - accuracy: 0.2632 - precision_m: 0.5247 - recall_m: 0.2174 - f1_m: 0.3015 - val_loss: 0.5013 - val_accuracy: 0.3273 - val_precision_m: 0.5824 - val_recall_m: 0.3934 - val_f1_m: 0.4681\n","Epoch 7/50\n","131/131 [==============================] - 6s 44ms/step - loss: 0.5474 - accuracy: 0.2737 - precision_m: 0.5118 - recall_m: 0.2121 - f1_m: 0.2912 - val_loss: 0.5008 - val_accuracy: 0.3273 - val_precision_m: 0.5824 - val_recall_m: 0.3934 - val_f1_m: 0.4681\n","Epoch 8/50\n","131/131 [==============================] - 6s 44ms/step - loss: 0.5460 - accuracy: 0.2754 - precision_m: 0.5224 - recall_m: 0.2443 - f1_m: 0.3263 - val_loss: 0.5005 - val_accuracy: 0.3273 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00 - val_f1_m: 0.0000e+00\n","Epoch 9/50\n","131/131 [==============================] - 6s 44ms/step - loss: 0.5451 - accuracy: 0.2731 - precision_m: 0.5119 - recall_m: 0.2216 - f1_m: 0.3049 - val_loss: 0.5048 - val_accuracy: 0.3273 - val_precision_m: 0.5824 - val_recall_m: 0.3934 - val_f1_m: 0.4681\n","Epoch 10/50\n","131/131 [==============================] - 6s 44ms/step - loss: 0.5509 - accuracy: 0.2564 - precision_m: 0.5325 - recall_m: 0.2019 - f1_m: 0.2826 - val_loss: 0.5006 - val_accuracy: 0.3273 - val_precision_m: 0.5824 - val_recall_m: 0.3934 - val_f1_m: 0.4681\n","Epoch 11/50\n","131/131 [==============================] - 6s 43ms/step - loss: 0.5513 - accuracy: 0.2617 - precision_m: 0.5091 - recall_m: 0.2264 - f1_m: 0.3085 - val_loss: 0.4998 - val_accuracy: 0.3273 - val_precision_m: 0.5824 - val_recall_m: 0.3934 - val_f1_m: 0.4681\n","Epoch 00011: early stopping\n","Score for fold 1: loss of 0.6524804830551147; accuracy of 15.566577017307281% ;precision_m of 0.5129217505455017 ;recall_m of 0.2593536674976349 ;            f1_m of 0.3432560861110687\n","Epoch 1/50\n","131/131 [==============================] - 9s 50ms/step - loss: 0.6536 - accuracy: 0.2118 - precision_m: 0.5105 - recall_m: 0.2065 - f1_m: 0.2691 - val_loss: 0.5182 - val_accuracy: 0.3279 - val_precision_m: 0.5827 - val_recall_m: 0.3938 - val_f1_m: 0.4685\n","Epoch 2/50\n","131/131 [==============================] - 6s 44ms/step - loss: 0.5903 - accuracy: 0.2132 - precision_m: 0.5402 - recall_m: 0.2210 - f1_m: 0.3068 - val_loss: 0.5307 - val_accuracy: 0.3279 - val_precision_m: 0.5827 - val_recall_m: 0.3938 - val_f1_m: 0.4685\n","Epoch 3/50\n","131/131 [==============================] - 6s 44ms/step - loss: 0.5932 - accuracy: 0.2159 - precision_m: 0.5300 - recall_m: 0.2080 - f1_m: 0.2924 - val_loss: 0.5159 - val_accuracy: 0.3279 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00 - val_f1_m: 0.0000e+00\n","Epoch 4/50\n","131/131 [==============================] - 6s 44ms/step - loss: 0.5933 - accuracy: 0.2107 - precision_m: 0.5177 - recall_m: 0.2099 - f1_m: 0.2928 - val_loss: 0.5222 - val_accuracy: 0.3279 - val_precision_m: 0.5827 - val_recall_m: 0.3938 - val_f1_m: 0.4685\n","Epoch 5/50\n","131/131 [==============================] - 6s 44ms/step - loss: 0.5953 - accuracy: 0.1978 - precision_m: 0.5117 - recall_m: 0.1961 - f1_m: 0.2786 - val_loss: 0.5151 - val_accuracy: 0.3279 - val_precision_m: 0.5827 - val_recall_m: 0.3938 - val_f1_m: 0.4685\n","Epoch 6/50\n","131/131 [==============================] - 6s 44ms/step - loss: 0.5942 - accuracy: 0.1990 - precision_m: 0.5255 - recall_m: 0.2519 - f1_m: 0.3368 - val_loss: 0.5220 - val_accuracy: 0.3279 - val_precision_m: 0.5827 - val_recall_m: 0.3938 - val_f1_m: 0.4685\n","Epoch 7/50\n","131/131 [==============================] - 6s 44ms/step - loss: 0.5911 - accuracy: 0.2106 - precision_m: 0.5277 - recall_m: 0.1862 - f1_m: 0.2633 - val_loss: 0.5237 - val_accuracy: 0.3279 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00 - val_f1_m: 0.0000e+00\n","Epoch 8/50\n","131/131 [==============================] - 6s 44ms/step - loss: 0.5947 - accuracy: 0.2041 - precision_m: 0.5162 - recall_m: 0.1781 - f1_m: 0.2580 - val_loss: 0.5158 - val_accuracy: 0.3279 - val_precision_m: 0.5827 - val_recall_m: 0.3938 - val_f1_m: 0.4685\n","Epoch 9/50\n","131/131 [==============================] - 6s 44ms/step - loss: 0.5900 - accuracy: 0.2181 - precision_m: 0.5160 - recall_m: 0.2313 - f1_m: 0.3162 - val_loss: 0.5197 - val_accuracy: 0.3279 - val_precision_m: 0.5827 - val_recall_m: 0.3938 - val_f1_m: 0.4685\n","Epoch 10/50\n","131/131 [==============================] - 6s 44ms/step - loss: 0.5898 - accuracy: 0.2039 - precision_m: 0.5195 - recall_m: 0.2418 - f1_m: 0.3280 - val_loss: 0.5141 - val_accuracy: 0.3279 - val_precision_m: 0.5827 - val_recall_m: 0.3938 - val_f1_m: 0.4685\n","Epoch 11/50\n","131/131 [==============================] - 6s 44ms/step - loss: 0.5877 - accuracy: 0.2134 - precision_m: 0.5230 - recall_m: 0.2342 - f1_m: 0.3200 - val_loss: 0.5254 - val_accuracy: 0.3279 - val_precision_m: 0.5827 - val_recall_m: 0.3938 - val_f1_m: 0.4685\n","Epoch 00011: early stopping\n","Score for fold 2: loss of 0.5700607895851135; accuracy of 25.076335668563843% ;precision_m of 0.5106163024902344 ;recall_m of 0.3112577795982361 ;            f1_m of 0.3850182890892029\n","Epoch 1/50\n","131/131 [==============================] - 9s 50ms/step - loss: 0.6354 - accuracy: 0.2126 - precision_m: 0.4399 - recall_m: 0.1483 - f1_m: 0.2119 - val_loss: 0.5600 - val_accuracy: 0.2822 - val_precision_m: 0.5127 - val_recall_m: 0.3279 - val_f1_m: 0.3987\n","Epoch 2/50\n","131/131 [==============================] - 6s 44ms/step - loss: 0.6115 - accuracy: 0.1868 - precision_m: 0.5021 - recall_m: 0.1361 - f1_m: 0.2046 - val_loss: 0.5606 - val_accuracy: 0.2822 - val_precision_m: 0.5127 - val_recall_m: 0.3279 - val_f1_m: 0.3987\n","Epoch 3/50\n","131/131 [==============================] - 6s 44ms/step - loss: 0.6095 - accuracy: 0.1821 - precision_m: 0.5162 - recall_m: 0.1617 - f1_m: 0.2362 - val_loss: 0.5686 - val_accuracy: 0.2822 - val_precision_m: 0.5127 - val_recall_m: 0.3279 - val_f1_m: 0.3987\n","Epoch 4/50\n","131/131 [==============================] - 6s 43ms/step - loss: 0.6054 - accuracy: 0.1765 - precision_m: 0.5190 - recall_m: 0.1736 - f1_m: 0.2544 - val_loss: 0.5643 - val_accuracy: 0.2822 - val_precision_m: 0.5127 - val_recall_m: 0.3279 - val_f1_m: 0.3987\n","Epoch 5/50\n","131/131 [==============================] - 6s 44ms/step - loss: 0.6043 - accuracy: 0.1903 - precision_m: 0.5088 - recall_m: 0.1665 - f1_m: 0.2433 - val_loss: 0.5572 - val_accuracy: 0.2822 - val_precision_m: 0.5127 - val_recall_m: 0.3279 - val_f1_m: 0.3987\n","Epoch 6/50\n","131/131 [==============================] - 6s 44ms/step - loss: 0.6080 - accuracy: 0.1839 - precision_m: 0.4757 - recall_m: 0.1593 - f1_m: 0.2273 - val_loss: 0.5697 - val_accuracy: 0.2822 - val_precision_m: 0.5127 - val_recall_m: 0.3279 - val_f1_m: 0.3987\n","Epoch 7/50\n","131/131 [==============================] - 6s 45ms/step - loss: 0.6070 - accuracy: 0.1858 - precision_m: 0.5144 - recall_m: 0.1628 - f1_m: 0.2357 - val_loss: 0.5577 - val_accuracy: 0.2822 - val_precision_m: 0.5127 - val_recall_m: 0.3279 - val_f1_m: 0.3987\n","Epoch 8/50\n","131/131 [==============================] - 6s 44ms/step - loss: 0.6079 - accuracy: 0.1798 - precision_m: 0.4655 - recall_m: 0.1451 - f1_m: 0.2073 - val_loss: 0.5601 - val_accuracy: 0.2822 - val_precision_m: 0.5127 - val_recall_m: 0.3279 - val_f1_m: 0.3987\n","Epoch 9/50\n","131/131 [==============================] - 6s 44ms/step - loss: 0.6053 - accuracy: 0.1869 - precision_m: 0.5013 - recall_m: 0.1708 - f1_m: 0.2477 - val_loss: 0.5613 - val_accuracy: 0.2822 - val_precision_m: 0.5127 - val_recall_m: 0.3279 - val_f1_m: 0.3987\n","Epoch 10/50\n","131/131 [==============================] - 6s 44ms/step - loss: 0.6089 - accuracy: 0.1791 - precision_m: 0.5135 - recall_m: 0.1918 - f1_m: 0.2727 - val_loss: 0.5590 - val_accuracy: 0.2822 - val_precision_m: 0.5127 - val_recall_m: 0.3279 - val_f1_m: 0.3987\n","Epoch 11/50\n","131/131 [==============================] - 6s 44ms/step - loss: 0.6050 - accuracy: 0.1931 - precision_m: 0.5044 - recall_m: 0.1877 - f1_m: 0.2716 - val_loss: 0.5597 - val_accuracy: 0.2822 - val_precision_m: 0.5127 - val_recall_m: 0.3279 - val_f1_m: 0.3987\n","Epoch 00011: early stopping\n","Score for fold 3: loss of 0.5382634401321411; accuracy of 31.068703532218933% ;precision_m of 0.5502504706382751 ;recall_m of 0.36772269010543823 ;            f1_m of 0.43958553671836853\n","Epoch 1/50\n","131/131 [==============================] - 9s 52ms/step - loss: 0.6255 - accuracy: 0.2579 - precision_m: 0.4574 - recall_m: 0.1834 - f1_m: 0.2343 - val_loss: 0.4979 - val_accuracy: 0.3273 - val_precision_m: 0.5824 - val_recall_m: 0.3934 - val_f1_m: 0.4681\n","Epoch 2/50\n","131/131 [==============================] - 6s 45ms/step - loss: 0.5578 - accuracy: 0.2567 - precision_m: 0.4954 - recall_m: 0.1594 - f1_m: 0.2312 - val_loss: 0.5049 - val_accuracy: 0.3273 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00 - val_f1_m: 0.0000e+00\n","Epoch 3/50\n","131/131 [==============================] - 6s 46ms/step - loss: 0.5513 - accuracy: 0.2532 - precision_m: 0.4983 - recall_m: 0.1420 - f1_m: 0.2077 - val_loss: 0.5000 - val_accuracy: 0.3273 - val_precision_m: 0.5824 - val_recall_m: 0.3934 - val_f1_m: 0.4681\n","Epoch 4/50\n","131/131 [==============================] - 6s 46ms/step - loss: 0.5462 - accuracy: 0.2718 - precision_m: 0.5216 - recall_m: 0.2007 - f1_m: 0.2798 - val_loss: 0.5044 - val_accuracy: 0.3273 - val_precision_m: 0.5824 - val_recall_m: 0.3934 - val_f1_m: 0.4681\n","Epoch 5/50\n","131/131 [==============================] - 6s 46ms/step - loss: 0.5504 - accuracy: 0.2634 - precision_m: 0.5112 - recall_m: 0.1845 - f1_m: 0.2624 - val_loss: 0.5008 - val_accuracy: 0.3273 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00 - val_f1_m: 0.0000e+00\n","Epoch 6/50\n","131/131 [==============================] - 6s 46ms/step - loss: 0.5420 - accuracy: 0.2810 - precision_m: 0.5240 - recall_m: 0.2082 - f1_m: 0.2816 - val_loss: 0.5033 - val_accuracy: 0.3273 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00 - val_f1_m: 0.0000e+00\n","Epoch 7/50\n","131/131 [==============================] - 6s 46ms/step - loss: 0.5444 - accuracy: 0.2736 - precision_m: 0.5401 - recall_m: 0.2357 - f1_m: 0.3189 - val_loss: 0.5028 - val_accuracy: 0.3273 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00 - val_f1_m: 0.0000e+00\n","Epoch 8/50\n","131/131 [==============================] - 6s 46ms/step - loss: 0.5482 - accuracy: 0.2650 - precision_m: 0.5430 - recall_m: 0.1805 - f1_m: 0.2546 - val_loss: 0.5036 - val_accuracy: 0.3273 - val_precision_m: 0.5824 - val_recall_m: 0.3934 - val_f1_m: 0.4681\n","Epoch 9/50\n","131/131 [==============================] - 6s 46ms/step - loss: 0.5507 - accuracy: 0.2607 - precision_m: 0.5154 - recall_m: 0.2062 - f1_m: 0.2862 - val_loss: 0.5004 - val_accuracy: 0.3273 - val_precision_m: 0.5824 - val_recall_m: 0.3934 - val_f1_m: 0.4681\n","Epoch 10/50\n","131/131 [==============================] - 6s 46ms/step - loss: 0.5456 - accuracy: 0.2643 - precision_m: 0.5160 - recall_m: 0.2147 - f1_m: 0.2952 - val_loss: 0.5005 - val_accuracy: 0.3273 - val_precision_m: 0.5824 - val_recall_m: 0.3934 - val_f1_m: 0.4681\n","Epoch 11/50\n","131/131 [==============================] - 6s 46ms/step - loss: 0.5483 - accuracy: 0.2659 - precision_m: 0.5354 - recall_m: 0.2074 - f1_m: 0.2906 - val_loss: 0.5024 - val_accuracy: 0.3273 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00 - val_f1_m: 0.0000e+00\n","Epoch 00011: early stopping\n","Score for fold 1: loss of 0.646846354007721; accuracy of 15.566577017307281% ;precision_m of 0.0 ;recall_m of 0.0 ;            f1_m of 0.0\n","Epoch 1/50\n","131/131 [==============================] - 9s 52ms/step - loss: 0.6345 - accuracy: 0.2114 - precision_m: 0.4709 - recall_m: 0.1996 - f1_m: 0.2614 - val_loss: 0.5248 - val_accuracy: 0.3279 - val_precision_m: 0.5827 - val_recall_m: 0.3938 - val_f1_m: 0.4685\n","Epoch 2/50\n","131/131 [==============================] - 6s 46ms/step - loss: 0.5984 - accuracy: 0.2088 - precision_m: 0.5060 - recall_m: 0.1704 - f1_m: 0.2500 - val_loss: 0.5127 - val_accuracy: 0.3279 - val_precision_m: 0.5827 - val_recall_m: 0.3938 - val_f1_m: 0.4685\n","Epoch 3/50\n","131/131 [==============================] - 6s 46ms/step - loss: 0.5893 - accuracy: 0.2093 - precision_m: 0.5170 - recall_m: 0.2110 - f1_m: 0.2876 - val_loss: 0.5112 - val_accuracy: 0.3279 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00 - val_f1_m: 0.0000e+00\n","Epoch 4/50\n","131/131 [==============================] - 6s 46ms/step - loss: 0.5924 - accuracy: 0.2097 - precision_m: 0.5187 - recall_m: 0.1900 - f1_m: 0.2716 - val_loss: 0.5199 - val_accuracy: 0.3279 - val_precision_m: 0.5827 - val_recall_m: 0.3938 - val_f1_m: 0.4685\n","Epoch 5/50\n","131/131 [==============================] - 6s 46ms/step - loss: 0.5913 - accuracy: 0.2084 - precision_m: 0.4924 - recall_m: 0.1950 - f1_m: 0.2684 - val_loss: 0.5209 - val_accuracy: 0.3279 - val_precision_m: 0.5827 - val_recall_m: 0.3938 - val_f1_m: 0.4685\n","Epoch 6/50\n","131/131 [==============================] - 6s 47ms/step - loss: 0.5946 - accuracy: 0.2025 - precision_m: 0.5257 - recall_m: 0.2148 - f1_m: 0.2987 - val_loss: 0.5128 - val_accuracy: 0.3279 - val_precision_m: 0.5827 - val_recall_m: 0.3938 - val_f1_m: 0.4685\n","Epoch 7/50\n","131/131 [==============================] - 6s 46ms/step - loss: 0.5936 - accuracy: 0.2109 - precision_m: 0.5110 - recall_m: 0.2004 - f1_m: 0.2781 - val_loss: 0.5074 - val_accuracy: 0.3279 - val_precision_m: 0.5827 - val_recall_m: 0.3938 - val_f1_m: 0.4685\n","Epoch 8/50\n","131/131 [==============================] - 6s 47ms/step - loss: 0.5975 - accuracy: 0.2052 - precision_m: 0.4980 - recall_m: 0.1808 - f1_m: 0.2545 - val_loss: 0.5135 - val_accuracy: 0.3279 - val_precision_m: 0.5827 - val_recall_m: 0.3938 - val_f1_m: 0.4685\n","Epoch 9/50\n","131/131 [==============================] - 6s 46ms/step - loss: 0.5921 - accuracy: 0.1960 - precision_m: 0.5164 - recall_m: 0.2293 - f1_m: 0.3123 - val_loss: 0.5120 - val_accuracy: 0.3279 - val_precision_m: 0.5827 - val_recall_m: 0.3938 - val_f1_m: 0.4685\n","Epoch 10/50\n","131/131 [==============================] - 6s 46ms/step - loss: 0.5890 - accuracy: 0.2188 - precision_m: 0.5279 - recall_m: 0.2561 - f1_m: 0.3404 - val_loss: 0.5240 - val_accuracy: 0.3279 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00 - val_f1_m: 0.0000e+00\n","Epoch 11/50\n","131/131 [==============================] - 6s 46ms/step - loss: 0.5897 - accuracy: 0.2151 - precision_m: 0.4723 - recall_m: 0.1876 - f1_m: 0.2558 - val_loss: 0.5157 - val_accuracy: 0.3279 - val_precision_m: 0.5827 - val_recall_m: 0.3938 - val_f1_m: 0.4685\n","Epoch 00011: early stopping\n","Score for fold 2: loss of 0.564917802810669; accuracy of 25.076335668563843% ;precision_m of 0.5106163024902344 ;recall_m of 0.3112577795982361 ;            f1_m of 0.3850182890892029\n","Epoch 1/50\n","131/131 [==============================] - 10s 52ms/step - loss: 0.6389 - accuracy: 0.2224 - precision_m: 0.5065 - recall_m: 0.1552 - f1_m: 0.2267 - val_loss: 0.5749 - val_accuracy: 0.2822 - val_precision_m: 0.5127 - val_recall_m: 0.3279 - val_f1_m: 0.3987\n","Epoch 2/50\n","131/131 [==============================] - 6s 46ms/step - loss: 0.6077 - accuracy: 0.1844 - precision_m: 0.4791 - recall_m: 0.1617 - f1_m: 0.2336 - val_loss: 0.5595 - val_accuracy: 0.2822 - val_precision_m: 0.5127 - val_recall_m: 0.3279 - val_f1_m: 0.3987\n","Epoch 3/50\n","131/131 [==============================] - 6s 46ms/step - loss: 0.6107 - accuracy: 0.1798 - precision_m: 0.5062 - recall_m: 0.1910 - f1_m: 0.2703 - val_loss: 0.5519 - val_accuracy: 0.2822 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00 - val_f1_m: 0.0000e+00\n","Epoch 4/50\n","131/131 [==============================] - 6s 46ms/step - loss: 0.6062 - accuracy: 0.1805 - precision_m: 0.5008 - recall_m: 0.1797 - f1_m: 0.2565 - val_loss: 0.5608 - val_accuracy: 0.2822 - val_precision_m: 0.5127 - val_recall_m: 0.3279 - val_f1_m: 0.3987\n","Epoch 5/50\n","131/131 [==============================] - 6s 46ms/step - loss: 0.6071 - accuracy: 0.1863 - precision_m: 0.5315 - recall_m: 0.1381 - f1_m: 0.2007 - val_loss: 0.5614 - val_accuracy: 0.2822 - val_precision_m: 0.5127 - val_recall_m: 0.3279 - val_f1_m: 0.3987\n","Epoch 6/50\n","131/131 [==============================] - 6s 46ms/step - loss: 0.6027 - accuracy: 0.1945 - precision_m: 0.5354 - recall_m: 0.1987 - f1_m: 0.2778 - val_loss: 0.5567 - val_accuracy: 0.2822 - val_precision_m: 0.5127 - val_recall_m: 0.3279 - val_f1_m: 0.3987\n","Epoch 7/50\n","131/131 [==============================] - 6s 46ms/step - loss: 0.6085 - accuracy: 0.1748 - precision_m: 0.5218 - recall_m: 0.2035 - f1_m: 0.2893 - val_loss: 0.5582 - val_accuracy: 0.2822 - val_precision_m: 0.5127 - val_recall_m: 0.3279 - val_f1_m: 0.3987\n","Epoch 8/50\n","131/131 [==============================] - 6s 47ms/step - loss: 0.6055 - accuracy: 0.1922 - precision_m: 0.5149 - recall_m: 0.2206 - f1_m: 0.3065 - val_loss: 0.5674 - val_accuracy: 0.2822 - val_precision_m: 0.5127 - val_recall_m: 0.3279 - val_f1_m: 0.3987\n","Epoch 9/50\n","131/131 [==============================] - 6s 46ms/step - loss: 0.6099 - accuracy: 0.1831 - precision_m: 0.4654 - recall_m: 0.1006 - f1_m: 0.1514 - val_loss: 0.5576 - val_accuracy: 0.2822 - val_precision_m: 0.5127 - val_recall_m: 0.3279 - val_f1_m: 0.3987\n","Epoch 10/50\n","131/131 [==============================] - 6s 46ms/step - loss: 0.6065 - accuracy: 0.1764 - precision_m: 0.5259 - recall_m: 0.1732 - f1_m: 0.2432 - val_loss: 0.5591 - val_accuracy: 0.2822 - val_precision_m: 0.5127 - val_recall_m: 0.3279 - val_f1_m: 0.3987\n","Epoch 11/50\n","131/131 [==============================] - 6s 46ms/step - loss: 0.6067 - accuracy: 0.1764 - precision_m: 0.5114 - recall_m: 0.1972 - f1_m: 0.2683 - val_loss: 0.5562 - val_accuracy: 0.2822 - val_precision_m: 0.5127 - val_recall_m: 0.3279 - val_f1_m: 0.3987\n","Epoch 00011: early stopping\n","Score for fold 3: loss of 0.5337641835212708; accuracy of 31.068703532218933% ;precision_m of 0.5502504706382751 ;recall_m of 0.36772269010543823 ;            f1_m of 0.43958553671836853\n","Epoch 1/50\n","131/131 [==============================] - 9s 54ms/step - loss: 0.5898 - accuracy: 0.2547 - precision_m: 0.4601 - recall_m: 0.1896 - f1_m: 0.2526 - val_loss: 0.5093 - val_accuracy: 0.3273 - val_precision_m: 0.5824 - val_recall_m: 0.3934 - val_f1_m: 0.4681\n","Epoch 2/50\n","131/131 [==============================] - 6s 48ms/step - loss: 0.5455 - accuracy: 0.2682 - precision_m: 0.5295 - recall_m: 0.2370 - f1_m: 0.3226 - val_loss: 0.5026 - val_accuracy: 0.3273 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00 - val_f1_m: 0.0000e+00\n","Epoch 3/50\n","131/131 [==============================] - 6s 49ms/step - loss: 0.5486 - accuracy: 0.2742 - precision_m: 0.5254 - recall_m: 0.1772 - f1_m: 0.2536 - val_loss: 0.5012 - val_accuracy: 0.3273 - val_precision_m: 0.5824 - val_recall_m: 0.3934 - val_f1_m: 0.4681\n","Epoch 4/50\n","131/131 [==============================] - 6s 48ms/step - loss: 0.5477 - accuracy: 0.2645 - precision_m: 0.5320 - recall_m: 0.2493 - f1_m: 0.3315 - val_loss: 0.5042 - val_accuracy: 0.3273 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00 - val_f1_m: 0.0000e+00\n","Epoch 5/50\n","131/131 [==============================] - 6s 48ms/step - loss: 0.5513 - accuracy: 0.2549 - precision_m: 0.5220 - recall_m: 0.2116 - f1_m: 0.2920 - val_loss: 0.5035 - val_accuracy: 0.3273 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00 - val_f1_m: 0.0000e+00\n","Epoch 6/50\n","131/131 [==============================] - 6s 48ms/step - loss: 0.5448 - accuracy: 0.2796 - precision_m: 0.5199 - recall_m: 0.2200 - f1_m: 0.3032 - val_loss: 0.5017 - val_accuracy: 0.3273 - val_precision_m: 0.5824 - val_recall_m: 0.3934 - val_f1_m: 0.4681\n","Epoch 7/50\n","131/131 [==============================] - 6s 49ms/step - loss: 0.5425 - accuracy: 0.2788 - precision_m: 0.5219 - recall_m: 0.2536 - f1_m: 0.3371 - val_loss: 0.5019 - val_accuracy: 0.3273 - val_precision_m: 0.5824 - val_recall_m: 0.3934 - val_f1_m: 0.4681\n","Epoch 8/50\n","131/131 [==============================] - 6s 48ms/step - loss: 0.5485 - accuracy: 0.2627 - precision_m: 0.5226 - recall_m: 0.2057 - f1_m: 0.2894 - val_loss: 0.4998 - val_accuracy: 0.3273 - val_precision_m: 0.5824 - val_recall_m: 0.3934 - val_f1_m: 0.4681\n","Epoch 9/50\n","131/131 [==============================] - 6s 48ms/step - loss: 0.5453 - accuracy: 0.2696 - precision_m: 0.5159 - recall_m: 0.2660 - f1_m: 0.3452 - val_loss: 0.5029 - val_accuracy: 0.3273 - val_precision_m: 0.5824 - val_recall_m: 0.3934 - val_f1_m: 0.4681\n","Epoch 10/50\n","131/131 [==============================] - 6s 47ms/step - loss: 0.5515 - accuracy: 0.2553 - precision_m: 0.4733 - recall_m: 0.1782 - f1_m: 0.2403 - val_loss: 0.4978 - val_accuracy: 0.3273 - val_precision_m: 0.5824 - val_recall_m: 0.3934 - val_f1_m: 0.4681\n","Epoch 11/50\n","131/131 [==============================] - 6s 48ms/step - loss: 0.5475 - accuracy: 0.2694 - precision_m: 0.4856 - recall_m: 0.2089 - f1_m: 0.2674 - val_loss: 0.5008 - val_accuracy: 0.3273 - val_precision_m: 0.5824 - val_recall_m: 0.3934 - val_f1_m: 0.4681\n","Epoch 00011: early stopping\n","Score for fold 1: loss of 0.651202380657196; accuracy of 15.566577017307281% ;precision_m of 0.5127865076065063 ;recall_m of 0.2593536674976349 ;            f1_m of 0.34322670102119446\n","Epoch 1/50\n","131/131 [==============================] - 9s 54ms/step - loss: 0.6215 - accuracy: 0.2260 - precision_m: 0.4977 - recall_m: 0.2120 - f1_m: 0.2915 - val_loss: 0.5289 - val_accuracy: 0.3279 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00 - val_f1_m: 0.0000e+00\n","Epoch 2/50\n","131/131 [==============================] - 6s 48ms/step - loss: 0.5964 - accuracy: 0.2067 - precision_m: 0.4800 - recall_m: 0.1319 - f1_m: 0.1979 - val_loss: 0.5232 - val_accuracy: 0.3279 - val_precision_m: 0.5827 - val_recall_m: 0.3938 - val_f1_m: 0.4685\n","Epoch 3/50\n","131/131 [==============================] - 6s 49ms/step - loss: 0.5925 - accuracy: 0.2149 - precision_m: 0.5318 - recall_m: 0.2296 - f1_m: 0.3137 - val_loss: 0.5164 - val_accuracy: 0.3279 - val_precision_m: 0.5827 - val_recall_m: 0.3938 - val_f1_m: 0.4685\n","Epoch 4/50\n","131/131 [==============================] - 6s 48ms/step - loss: 0.5938 - accuracy: 0.2138 - precision_m: 0.5056 - recall_m: 0.1996 - f1_m: 0.2839 - val_loss: 0.5198 - val_accuracy: 0.3279 - val_precision_m: 0.5827 - val_recall_m: 0.3938 - val_f1_m: 0.4685\n","Epoch 5/50\n","131/131 [==============================] - 6s 49ms/step - loss: 0.5910 - accuracy: 0.2110 - precision_m: 0.5061 - recall_m: 0.1846 - f1_m: 0.2604 - val_loss: 0.5200 - val_accuracy: 0.3279 - val_precision_m: 0.5827 - val_recall_m: 0.3938 - val_f1_m: 0.4685\n","Epoch 6/50\n","131/131 [==============================] - 6s 49ms/step - loss: 0.5890 - accuracy: 0.2071 - precision_m: 0.5258 - recall_m: 0.2148 - f1_m: 0.3019 - val_loss: 0.5183 - val_accuracy: 0.3279 - val_precision_m: 0.5827 - val_recall_m: 0.3938 - val_f1_m: 0.4685\n","Epoch 7/50\n","131/131 [==============================] - 6s 49ms/step - loss: 0.5946 - accuracy: 0.2075 - precision_m: 0.5250 - recall_m: 0.2285 - f1_m: 0.3163 - val_loss: 0.5257 - val_accuracy: 0.3279 - val_precision_m: 0.5827 - val_recall_m: 0.3938 - val_f1_m: 0.4685\n","Epoch 8/50\n","131/131 [==============================] - 6s 48ms/step - loss: 0.5909 - accuracy: 0.2094 - precision_m: 0.5149 - recall_m: 0.2147 - f1_m: 0.3003 - val_loss: 0.5354 - val_accuracy: 0.3279 - val_precision_m: 0.5827 - val_recall_m: 0.3938 - val_f1_m: 0.4685\n","Epoch 9/50\n","131/131 [==============================] - 6s 49ms/step - loss: 0.5951 - accuracy: 0.2099 - precision_m: 0.5126 - recall_m: 0.1944 - f1_m: 0.2731 - val_loss: 0.5230 - val_accuracy: 0.3279 - val_precision_m: 0.5827 - val_recall_m: 0.3938 - val_f1_m: 0.4685\n","Epoch 10/50\n","131/131 [==============================] - 6s 48ms/step - loss: 0.5903 - accuracy: 0.2107 - precision_m: 0.5288 - recall_m: 0.2383 - f1_m: 0.3239 - val_loss: 0.5161 - val_accuracy: 0.3279 - val_precision_m: 0.5827 - val_recall_m: 0.3938 - val_f1_m: 0.4685\n","Epoch 11/50\n","131/131 [==============================] - 6s 49ms/step - loss: 0.5896 - accuracy: 0.2180 - precision_m: 0.5237 - recall_m: 0.2522 - f1_m: 0.3356 - val_loss: 0.5248 - val_accuracy: 0.3279 - val_precision_m: 0.5827 - val_recall_m: 0.3938 - val_f1_m: 0.4685\n","Epoch 12/50\n","131/131 [==============================] - 6s 48ms/step - loss: 0.6956 - accuracy: 0.2081 - precision_m: 0.5139 - recall_m: 0.2429 - f1_m: 0.3106 - val_loss: 0.5107 - val_accuracy: 0.3279 - val_precision_m: 0.5827 - val_recall_m: 0.3938 - val_f1_m: 0.4685\n","Epoch 00012: early stopping\n","Score for fold 2: loss of 0.5646792650222778; accuracy of 25.076335668563843% ;precision_m of 0.5106163024902344 ;recall_m of 0.3112577795982361 ;            f1_m of 0.3850182890892029\n","Epoch 1/50\n","131/131 [==============================] - 10s 54ms/step - loss: 0.6264 - accuracy: 0.2013 - precision_m: 0.4676 - recall_m: 0.1579 - f1_m: 0.2245 - val_loss: 0.5596 - val_accuracy: 0.2822 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00 - val_f1_m: 0.0000e+00\n","Epoch 2/50\n","131/131 [==============================] - 6s 48ms/step - loss: 0.6058 - accuracy: 0.1841 - precision_m: 0.4785 - recall_m: 0.1430 - f1_m: 0.2135 - val_loss: 0.5663 - val_accuracy: 0.2822 - val_precision_m: 0.5127 - val_recall_m: 0.3279 - val_f1_m: 0.3987\n","Epoch 3/50\n","131/131 [==============================] - 6s 48ms/step - loss: 0.6091 - accuracy: 0.1784 - precision_m: 0.4833 - recall_m: 0.1242 - f1_m: 0.1849 - val_loss: 0.5610 - val_accuracy: 0.2822 - val_precision_m: 0.5127 - val_recall_m: 0.3279 - val_f1_m: 0.3987\n","Epoch 4/50\n","131/131 [==============================] - 6s 48ms/step - loss: 0.6084 - accuracy: 0.1848 - precision_m: 0.4863 - recall_m: 0.1535 - f1_m: 0.2287 - val_loss: 0.5652 - val_accuracy: 0.2822 - val_precision_m: 0.5127 - val_recall_m: 0.3279 - val_f1_m: 0.3987\n","Epoch 5/50\n","131/131 [==============================] - 6s 48ms/step - loss: 0.6079 - accuracy: 0.1802 - precision_m: 0.4393 - recall_m: 0.1410 - f1_m: 0.1987 - val_loss: 0.5680 - val_accuracy: 0.2822 - val_precision_m: 0.5127 - val_recall_m: 0.3279 - val_f1_m: 0.3987\n","Epoch 6/50\n","131/131 [==============================] - 6s 48ms/step - loss: 0.6094 - accuracy: 0.1754 - precision_m: 0.5076 - recall_m: 0.1849 - f1_m: 0.2665 - val_loss: 0.5561 - val_accuracy: 0.2822 - val_precision_m: 0.5127 - val_recall_m: 0.3279 - val_f1_m: 0.3987\n","Epoch 7/50\n","131/131 [==============================] - 6s 48ms/step - loss: 0.6031 - accuracy: 0.1878 - precision_m: 0.5249 - recall_m: 0.1974 - f1_m: 0.2792 - val_loss: 0.5583 - val_accuracy: 0.2822 - val_precision_m: 0.5127 - val_recall_m: 0.3279 - val_f1_m: 0.3987\n","Epoch 8/50\n","131/131 [==============================] - 6s 48ms/step - loss: 0.6088 - accuracy: 0.1884 - precision_m: 0.5114 - recall_m: 0.1833 - f1_m: 0.2635 - val_loss: 0.5603 - val_accuracy: 0.2822 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00 - val_f1_m: 0.0000e+00\n","Epoch 9/50\n","131/131 [==============================] - 6s 49ms/step - loss: 0.6158 - accuracy: 0.1812 - precision_m: 0.4873 - recall_m: 0.1517 - f1_m: 0.2223 - val_loss: 0.5549 - val_accuracy: 0.2822 - val_precision_m: 0.5127 - val_recall_m: 0.3279 - val_f1_m: 0.3987\n","Epoch 10/50\n","131/131 [==============================] - 6s 48ms/step - loss: 0.6058 - accuracy: 0.1772 - precision_m: 0.5134 - recall_m: 0.1797 - f1_m: 0.2589 - val_loss: 0.5600 - val_accuracy: 0.2822 - val_precision_m: 0.5127 - val_recall_m: 0.3279 - val_f1_m: 0.3987\n","Epoch 11/50\n","131/131 [==============================] - 6s 48ms/step - loss: 0.6053 - accuracy: 0.1845 - precision_m: 0.4613 - recall_m: 0.1162 - f1_m: 0.1718 - val_loss: 0.5589 - val_accuracy: 0.2822 - val_precision_m: 0.5127 - val_recall_m: 0.3279 - val_f1_m: 0.3987\n","Epoch 12/50\n","131/131 [==============================] - 6s 48ms/step - loss: 0.6060 - accuracy: 0.1924 - precision_m: 0.5087 - recall_m: 0.1830 - f1_m: 0.2597 - val_loss: 0.5525 - val_accuracy: 0.2822 - val_precision_m: 0.5127 - val_recall_m: 0.3279 - val_f1_m: 0.3987\n","Epoch 00012: early stopping\n","Score for fold 3: loss of 0.5246492624282837; accuracy of 31.068703532218933% ;precision_m of 0.5502504706382751 ;recall_m of 0.36772269010543823 ;            f1_m of 0.43958553671836853\n","Epoch 1/50\n","131/131 [==============================] - 9s 49ms/step - loss: 0.5857 - accuracy: 0.2791 - precision_m: 0.4977 - recall_m: 0.2092 - f1_m: 0.2822 - val_loss: 0.5043 - val_accuracy: 0.3273 - val_precision_m: 0.5824 - val_recall_m: 0.3934 - val_f1_m: 0.4681\n","Epoch 2/50\n","131/131 [==============================] - 6s 44ms/step - loss: 0.5523 - accuracy: 0.2637 - precision_m: 0.5221 - recall_m: 0.2162 - f1_m: 0.3003 - val_loss: 0.5014 - val_accuracy: 0.3273 - val_precision_m: 0.5824 - val_recall_m: 0.3934 - val_f1_m: 0.4681\n","Epoch 3/50\n","131/131 [==============================] - 6s 44ms/step - loss: 0.5495 - accuracy: 0.2700 - precision_m: 0.5313 - recall_m: 0.2417 - f1_m: 0.3231 - val_loss: 0.5098 - val_accuracy: 0.3273 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00 - val_f1_m: 0.0000e+00\n","Epoch 4/50\n","131/131 [==============================] - 6s 44ms/step - loss: 0.5440 - accuracy: 0.2796 - precision_m: 0.4698 - recall_m: 0.1791 - f1_m: 0.2445 - val_loss: 0.4980 - val_accuracy: 0.3273 - val_precision_m: 0.5824 - val_recall_m: 0.3934 - val_f1_m: 0.4681\n","Epoch 5/50\n","131/131 [==============================] - 6s 44ms/step - loss: 0.5498 - accuracy: 0.2619 - precision_m: 0.5363 - recall_m: 0.2060 - f1_m: 0.2782 - val_loss: 0.5035 - val_accuracy: 0.3273 - val_precision_m: 0.5824 - val_recall_m: 0.3934 - val_f1_m: 0.4681\n","Epoch 6/50\n","131/131 [==============================] - 6s 44ms/step - loss: 0.5516 - accuracy: 0.2522 - precision_m: 0.5034 - recall_m: 0.2148 - f1_m: 0.2940 - val_loss: 0.5024 - val_accuracy: 0.3273 - val_precision_m: 0.5824 - val_recall_m: 0.3934 - val_f1_m: 0.4681\n","Epoch 7/50\n","131/131 [==============================] - 6s 44ms/step - loss: 0.5444 - accuracy: 0.2752 - precision_m: 0.5037 - recall_m: 0.2131 - f1_m: 0.2914 - val_loss: 0.5052 - val_accuracy: 0.3273 - val_precision_m: 0.5824 - val_recall_m: 0.3934 - val_f1_m: 0.4681\n","Epoch 8/50\n","131/131 [==============================] - 6s 44ms/step - loss: 0.5513 - accuracy: 0.2588 - precision_m: 0.5143 - recall_m: 0.2366 - f1_m: 0.3158 - val_loss: 0.4992 - val_accuracy: 0.3273 - val_precision_m: 0.5824 - val_recall_m: 0.3934 - val_f1_m: 0.4681\n","Epoch 9/50\n","131/131 [==============================] - 6s 43ms/step - loss: 0.5453 - accuracy: 0.2769 - precision_m: 0.5201 - recall_m: 0.2487 - f1_m: 0.3231 - val_loss: 0.4999 - val_accuracy: 0.3273 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00 - val_f1_m: 0.0000e+00\n","Epoch 10/50\n","131/131 [==============================] - 6s 44ms/step - loss: 0.5481 - accuracy: 0.2658 - precision_m: 0.5128 - recall_m: 0.1978 - f1_m: 0.2753 - val_loss: 0.5012 - val_accuracy: 0.3273 - val_precision_m: 0.5824 - val_recall_m: 0.3934 - val_f1_m: 0.4681\n","Epoch 11/50\n","131/131 [==============================] - 6s 44ms/step - loss: 0.5405 - accuracy: 0.2691 - precision_m: 0.5288 - recall_m: 0.2426 - f1_m: 0.3251 - val_loss: 0.5007 - val_accuracy: 0.3273 - val_precision_m: 0.5824 - val_recall_m: 0.3934 - val_f1_m: 0.4681\n","Epoch 00011: early stopping\n","Score for fold 1: loss of 0.6494567394256592; accuracy of 15.566577017307281% ;precision_m of 0.5127865076065063 ;recall_m of 0.2593536674976349 ;            f1_m of 0.34322670102119446\n","Epoch 1/50\n","131/131 [==============================] - 9s 50ms/step - loss: 0.6140 - accuracy: 0.2063 - precision_m: 0.4942 - recall_m: 0.1823 - f1_m: 0.2605 - val_loss: 0.5262 - val_accuracy: 0.3279 - val_precision_m: 0.5827 - val_recall_m: 0.3938 - val_f1_m: 0.4685\n","Epoch 2/50\n","131/131 [==============================] - 6s 43ms/step - loss: 0.5957 - accuracy: 0.2024 - precision_m: 0.5119 - recall_m: 0.2024 - f1_m: 0.2808 - val_loss: 0.5243 - val_accuracy: 0.3279 - val_precision_m: 0.5827 - val_recall_m: 0.3938 - val_f1_m: 0.4685\n","Epoch 3/50\n","131/131 [==============================] - 6s 44ms/step - loss: 0.5932 - accuracy: 0.2146 - precision_m: 0.5231 - recall_m: 0.1616 - f1_m: 0.2342 - val_loss: 0.5256 - val_accuracy: 0.3279 - val_precision_m: 0.5827 - val_recall_m: 0.3938 - val_f1_m: 0.4685\n","Epoch 4/50\n","131/131 [==============================] - 6s 44ms/step - loss: 0.5913 - accuracy: 0.2078 - precision_m: 0.5293 - recall_m: 0.1937 - f1_m: 0.2681 - val_loss: 0.5226 - val_accuracy: 0.3279 - val_precision_m: 0.5827 - val_recall_m: 0.3938 - val_f1_m: 0.4685\n","Epoch 5/50\n","131/131 [==============================] - 6s 44ms/step - loss: 0.5913 - accuracy: 0.2151 - precision_m: 0.5172 - recall_m: 0.2210 - f1_m: 0.3028 - val_loss: 0.5269 - val_accuracy: 0.3279 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00 - val_f1_m: 0.0000e+00\n","Epoch 6/50\n","131/131 [==============================] - 6s 44ms/step - loss: 0.5923 - accuracy: 0.2084 - precision_m: 0.4951 - recall_m: 0.1600 - f1_m: 0.2345 - val_loss: 0.5186 - val_accuracy: 0.3279 - val_precision_m: 0.5827 - val_recall_m: 0.3938 - val_f1_m: 0.4685\n","Epoch 7/50\n","131/131 [==============================] - 6s 44ms/step - loss: 0.5899 - accuracy: 0.2075 - precision_m: 0.5292 - recall_m: 0.2476 - f1_m: 0.3323 - val_loss: 0.5223 - val_accuracy: 0.3279 - val_precision_m: 0.5827 - val_recall_m: 0.3938 - val_f1_m: 0.4685\n","Epoch 8/50\n","131/131 [==============================] - 6s 44ms/step - loss: 0.5924 - accuracy: 0.2130 - precision_m: 0.5075 - recall_m: 0.1943 - f1_m: 0.2778 - val_loss: 0.5212 - val_accuracy: 0.3279 - val_precision_m: 0.5827 - val_recall_m: 0.3938 - val_f1_m: 0.4685\n","Epoch 9/50\n","131/131 [==============================] - 6s 44ms/step - loss: 0.5858 - accuracy: 0.2221 - precision_m: 0.5325 - recall_m: 0.2310 - f1_m: 0.3192 - val_loss: 0.5290 - val_accuracy: 0.3279 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00 - val_f1_m: 0.0000e+00\n","Epoch 10/50\n","131/131 [==============================] - 6s 44ms/step - loss: 0.5906 - accuracy: 0.2067 - precision_m: 0.5166 - recall_m: 0.1685 - f1_m: 0.2418 - val_loss: 0.5184 - val_accuracy: 0.3279 - val_precision_m: 0.5827 - val_recall_m: 0.3938 - val_f1_m: 0.4685\n","Epoch 11/50\n","131/131 [==============================] - 6s 44ms/step - loss: 0.6015 - accuracy: 0.1954 - precision_m: 0.5021 - recall_m: 0.1664 - f1_m: 0.2447 - val_loss: 0.5174 - val_accuracy: 0.3279 - val_precision_m: 0.5827 - val_recall_m: 0.3938 - val_f1_m: 0.4685\n","Epoch 00011: early stopping\n","Score for fold 2: loss of 0.5706810355186462; accuracy of 25.076335668563843% ;precision_m of 0.5106163024902344 ;recall_m of 0.3112577795982361 ;            f1_m of 0.3850182890892029\n","Epoch 1/50\n","131/131 [==============================] - 9s 50ms/step - loss: 0.6283 - accuracy: 0.1964 - precision_m: 0.5046 - recall_m: 0.1596 - f1_m: 0.2252 - val_loss: 0.5651 - val_accuracy: 0.2822 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00 - val_f1_m: 0.0000e+00\n","Epoch 2/50\n","131/131 [==============================] - 6s 43ms/step - loss: 0.6039 - accuracy: 0.1948 - precision_m: 0.5152 - recall_m: 0.1874 - f1_m: 0.2672 - val_loss: 0.5522 - val_accuracy: 0.2822 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00 - val_f1_m: 0.0000e+00\n","Epoch 3/50\n","131/131 [==============================] - 6s 44ms/step - loss: 0.6105 - accuracy: 0.1820 - precision_m: 0.5051 - recall_m: 0.1499 - f1_m: 0.2195 - val_loss: 0.5534 - val_accuracy: 0.2822 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00 - val_f1_m: 0.0000e+00\n","Epoch 4/50\n","131/131 [==============================] - 6s 44ms/step - loss: 0.6064 - accuracy: 0.1810 - precision_m: 0.4824 - recall_m: 0.1701 - f1_m: 0.2386 - val_loss: 0.5602 - val_accuracy: 0.2822 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00 - val_f1_m: 0.0000e+00\n","Epoch 5/50\n","131/131 [==============================] - 6s 44ms/step - loss: 0.6351 - accuracy: 0.1879 - precision_m: 0.4917 - recall_m: 0.1374 - f1_m: 0.2013 - val_loss: 0.5467 - val_accuracy: 0.2822 - val_precision_m: 0.5118 - val_recall_m: 0.3267 - val_f1_m: 0.3976\n","Epoch 6/50\n","131/131 [==============================] - 6s 44ms/step - loss: 0.6076 - accuracy: 0.2116 - precision_m: 0.4885 - recall_m: 0.1833 - f1_m: 0.2625 - val_loss: 0.5451 - val_accuracy: 0.2822 - val_precision_m: 0.5127 - val_recall_m: 0.3279 - val_f1_m: 0.3987\n","Epoch 7/50\n","131/131 [==============================] - 6s 44ms/step - loss: 0.6041 - accuracy: 0.2098 - precision_m: 0.5217 - recall_m: 0.1860 - f1_m: 0.2686 - val_loss: 0.5495 - val_accuracy: 0.2822 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00 - val_f1_m: 0.0000e+00\n","Epoch 8/50\n","131/131 [==============================] - 6s 44ms/step - loss: 0.6042 - accuracy: 0.1992 - precision_m: 0.5133 - recall_m: 0.1694 - f1_m: 0.2519 - val_loss: 0.5415 - val_accuracy: 0.2822 - val_precision_m: 0.5127 - val_recall_m: 0.3279 - val_f1_m: 0.3987\n","Epoch 9/50\n","131/131 [==============================] - 6s 44ms/step - loss: 0.5925 - accuracy: 0.2288 - precision_m: 0.5468 - recall_m: 0.2085 - f1_m: 0.2982 - val_loss: 0.5539 - val_accuracy: 0.3003 - val_precision_m: 0.5715 - val_recall_m: 0.3089 - val_f1_m: 0.3977\n","Epoch 10/50\n","131/131 [==============================] - 6s 44ms/step - loss: 0.5800 - accuracy: 0.2311 - precision_m: 0.5609 - recall_m: 0.2906 - f1_m: 0.3769 - val_loss: 0.5103 - val_accuracy: 0.3022 - val_precision_m: 0.5240 - val_recall_m: 0.4397 - val_f1_m: 0.4773\n","Epoch 11/50\n","131/131 [==============================] - 6s 44ms/step - loss: 0.5439 - accuracy: 0.2649 - precision_m: 0.5795 - recall_m: 0.3723 - f1_m: 0.4480 - val_loss: 0.4893 - val_accuracy: 0.3775 - val_precision_m: 0.5675 - val_recall_m: 0.3752 - val_f1_m: 0.4504\n","Epoch 12/50\n","131/131 [==============================] - 6s 44ms/step - loss: 0.5317 - accuracy: 0.2614 - precision_m: 0.5981 - recall_m: 0.3989 - f1_m: 0.4745 - val_loss: 0.4856 - val_accuracy: 0.3174 - val_precision_m: 0.5484 - val_recall_m: 0.5496 - val_f1_m: 0.5478\n","Epoch 13/50\n","131/131 [==============================] - 6s 44ms/step - loss: 0.5387 - accuracy: 0.2193 - precision_m: 0.6073 - recall_m: 0.4175 - f1_m: 0.4913 - val_loss: 0.4799 - val_accuracy: 0.3823 - val_precision_m: 0.5605 - val_recall_m: 0.4322 - val_f1_m: 0.4867\n","Epoch 14/50\n","131/131 [==============================] - 6s 44ms/step - loss: 0.5420 - accuracy: 0.2973 - precision_m: 0.5914 - recall_m: 0.4015 - f1_m: 0.4732 - val_loss: 0.4785 - val_accuracy: 0.3194 - val_precision_m: 0.5721 - val_recall_m: 0.5030 - val_f1_m: 0.5342\n","Epoch 15/50\n","131/131 [==============================] - 6s 44ms/step - loss: 0.5291 - accuracy: 0.2633 - precision_m: 0.6057 - recall_m: 0.4163 - f1_m: 0.4888 - val_loss: 0.4795 - val_accuracy: 0.3823 - val_precision_m: 0.5644 - val_recall_m: 0.5611 - val_f1_m: 0.5615\n","Epoch 16/50\n","131/131 [==============================] - 6s 43ms/step - loss: 0.5219 - accuracy: 0.2724 - precision_m: 0.6006 - recall_m: 0.4496 - f1_m: 0.5115 - val_loss: 0.4823 - val_accuracy: 0.3727 - val_precision_m: 0.5844 - val_recall_m: 0.5228 - val_f1_m: 0.5502\n","Epoch 17/50\n","131/131 [==============================] - 6s 44ms/step - loss: 0.5302 - accuracy: 0.2624 - precision_m: 0.6020 - recall_m: 0.4476 - f1_m: 0.5065 - val_loss: 0.4984 - val_accuracy: 0.3012 - val_precision_m: 0.5894 - val_recall_m: 0.3759 - val_f1_m: 0.4575\n","Epoch 18/50\n","131/131 [==============================] - 6s 44ms/step - loss: 0.5276 - accuracy: 0.2647 - precision_m: 0.6078 - recall_m: 0.4319 - f1_m: 0.4995 - val_loss: 0.4940 - val_accuracy: 0.3260 - val_precision_m: 0.5990 - val_recall_m: 0.3623 - val_f1_m: 0.4495\n","Epoch 19/50\n","131/131 [==============================] - 6s 44ms/step - loss: 0.5204 - accuracy: 0.2865 - precision_m: 0.6149 - recall_m: 0.4396 - f1_m: 0.5095 - val_loss: 0.4830 - val_accuracy: 0.3022 - val_precision_m: 0.6057 - val_recall_m: 0.3859 - val_f1_m: 0.4697\n","Epoch 20/50\n","131/131 [==============================] - 6s 44ms/step - loss: 0.5119 - accuracy: 0.2510 - precision_m: 0.6244 - recall_m: 0.4575 - f1_m: 0.5229 - val_loss: 0.4792 - val_accuracy: 0.3432 - val_precision_m: 0.5980 - val_recall_m: 0.4268 - val_f1_m: 0.4962\n","Epoch 21/50\n","131/131 [==============================] - 6s 44ms/step - loss: 0.5103 - accuracy: 0.2533 - precision_m: 0.6168 - recall_m: 0.4586 - f1_m: 0.5232 - val_loss: 0.4657 - val_accuracy: 0.3375 - val_precision_m: 0.5708 - val_recall_m: 0.5587 - val_f1_m: 0.5635\n","Epoch 22/50\n","131/131 [==============================] - 6s 44ms/step - loss: 0.5029 - accuracy: 0.2683 - precision_m: 0.6144 - recall_m: 0.4886 - f1_m: 0.5419 - val_loss: 0.4545 - val_accuracy: 0.3746 - val_precision_m: 0.5874 - val_recall_m: 0.5502 - val_f1_m: 0.5672\n","Epoch 23/50\n","131/131 [==============================] - 6s 44ms/step - loss: 0.5027 - accuracy: 0.2508 - precision_m: 0.6079 - recall_m: 0.4993 - f1_m: 0.5461 - val_loss: 0.4491 - val_accuracy: 0.4004 - val_precision_m: 0.5828 - val_recall_m: 0.6552 - val_f1_m: 0.6158\n","Epoch 24/50\n","131/131 [==============================] - 6s 44ms/step - loss: 0.4939 - accuracy: 0.2969 - precision_m: 0.6115 - recall_m: 0.5338 - f1_m: 0.5681 - val_loss: 0.4621 - val_accuracy: 0.5386 - val_precision_m: 0.5914 - val_recall_m: 0.5972 - val_f1_m: 0.5924\n","Epoch 25/50\n","131/131 [==============================] - 6s 44ms/step - loss: 0.5067 - accuracy: 0.3529 - precision_m: 0.6097 - recall_m: 0.5070 - f1_m: 0.5510 - val_loss: 0.4319 - val_accuracy: 0.5596 - val_precision_m: 0.6658 - val_recall_m: 0.6449 - val_f1_m: 0.6540\n","Epoch 26/50\n","131/131 [==============================] - 6s 44ms/step - loss: 0.4900 - accuracy: 0.4004 - precision_m: 0.6705 - recall_m: 0.5169 - f1_m: 0.5821 - val_loss: 0.4245 - val_accuracy: 0.5796 - val_precision_m: 0.6989 - val_recall_m: 0.5800 - val_f1_m: 0.6327\n","Epoch 27/50\n","131/131 [==============================] - 6s 44ms/step - loss: 0.4936 - accuracy: 0.4021 - precision_m: 0.6758 - recall_m: 0.4887 - f1_m: 0.5652 - val_loss: 0.4314 - val_accuracy: 0.5377 - val_precision_m: 0.6799 - val_recall_m: 0.5659 - val_f1_m: 0.6162\n","Epoch 28/50\n","131/131 [==============================] - 6s 43ms/step - loss: 0.4873 - accuracy: 0.3996 - precision_m: 0.6765 - recall_m: 0.5085 - f1_m: 0.5783 - val_loss: 0.4081 - val_accuracy: 0.5739 - val_precision_m: 0.7363 - val_recall_m: 0.5956 - val_f1_m: 0.6570\n","Epoch 29/50\n","131/131 [==============================] - 6s 44ms/step - loss: 0.5186 - accuracy: 0.3784 - precision_m: 0.6910 - recall_m: 0.4724 - f1_m: 0.5594 - val_loss: 0.4566 - val_accuracy: 0.5129 - val_precision_m: 0.7174 - val_recall_m: 0.5112 - val_f1_m: 0.5956\n","Epoch 30/50\n","131/131 [==============================] - 6s 44ms/step - loss: 0.5019 - accuracy: 0.4094 - precision_m: 0.7055 - recall_m: 0.4608 - f1_m: 0.5543 - val_loss: 0.4626 - val_accuracy: 0.5396 - val_precision_m: 0.6909 - val_recall_m: 0.5361 - val_f1_m: 0.6026\n","Epoch 31/50\n","131/131 [==============================] - 6s 44ms/step - loss: 0.4813 - accuracy: 0.4222 - precision_m: 0.7208 - recall_m: 0.5079 - f1_m: 0.5943 - val_loss: 0.4093 - val_accuracy: 0.5825 - val_precision_m: 0.7058 - val_recall_m: 0.5808 - val_f1_m: 0.6362\n","Epoch 32/50\n","131/131 [==============================] - 6s 43ms/step - loss: 0.4674 - accuracy: 0.4561 - precision_m: 0.6952 - recall_m: 0.5243 - f1_m: 0.5964 - val_loss: 0.4089 - val_accuracy: 0.5558 - val_precision_m: 0.6691 - val_recall_m: 0.6315 - val_f1_m: 0.6484\n","Epoch 33/50\n","131/131 [==============================] - 6s 44ms/step - loss: 0.4706 - accuracy: 0.4364 - precision_m: 0.7089 - recall_m: 0.5257 - f1_m: 0.6017 - val_loss: 0.4848 - val_accuracy: 0.4909 - val_precision_m: 0.6876 - val_recall_m: 0.4787 - val_f1_m: 0.5628\n","Epoch 34/50\n","131/131 [==============================] - 6s 44ms/step - loss: 0.4950 - accuracy: 0.4445 - precision_m: 0.7110 - recall_m: 0.4728 - f1_m: 0.5646 - val_loss: 0.3941 - val_accuracy: 0.5729 - val_precision_m: 0.6959 - val_recall_m: 0.5969 - val_f1_m: 0.6415\n","Epoch 35/50\n","131/131 [==============================] - 6s 44ms/step - loss: 0.4660 - accuracy: 0.4441 - precision_m: 0.7235 - recall_m: 0.5114 - f1_m: 0.5961 - val_loss: 0.4249 - val_accuracy: 0.4976 - val_precision_m: 0.7127 - val_recall_m: 0.5019 - val_f1_m: 0.5871\n","Epoch 36/50\n","131/131 [==============================] - 6s 44ms/step - loss: 0.4956 - accuracy: 0.4869 - precision_m: 0.6985 - recall_m: 0.4103 - f1_m: 0.5135 - val_loss: 0.4252 - val_accuracy: 0.5338 - val_precision_m: 0.7000 - val_recall_m: 0.6069 - val_f1_m: 0.6487\n","Epoch 37/50\n","131/131 [==============================] - 6s 44ms/step - loss: 0.4776 - accuracy: 0.4666 - precision_m: 0.6870 - recall_m: 0.5117 - f1_m: 0.5843 - val_loss: 0.4275 - val_accuracy: 0.5691 - val_precision_m: 0.6647 - val_recall_m: 0.6070 - val_f1_m: 0.6336\n","Epoch 38/50\n","131/131 [==============================] - 6s 44ms/step - loss: 0.4741 - accuracy: 0.4482 - precision_m: 0.6972 - recall_m: 0.5307 - f1_m: 0.6006 - val_loss: 0.4181 - val_accuracy: 0.5872 - val_precision_m: 0.6970 - val_recall_m: 0.6174 - val_f1_m: 0.6533\n","Epoch 00038: early stopping\n","Score for fold 3: loss of 0.4080599844455719; accuracy of 57.824426889419556% ;precision_m of 0.7060980200767517 ;recall_m of 0.6115258932113647 ;            f1_m of 0.6538573503494263\n","Epoch 1/50\n","131/131 [==============================] - 9s 51ms/step - loss: 0.5886 - accuracy: 0.2522 - precision_m: 0.4986 - recall_m: 0.1986 - f1_m: 0.2676 - val_loss: 0.4974 - val_accuracy: 0.3273 - val_precision_m: 0.5824 - val_recall_m: 0.3934 - val_f1_m: 0.4681\n","Epoch 2/50\n","131/131 [==============================] - 6s 45ms/step - loss: 0.5502 - accuracy: 0.2769 - precision_m: 0.4987 - recall_m: 0.2165 - f1_m: 0.2908 - val_loss: 0.5024 - val_accuracy: 0.3273 - val_precision_m: 0.5824 - val_recall_m: 0.3934 - val_f1_m: 0.4681\n","Epoch 3/50\n","131/131 [==============================] - 6s 46ms/step - loss: 0.5464 - accuracy: 0.2682 - precision_m: 0.5247 - recall_m: 0.2214 - f1_m: 0.3033 - val_loss: 0.5065 - val_accuracy: 0.3273 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00 - val_f1_m: 0.0000e+00\n","Epoch 4/50\n","131/131 [==============================] - 6s 46ms/step - loss: 0.5528 - accuracy: 0.2622 - precision_m: 0.5281 - recall_m: 0.1547 - f1_m: 0.2185 - val_loss: 0.5009 - val_accuracy: 0.3273 - val_precision_m: 0.5824 - val_recall_m: 0.3934 - val_f1_m: 0.4681\n","Epoch 5/50\n","131/131 [==============================] - 6s 46ms/step - loss: 0.5438 - accuracy: 0.2730 - precision_m: 0.5054 - recall_m: 0.2400 - f1_m: 0.3200 - val_loss: 0.5120 - val_accuracy: 0.3273 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00 - val_f1_m: 0.0000e+00\n","Epoch 6/50\n","131/131 [==============================] - 6s 45ms/step - loss: 0.5462 - accuracy: 0.2632 - precision_m: 0.4374 - recall_m: 0.1462 - f1_m: 0.2012 - val_loss: 0.4996 - val_accuracy: 0.3273 - val_precision_m: 0.5824 - val_recall_m: 0.3934 - val_f1_m: 0.4681\n","Epoch 7/50\n","131/131 [==============================] - 6s 46ms/step - loss: 0.5471 - accuracy: 0.2594 - precision_m: 0.5226 - recall_m: 0.2442 - f1_m: 0.3280 - val_loss: 0.4985 - val_accuracy: 0.3273 - val_precision_m: 0.5824 - val_recall_m: 0.3934 - val_f1_m: 0.4681\n","Epoch 8/50\n","131/131 [==============================] - 6s 45ms/step - loss: 0.5468 - accuracy: 0.2652 - precision_m: 0.5149 - recall_m: 0.2167 - f1_m: 0.2957 - val_loss: 0.4982 - val_accuracy: 0.3273 - val_precision_m: 0.5824 - val_recall_m: 0.3934 - val_f1_m: 0.4681\n","Epoch 9/50\n","131/131 [==============================] - 6s 46ms/step - loss: 0.5453 - accuracy: 0.2734 - precision_m: 0.5190 - recall_m: 0.2717 - f1_m: 0.3548 - val_loss: 0.5026 - val_accuracy: 0.3273 - val_precision_m: 0.5824 - val_recall_m: 0.3934 - val_f1_m: 0.4681\n","Epoch 10/50\n","131/131 [==============================] - 6s 45ms/step - loss: 0.5468 - accuracy: 0.2679 - precision_m: 0.5067 - recall_m: 0.1960 - f1_m: 0.2621 - val_loss: 0.5077 - val_accuracy: 0.3273 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00 - val_f1_m: 0.0000e+00\n","Epoch 11/50\n","131/131 [==============================] - 6s 45ms/step - loss: 0.5499 - accuracy: 0.2612 - precision_m: 0.5145 - recall_m: 0.1750 - f1_m: 0.2420 - val_loss: 0.4971 - val_accuracy: 0.3273 - val_precision_m: 0.5824 - val_recall_m: 0.3934 - val_f1_m: 0.4681\n","Epoch 00011: early stopping\n","Score for fold 1: loss of 0.6617956161499023; accuracy of 15.566577017307281% ;precision_m of 0.5127865076065063 ;recall_m of 0.2593536674976349 ;            f1_m of 0.34322670102119446\n","Epoch 1/50\n","131/131 [==============================] - 10s 52ms/step - loss: 0.6310 - accuracy: 0.2279 - precision_m: 0.4712 - recall_m: 0.1753 - f1_m: 0.2281 - val_loss: 0.5456 - val_accuracy: 0.3279 - val_precision_m: 0.5827 - val_recall_m: 0.3938 - val_f1_m: 0.4685\n","Epoch 2/50\n","131/131 [==============================] - 6s 45ms/step - loss: 0.5989 - accuracy: 0.2013 - precision_m: 0.4980 - recall_m: 0.1750 - f1_m: 0.2510 - val_loss: 0.5096 - val_accuracy: 0.3279 - val_precision_m: 0.5827 - val_recall_m: 0.3938 - val_f1_m: 0.4685\n","Epoch 3/50\n","131/131 [==============================] - 6s 46ms/step - loss: 0.5956 - accuracy: 0.2051 - precision_m: 0.5060 - recall_m: 0.1939 - f1_m: 0.2662 - val_loss: 0.5310 - val_accuracy: 0.3279 - val_precision_m: 0.5827 - val_recall_m: 0.3938 - val_f1_m: 0.4685\n","Epoch 4/50\n","131/131 [==============================] - 6s 46ms/step - loss: 0.5907 - accuracy: 0.2083 - precision_m: 0.5199 - recall_m: 0.2260 - f1_m: 0.3113 - val_loss: 0.5179 - val_accuracy: 0.3279 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00 - val_f1_m: 0.0000e+00\n","Epoch 5/50\n","131/131 [==============================] - 6s 46ms/step - loss: 0.5953 - accuracy: 0.2040 - precision_m: 0.4416 - recall_m: 0.1231 - f1_m: 0.1738 - val_loss: 0.5265 - val_accuracy: 0.3279 - val_precision_m: 0.5827 - val_recall_m: 0.3938 - val_f1_m: 0.4685\n","Epoch 6/50\n","131/131 [==============================] - 6s 46ms/step - loss: 0.5910 - accuracy: 0.2135 - precision_m: 0.5241 - recall_m: 0.2072 - f1_m: 0.2913 - val_loss: 0.5256 - val_accuracy: 0.3279 - val_precision_m: 0.5827 - val_recall_m: 0.3938 - val_f1_m: 0.4685\n","Epoch 7/50\n","131/131 [==============================] - 6s 46ms/step - loss: 0.5918 - accuracy: 0.2129 - precision_m: 0.5228 - recall_m: 0.2324 - f1_m: 0.3169 - val_loss: 0.5141 - val_accuracy: 0.3279 - val_precision_m: 0.5827 - val_recall_m: 0.3938 - val_f1_m: 0.4685\n","Epoch 8/50\n","131/131 [==============================] - 6s 46ms/step - loss: 0.5933 - accuracy: 0.2138 - precision_m: 0.5205 - recall_m: 0.2399 - f1_m: 0.3216 - val_loss: 0.5268 - val_accuracy: 0.3279 - val_precision_m: 0.5827 - val_recall_m: 0.3938 - val_f1_m: 0.4685\n","Epoch 9/50\n","131/131 [==============================] - 6s 46ms/step - loss: 0.5902 - accuracy: 0.2058 - precision_m: 0.5213 - recall_m: 0.2312 - f1_m: 0.3119 - val_loss: 0.5172 - val_accuracy: 0.3279 - val_precision_m: 0.5827 - val_recall_m: 0.3938 - val_f1_m: 0.4685\n","Epoch 10/50\n","131/131 [==============================] - 6s 45ms/step - loss: 0.5894 - accuracy: 0.2137 - precision_m: 0.5228 - recall_m: 0.2454 - f1_m: 0.3314 - val_loss: 0.5223 - val_accuracy: 0.3279 - val_precision_m: 0.5827 - val_recall_m: 0.3938 - val_f1_m: 0.4685\n","Epoch 11/50\n","131/131 [==============================] - 6s 46ms/step - loss: 0.5921 - accuracy: 0.2102 - precision_m: 0.5148 - recall_m: 0.2286 - f1_m: 0.3149 - val_loss: 0.5207 - val_accuracy: 0.3279 - val_precision_m: 0.5827 - val_recall_m: 0.3938 - val_f1_m: 0.4685\n","Epoch 00011: early stopping\n","Score for fold 2: loss of 0.565959095954895; accuracy of 25.076335668563843% ;precision_m of 0.5106163024902344 ;recall_m of 0.3112577795982361 ;            f1_m of 0.3850182890892029\n","Epoch 1/50\n","131/131 [==============================] - 9s 52ms/step - loss: 0.6308 - accuracy: 0.1935 - precision_m: 0.4559 - recall_m: 0.1703 - f1_m: 0.2368 - val_loss: 0.5537 - val_accuracy: 0.2822 - val_precision_m: 0.5127 - val_recall_m: 0.3279 - val_f1_m: 0.3987\n","Epoch 2/50\n","131/131 [==============================] - 6s 46ms/step - loss: 0.6037 - accuracy: 0.1929 - precision_m: 0.5168 - recall_m: 0.1885 - f1_m: 0.2729 - val_loss: 0.5638 - val_accuracy: 0.2822 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00 - val_f1_m: 0.0000e+00\n","Epoch 3/50\n","131/131 [==============================] - 6s 46ms/step - loss: 0.6143 - accuracy: 0.1811 - precision_m: 0.4848 - recall_m: 0.1257 - f1_m: 0.1881 - val_loss: 0.5534 - val_accuracy: 0.2822 - val_precision_m: 0.5127 - val_recall_m: 0.3279 - val_f1_m: 0.3987\n","Epoch 4/50\n","131/131 [==============================] - 6s 46ms/step - loss: 0.6112 - accuracy: 0.1778 - precision_m: 0.5249 - recall_m: 0.1683 - f1_m: 0.2495 - val_loss: 0.5612 - val_accuracy: 0.2822 - val_precision_m: 0.5127 - val_recall_m: 0.3279 - val_f1_m: 0.3987\n","Epoch 5/50\n","131/131 [==============================] - 6s 46ms/step - loss: 0.6105 - accuracy: 0.1799 - precision_m: 0.5170 - recall_m: 0.1647 - f1_m: 0.2440 - val_loss: 0.5653 - val_accuracy: 0.2822 - val_precision_m: 0.5127 - val_recall_m: 0.3279 - val_f1_m: 0.3987\n","Epoch 6/50\n","131/131 [==============================] - 6s 47ms/step - loss: 0.6057 - accuracy: 0.1862 - precision_m: 0.4917 - recall_m: 0.1756 - f1_m: 0.2534 - val_loss: 0.5596 - val_accuracy: 0.2822 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00 - val_f1_m: 0.0000e+00\n","Epoch 7/50\n","131/131 [==============================] - 6s 46ms/step - loss: 0.6064 - accuracy: 0.1804 - precision_m: 0.4857 - recall_m: 0.1300 - f1_m: 0.1980 - val_loss: 0.5623 - val_accuracy: 0.2822 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00 - val_f1_m: 0.0000e+00\n","Epoch 8/50\n","131/131 [==============================] - 6s 46ms/step - loss: 0.6089 - accuracy: 0.1706 - precision_m: 0.4915 - recall_m: 0.1190 - f1_m: 0.1803 - val_loss: 0.5627 - val_accuracy: 0.2822 - val_precision_m: 0.5127 - val_recall_m: 0.3279 - val_f1_m: 0.3987\n","Epoch 9/50\n","131/131 [==============================] - 6s 46ms/step - loss: 0.6097 - accuracy: 0.1709 - precision_m: 0.5184 - recall_m: 0.1948 - f1_m: 0.2803 - val_loss: 0.5577 - val_accuracy: 0.2822 - val_precision_m: 0.5127 - val_recall_m: 0.3279 - val_f1_m: 0.3987\n","Epoch 10/50\n","131/131 [==============================] - 6s 46ms/step - loss: 0.6048 - accuracy: 0.1852 - precision_m: 0.5065 - recall_m: 0.2194 - f1_m: 0.3044 - val_loss: 0.5602 - val_accuracy: 0.2822 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00 - val_f1_m: 0.0000e+00\n","Epoch 11/50\n","131/131 [==============================] - 6s 46ms/step - loss: 0.6072 - accuracy: 0.1819 - precision_m: 0.4899 - recall_m: 0.1387 - f1_m: 0.2081 - val_loss: 0.5559 - val_accuracy: 0.2822 - val_precision_m: 0.5127 - val_recall_m: 0.3279 - val_f1_m: 0.3987\n","Epoch 00011: early stopping\n","Score for fold 3: loss of 0.5312747955322266; accuracy of 31.068703532218933% ;precision_m of 0.5502504706382751 ;recall_m of 0.36772269010543823 ;            f1_m of 0.43958553671836853\n","Epoch 1/50\n","131/131 [==============================] - 9s 54ms/step - loss: 0.6423 - accuracy: 0.2596 - precision_m: 0.4208 - recall_m: 0.1935 - f1_m: 0.2415 - val_loss: 0.5004 - val_accuracy: 0.3273 - val_precision_m: 0.5824 - val_recall_m: 0.3934 - val_f1_m: 0.4681\n","Epoch 2/50\n","131/131 [==============================] - 6s 48ms/step - loss: 0.5549 - accuracy: 0.2651 - precision_m: 0.4964 - recall_m: 0.1788 - f1_m: 0.2480 - val_loss: 0.5014 - val_accuracy: 0.3273 - val_precision_m: 0.5824 - val_recall_m: 0.3934 - val_f1_m: 0.4681\n","Epoch 3/50\n","131/131 [==============================] - 6s 48ms/step - loss: 0.5520 - accuracy: 0.2640 - precision_m: 0.4936 - recall_m: 0.1938 - f1_m: 0.2675 - val_loss: 0.5001 - val_accuracy: 0.3273 - val_precision_m: 0.5824 - val_recall_m: 0.3934 - val_f1_m: 0.4681\n","Epoch 4/50\n","131/131 [==============================] - 6s 49ms/step - loss: 0.5451 - accuracy: 0.2776 - precision_m: 0.5242 - recall_m: 0.2103 - f1_m: 0.2955 - val_loss: 0.5052 - val_accuracy: 0.3273 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00 - val_f1_m: 0.0000e+00\n","Epoch 5/50\n","131/131 [==============================] - 6s 49ms/step - loss: 0.5466 - accuracy: 0.2737 - precision_m: 0.4927 - recall_m: 0.1794 - f1_m: 0.2552 - val_loss: 0.5009 - val_accuracy: 0.3273 - val_precision_m: 0.5824 - val_recall_m: 0.3934 - val_f1_m: 0.4681\n","Epoch 6/50\n","131/131 [==============================] - 6s 49ms/step - loss: 0.5495 - accuracy: 0.2597 - precision_m: 0.4793 - recall_m: 0.1621 - f1_m: 0.2354 - val_loss: 0.4967 - val_accuracy: 0.3273 - val_precision_m: 0.5824 - val_recall_m: 0.3934 - val_f1_m: 0.4681\n","Epoch 7/50\n","131/131 [==============================] - 6s 48ms/step - loss: 0.5536 - accuracy: 0.2693 - precision_m: 0.5182 - recall_m: 0.2139 - f1_m: 0.2947 - val_loss: 0.5022 - val_accuracy: 0.3273 - val_precision_m: 0.5824 - val_recall_m: 0.3934 - val_f1_m: 0.4681\n","Epoch 8/50\n","131/131 [==============================] - 6s 49ms/step - loss: 0.5468 - accuracy: 0.2693 - precision_m: 0.5169 - recall_m: 0.1987 - f1_m: 0.2834 - val_loss: 0.4994 - val_accuracy: 0.3273 - val_precision_m: 0.5824 - val_recall_m: 0.3934 - val_f1_m: 0.4681\n","Epoch 9/50\n","131/131 [==============================] - 6s 48ms/step - loss: 0.5467 - accuracy: 0.2721 - precision_m: 0.5071 - recall_m: 0.2500 - f1_m: 0.3314 - val_loss: 0.5101 - val_accuracy: 0.3273 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00 - val_f1_m: 0.0000e+00\n","Epoch 10/50\n","131/131 [==============================] - 6s 49ms/step - loss: 0.5490 - accuracy: 0.2653 - precision_m: 0.4885 - recall_m: 0.1528 - f1_m: 0.2123 - val_loss: 0.5005 - val_accuracy: 0.3273 - val_precision_m: 0.5824 - val_recall_m: 0.3934 - val_f1_m: 0.4681\n","Epoch 11/50\n","131/131 [==============================] - 6s 47ms/step - loss: 0.5456 - accuracy: 0.2800 - precision_m: 0.5169 - recall_m: 0.2878 - f1_m: 0.3677 - val_loss: 0.5000 - val_accuracy: 0.3273 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00 - val_f1_m: 0.0000e+00\n","Epoch 00011: early stopping\n","Score for fold 1: loss of 0.6534335017204285; accuracy of 15.566577017307281% ;precision_m of 0.0 ;recall_m of 0.0 ;            f1_m of 0.0\n","Epoch 1/50\n","131/131 [==============================] - 10s 54ms/step - loss: 0.6264 - accuracy: 0.2210 - precision_m: 0.5116 - recall_m: 0.1956 - f1_m: 0.2718 - val_loss: 0.5407 - val_accuracy: 0.3279 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00 - val_f1_m: 0.0000e+00\n","Epoch 2/50\n","131/131 [==============================] - 6s 47ms/step - loss: 0.5923 - accuracy: 0.2090 - precision_m: 0.5306 - recall_m: 0.1715 - f1_m: 0.2469 - val_loss: 0.5253 - val_accuracy: 0.3279 - val_precision_m: 0.5827 - val_recall_m: 0.3938 - val_f1_m: 0.4685\n","Epoch 3/50\n","131/131 [==============================] - 6s 48ms/step - loss: 0.5921 - accuracy: 0.2152 - precision_m: 0.5296 - recall_m: 0.2334 - f1_m: 0.3195 - val_loss: 0.5260 - val_accuracy: 0.3279 - val_precision_m: 0.5827 - val_recall_m: 0.3938 - val_f1_m: 0.4685\n","Epoch 4/50\n","131/131 [==============================] - 6s 48ms/step - loss: 0.5964 - accuracy: 0.2085 - precision_m: 0.4882 - recall_m: 0.1424 - f1_m: 0.2065 - val_loss: 0.5232 - val_accuracy: 0.3279 - val_precision_m: 0.5827 - val_recall_m: 0.3938 - val_f1_m: 0.4685\n","Epoch 5/50\n","131/131 [==============================] - 6s 48ms/step - loss: 0.5918 - accuracy: 0.2120 - precision_m: 0.5063 - recall_m: 0.1543 - f1_m: 0.2257 - val_loss: 0.5120 - val_accuracy: 0.3279 - val_precision_m: 0.5827 - val_recall_m: 0.3938 - val_f1_m: 0.4685\n","Epoch 6/50\n","131/131 [==============================] - 6s 48ms/step - loss: 0.5904 - accuracy: 0.2106 - precision_m: 0.5253 - recall_m: 0.2046 - f1_m: 0.2777 - val_loss: 0.5295 - val_accuracy: 0.3279 - val_precision_m: 0.5827 - val_recall_m: 0.3938 - val_f1_m: 0.4685\n","Epoch 7/50\n","131/131 [==============================] - 6s 49ms/step - loss: 0.5933 - accuracy: 0.1972 - precision_m: 0.4985 - recall_m: 0.1478 - f1_m: 0.2155 - val_loss: 0.5211 - val_accuracy: 0.3279 - val_precision_m: 0.5827 - val_recall_m: 0.3938 - val_f1_m: 0.4685\n","Epoch 8/50\n","131/131 [==============================] - 6s 48ms/step - loss: 0.6000 - accuracy: 0.2145 - precision_m: 0.5217 - recall_m: 0.2479 - f1_m: 0.3311 - val_loss: 0.5115 - val_accuracy: 0.3279 - val_precision_m: 0.5827 - val_recall_m: 0.3938 - val_f1_m: 0.4685\n","Epoch 9/50\n","131/131 [==============================] - 6s 48ms/step - loss: 0.5877 - accuracy: 0.2162 - precision_m: 0.5179 - recall_m: 0.2476 - f1_m: 0.3320 - val_loss: 0.5222 - val_accuracy: 0.3279 - val_precision_m: 0.5827 - val_recall_m: 0.3938 - val_f1_m: 0.4685\n","Epoch 10/50\n","131/131 [==============================] - 6s 48ms/step - loss: 0.5895 - accuracy: 0.2074 - precision_m: 0.5275 - recall_m: 0.2264 - f1_m: 0.3140 - val_loss: 0.5253 - val_accuracy: 0.3279 - val_precision_m: 0.5827 - val_recall_m: 0.3938 - val_f1_m: 0.4685\n","Epoch 11/50\n","131/131 [==============================] - 6s 48ms/step - loss: 0.5902 - accuracy: 0.2191 - precision_m: 0.5186 - recall_m: 0.2059 - f1_m: 0.2860 - val_loss: 0.5206 - val_accuracy: 0.3279 - val_precision_m: 0.5827 - val_recall_m: 0.3938 - val_f1_m: 0.4685\n","Epoch 12/50\n","131/131 [==============================] - 6s 47ms/step - loss: 0.5909 - accuracy: 0.2096 - precision_m: 0.5121 - recall_m: 0.2237 - f1_m: 0.3054 - val_loss: 0.5190 - val_accuracy: 0.3279 - val_precision_m: 0.5827 - val_recall_m: 0.3938 - val_f1_m: 0.4685\n","Epoch 00012: early stopping\n","Score for fold 2: loss of 0.5656947493553162; accuracy of 25.076335668563843% ;precision_m of 0.5106163024902344 ;recall_m of 0.3112577795982361 ;            f1_m of 0.3850182890892029\n","Epoch 1/50\n","131/131 [==============================] - 9s 53ms/step - loss: 0.6298 - accuracy: 0.1798 - precision_m: 0.4695 - recall_m: 0.1709 - f1_m: 0.2302 - val_loss: 0.5693 - val_accuracy: 0.2822 - val_precision_m: 0.5127 - val_recall_m: 0.3279 - val_f1_m: 0.3987\n","Epoch 2/50\n","131/131 [==============================] - 6s 48ms/step - loss: 0.6077 - accuracy: 0.1870 - precision_m: 0.5189 - recall_m: 0.1537 - f1_m: 0.2274 - val_loss: 0.5652 - val_accuracy: 0.2822 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00 - val_f1_m: 0.0000e+00\n","Epoch 3/50\n","131/131 [==============================] - 6s 48ms/step - loss: 0.6085 - accuracy: 0.1835 - precision_m: 0.4582 - recall_m: 0.1191 - f1_m: 0.1782 - val_loss: 0.5575 - val_accuracy: 0.2822 - val_precision_m: 0.5127 - val_recall_m: 0.3279 - val_f1_m: 0.3987\n","Epoch 4/50\n","131/131 [==============================] - 6s 49ms/step - loss: 0.6068 - accuracy: 0.1831 - precision_m: 0.5138 - recall_m: 0.2217 - f1_m: 0.3071 - val_loss: 0.5678 - val_accuracy: 0.2822 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00 - val_f1_m: 0.0000e+00\n","Epoch 5/50\n","131/131 [==============================] - 6s 48ms/step - loss: 0.6088 - accuracy: 0.1839 - precision_m: 0.5271 - recall_m: 0.1324 - f1_m: 0.1968 - val_loss: 0.5606 - val_accuracy: 0.2822 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00 - val_f1_m: 0.0000e+00\n","Epoch 6/50\n","131/131 [==============================] - 6s 49ms/step - loss: 0.6089 - accuracy: 0.1911 - precision_m: 0.5406 - recall_m: 0.1792 - f1_m: 0.2565 - val_loss: 0.5659 - val_accuracy: 0.2822 - val_precision_m: 0.5127 - val_recall_m: 0.3279 - val_f1_m: 0.3987\n","Epoch 7/50\n","131/131 [==============================] - 6s 48ms/step - loss: 0.6063 - accuracy: 0.1867 - precision_m: 0.5151 - recall_m: 0.2198 - f1_m: 0.3040 - val_loss: 0.5536 - val_accuracy: 0.2822 - val_precision_m: 0.5127 - val_recall_m: 0.3279 - val_f1_m: 0.3987\n","Epoch 8/50\n","131/131 [==============================] - 6s 48ms/step - loss: 0.6094 - accuracy: 0.1854 - precision_m: 0.5076 - recall_m: 0.1661 - f1_m: 0.2405 - val_loss: 0.5599 - val_accuracy: 0.2822 - val_precision_m: 0.5127 - val_recall_m: 0.3279 - val_f1_m: 0.3987\n","Epoch 9/50\n","131/131 [==============================] - 6s 48ms/step - loss: 0.6045 - accuracy: 0.1911 - precision_m: 0.5262 - recall_m: 0.2050 - f1_m: 0.2905 - val_loss: 0.5569 - val_accuracy: 0.2822 - val_precision_m: 0.5127 - val_recall_m: 0.3279 - val_f1_m: 0.3987\n","Epoch 10/50\n","131/131 [==============================] - 6s 48ms/step - loss: 0.6026 - accuracy: 0.1820 - precision_m: 0.5143 - recall_m: 0.1941 - f1_m: 0.2760 - val_loss: 0.5563 - val_accuracy: 0.2822 - val_precision_m: 0.5127 - val_recall_m: 0.3279 - val_f1_m: 0.3987\n","Epoch 11/50\n","131/131 [==============================] - 6s 48ms/step - loss: 0.6084 - accuracy: 0.1758 - precision_m: 0.4971 - recall_m: 0.1393 - f1_m: 0.2126 - val_loss: 0.5629 - val_accuracy: 0.2822 - val_precision_m: 0.5127 - val_recall_m: 0.3279 - val_f1_m: 0.3987\n","Epoch 00011: early stopping\n","Score for fold 3: loss of 0.540004312992096; accuracy of 31.068703532218933% ;precision_m of 0.5502504706382751 ;recall_m of 0.36772269010543823 ;            f1_m of 0.43958553671836853\n","Epoch 1/50\n","131/131 [==============================] - 9s 50ms/step - loss: 0.5758 - accuracy: 0.2609 - precision_m: 0.4475 - recall_m: 0.1663 - f1_m: 0.2303 - val_loss: 0.4989 - val_accuracy: 0.3273 - val_precision_m: 0.5824 - val_recall_m: 0.3934 - val_f1_m: 0.4681\n","Epoch 2/50\n","131/131 [==============================] - 6s 43ms/step - loss: 0.5513 - accuracy: 0.2643 - precision_m: 0.5183 - recall_m: 0.1873 - f1_m: 0.2586 - val_loss: 0.4980 - val_accuracy: 0.3273 - val_precision_m: 0.5824 - val_recall_m: 0.3934 - val_f1_m: 0.4681\n","Epoch 3/50\n","131/131 [==============================] - 6s 44ms/step - loss: 0.5487 - accuracy: 0.2646 - precision_m: 0.5138 - recall_m: 0.2143 - f1_m: 0.2929 - val_loss: 0.5068 - val_accuracy: 0.3273 - val_precision_m: 0.5824 - val_recall_m: 0.3934 - val_f1_m: 0.4681\n","Epoch 4/50\n","131/131 [==============================] - 6s 44ms/step - loss: 0.5493 - accuracy: 0.2686 - precision_m: 0.5260 - recall_m: 0.2014 - f1_m: 0.2787 - val_loss: 0.5007 - val_accuracy: 0.3273 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00 - val_f1_m: 0.0000e+00\n","Epoch 5/50\n","131/131 [==============================] - 6s 44ms/step - loss: 0.5506 - accuracy: 0.2601 - precision_m: 0.5289 - recall_m: 0.2267 - f1_m: 0.3063 - val_loss: 0.5021 - val_accuracy: 0.3273 - val_precision_m: 0.5824 - val_recall_m: 0.3934 - val_f1_m: 0.4681\n","Epoch 6/50\n","131/131 [==============================] - 6s 44ms/step - loss: 0.5486 - accuracy: 0.2549 - precision_m: 0.5148 - recall_m: 0.2158 - f1_m: 0.3006 - val_loss: 0.4976 - val_accuracy: 0.3273 - val_precision_m: 0.5824 - val_recall_m: 0.3934 - val_f1_m: 0.4681\n","Epoch 7/50\n","131/131 [==============================] - 6s 44ms/step - loss: 0.5486 - accuracy: 0.2693 - precision_m: 0.5199 - recall_m: 0.2565 - f1_m: 0.3379 - val_loss: 0.5003 - val_accuracy: 0.3273 - val_precision_m: 0.5824 - val_recall_m: 0.3934 - val_f1_m: 0.4681\n","Epoch 8/50\n","131/131 [==============================] - 6s 43ms/step - loss: 0.5481 - accuracy: 0.2641 - precision_m: 0.5066 - recall_m: 0.1867 - f1_m: 0.2649 - val_loss: 0.5047 - val_accuracy: 0.3273 - val_precision_m: 0.5824 - val_recall_m: 0.3934 - val_f1_m: 0.4681\n","Epoch 9/50\n","131/131 [==============================] - 6s 44ms/step - loss: 0.5472 - accuracy: 0.2625 - precision_m: 0.4934 - recall_m: 0.2012 - f1_m: 0.2781 - val_loss: 0.4979 - val_accuracy: 0.3273 - val_precision_m: 0.5824 - val_recall_m: 0.3934 - val_f1_m: 0.4681\n","Epoch 10/50\n","131/131 [==============================] - 6s 44ms/step - loss: 0.5421 - accuracy: 0.2825 - precision_m: 0.5267 - recall_m: 0.2905 - f1_m: 0.3680 - val_loss: 0.5028 - val_accuracy: 0.3273 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00 - val_f1_m: 0.0000e+00\n","Epoch 11/50\n","131/131 [==============================] - 6s 43ms/step - loss: 0.5455 - accuracy: 0.2759 - precision_m: 0.5267 - recall_m: 0.2096 - f1_m: 0.2875 - val_loss: 0.5043 - val_accuracy: 0.3273 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00 - val_f1_m: 0.0000e+00\n","Epoch 00011: early stopping\n","Score for fold 1: loss of 0.6501014232635498; accuracy of 15.566577017307281% ;precision_m of 0.0 ;recall_m of 0.0 ;            f1_m of 0.0\n","Epoch 1/50\n","131/131 [==============================] - 9s 50ms/step - loss: 0.6202 - accuracy: 0.2020 - precision_m: 0.4938 - recall_m: 0.1642 - f1_m: 0.2316 - val_loss: 0.5207 - val_accuracy: 0.3279 - val_precision_m: 0.5827 - val_recall_m: 0.3938 - val_f1_m: 0.4685\n","Epoch 2/50\n","131/131 [==============================] - 6s 43ms/step - loss: 0.5900 - accuracy: 0.2143 - precision_m: 0.5207 - recall_m: 0.1770 - f1_m: 0.2553 - val_loss: 0.5341 - val_accuracy: 0.3279 - val_precision_m: 0.5827 - val_recall_m: 0.3938 - val_f1_m: 0.4685\n","Epoch 3/50\n","131/131 [==============================] - 6s 44ms/step - loss: 0.6129 - accuracy: 0.1918 - precision_m: 0.5050 - recall_m: 0.1707 - f1_m: 0.2439 - val_loss: 0.5310 - val_accuracy: 0.3279 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00 - val_f1_m: 0.0000e+00\n","Epoch 4/50\n","131/131 [==============================] - 6s 43ms/step - loss: 0.5952 - accuracy: 0.2086 - precision_m: 0.5414 - recall_m: 0.1787 - f1_m: 0.2575 - val_loss: 0.5122 - val_accuracy: 0.3279 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00 - val_f1_m: 0.0000e+00\n","Epoch 5/50\n","131/131 [==============================] - 6s 44ms/step - loss: 0.5960 - accuracy: 0.2013 - precision_m: 0.5201 - recall_m: 0.1782 - f1_m: 0.2593 - val_loss: 0.5144 - val_accuracy: 0.3279 - val_precision_m: 0.5827 - val_recall_m: 0.3938 - val_f1_m: 0.4685\n","Epoch 6/50\n","131/131 [==============================] - 6s 44ms/step - loss: 0.5932 - accuracy: 0.2002 - precision_m: 0.5177 - recall_m: 0.2298 - f1_m: 0.3135 - val_loss: 0.5183 - val_accuracy: 0.3279 - val_precision_m: 0.5827 - val_recall_m: 0.3938 - val_f1_m: 0.4685\n","Epoch 7/50\n","131/131 [==============================] - 6s 45ms/step - loss: 0.5895 - accuracy: 0.2125 - precision_m: 0.5326 - recall_m: 0.2197 - f1_m: 0.3049 - val_loss: 0.5252 - val_accuracy: 0.3279 - val_precision_m: 0.5827 - val_recall_m: 0.3938 - val_f1_m: 0.4685\n","Epoch 8/50\n","131/131 [==============================] - 6s 44ms/step - loss: 0.5903 - accuracy: 0.2150 - precision_m: 0.5424 - recall_m: 0.2337 - f1_m: 0.3217 - val_loss: 0.5162 - val_accuracy: 0.3279 - val_precision_m: 0.5827 - val_recall_m: 0.3938 - val_f1_m: 0.4685\n","Epoch 9/50\n","131/131 [==============================] - 6s 44ms/step - loss: 0.5885 - accuracy: 0.2144 - precision_m: 0.5297 - recall_m: 0.2197 - f1_m: 0.3066 - val_loss: 0.5240 - val_accuracy: 0.3279 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00 - val_f1_m: 0.0000e+00\n","Epoch 10/50\n","131/131 [==============================] - 6s 43ms/step - loss: 0.5944 - accuracy: 0.1999 - precision_m: 0.5316 - recall_m: 0.1865 - f1_m: 0.2661 - val_loss: 0.5171 - val_accuracy: 0.3279 - val_precision_m: 0.5827 - val_recall_m: 0.3938 - val_f1_m: 0.4685\n","Epoch 11/50\n","131/131 [==============================] - 6s 44ms/step - loss: 0.5936 - accuracy: 0.2052 - precision_m: 0.5231 - recall_m: 0.2397 - f1_m: 0.3260 - val_loss: 0.5147 - val_accuracy: 0.3279 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00 - val_f1_m: 0.0000e+00\n","Epoch 00011: early stopping\n","Score for fold 2: loss of 0.5651798844337463; accuracy of 25.076335668563843% ;precision_m of 0.0 ;recall_m of 0.0 ;            f1_m of 0.0\n","Epoch 1/50\n","131/131 [==============================] - 9s 50ms/step - loss: 0.6299 - accuracy: 0.2006 - precision_m: 0.4652 - recall_m: 0.1568 - f1_m: 0.2220 - val_loss: 0.5604 - val_accuracy: 0.2822 - val_precision_m: 0.5127 - val_recall_m: 0.3279 - val_f1_m: 0.3987\n","Epoch 2/50\n","131/131 [==============================] - 6s 44ms/step - loss: 0.6088 - accuracy: 0.1768 - precision_m: 0.5166 - recall_m: 0.1722 - f1_m: 0.2495 - val_loss: 0.5724 - val_accuracy: 0.2822 - val_precision_m: 0.5127 - val_recall_m: 0.3279 - val_f1_m: 0.3987\n","Epoch 3/50\n","131/131 [==============================] - 6s 43ms/step - loss: 0.6099 - accuracy: 0.1799 - precision_m: 0.5086 - recall_m: 0.1716 - f1_m: 0.2504 - val_loss: 0.5548 - val_accuracy: 0.2822 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00 - val_f1_m: 0.0000e+00\n","Epoch 4/50\n","131/131 [==============================] - 6s 44ms/step - loss: 0.6067 - accuracy: 0.1873 - precision_m: 0.5303 - recall_m: 0.1929 - f1_m: 0.2742 - val_loss: 0.5659 - val_accuracy: 0.2822 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00 - val_f1_m: 0.0000e+00\n","Epoch 5/50\n","131/131 [==============================] - 6s 44ms/step - loss: 0.6258 - accuracy: 0.1837 - precision_m: 0.4890 - recall_m: 0.1639 - f1_m: 0.2347 - val_loss: 0.5641 - val_accuracy: 0.2822 - val_precision_m: 0.5127 - val_recall_m: 0.3279 - val_f1_m: 0.3987\n","Epoch 6/50\n","131/131 [==============================] - 6s 44ms/step - loss: 0.6042 - accuracy: 0.1954 - precision_m: 0.5008 - recall_m: 0.1764 - f1_m: 0.2532 - val_loss: 0.5598 - val_accuracy: 0.2822 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00 - val_f1_m: 0.0000e+00\n","Epoch 7/50\n","131/131 [==============================] - 6s 43ms/step - loss: 0.6021 - accuracy: 0.1956 - precision_m: 0.5290 - recall_m: 0.2188 - f1_m: 0.3062 - val_loss: 0.5612 - val_accuracy: 0.2822 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00 - val_f1_m: 0.0000e+00\n","Epoch 8/50\n","131/131 [==============================] - 6s 44ms/step - loss: 0.6063 - accuracy: 0.1835 - precision_m: 0.4846 - recall_m: 0.1217 - f1_m: 0.1842 - val_loss: 0.5581 - val_accuracy: 0.2822 - val_precision_m: 0.5127 - val_recall_m: 0.3279 - val_f1_m: 0.3987\n","Epoch 9/50\n","131/131 [==============================] - 6s 44ms/step - loss: 0.6025 - accuracy: 0.1874 - precision_m: 0.4991 - recall_m: 0.1933 - f1_m: 0.2709 - val_loss: 0.5633 - val_accuracy: 0.2822 - val_precision_m: 0.5127 - val_recall_m: 0.3279 - val_f1_m: 0.3987\n","Epoch 10/50\n","131/131 [==============================] - 6s 43ms/step - loss: 0.6031 - accuracy: 0.1914 - precision_m: 0.5073 - recall_m: 0.2252 - f1_m: 0.3083 - val_loss: 0.5595 - val_accuracy: 0.2822 - val_precision_m: 0.5127 - val_recall_m: 0.3279 - val_f1_m: 0.3987\n","Epoch 11/50\n","131/131 [==============================] - 6s 44ms/step - loss: 0.6102 - accuracy: 0.1852 - precision_m: 0.4950 - recall_m: 0.1419 - f1_m: 0.2122 - val_loss: 0.5632 - val_accuracy: 0.2822 - val_precision_m: 0.5127 - val_recall_m: 0.3279 - val_f1_m: 0.3987\n","Epoch 00011: early stopping\n","Score for fold 3: loss of 0.5409813523292542; accuracy of 31.068703532218933% ;precision_m of 0.5502504706382751 ;recall_m of 0.36772269010543823 ;            f1_m of 0.43958553671836853\n","Epoch 1/50\n","131/131 [==============================] - 10s 57ms/step - loss: 0.5957 - accuracy: 0.2539 - precision_m: 0.4558 - recall_m: 0.1802 - f1_m: 0.2476 - val_loss: 0.5010 - val_accuracy: 0.3273 - val_precision_m: 0.5824 - val_recall_m: 0.3934 - val_f1_m: 0.4681\n","Epoch 2/50\n","131/131 [==============================] - 6s 46ms/step - loss: 0.5441 - accuracy: 0.2764 - precision_m: 0.5305 - recall_m: 0.2341 - f1_m: 0.3185 - val_loss: 0.5009 - val_accuracy: 0.3273 - val_precision_m: 0.5824 - val_recall_m: 0.3934 - val_f1_m: 0.4681\n","Epoch 3/50\n","131/131 [==============================] - 6s 45ms/step - loss: 0.5495 - accuracy: 0.2736 - precision_m: 0.5259 - recall_m: 0.1835 - f1_m: 0.2645 - val_loss: 0.4984 - val_accuracy: 0.3273 - val_precision_m: 0.5824 - val_recall_m: 0.3934 - val_f1_m: 0.4681\n","Epoch 4/50\n","131/131 [==============================] - 6s 46ms/step - loss: 0.5476 - accuracy: 0.2758 - precision_m: 0.5097 - recall_m: 0.2044 - f1_m: 0.2848 - val_loss: 0.5006 - val_accuracy: 0.3273 - val_precision_m: 0.5824 - val_recall_m: 0.3934 - val_f1_m: 0.4681\n","Epoch 5/50\n","131/131 [==============================] - 6s 46ms/step - loss: 0.5488 - accuracy: 0.2611 - precision_m: 0.5166 - recall_m: 0.2144 - f1_m: 0.2966 - val_loss: 0.4978 - val_accuracy: 0.3273 - val_precision_m: 0.5824 - val_recall_m: 0.3934 - val_f1_m: 0.4681\n","Epoch 6/50\n","131/131 [==============================] - 6s 46ms/step - loss: 0.5477 - accuracy: 0.2711 - precision_m: 0.5349 - recall_m: 0.2592 - f1_m: 0.3358 - val_loss: 0.5026 - val_accuracy: 0.3273 - val_precision_m: 0.5824 - val_recall_m: 0.3934 - val_f1_m: 0.4681\n","Epoch 7/50\n","131/131 [==============================] - 6s 46ms/step - loss: 0.5436 - accuracy: 0.2789 - precision_m: 0.5368 - recall_m: 0.2656 - f1_m: 0.3502 - val_loss: 0.5034 - val_accuracy: 0.3273 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00 - val_f1_m: 0.0000e+00\n","Epoch 8/50\n","131/131 [==============================] - 6s 46ms/step - loss: 0.5472 - accuracy: 0.2623 - precision_m: 0.5245 - recall_m: 0.1543 - f1_m: 0.2246 - val_loss: 0.5010 - val_accuracy: 0.3273 - val_precision_m: 0.5824 - val_recall_m: 0.3934 - val_f1_m: 0.4681\n","Epoch 9/50\n","131/131 [==============================] - 6s 46ms/step - loss: 0.5454 - accuracy: 0.2660 - precision_m: 0.5305 - recall_m: 0.2647 - f1_m: 0.3503 - val_loss: 0.5006 - val_accuracy: 0.3273 - val_precision_m: 0.5824 - val_recall_m: 0.3934 - val_f1_m: 0.4681\n","Epoch 10/50\n","131/131 [==============================] - 6s 46ms/step - loss: 0.5471 - accuracy: 0.2671 - precision_m: 0.4967 - recall_m: 0.2239 - f1_m: 0.3043 - val_loss: 0.4998 - val_accuracy: 0.3273 - val_precision_m: 0.5824 - val_recall_m: 0.3934 - val_f1_m: 0.4681\n","Epoch 11/50\n","131/131 [==============================] - 6s 45ms/step - loss: 0.5424 - accuracy: 0.2757 - precision_m: 0.5337 - recall_m: 0.2673 - f1_m: 0.3506 - val_loss: 0.4996 - val_accuracy: 0.3273 - val_precision_m: 0.5824 - val_recall_m: 0.3934 - val_f1_m: 0.4681\n","Epoch 00011: early stopping\n","Score for fold 1: loss of 0.6501389145851135; accuracy of 15.566577017307281% ;precision_m of 0.5127865076065063 ;recall_m of 0.2593536674976349 ;            f1_m of 0.34322670102119446\n","Epoch 1/50\n","131/131 [==============================] - 9s 52ms/step - loss: 0.6192 - accuracy: 0.2269 - precision_m: 0.5077 - recall_m: 0.1765 - f1_m: 0.2479 - val_loss: 0.5452 - val_accuracy: 0.3279 - val_precision_m: 0.5827 - val_recall_m: 0.3938 - val_f1_m: 0.4685\n","Epoch 2/50\n","131/131 [==============================] - 6s 46ms/step - loss: 0.5966 - accuracy: 0.2115 - precision_m: 0.5181 - recall_m: 0.1592 - f1_m: 0.2320 - val_loss: 0.5262 - val_accuracy: 0.3279 - val_precision_m: 0.5827 - val_recall_m: 0.3938 - val_f1_m: 0.4685\n","Epoch 3/50\n","131/131 [==============================] - 6s 46ms/step - loss: 0.5905 - accuracy: 0.2117 - precision_m: 0.5174 - recall_m: 0.2146 - f1_m: 0.2970 - val_loss: 0.5258 - val_accuracy: 0.3279 - val_precision_m: 0.5827 - val_recall_m: 0.3938 - val_f1_m: 0.4685\n","Epoch 4/50\n","131/131 [==============================] - 6s 46ms/step - loss: 0.5894 - accuracy: 0.2160 - precision_m: 0.5077 - recall_m: 0.1990 - f1_m: 0.2800 - val_loss: 0.5102 - val_accuracy: 0.3279 - val_precision_m: 0.5827 - val_recall_m: 0.3938 - val_f1_m: 0.4685\n","Epoch 5/50\n","131/131 [==============================] - 6s 46ms/step - loss: 0.5932 - accuracy: 0.2080 - precision_m: 0.5168 - recall_m: 0.2070 - f1_m: 0.2859 - val_loss: 0.5339 - val_accuracy: 0.3279 - val_precision_m: 0.5827 - val_recall_m: 0.3938 - val_f1_m: 0.4685\n","Epoch 6/50\n","131/131 [==============================] - 6s 46ms/step - loss: 0.5979 - accuracy: 0.2050 - precision_m: 0.5116 - recall_m: 0.1964 - f1_m: 0.2801 - val_loss: 0.5202 - val_accuracy: 0.3279 - val_precision_m: 0.5827 - val_recall_m: 0.3938 - val_f1_m: 0.4685\n","Epoch 7/50\n","131/131 [==============================] - 6s 46ms/step - loss: 0.5894 - accuracy: 0.2174 - precision_m: 0.5118 - recall_m: 0.2162 - f1_m: 0.2957 - val_loss: 0.5247 - val_accuracy: 0.3279 - val_precision_m: 0.5827 - val_recall_m: 0.3938 - val_f1_m: 0.4685\n","Epoch 8/50\n","131/131 [==============================] - 6s 46ms/step - loss: 0.5892 - accuracy: 0.2152 - precision_m: 0.5043 - recall_m: 0.2151 - f1_m: 0.2980 - val_loss: 0.5188 - val_accuracy: 0.3279 - val_precision_m: 0.5827 - val_recall_m: 0.3938 - val_f1_m: 0.4685\n","Epoch 9/50\n","131/131 [==============================] - 6s 47ms/step - loss: 0.6992 - accuracy: 0.2027 - precision_m: 0.4993 - recall_m: 0.2525 - f1_m: 0.3196 - val_loss: 0.5282 - val_accuracy: 0.3279 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00 - val_f1_m: 0.0000e+00\n","Epoch 10/50\n","131/131 [==============================] - 6s 46ms/step - loss: 0.6008 - accuracy: 0.1975 - precision_m: 0.4886 - recall_m: 0.1522 - f1_m: 0.2229 - val_loss: 0.5195 - val_accuracy: 0.3279 - val_precision_m: 0.5827 - val_recall_m: 0.3938 - val_f1_m: 0.4685\n","Epoch 11/50\n","131/131 [==============================] - 6s 46ms/step - loss: 0.5951 - accuracy: 0.2101 - precision_m: 0.5164 - recall_m: 0.1892 - f1_m: 0.2727 - val_loss: 0.5240 - val_accuracy: 0.3279 - val_precision_m: 0.5827 - val_recall_m: 0.3938 - val_f1_m: 0.4685\n","Epoch 00011: early stopping\n","Score for fold 2: loss of 0.5684610605239868; accuracy of 25.076335668563843% ;precision_m of 0.5106163024902344 ;recall_m of 0.3112577795982361 ;            f1_m of 0.3850182890892029\n","Epoch 1/50\n","131/131 [==============================] - 9s 52ms/step - loss: 0.6381 - accuracy: 0.2054 - precision_m: 0.4915 - recall_m: 0.1226 - f1_m: 0.1750 - val_loss: 0.5614 - val_accuracy: 0.2822 - val_precision_m: 0.5127 - val_recall_m: 0.3279 - val_f1_m: 0.3987\n","Epoch 2/50\n","131/131 [==============================] - 6s 46ms/step - loss: 0.6138 - accuracy: 0.1785 - precision_m: 0.4332 - recall_m: 0.1626 - f1_m: 0.2281 - val_loss: 0.5660 - val_accuracy: 0.2822 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00 - val_f1_m: 0.0000e+00\n","Epoch 3/50\n","131/131 [==============================] - 6s 47ms/step - loss: 0.6069 - accuracy: 0.1852 - precision_m: 0.5184 - recall_m: 0.1691 - f1_m: 0.2437 - val_loss: 0.5564 - val_accuracy: 0.2822 - val_precision_m: 0.5127 - val_recall_m: 0.3279 - val_f1_m: 0.3987\n","Epoch 4/50\n","131/131 [==============================] - 6s 46ms/step - loss: 0.6145 - accuracy: 0.1836 - precision_m: 0.5026 - recall_m: 0.1490 - f1_m: 0.2238 - val_loss: 0.5694 - val_accuracy: 0.2822 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00 - val_f1_m: 0.0000e+00\n","Epoch 5/50\n","131/131 [==============================] - 6s 46ms/step - loss: 0.6065 - accuracy: 0.1979 - precision_m: 0.5129 - recall_m: 0.1698 - f1_m: 0.2493 - val_loss: 0.5598 - val_accuracy: 0.2822 - val_precision_m: 0.5127 - val_recall_m: 0.3279 - val_f1_m: 0.3987\n","Epoch 6/50\n","131/131 [==============================] - 6s 46ms/step - loss: 0.6058 - accuracy: 0.1776 - precision_m: 0.5052 - recall_m: 0.1804 - f1_m: 0.2560 - val_loss: 0.5640 - val_accuracy: 0.2822 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00 - val_f1_m: 0.0000e+00\n","Epoch 7/50\n","131/131 [==============================] - 6s 46ms/step - loss: 0.6065 - accuracy: 0.1805 - precision_m: 0.4997 - recall_m: 0.1157 - f1_m: 0.1760 - val_loss: 0.5617 - val_accuracy: 0.2822 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00 - val_f1_m: 0.0000e+00\n","Epoch 8/50\n","131/131 [==============================] - 6s 46ms/step - loss: 0.6066 - accuracy: 0.1820 - precision_m: 0.4756 - recall_m: 0.1462 - f1_m: 0.2142 - val_loss: 0.5574 - val_accuracy: 0.2822 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00 - val_f1_m: 0.0000e+00\n","Epoch 9/50\n","131/131 [==============================] - 6s 46ms/step - loss: 0.6055 - accuracy: 0.1865 - precision_m: 0.4380 - recall_m: 0.1402 - f1_m: 0.1998 - val_loss: 0.5561 - val_accuracy: 0.2822 - val_precision_m: 0.5127 - val_recall_m: 0.3279 - val_f1_m: 0.3987\n","Epoch 10/50\n","131/131 [==============================] - 6s 46ms/step - loss: 0.6039 - accuracy: 0.1884 - precision_m: 0.5377 - recall_m: 0.2387 - f1_m: 0.3243 - val_loss: 0.5649 - val_accuracy: 0.2822 - val_precision_m: 0.5127 - val_recall_m: 0.3279 - val_f1_m: 0.3987\n","Epoch 11/50\n","131/131 [==============================] - 6s 46ms/step - loss: 0.6117 - accuracy: 0.1763 - precision_m: 0.5074 - recall_m: 0.1296 - f1_m: 0.1994 - val_loss: 0.5621 - val_accuracy: 0.2822 - val_precision_m: 0.5127 - val_recall_m: 0.3279 - val_f1_m: 0.3987\n","Epoch 00011: early stopping\n","Score for fold 3: loss of 0.5391688942909241; accuracy of 31.068703532218933% ;precision_m of 0.5502504706382751 ;recall_m of 0.36772269010543823 ;            f1_m of 0.43958553671836853\n","Epoch 1/50\n","131/131 [==============================] - 10s 54ms/step - loss: 0.5945 - accuracy: 0.2511 - precision_m: 0.4828 - recall_m: 0.2172 - f1_m: 0.2818 - val_loss: 0.4979 - val_accuracy: 0.3273 - val_precision_m: 0.5824 - val_recall_m: 0.3934 - val_f1_m: 0.4681\n","Epoch 2/50\n","131/131 [==============================] - 6s 49ms/step - loss: 0.5466 - accuracy: 0.2721 - precision_m: 0.5327 - recall_m: 0.2287 - f1_m: 0.3125 - val_loss: 0.4961 - val_accuracy: 0.3273 - val_precision_m: 0.5824 - val_recall_m: 0.3934 - val_f1_m: 0.4681\n","Epoch 3/50\n","131/131 [==============================] - 6s 49ms/step - loss: 0.5457 - accuracy: 0.2714 - precision_m: 0.5173 - recall_m: 0.2230 - f1_m: 0.2975 - val_loss: 0.5052 - val_accuracy: 0.3273 - val_precision_m: 0.5824 - val_recall_m: 0.3934 - val_f1_m: 0.4681\n","Epoch 4/50\n","131/131 [==============================] - 6s 49ms/step - loss: 0.5456 - accuracy: 0.2701 - precision_m: 0.5008 - recall_m: 0.2127 - f1_m: 0.2936 - val_loss: 0.5052 - val_accuracy: 0.3273 - val_precision_m: 0.5824 - val_recall_m: 0.3934 - val_f1_m: 0.4681\n","Epoch 5/50\n","131/131 [==============================] - 6s 48ms/step - loss: 0.5449 - accuracy: 0.2774 - precision_m: 0.5166 - recall_m: 0.2335 - f1_m: 0.3076 - val_loss: 0.4984 - val_accuracy: 0.3273 - val_precision_m: 0.5824 - val_recall_m: 0.3934 - val_f1_m: 0.4681\n","Epoch 6/50\n","131/131 [==============================] - 6s 48ms/step - loss: 0.5486 - accuracy: 0.2656 - precision_m: 0.5069 - recall_m: 0.2345 - f1_m: 0.3088 - val_loss: 0.4972 - val_accuracy: 0.3273 - val_precision_m: 0.5824 - val_recall_m: 0.3934 - val_f1_m: 0.4681\n","Epoch 7/50\n","131/131 [==============================] - 6s 49ms/step - loss: 0.5444 - accuracy: 0.2732 - precision_m: 0.5273 - recall_m: 0.2641 - f1_m: 0.3464 - val_loss: 0.5057 - val_accuracy: 0.3273 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00 - val_f1_m: 0.0000e+00\n","Epoch 8/50\n","131/131 [==============================] - 6s 48ms/step - loss: 0.5469 - accuracy: 0.2700 - precision_m: 0.5085 - recall_m: 0.1823 - f1_m: 0.2599 - val_loss: 0.4973 - val_accuracy: 0.3273 - val_precision_m: 0.5824 - val_recall_m: 0.3934 - val_f1_m: 0.4681\n","Epoch 9/50\n","131/131 [==============================] - 6s 48ms/step - loss: 0.5471 - accuracy: 0.2627 - precision_m: 0.5135 - recall_m: 0.2493 - f1_m: 0.3248 - val_loss: 0.4978 - val_accuracy: 0.3273 - val_precision_m: 0.5824 - val_recall_m: 0.3934 - val_f1_m: 0.4681\n","Epoch 10/50\n","131/131 [==============================] - 6s 49ms/step - loss: 0.5441 - accuracy: 0.2731 - precision_m: 0.5210 - recall_m: 0.2773 - f1_m: 0.3581 - val_loss: 0.4981 - val_accuracy: 0.3273 - val_precision_m: 0.5824 - val_recall_m: 0.3934 - val_f1_m: 0.4681\n","Epoch 11/50\n","131/131 [==============================] - 6s 48ms/step - loss: 0.5458 - accuracy: 0.2729 - precision_m: 0.5191 - recall_m: 0.2672 - f1_m: 0.3493 - val_loss: 0.5014 - val_accuracy: 0.3273 - val_precision_m: 0.5824 - val_recall_m: 0.3934 - val_f1_m: 0.4681\n","Epoch 00011: early stopping\n","Score for fold 1: loss of 0.6491080522537231; accuracy of 15.566577017307281% ;precision_m of 0.5129217505455017 ;recall_m of 0.2593536674976349 ;            f1_m of 0.3432560861110687\n","Epoch 1/50\n","131/131 [==============================] - 9s 54ms/step - loss: 0.6323 - accuracy: 0.1981 - precision_m: 0.4451 - recall_m: 0.1695 - f1_m: 0.2229 - val_loss: 0.5072 - val_accuracy: 0.3279 - val_precision_m: 0.5827 - val_recall_m: 0.3938 - val_f1_m: 0.4685\n","Epoch 2/50\n","131/131 [==============================] - 6s 49ms/step - loss: 0.5999 - accuracy: 0.1949 - precision_m: 0.4911 - recall_m: 0.1463 - f1_m: 0.2137 - val_loss: 0.5170 - val_accuracy: 0.3279 - val_precision_m: 0.5827 - val_recall_m: 0.3938 - val_f1_m: 0.4685\n","Epoch 3/50\n","131/131 [==============================] - 6s 48ms/step - loss: 0.5900 - accuracy: 0.2122 - precision_m: 0.5374 - recall_m: 0.2277 - f1_m: 0.3156 - val_loss: 0.5207 - val_accuracy: 0.3279 - val_precision_m: 0.5827 - val_recall_m: 0.3938 - val_f1_m: 0.4685\n","Epoch 4/50\n","131/131 [==============================] - 6s 49ms/step - loss: 0.5886 - accuracy: 0.2229 - precision_m: 0.5196 - recall_m: 0.2275 - f1_m: 0.3109 - val_loss: 0.5161 - val_accuracy: 0.3279 - val_precision_m: 0.5827 - val_recall_m: 0.3938 - val_f1_m: 0.4685\n","Epoch 5/50\n","131/131 [==============================] - 6s 48ms/step - loss: 0.5925 - accuracy: 0.2096 - precision_m: 0.5108 - recall_m: 0.2224 - f1_m: 0.3070 - val_loss: 0.5164 - val_accuracy: 0.3279 - val_precision_m: 0.5827 - val_recall_m: 0.3938 - val_f1_m: 0.4685\n","Epoch 6/50\n","131/131 [==============================] - 6s 49ms/step - loss: 0.5915 - accuracy: 0.2174 - precision_m: 0.5044 - recall_m: 0.1997 - f1_m: 0.2753 - val_loss: 0.5108 - val_accuracy: 0.3279 - val_precision_m: 0.5827 - val_recall_m: 0.3938 - val_f1_m: 0.4685\n","Epoch 7/50\n","131/131 [==============================] - 6s 49ms/step - loss: 0.5885 - accuracy: 0.2236 - precision_m: 0.5249 - recall_m: 0.2527 - f1_m: 0.3371 - val_loss: 0.5221 - val_accuracy: 0.3279 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00 - val_f1_m: 0.0000e+00\n","Epoch 8/50\n","131/131 [==============================] - 6s 49ms/step - loss: 0.5916 - accuracy: 0.2122 - precision_m: 0.4944 - recall_m: 0.1794 - f1_m: 0.2577 - val_loss: 0.5163 - val_accuracy: 0.3279 - val_precision_m: 0.5827 - val_recall_m: 0.3938 - val_f1_m: 0.4685\n","Epoch 9/50\n","131/131 [==============================] - 6s 48ms/step - loss: 0.5920 - accuracy: 0.2102 - precision_m: 0.5152 - recall_m: 0.2269 - f1_m: 0.3061 - val_loss: 0.5198 - val_accuracy: 0.3279 - val_precision_m: 0.5827 - val_recall_m: 0.3938 - val_f1_m: 0.4685\n","Epoch 10/50\n","131/131 [==============================] - 6s 49ms/step - loss: 0.5942 - accuracy: 0.2079 - precision_m: 0.5029 - recall_m: 0.1963 - f1_m: 0.2699 - val_loss: 0.5227 - val_accuracy: 0.3279 - val_precision_m: 0.5827 - val_recall_m: 0.3938 - val_f1_m: 0.4685\n","Epoch 11/50\n","131/131 [==============================] - 6s 48ms/step - loss: 0.5900 - accuracy: 0.2067 - precision_m: 0.5231 - recall_m: 0.2438 - f1_m: 0.3275 - val_loss: 0.5203 - val_accuracy: 0.3279 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00 - val_f1_m: 0.0000e+00\n","Epoch 00011: early stopping\n","Score for fold 2: loss of 0.5661202073097229; accuracy of 25.076335668563843% ;precision_m of 0.0 ;recall_m of 0.0 ;            f1_m of 0.0\n","Epoch 1/50\n","131/131 [==============================] - 9s 54ms/step - loss: 0.6265 - accuracy: 0.1793 - precision_m: 0.4478 - recall_m: 0.1544 - f1_m: 0.2201 - val_loss: 0.5605 - val_accuracy: 0.2822 - val_precision_m: 0.5127 - val_recall_m: 0.3279 - val_f1_m: 0.3987\n","Epoch 2/50\n","131/131 [==============================] - 6s 48ms/step - loss: 0.6094 - accuracy: 0.1856 - precision_m: 0.5110 - recall_m: 0.1587 - f1_m: 0.2352 - val_loss: 0.5592 - val_accuracy: 0.2822 - val_precision_m: 0.5127 - val_recall_m: 0.3279 - val_f1_m: 0.3987\n","Epoch 3/50\n","131/131 [==============================] - 6s 48ms/step - loss: 0.6067 - accuracy: 0.1851 - precision_m: 0.4975 - recall_m: 0.1945 - f1_m: 0.2720 - val_loss: 0.5715 - val_accuracy: 0.2822 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00 - val_f1_m: 0.0000e+00\n","Epoch 4/50\n","131/131 [==============================] - 6s 49ms/step - loss: 0.6112 - accuracy: 0.1743 - precision_m: 0.4117 - recall_m: 0.1250 - f1_m: 0.1836 - val_loss: 0.5534 - val_accuracy: 0.2822 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00 - val_f1_m: 0.0000e+00\n","Epoch 5/50\n","131/131 [==============================] - 6s 48ms/step - loss: 0.6051 - accuracy: 0.1832 - precision_m: 0.4933 - recall_m: 0.1479 - f1_m: 0.2229 - val_loss: 0.5605 - val_accuracy: 0.2822 - val_precision_m: 0.5127 - val_recall_m: 0.3279 - val_f1_m: 0.3987\n","Epoch 6/50\n","131/131 [==============================] - 6s 48ms/step - loss: 0.6029 - accuracy: 0.1840 - precision_m: 0.5107 - recall_m: 0.1921 - f1_m: 0.2692 - val_loss: 0.5564 - val_accuracy: 0.2822 - val_precision_m: 0.5127 - val_recall_m: 0.3279 - val_f1_m: 0.3987\n","Epoch 7/50\n","131/131 [==============================] - 6s 49ms/step - loss: 0.6082 - accuracy: 0.1863 - precision_m: 0.5158 - recall_m: 0.2144 - f1_m: 0.2987 - val_loss: 0.5539 - val_accuracy: 0.2822 - val_precision_m: 0.5127 - val_recall_m: 0.3279 - val_f1_m: 0.3987\n","Epoch 8/50\n","131/131 [==============================] - 6s 48ms/step - loss: 0.6065 - accuracy: 0.1848 - precision_m: 0.5237 - recall_m: 0.1990 - f1_m: 0.2809 - val_loss: 0.5568 - val_accuracy: 0.2822 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00 - val_f1_m: 0.0000e+00\n","Epoch 9/50\n","131/131 [==============================] - 6s 49ms/step - loss: 0.6069 - accuracy: 0.1846 - precision_m: 0.5085 - recall_m: 0.1697 - f1_m: 0.2486 - val_loss: 0.5587 - val_accuracy: 0.2822 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00 - val_f1_m: 0.0000e+00\n","Epoch 10/50\n","131/131 [==============================] - 6s 48ms/step - loss: 0.7223 - accuracy: 0.1869 - precision_m: 0.4877 - recall_m: 0.1890 - f1_m: 0.2497 - val_loss: 0.5561 - val_accuracy: 0.2822 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00 - val_f1_m: 0.0000e+00\n","Epoch 11/50\n","131/131 [==============================] - 6s 49ms/step - loss: 0.6216 - accuracy: 0.2041 - precision_m: 0.4759 - recall_m: 0.1646 - f1_m: 0.2398 - val_loss: 0.5691 - val_accuracy: 0.2822 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00 - val_f1_m: 0.0000e+00\n","Epoch 00011: early stopping\n","Score for fold 3: loss of 0.5477655529975891; accuracy of 31.068703532218933% ;precision_m of 0.0 ;recall_m of 0.0 ;            f1_m of 0.0\n","Epoch 1/50\n","131/131 [==============================] - 6s 38ms/step - loss: 0.5869 - accuracy: 0.2468 - precision_m: 0.4905 - recall_m: 0.1773 - f1_m: 0.2459 - val_loss: 0.5013 - val_accuracy: 0.3273 - val_precision_m: 0.5824 - val_recall_m: 0.3934 - val_f1_m: 0.4681\n","Epoch 2/50\n","131/131 [==============================] - 4s 33ms/step - loss: 0.5467 - accuracy: 0.2837 - precision_m: 0.5078 - recall_m: 0.2036 - f1_m: 0.2853 - val_loss: 0.5017 - val_accuracy: 0.3273 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00 - val_f1_m: 0.0000e+00\n","Epoch 3/50\n","131/131 [==============================] - 4s 33ms/step - loss: 0.5499 - accuracy: 0.2751 - precision_m: 0.5179 - recall_m: 0.1949 - f1_m: 0.2745 - val_loss: 0.5133 - val_accuracy: 0.3273 - val_precision_m: 0.5824 - val_recall_m: 0.3934 - val_f1_m: 0.4681\n","Epoch 4/50\n","131/131 [==============================] - 4s 34ms/step - loss: 0.5501 - accuracy: 0.2718 - precision_m: 0.5205 - recall_m: 0.1988 - f1_m: 0.2826 - val_loss: 0.5034 - val_accuracy: 0.3273 - val_precision_m: 0.5824 - val_recall_m: 0.3934 - val_f1_m: 0.4681\n","Epoch 5/50\n","131/131 [==============================] - 4s 34ms/step - loss: 0.5528 - accuracy: 0.2625 - precision_m: 0.5043 - recall_m: 0.2037 - f1_m: 0.2848 - val_loss: 0.4976 - val_accuracy: 0.3273 - val_precision_m: 0.5824 - val_recall_m: 0.3934 - val_f1_m: 0.4681\n","Epoch 6/50\n","131/131 [==============================] - 4s 34ms/step - loss: 0.5426 - accuracy: 0.2812 - precision_m: 0.5190 - recall_m: 0.2733 - f1_m: 0.3565 - val_loss: 0.5038 - val_accuracy: 0.3273 - val_precision_m: 0.5824 - val_recall_m: 0.3934 - val_f1_m: 0.4681\n","Epoch 7/50\n","131/131 [==============================] - 4s 34ms/step - loss: 0.5473 - accuracy: 0.2625 - precision_m: 0.5144 - recall_m: 0.1957 - f1_m: 0.2783 - val_loss: 0.4996 - val_accuracy: 0.3273 - val_precision_m: 0.5824 - val_recall_m: 0.3934 - val_f1_m: 0.4681\n","Epoch 8/50\n","131/131 [==============================] - 4s 33ms/step - loss: 0.5459 - accuracy: 0.2723 - precision_m: 0.5141 - recall_m: 0.2540 - f1_m: 0.3376 - val_loss: 0.5059 - val_accuracy: 0.3273 - val_precision_m: 0.5824 - val_recall_m: 0.3934 - val_f1_m: 0.4681\n","Epoch 9/50\n","131/131 [==============================] - 4s 34ms/step - loss: 0.5478 - accuracy: 0.2714 - precision_m: 0.5235 - recall_m: 0.2793 - f1_m: 0.3622 - val_loss: 0.5021 - val_accuracy: 0.3273 - val_precision_m: 0.5824 - val_recall_m: 0.3934 - val_f1_m: 0.4681\n","Epoch 10/50\n","131/131 [==============================] - 4s 34ms/step - loss: 0.5526 - accuracy: 0.2513 - precision_m: 0.5015 - recall_m: 0.1624 - f1_m: 0.2350 - val_loss: 0.5013 - val_accuracy: 0.3273 - val_precision_m: 0.5824 - val_recall_m: 0.3934 - val_f1_m: 0.4681\n","Epoch 11/50\n","131/131 [==============================] - 4s 34ms/step - loss: 0.5488 - accuracy: 0.2645 - precision_m: 0.5133 - recall_m: 0.2340 - f1_m: 0.3175 - val_loss: 0.5037 - val_accuracy: 0.3273 - val_precision_m: 0.5824 - val_recall_m: 0.3934 - val_f1_m: 0.4681\n","Epoch 00011: early stopping\n","Score for fold 1: loss of 0.645530641078949; accuracy of 15.566577017307281% ;precision_m of 0.5127865076065063 ;recall_m of 0.2593536674976349 ;            f1_m of 0.34322670102119446\n","Epoch 1/50\n","131/131 [==============================] - 6s 37ms/step - loss: 0.6175 - accuracy: 0.2113 - precision_m: 0.4993 - recall_m: 0.1591 - f1_m: 0.2312 - val_loss: 0.5340 - val_accuracy: 0.3279 - val_precision_m: 0.5827 - val_recall_m: 0.3938 - val_f1_m: 0.4685\n","Epoch 2/50\n","131/131 [==============================] - 4s 34ms/step - loss: 0.5931 - accuracy: 0.2130 - precision_m: 0.5083 - recall_m: 0.1686 - f1_m: 0.2487 - val_loss: 0.5473 - val_accuracy: 0.3279 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00 - val_f1_m: 0.0000e+00\n","Epoch 3/50\n","131/131 [==============================] - 4s 33ms/step - loss: 0.5943 - accuracy: 0.2110 - precision_m: 0.5100 - recall_m: 0.1715 - f1_m: 0.2513 - val_loss: 0.5189 - val_accuracy: 0.3279 - val_precision_m: 0.5827 - val_recall_m: 0.3938 - val_f1_m: 0.4685\n","Epoch 4/50\n","131/131 [==============================] - 4s 34ms/step - loss: 0.5962 - accuracy: 0.2064 - precision_m: 0.5230 - recall_m: 0.1893 - f1_m: 0.2748 - val_loss: 0.5222 - val_accuracy: 0.3279 - val_precision_m: 0.5827 - val_recall_m: 0.3938 - val_f1_m: 0.4685\n","Epoch 5/50\n","131/131 [==============================] - 4s 34ms/step - loss: 0.5921 - accuracy: 0.2065 - precision_m: 0.5068 - recall_m: 0.1898 - f1_m: 0.2731 - val_loss: 0.5186 - val_accuracy: 0.3279 - val_precision_m: 0.5827 - val_recall_m: 0.3938 - val_f1_m: 0.4685\n","Epoch 6/50\n","131/131 [==============================] - 4s 34ms/step - loss: 0.5926 - accuracy: 0.2093 - precision_m: 0.5247 - recall_m: 0.2360 - f1_m: 0.3237 - val_loss: 0.5229 - val_accuracy: 0.3279 - val_precision_m: 0.5827 - val_recall_m: 0.3938 - val_f1_m: 0.4685\n","Epoch 7/50\n","131/131 [==============================] - 4s 34ms/step - loss: 0.5932 - accuracy: 0.2057 - precision_m: 0.5184 - recall_m: 0.2193 - f1_m: 0.3048 - val_loss: 0.5183 - val_accuracy: 0.3279 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00 - val_f1_m: 0.0000e+00\n","Epoch 8/50\n","131/131 [==============================] - 4s 34ms/step - loss: 0.5953 - accuracy: 0.2074 - precision_m: 0.5065 - recall_m: 0.1556 - f1_m: 0.2301 - val_loss: 0.5204 - val_accuracy: 0.3279 - val_precision_m: 0.5827 - val_recall_m: 0.3938 - val_f1_m: 0.4685\n","Epoch 9/50\n","131/131 [==============================] - 4s 34ms/step - loss: 0.5894 - accuracy: 0.2081 - precision_m: 0.5108 - recall_m: 0.2006 - f1_m: 0.2856 - val_loss: 0.5247 - val_accuracy: 0.3279 - val_precision_m: 0.5827 - val_recall_m: 0.3938 - val_f1_m: 0.4685\n","Epoch 10/50\n","131/131 [==============================] - 4s 34ms/step - loss: 0.5917 - accuracy: 0.2001 - precision_m: 0.5149 - recall_m: 0.2237 - f1_m: 0.3105 - val_loss: 0.5190 - val_accuracy: 0.3279 - val_precision_m: 0.5827 - val_recall_m: 0.3938 - val_f1_m: 0.4685\n","Epoch 11/50\n","131/131 [==============================] - 4s 33ms/step - loss: 0.5900 - accuracy: 0.2040 - precision_m: 0.5212 - recall_m: 0.2583 - f1_m: 0.3442 - val_loss: 0.5221 - val_accuracy: 0.3279 - val_precision_m: 0.5827 - val_recall_m: 0.3938 - val_f1_m: 0.4685\n","Epoch 00011: early stopping\n","Score for fold 2: loss of 0.5673094391822815; accuracy of 25.076335668563843% ;precision_m of 0.5106163024902344 ;recall_m of 0.3112577795982361 ;            f1_m of 0.3850182890892029\n","Epoch 1/50\n","131/131 [==============================] - 6s 37ms/step - loss: 0.6496 - accuracy: 0.1992 - precision_m: 0.4393 - recall_m: 0.1790 - f1_m: 0.2286 - val_loss: 0.5640 - val_accuracy: 0.2822 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00 - val_f1_m: 0.0000e+00\n","Epoch 2/50\n","131/131 [==============================] - 4s 34ms/step - loss: 0.6134 - accuracy: 0.1851 - precision_m: 0.5180 - recall_m: 0.1464 - f1_m: 0.2220 - val_loss: 0.5603 - val_accuracy: 0.2822 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00 - val_f1_m: 0.0000e+00\n","Epoch 3/50\n","131/131 [==============================] - 4s 34ms/step - loss: 0.6104 - accuracy: 0.1859 - precision_m: 0.5125 - recall_m: 0.1616 - f1_m: 0.2403 - val_loss: 0.5631 - val_accuracy: 0.2822 - val_precision_m: 0.5127 - val_recall_m: 0.3279 - val_f1_m: 0.3987\n","Epoch 4/50\n","131/131 [==============================] - 4s 34ms/step - loss: 0.6111 - accuracy: 0.1756 - precision_m: 0.4911 - recall_m: 0.1248 - f1_m: 0.1926 - val_loss: 0.5584 - val_accuracy: 0.2822 - val_precision_m: 0.5127 - val_recall_m: 0.3279 - val_f1_m: 0.3987\n","Epoch 5/50\n","131/131 [==============================] - 4s 34ms/step - loss: 0.6101 - accuracy: 0.1868 - precision_m: 0.5075 - recall_m: 0.2050 - f1_m: 0.2901 - val_loss: 0.5659 - val_accuracy: 0.2822 - val_precision_m: 0.5127 - val_recall_m: 0.3279 - val_f1_m: 0.3987\n","Epoch 6/50\n","131/131 [==============================] - 4s 34ms/step - loss: 0.6048 - accuracy: 0.1914 - precision_m: 0.4963 - recall_m: 0.1657 - f1_m: 0.2423 - val_loss: 0.5588 - val_accuracy: 0.2822 - val_precision_m: 0.5127 - val_recall_m: 0.3279 - val_f1_m: 0.3987\n","Epoch 7/50\n","131/131 [==============================] - 4s 34ms/step - loss: 0.6050 - accuracy: 0.1839 - precision_m: 0.5217 - recall_m: 0.1581 - f1_m: 0.2390 - val_loss: 0.5675 - val_accuracy: 0.2822 - val_precision_m: 0.5127 - val_recall_m: 0.3279 - val_f1_m: 0.3987\n","Epoch 8/50\n","131/131 [==============================] - 4s 34ms/step - loss: 0.6090 - accuracy: 0.1826 - precision_m: 0.5051 - recall_m: 0.2121 - f1_m: 0.2957 - val_loss: 0.5607 - val_accuracy: 0.2822 - val_precision_m: 0.5127 - val_recall_m: 0.3279 - val_f1_m: 0.3987\n","Epoch 9/50\n","131/131 [==============================] - 4s 34ms/step - loss: 0.6098 - accuracy: 0.1850 - precision_m: 0.5182 - recall_m: 0.2168 - f1_m: 0.3021 - val_loss: 0.5558 - val_accuracy: 0.2822 - val_precision_m: 0.5127 - val_recall_m: 0.3279 - val_f1_m: 0.3987\n","Epoch 10/50\n","131/131 [==============================] - 4s 34ms/step - loss: 0.6078 - accuracy: 0.1844 - precision_m: 0.5079 - recall_m: 0.2160 - f1_m: 0.3017 - val_loss: 0.5643 - val_accuracy: 0.2822 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00 - val_f1_m: 0.0000e+00\n","Epoch 11/50\n","131/131 [==============================] - 4s 34ms/step - loss: 0.6081 - accuracy: 0.1815 - precision_m: 0.4789 - recall_m: 0.0985 - f1_m: 0.1462 - val_loss: 0.5568 - val_accuracy: 0.2822 - val_precision_m: 0.5127 - val_recall_m: 0.3279 - val_f1_m: 0.3987\n","Epoch 12/50\n","131/131 [==============================] - 4s 34ms/step - loss: 0.6065 - accuracy: 0.1828 - precision_m: 0.5038 - recall_m: 0.2041 - f1_m: 0.2883 - val_loss: 0.5624 - val_accuracy: 0.2822 - val_precision_m: 0.5127 - val_recall_m: 0.3279 - val_f1_m: 0.3987\n","Epoch 13/50\n","131/131 [==============================] - 4s 34ms/step - loss: 0.6662 - accuracy: 0.1911 - precision_m: 0.4704 - recall_m: 0.2097 - f1_m: 0.2796 - val_loss: 0.5786 - val_accuracy: 0.2822 - val_precision_m: 0.5127 - val_recall_m: 0.3279 - val_f1_m: 0.3987\n","Epoch 00013: early stopping\n","Score for fold 3: loss of 0.5626401901245117; accuracy of 31.068703532218933% ;precision_m of 0.5502504706382751 ;recall_m of 0.36772269010543823 ;            f1_m of 0.43958553671836853\n","Epoch 1/50\n","131/131 [==============================] - 7s 42ms/step - loss: 0.5798 - accuracy: 0.2514 - precision_m: 0.5000 - recall_m: 0.1589 - f1_m: 0.2255 - val_loss: 0.5007 - val_accuracy: 0.3273 - val_precision_m: 0.5824 - val_recall_m: 0.3934 - val_f1_m: 0.4681\n","Epoch 2/50\n","131/131 [==============================] - 5s 38ms/step - loss: 0.5437 - accuracy: 0.2782 - precision_m: 0.5169 - recall_m: 0.2269 - f1_m: 0.3058 - val_loss: 0.5103 - val_accuracy: 0.3273 - val_precision_m: 0.5824 - val_recall_m: 0.3934 - val_f1_m: 0.4681\n","Epoch 3/50\n","131/131 [==============================] - 5s 38ms/step - loss: 0.5486 - accuracy: 0.2747 - precision_m: 0.5129 - recall_m: 0.2179 - f1_m: 0.3035 - val_loss: 0.5040 - val_accuracy: 0.3273 - val_precision_m: 0.5824 - val_recall_m: 0.3934 - val_f1_m: 0.4681\n","Epoch 4/50\n","131/131 [==============================] - 5s 38ms/step - loss: 0.5471 - accuracy: 0.2685 - precision_m: 0.5099 - recall_m: 0.2332 - f1_m: 0.3169 - val_loss: 0.5031 - val_accuracy: 0.3273 - val_precision_m: 0.5824 - val_recall_m: 0.3934 - val_f1_m: 0.4681\n","Epoch 5/50\n","131/131 [==============================] - 5s 38ms/step - loss: 0.5458 - accuracy: 0.2698 - precision_m: 0.5137 - recall_m: 0.2475 - f1_m: 0.3280 - val_loss: 0.5002 - val_accuracy: 0.3273 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00 - val_f1_m: 0.0000e+00\n","Epoch 6/50\n","131/131 [==============================] - 5s 38ms/step - loss: 0.5488 - accuracy: 0.2651 - precision_m: 0.5070 - recall_m: 0.2036 - f1_m: 0.2834 - val_loss: 0.5041 - val_accuracy: 0.3273 - val_precision_m: 0.5824 - val_recall_m: 0.3934 - val_f1_m: 0.4681\n","Epoch 7/50\n","131/131 [==============================] - 5s 38ms/step - loss: 0.5447 - accuracy: 0.2767 - precision_m: 0.5330 - recall_m: 0.2666 - f1_m: 0.3506 - val_loss: 0.4982 - val_accuracy: 0.3273 - val_precision_m: 0.5824 - val_recall_m: 0.3934 - val_f1_m: 0.4681\n","Epoch 8/50\n","131/131 [==============================] - 5s 38ms/step - loss: 0.5463 - accuracy: 0.2798 - precision_m: 0.5333 - recall_m: 0.2792 - f1_m: 0.3620 - val_loss: 0.5023 - val_accuracy: 0.3273 - val_precision_m: 0.5824 - val_recall_m: 0.3934 - val_f1_m: 0.4681\n","Epoch 9/50\n","131/131 [==============================] - 5s 38ms/step - loss: 0.5489 - accuracy: 0.2623 - precision_m: 0.5322 - recall_m: 0.2667 - f1_m: 0.3524 - val_loss: 0.5032 - val_accuracy: 0.3273 - val_precision_m: 0.5824 - val_recall_m: 0.3934 - val_f1_m: 0.4681\n","Epoch 10/50\n","131/131 [==============================] - 5s 37ms/step - loss: 0.5443 - accuracy: 0.2787 - precision_m: 0.5168 - recall_m: 0.2653 - f1_m: 0.3459 - val_loss: 0.5016 - val_accuracy: 0.3273 - val_precision_m: 0.5824 - val_recall_m: 0.3934 - val_f1_m: 0.4681\n","Epoch 11/50\n","131/131 [==============================] - 5s 38ms/step - loss: 0.5476 - accuracy: 0.2734 - precision_m: 0.5229 - recall_m: 0.2928 - f1_m: 0.3739 - val_loss: 0.5025 - val_accuracy: 0.3273 - val_precision_m: 0.5824 - val_recall_m: 0.3934 - val_f1_m: 0.4681\n","Epoch 00011: early stopping\n","Score for fold 1: loss of 0.6455187201499939; accuracy of 15.566577017307281% ;precision_m of 0.5127865076065063 ;recall_m of 0.2593536674976349 ;            f1_m of 0.34322670102119446\n","Epoch 1/50\n","131/131 [==============================] - 7s 42ms/step - loss: 0.6304 - accuracy: 0.2045 - precision_m: 0.4772 - recall_m: 0.1842 - f1_m: 0.2498 - val_loss: 0.5201 - val_accuracy: 0.3279 - val_precision_m: 0.5827 - val_recall_m: 0.3938 - val_f1_m: 0.4685\n","Epoch 2/50\n","131/131 [==============================] - 5s 38ms/step - loss: 0.5921 - accuracy: 0.2063 - precision_m: 0.5193 - recall_m: 0.2157 - f1_m: 0.3008 - val_loss: 0.5244 - val_accuracy: 0.3279 - val_precision_m: 0.5827 - val_recall_m: 0.3938 - val_f1_m: 0.4685\n","Epoch 3/50\n","131/131 [==============================] - 5s 38ms/step - loss: 0.5937 - accuracy: 0.2024 - precision_m: 0.5278 - recall_m: 0.2081 - f1_m: 0.2962 - val_loss: 0.5272 - val_accuracy: 0.3279 - val_precision_m: 0.5827 - val_recall_m: 0.3938 - val_f1_m: 0.4685\n","Epoch 4/50\n","131/131 [==============================] - 5s 37ms/step - loss: 0.5938 - accuracy: 0.1986 - precision_m: 0.5273 - recall_m: 0.2397 - f1_m: 0.3265 - val_loss: 0.5198 - val_accuracy: 0.3279 - val_precision_m: 0.5827 - val_recall_m: 0.3938 - val_f1_m: 0.4685\n","Epoch 5/50\n","131/131 [==============================] - 5s 38ms/step - loss: 0.5935 - accuracy: 0.2071 - precision_m: 0.5172 - recall_m: 0.2217 - f1_m: 0.3072 - val_loss: 0.5164 - val_accuracy: 0.3279 - val_precision_m: 0.5827 - val_recall_m: 0.3938 - val_f1_m: 0.4685\n","Epoch 6/50\n","131/131 [==============================] - 5s 38ms/step - loss: 0.5857 - accuracy: 0.2164 - precision_m: 0.5292 - recall_m: 0.2303 - f1_m: 0.3178 - val_loss: 0.5200 - val_accuracy: 0.3279 - val_precision_m: 0.5827 - val_recall_m: 0.3938 - val_f1_m: 0.4685\n","Epoch 7/50\n","131/131 [==============================] - 5s 38ms/step - loss: 0.5918 - accuracy: 0.2061 - precision_m: 0.5235 - recall_m: 0.2532 - f1_m: 0.3401 - val_loss: 0.5216 - val_accuracy: 0.3279 - val_precision_m: 0.5827 - val_recall_m: 0.3938 - val_f1_m: 0.4685\n","Epoch 8/50\n","131/131 [==============================] - 5s 38ms/step - loss: 0.5958 - accuracy: 0.2041 - precision_m: 0.5116 - recall_m: 0.2107 - f1_m: 0.2938 - val_loss: 0.5151 - val_accuracy: 0.3279 - val_precision_m: 0.5827 - val_recall_m: 0.3938 - val_f1_m: 0.4685\n","Epoch 9/50\n","131/131 [==============================] - 5s 38ms/step - loss: 0.5966 - accuracy: 0.2048 - precision_m: 0.5045 - recall_m: 0.2217 - f1_m: 0.3031 - val_loss: 0.5151 - val_accuracy: 0.3279 - val_precision_m: 0.5827 - val_recall_m: 0.3938 - val_f1_m: 0.4685\n","Epoch 10/50\n","131/131 [==============================] - 5s 38ms/step - loss: 0.5891 - accuracy: 0.2063 - precision_m: 0.5341 - recall_m: 0.2517 - f1_m: 0.3346 - val_loss: 0.5253 - val_accuracy: 0.3279 - val_precision_m: 0.5827 - val_recall_m: 0.3938 - val_f1_m: 0.4685\n","Epoch 11/50\n","131/131 [==============================] - 5s 38ms/step - loss: 0.5918 - accuracy: 0.2176 - precision_m: 0.5397 - recall_m: 0.2628 - f1_m: 0.3511 - val_loss: 0.5195 - val_accuracy: 0.3279 - val_precision_m: 0.5827 - val_recall_m: 0.3938 - val_f1_m: 0.4685\n","Epoch 00011: early stopping\n","Score for fold 2: loss of 0.5657695531845093; accuracy of 25.076335668563843% ;precision_m of 0.5106163024902344 ;recall_m of 0.3112577795982361 ;            f1_m of 0.3850182890892029\n","Epoch 1/50\n","131/131 [==============================] - 7s 41ms/step - loss: 0.6303 - accuracy: 0.1869 - precision_m: 0.4581 - recall_m: 0.1408 - f1_m: 0.2079 - val_loss: 0.5819 - val_accuracy: 0.2612 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00 - val_f1_m: 0.0000e+00\n","Epoch 2/50\n","131/131 [==============================] - 5s 37ms/step - loss: 0.6216 - accuracy: 0.1876 - precision_m: 0.4923 - recall_m: 0.1566 - f1_m: 0.2264 - val_loss: 0.5644 - val_accuracy: 0.2822 - val_precision_m: 0.5127 - val_recall_m: 0.3279 - val_f1_m: 0.3987\n","Epoch 3/50\n","131/131 [==============================] - 5s 37ms/step - loss: 0.6094 - accuracy: 0.1776 - precision_m: 0.4975 - recall_m: 0.1497 - f1_m: 0.2240 - val_loss: 0.5654 - val_accuracy: 0.2822 - val_precision_m: 0.5127 - val_recall_m: 0.3279 - val_f1_m: 0.3987\n","Epoch 4/50\n","131/131 [==============================] - 5s 38ms/step - loss: 0.6087 - accuracy: 0.1862 - precision_m: 0.5139 - recall_m: 0.1713 - f1_m: 0.2531 - val_loss: 0.5612 - val_accuracy: 0.2822 - val_precision_m: 0.5127 - val_recall_m: 0.3279 - val_f1_m: 0.3987\n","Epoch 5/50\n","131/131 [==============================] - 5s 37ms/step - loss: 0.6093 - accuracy: 0.1846 - precision_m: 0.5179 - recall_m: 0.2051 - f1_m: 0.2912 - val_loss: 0.5545 - val_accuracy: 0.2822 - val_precision_m: 0.5127 - val_recall_m: 0.3279 - val_f1_m: 0.3987\n","Epoch 6/50\n","131/131 [==============================] - 5s 37ms/step - loss: 0.6081 - accuracy: 0.1847 - precision_m: 0.5013 - recall_m: 0.1907 - f1_m: 0.2711 - val_loss: 0.5662 - val_accuracy: 0.2822 - val_precision_m: 0.5127 - val_recall_m: 0.3279 - val_f1_m: 0.3987\n","Epoch 7/50\n","131/131 [==============================] - 5s 38ms/step - loss: 0.6060 - accuracy: 0.1839 - precision_m: 0.5174 - recall_m: 0.2227 - f1_m: 0.3090 - val_loss: 0.5604 - val_accuracy: 0.2822 - val_precision_m: 0.5127 - val_recall_m: 0.3279 - val_f1_m: 0.3987\n","Epoch 8/50\n","131/131 [==============================] - 5s 38ms/step - loss: 0.6027 - accuracy: 0.1896 - precision_m: 0.4997 - recall_m: 0.1874 - f1_m: 0.2688 - val_loss: 0.5644 - val_accuracy: 0.2822 - val_precision_m: 0.5127 - val_recall_m: 0.3279 - val_f1_m: 0.3987\n","Epoch 9/50\n","131/131 [==============================] - 5s 38ms/step - loss: 0.6056 - accuracy: 0.1902 - precision_m: 0.5109 - recall_m: 0.2175 - f1_m: 0.3031 - val_loss: 0.5592 - val_accuracy: 0.2822 - val_precision_m: 0.5127 - val_recall_m: 0.3279 - val_f1_m: 0.3987\n","Epoch 10/50\n","131/131 [==============================] - 5s 37ms/step - loss: 0.6058 - accuracy: 0.1885 - precision_m: 0.5048 - recall_m: 0.1845 - f1_m: 0.2677 - val_loss: 0.5548 - val_accuracy: 0.2822 - val_precision_m: 0.5127 - val_recall_m: 0.3279 - val_f1_m: 0.3987\n","Epoch 11/50\n","131/131 [==============================] - 5s 37ms/step - loss: 0.6076 - accuracy: 0.1824 - precision_m: 0.5184 - recall_m: 0.2172 - f1_m: 0.3016 - val_loss: 0.5591 - val_accuracy: 0.2822 - val_precision_m: 0.5127 - val_recall_m: 0.3279 - val_f1_m: 0.3987\n","Epoch 12/50\n","131/131 [==============================] - 5s 37ms/step - loss: 0.6078 - accuracy: 0.1790 - precision_m: 0.4900 - recall_m: 0.2036 - f1_m: 0.2849 - val_loss: 0.5565 - val_accuracy: 0.2822 - val_precision_m: 0.5127 - val_recall_m: 0.3279 - val_f1_m: 0.3987\n","Epoch 00012: early stopping\n","Score for fold 3: loss of 0.5335184335708618; accuracy of 31.068703532218933% ;precision_m of 0.5502504706382751 ;recall_m of 0.36772269010543823 ;            f1_m of 0.43958553671836853\n","Epoch 1/50\n","131/131 [==============================] - 7s 44ms/step - loss: 0.5900 - accuracy: 0.2580 - precision_m: 0.4143 - recall_m: 0.1799 - f1_m: 0.2366 - val_loss: 0.4988 - val_accuracy: 0.3273 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00 - val_f1_m: 0.0000e+00\n","Epoch 2/50\n","131/131 [==============================] - 5s 41ms/step - loss: 0.5515 - accuracy: 0.2658 - precision_m: 0.5298 - recall_m: 0.1953 - f1_m: 0.2793 - val_loss: 0.5028 - val_accuracy: 0.3273 - val_precision_m: 0.5824 - val_recall_m: 0.3934 - val_f1_m: 0.4681\n","Epoch 3/50\n","131/131 [==============================] - 5s 41ms/step - loss: 0.5495 - accuracy: 0.2712 - precision_m: 0.5083 - recall_m: 0.2121 - f1_m: 0.2949 - val_loss: 0.5050 - val_accuracy: 0.3273 - val_precision_m: 0.5824 - val_recall_m: 0.3934 - val_f1_m: 0.4681\n","Epoch 4/50\n","131/131 [==============================] - 5s 41ms/step - loss: 0.5450 - accuracy: 0.2758 - precision_m: 0.5335 - recall_m: 0.2508 - f1_m: 0.3390 - val_loss: 0.5024 - val_accuracy: 0.3273 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00 - val_f1_m: 0.0000e+00\n","Epoch 5/50\n","131/131 [==============================] - 5s 42ms/step - loss: 0.5495 - accuracy: 0.2623 - precision_m: 0.4843 - recall_m: 0.1844 - f1_m: 0.2546 - val_loss: 0.4986 - val_accuracy: 0.3273 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00 - val_f1_m: 0.0000e+00\n","Epoch 6/50\n","131/131 [==============================] - 5s 41ms/step - loss: 0.5501 - accuracy: 0.2789 - precision_m: 0.5220 - recall_m: 0.2078 - f1_m: 0.2913 - val_loss: 0.5083 - val_accuracy: 0.3273 - val_precision_m: 0.5824 - val_recall_m: 0.3934 - val_f1_m: 0.4681\n","Epoch 7/50\n","131/131 [==============================] - 5s 41ms/step - loss: 0.5430 - accuracy: 0.2786 - precision_m: 0.5315 - recall_m: 0.2354 - f1_m: 0.3238 - val_loss: 0.5075 - val_accuracy: 0.3273 - val_precision_m: 0.5824 - val_recall_m: 0.3934 - val_f1_m: 0.4681\n","Epoch 8/50\n","131/131 [==============================] - 5s 41ms/step - loss: 0.5476 - accuracy: 0.2701 - precision_m: 0.5209 - recall_m: 0.1848 - f1_m: 0.2659 - val_loss: 0.4994 - val_accuracy: 0.3273 - val_precision_m: 0.5824 - val_recall_m: 0.3934 - val_f1_m: 0.4681\n","Epoch 9/50\n","131/131 [==============================] - 5s 41ms/step - loss: 0.5480 - accuracy: 0.2704 - precision_m: 0.5047 - recall_m: 0.2419 - f1_m: 0.3204 - val_loss: 0.4994 - val_accuracy: 0.3273 - val_precision_m: 0.5824 - val_recall_m: 0.3934 - val_f1_m: 0.4681\n","Epoch 10/50\n","131/131 [==============================] - 5s 41ms/step - loss: 0.5524 - accuracy: 0.2594 - precision_m: 0.5000 - recall_m: 0.1953 - f1_m: 0.2729 - val_loss: 0.5031 - val_accuracy: 0.3273 - val_precision_m: 0.5824 - val_recall_m: 0.3934 - val_f1_m: 0.4681\n","Epoch 11/50\n","131/131 [==============================] - 5s 40ms/step - loss: 0.5476 - accuracy: 0.2712 - precision_m: 0.5291 - recall_m: 0.2894 - f1_m: 0.3723 - val_loss: 0.4982 - val_accuracy: 0.3273 - val_precision_m: 0.5824 - val_recall_m: 0.3934 - val_f1_m: 0.4681\n","Epoch 12/50\n","131/131 [==============================] - 5s 40ms/step - loss: 0.5476 - accuracy: 0.2652 - precision_m: 0.5376 - recall_m: 0.2600 - f1_m: 0.3406 - val_loss: 0.4995 - val_accuracy: 0.3273 - val_precision_m: 0.5824 - val_recall_m: 0.3934 - val_f1_m: 0.4681\n","Epoch 00012: early stopping\n","Score for fold 1: loss of 0.65179443359375; accuracy of 15.566577017307281% ;precision_m of 0.5127865076065063 ;recall_m of 0.2593536674976349 ;            f1_m of 0.34322670102119446\n","Epoch 1/50\n","131/131 [==============================] - 7s 45ms/step - loss: 0.6203 - accuracy: 0.2215 - precision_m: 0.4693 - recall_m: 0.1600 - f1_m: 0.2260 - val_loss: 0.5209 - val_accuracy: 0.3279 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00 - val_f1_m: 0.0000e+00\n","Epoch 2/50\n","131/131 [==============================] - 5s 41ms/step - loss: 0.5959 - accuracy: 0.2145 - precision_m: 0.5215 - recall_m: 0.1853 - f1_m: 0.2678 - val_loss: 0.5113 - val_accuracy: 0.3279 - val_precision_m: 0.5827 - val_recall_m: 0.3938 - val_f1_m: 0.4685\n","Epoch 3/50\n","131/131 [==============================] - 5s 41ms/step - loss: 0.5964 - accuracy: 0.2126 - precision_m: 0.5097 - recall_m: 0.1884 - f1_m: 0.2715 - val_loss: 0.5094 - val_accuracy: 0.3279 - val_precision_m: 0.5827 - val_recall_m: 0.3938 - val_f1_m: 0.4685\n","Epoch 4/50\n","131/131 [==============================] - 5s 41ms/step - loss: 0.5950 - accuracy: 0.2031 - precision_m: 0.5160 - recall_m: 0.1847 - f1_m: 0.2701 - val_loss: 0.5228 - val_accuracy: 0.3279 - val_precision_m: 0.5827 - val_recall_m: 0.3938 - val_f1_m: 0.4685\n","Epoch 5/50\n","131/131 [==============================] - 5s 41ms/step - loss: 0.5922 - accuracy: 0.2090 - precision_m: 0.4942 - recall_m: 0.1880 - f1_m: 0.2633 - val_loss: 0.5285 - val_accuracy: 0.3279 - val_precision_m: 0.5827 - val_recall_m: 0.3938 - val_f1_m: 0.4685\n","Epoch 6/50\n","131/131 [==============================] - 5s 41ms/step - loss: 0.5893 - accuracy: 0.2228 - precision_m: 0.5103 - recall_m: 0.2221 - f1_m: 0.3051 - val_loss: 0.5192 - val_accuracy: 0.3279 - val_precision_m: 0.5827 - val_recall_m: 0.3938 - val_f1_m: 0.4685\n","Epoch 7/50\n","131/131 [==============================] - 5s 41ms/step - loss: 0.5927 - accuracy: 0.2096 - precision_m: 0.5179 - recall_m: 0.2449 - f1_m: 0.3311 - val_loss: 0.5163 - val_accuracy: 0.3279 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00 - val_f1_m: 0.0000e+00\n","Epoch 8/50\n","131/131 [==============================] - 5s 41ms/step - loss: 0.5934 - accuracy: 0.2108 - precision_m: 0.5083 - recall_m: 0.2036 - f1_m: 0.2863 - val_loss: 0.5190 - val_accuracy: 0.3279 - val_precision_m: 0.5827 - val_recall_m: 0.3938 - val_f1_m: 0.4685\n","Epoch 9/50\n","131/131 [==============================] - 5s 41ms/step - loss: 0.5898 - accuracy: 0.2114 - precision_m: 0.5087 - recall_m: 0.2023 - f1_m: 0.2866 - val_loss: 0.5179 - val_accuracy: 0.3279 - val_precision_m: 0.5827 - val_recall_m: 0.3938 - val_f1_m: 0.4685\n","Epoch 10/50\n","131/131 [==============================] - 6s 42ms/step - loss: 0.5924 - accuracy: 0.2010 - precision_m: 0.5035 - recall_m: 0.2313 - f1_m: 0.3136 - val_loss: 0.5103 - val_accuracy: 0.3279 - val_precision_m: 0.5827 - val_recall_m: 0.3938 - val_f1_m: 0.4685\n","Epoch 11/50\n","131/131 [==============================] - 5s 41ms/step - loss: 0.5918 - accuracy: 0.2160 - precision_m: 0.5187 - recall_m: 0.2546 - f1_m: 0.3405 - val_loss: 0.5172 - val_accuracy: 0.3279 - val_precision_m: 0.5827 - val_recall_m: 0.3938 - val_f1_m: 0.4685\n","Epoch 12/50\n","131/131 [==============================] - 5s 41ms/step - loss: 0.5892 - accuracy: 0.2136 - precision_m: 0.5201 - recall_m: 0.2225 - f1_m: 0.3070 - val_loss: 0.5217 - val_accuracy: 0.3279 - val_precision_m: 0.5827 - val_recall_m: 0.3938 - val_f1_m: 0.4685\n","Epoch 00012: early stopping\n","Score for fold 2: loss of 0.5665931701660156; accuracy of 25.076335668563843% ;precision_m of 0.5106163024902344 ;recall_m of 0.3112577795982361 ;            f1_m of 0.3850182890892029\n","Epoch 1/50\n","131/131 [==============================] - 8s 45ms/step - loss: 0.6413 - accuracy: 0.2100 - precision_m: 0.4917 - recall_m: 0.1438 - f1_m: 0.2091 - val_loss: 0.5544 - val_accuracy: 0.2822 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00 - val_f1_m: 0.0000e+00\n","Epoch 2/50\n","131/131 [==============================] - 5s 41ms/step - loss: 0.6067 - accuracy: 0.1914 - precision_m: 0.5198 - recall_m: 0.1694 - f1_m: 0.2501 - val_loss: 0.5637 - val_accuracy: 0.2822 - val_precision_m: 0.5127 - val_recall_m: 0.3279 - val_f1_m: 0.3987\n","Epoch 3/50\n","131/131 [==============================] - 5s 41ms/step - loss: 0.6084 - accuracy: 0.1840 - precision_m: 0.5135 - recall_m: 0.1639 - f1_m: 0.2428 - val_loss: 0.5593 - val_accuracy: 0.2822 - val_precision_m: 0.5127 - val_recall_m: 0.3279 - val_f1_m: 0.3987\n","Epoch 4/50\n","131/131 [==============================] - 5s 41ms/step - loss: 0.6052 - accuracy: 0.1857 - precision_m: 0.5110 - recall_m: 0.1717 - f1_m: 0.2523 - val_loss: 0.5649 - val_accuracy: 0.2822 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00 - val_f1_m: 0.0000e+00\n","Epoch 5/50\n","131/131 [==============================] - 5s 41ms/step - loss: 0.6100 - accuracy: 0.1770 - precision_m: 0.5324 - recall_m: 0.1378 - f1_m: 0.2122 - val_loss: 0.5602 - val_accuracy: 0.2822 - val_precision_m: 0.5127 - val_recall_m: 0.3279 - val_f1_m: 0.3987\n","Epoch 6/50\n","131/131 [==============================] - 5s 41ms/step - loss: 0.6080 - accuracy: 0.1802 - precision_m: 0.5110 - recall_m: 0.1817 - f1_m: 0.2635 - val_loss: 0.5558 - val_accuracy: 0.2822 - val_precision_m: 0.5127 - val_recall_m: 0.3279 - val_f1_m: 0.3987\n","Epoch 7/50\n","131/131 [==============================] - 5s 41ms/step - loss: 0.6059 - accuracy: 0.1808 - precision_m: 0.5168 - recall_m: 0.2000 - f1_m: 0.2846 - val_loss: 0.5636 - val_accuracy: 0.2822 - val_precision_m: 0.5127 - val_recall_m: 0.3279 - val_f1_m: 0.3987\n","Epoch 8/50\n","131/131 [==============================] - 5s 41ms/step - loss: 0.6071 - accuracy: 0.1829 - precision_m: 0.5219 - recall_m: 0.2301 - f1_m: 0.3157 - val_loss: 0.5624 - val_accuracy: 0.2822 - val_precision_m: 0.5127 - val_recall_m: 0.3279 - val_f1_m: 0.3987\n","Epoch 9/50\n","131/131 [==============================] - 5s 41ms/step - loss: 0.6063 - accuracy: 0.1874 - precision_m: 0.4945 - recall_m: 0.1864 - f1_m: 0.2679 - val_loss: 0.5563 - val_accuracy: 0.2822 - val_precision_m: 0.5127 - val_recall_m: 0.3279 - val_f1_m: 0.3987\n","Epoch 10/50\n","131/131 [==============================] - 5s 41ms/step - loss: 0.6095 - accuracy: 0.1766 - precision_m: 0.4973 - recall_m: 0.1563 - f1_m: 0.2353 - val_loss: 0.5566 - val_accuracy: 0.2822 - val_precision_m: 0.5127 - val_recall_m: 0.3279 - val_f1_m: 0.3987\n","Epoch 11/50\n","131/131 [==============================] - 5s 41ms/step - loss: 0.6062 - accuracy: 0.1755 - precision_m: 0.5100 - recall_m: 0.2113 - f1_m: 0.2952 - val_loss: 0.5653 - val_accuracy: 0.2822 - val_precision_m: 0.5127 - val_recall_m: 0.3279 - val_f1_m: 0.3987\n","Epoch 12/50\n","131/131 [==============================] - 5s 41ms/step - loss: 0.6004 - accuracy: 0.1987 - precision_m: 0.5340 - recall_m: 0.2366 - f1_m: 0.3244 - val_loss: 0.5561 - val_accuracy: 0.2822 - val_precision_m: 0.5127 - val_recall_m: 0.3279 - val_f1_m: 0.3987\n","Epoch 00012: early stopping\n","Score for fold 3: loss of 0.5327799320220947; accuracy of 31.068703532218933% ;precision_m of 0.5502504706382751 ;recall_m of 0.36772269010543823 ;            f1_m of 0.43958553671836853\n","Epoch 1/50\n","131/131 [==============================] - 6s 38ms/step - loss: 0.5915 - accuracy: 0.2510 - precision_m: 0.4093 - recall_m: 0.1566 - f1_m: 0.2059 - val_loss: 0.5137 - val_accuracy: 0.3273 - val_precision_m: 0.5824 - val_recall_m: 0.3934 - val_f1_m: 0.4681\n","Epoch 2/50\n","131/131 [==============================] - 4s 33ms/step - loss: 0.5464 - accuracy: 0.2783 - precision_m: 0.5218 - recall_m: 0.2088 - f1_m: 0.2968 - val_loss: 0.4986 - val_accuracy: 0.3273 - val_precision_m: 0.5824 - val_recall_m: 0.3934 - val_f1_m: 0.4681\n","Epoch 3/50\n","131/131 [==============================] - 4s 33ms/step - loss: 0.5466 - accuracy: 0.2653 - precision_m: 0.5188 - recall_m: 0.2455 - f1_m: 0.3282 - val_loss: 0.5017 - val_accuracy: 0.3273 - val_precision_m: 0.5824 - val_recall_m: 0.3934 - val_f1_m: 0.4681\n","Epoch 4/50\n","131/131 [==============================] - 4s 33ms/step - loss: 0.5468 - accuracy: 0.2628 - precision_m: 0.5162 - recall_m: 0.2199 - f1_m: 0.3055 - val_loss: 0.5065 - val_accuracy: 0.3273 - val_precision_m: 0.5824 - val_recall_m: 0.3934 - val_f1_m: 0.4681\n","Epoch 5/50\n","131/131 [==============================] - 4s 34ms/step - loss: 0.5467 - accuracy: 0.2627 - precision_m: 0.5200 - recall_m: 0.1958 - f1_m: 0.2753 - val_loss: 0.4990 - val_accuracy: 0.3273 - val_precision_m: 0.5824 - val_recall_m: 0.3934 - val_f1_m: 0.4681\n","Epoch 6/50\n","131/131 [==============================] - 4s 33ms/step - loss: 0.5466 - accuracy: 0.2742 - precision_m: 0.5284 - recall_m: 0.2560 - f1_m: 0.3428 - val_loss: 0.5099 - val_accuracy: 0.3273 - val_precision_m: 0.5824 - val_recall_m: 0.3934 - val_f1_m: 0.4681\n","Epoch 7/50\n","131/131 [==============================] - 4s 33ms/step - loss: 0.5478 - accuracy: 0.2665 - precision_m: 0.5201 - recall_m: 0.2186 - f1_m: 0.3044 - val_loss: 0.5015 - val_accuracy: 0.3273 - val_precision_m: 0.5824 - val_recall_m: 0.3934 - val_f1_m: 0.4681\n","Epoch 8/50\n","131/131 [==============================] - 4s 33ms/step - loss: 0.5458 - accuracy: 0.2719 - precision_m: 0.5205 - recall_m: 0.2499 - f1_m: 0.3343 - val_loss: 0.5016 - val_accuracy: 0.3273 - val_precision_m: 0.5824 - val_recall_m: 0.3934 - val_f1_m: 0.4681\n","Epoch 9/50\n","131/131 [==============================] - 4s 34ms/step - loss: 0.5471 - accuracy: 0.2656 - precision_m: 0.5143 - recall_m: 0.2388 - f1_m: 0.3216 - val_loss: 0.4966 - val_accuracy: 0.3273 - val_precision_m: 0.5824 - val_recall_m: 0.3934 - val_f1_m: 0.4681\n","Epoch 10/50\n","131/131 [==============================] - 4s 34ms/step - loss: 0.5469 - accuracy: 0.2683 - precision_m: 0.5167 - recall_m: 0.2937 - f1_m: 0.3731 - val_loss: 0.4979 - val_accuracy: 0.3273 - val_precision_m: 0.5824 - val_recall_m: 0.3934 - val_f1_m: 0.4681\n","Epoch 11/50\n","131/131 [==============================] - 4s 33ms/step - loss: 0.5456 - accuracy: 0.2716 - precision_m: 0.5055 - recall_m: 0.2514 - f1_m: 0.3314 - val_loss: 0.4989 - val_accuracy: 0.3273 - val_precision_m: 0.5824 - val_recall_m: 0.3934 - val_f1_m: 0.4681\n","Epoch 00011: early stopping\n","Score for fold 1: loss of 0.6525154113769531; accuracy of 15.604731440544128% ;precision_m of 0.5129217505455017 ;recall_m of 0.2593536674976349 ;            f1_m of 0.3432560861110687\n","Epoch 1/50\n","131/131 [==============================] - 6s 38ms/step - loss: 0.6342 - accuracy: 0.2087 - precision_m: 0.5025 - recall_m: 0.1711 - f1_m: 0.2498 - val_loss: 0.5210 - val_accuracy: 0.3279 - val_precision_m: 0.5827 - val_recall_m: 0.3938 - val_f1_m: 0.4685\n","Epoch 2/50\n","131/131 [==============================] - 4s 34ms/step - loss: 0.5935 - accuracy: 0.2090 - precision_m: 0.5227 - recall_m: 0.1847 - f1_m: 0.2655 - val_loss: 0.5302 - val_accuracy: 0.3279 - val_precision_m: 0.5827 - val_recall_m: 0.3938 - val_f1_m: 0.4685\n","Epoch 3/50\n","131/131 [==============================] - 4s 34ms/step - loss: 0.5932 - accuracy: 0.2096 - precision_m: 0.5062 - recall_m: 0.1718 - f1_m: 0.2505 - val_loss: 0.5258 - val_accuracy: 0.3279 - val_precision_m: 0.5827 - val_recall_m: 0.3938 - val_f1_m: 0.4685\n","Epoch 4/50\n","131/131 [==============================] - 4s 34ms/step - loss: 0.5932 - accuracy: 0.2073 - precision_m: 0.5148 - recall_m: 0.1724 - f1_m: 0.2561 - val_loss: 0.5242 - val_accuracy: 0.3279 - val_precision_m: 0.5827 - val_recall_m: 0.3938 - val_f1_m: 0.4685\n","Epoch 5/50\n","131/131 [==============================] - 4s 33ms/step - loss: 0.5919 - accuracy: 0.2172 - precision_m: 0.5255 - recall_m: 0.2578 - f1_m: 0.3429 - val_loss: 0.5196 - val_accuracy: 0.3279 - val_precision_m: 0.5827 - val_recall_m: 0.3938 - val_f1_m: 0.4685\n","Epoch 6/50\n","131/131 [==============================] - 4s 34ms/step - loss: 0.5915 - accuracy: 0.2186 - precision_m: 0.5171 - recall_m: 0.2297 - f1_m: 0.3166 - val_loss: 0.5190 - val_accuracy: 0.3279 - val_precision_m: 0.5827 - val_recall_m: 0.3938 - val_f1_m: 0.4685\n","Epoch 7/50\n","131/131 [==============================] - 4s 34ms/step - loss: 0.5863 - accuracy: 0.2093 - precision_m: 0.5364 - recall_m: 0.2556 - f1_m: 0.3439 - val_loss: 0.5219 - val_accuracy: 0.3279 - val_precision_m: 0.5827 - val_recall_m: 0.3938 - val_f1_m: 0.4685\n","Epoch 8/50\n","131/131 [==============================] - 4s 33ms/step - loss: 0.5939 - accuracy: 0.2025 - precision_m: 0.5331 - recall_m: 0.2124 - f1_m: 0.3016 - val_loss: 0.5159 - val_accuracy: 0.3279 - val_precision_m: 0.5827 - val_recall_m: 0.3938 - val_f1_m: 0.4685\n","Epoch 9/50\n","131/131 [==============================] - 4s 33ms/step - loss: 0.5924 - accuracy: 0.2041 - precision_m: 0.5214 - recall_m: 0.2433 - f1_m: 0.3296 - val_loss: 0.5173 - val_accuracy: 0.3279 - val_precision_m: 0.5827 - val_recall_m: 0.3938 - val_f1_m: 0.4685\n","Epoch 10/50\n","131/131 [==============================] - 4s 34ms/step - loss: 0.5898 - accuracy: 0.2113 - precision_m: 0.5180 - recall_m: 0.2579 - f1_m: 0.3433 - val_loss: 0.5284 - val_accuracy: 0.3279 - val_precision_m: 0.5827 - val_recall_m: 0.3938 - val_f1_m: 0.4685\n","Epoch 11/50\n","131/131 [==============================] - 4s 33ms/step - loss: 0.5902 - accuracy: 0.2100 - precision_m: 0.5257 - recall_m: 0.2294 - f1_m: 0.3160 - val_loss: 0.5275 - val_accuracy: 0.3279 - val_precision_m: 0.5827 - val_recall_m: 0.3938 - val_f1_m: 0.4685\n","Epoch 00011: early stopping\n","Score for fold 2: loss of 0.5690342783927917; accuracy of 25.076335668563843% ;precision_m of 0.5106163024902344 ;recall_m of 0.3112577795982361 ;            f1_m of 0.3850182890892029\n","Epoch 1/50\n","131/131 [==============================] - 6s 38ms/step - loss: 0.6316 - accuracy: 0.1872 - precision_m: 0.4617 - recall_m: 0.1306 - f1_m: 0.1980 - val_loss: 0.5640 - val_accuracy: 0.2822 - val_precision_m: 0.5127 - val_recall_m: 0.3279 - val_f1_m: 0.3987\n","Epoch 2/50\n","131/131 [==============================] - 4s 34ms/step - loss: 0.6076 - accuracy: 0.1844 - precision_m: 0.5272 - recall_m: 0.1874 - f1_m: 0.2712 - val_loss: 0.5658 - val_accuracy: 0.2822 - val_precision_m: 0.5127 - val_recall_m: 0.3279 - val_f1_m: 0.3987\n","Epoch 3/50\n","131/131 [==============================] - 4s 34ms/step - loss: 0.6075 - accuracy: 0.1762 - precision_m: 0.5078 - recall_m: 0.1616 - f1_m: 0.2428 - val_loss: 0.5572 - val_accuracy: 0.2822 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00 - val_f1_m: 0.0000e+00\n","Epoch 4/50\n","131/131 [==============================] - 4s 34ms/step - loss: 0.6071 - accuracy: 0.1842 - precision_m: 0.5204 - recall_m: 0.1567 - f1_m: 0.2372 - val_loss: 0.5573 - val_accuracy: 0.2822 - val_precision_m: 0.5127 - val_recall_m: 0.3279 - val_f1_m: 0.3987\n","Epoch 5/50\n","131/131 [==============================] - 4s 33ms/step - loss: 0.6064 - accuracy: 0.1827 - precision_m: 0.5118 - recall_m: 0.2081 - f1_m: 0.2907 - val_loss: 0.5624 - val_accuracy: 0.2822 - val_precision_m: 0.5127 - val_recall_m: 0.3279 - val_f1_m: 0.3987\n","Epoch 6/50\n","131/131 [==============================] - 4s 33ms/step - loss: 0.6096 - accuracy: 0.1847 - precision_m: 0.5127 - recall_m: 0.2221 - f1_m: 0.3086 - val_loss: 0.5575 - val_accuracy: 0.2822 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00 - val_f1_m: 0.0000e+00\n","Epoch 7/50\n","131/131 [==============================] - 4s 33ms/step - loss: 0.6031 - accuracy: 0.1943 - precision_m: 0.5099 - recall_m: 0.1570 - f1_m: 0.2356 - val_loss: 0.5625 - val_accuracy: 0.2822 - val_precision_m: 0.5127 - val_recall_m: 0.3279 - val_f1_m: 0.3987\n","Epoch 8/50\n","131/131 [==============================] - 4s 34ms/step - loss: 0.6070 - accuracy: 0.1816 - precision_m: 0.4956 - recall_m: 0.1790 - f1_m: 0.2603 - val_loss: 0.5589 - val_accuracy: 0.2822 - val_precision_m: 0.5127 - val_recall_m: 0.3279 - val_f1_m: 0.3987\n","Epoch 9/50\n","131/131 [==============================] - 4s 34ms/step - loss: 0.6065 - accuracy: 0.1826 - precision_m: 0.5137 - recall_m: 0.2076 - f1_m: 0.2901 - val_loss: 0.5585 - val_accuracy: 0.2822 - val_precision_m: 0.5127 - val_recall_m: 0.3279 - val_f1_m: 0.3987\n","Epoch 10/50\n","131/131 [==============================] - 4s 34ms/step - loss: 0.6053 - accuracy: 0.1834 - precision_m: 0.5268 - recall_m: 0.2449 - f1_m: 0.3328 - val_loss: 0.5604 - val_accuracy: 0.2822 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00 - val_f1_m: 0.0000e+00\n","Epoch 11/50\n","131/131 [==============================] - 4s 34ms/step - loss: 0.6065 - accuracy: 0.1762 - precision_m: 0.5544 - recall_m: 0.1053 - f1_m: 0.1683 - val_loss: 0.5615 - val_accuracy: 0.2822 - val_precision_m: 0.5127 - val_recall_m: 0.3279 - val_f1_m: 0.3987\n","Epoch 00011: early stopping\n","Score for fold 3: loss of 0.5378075242042542; accuracy of 31.068703532218933% ;precision_m of 0.5502504706382751 ;recall_m of 0.36772269010543823 ;            f1_m of 0.43958553671836853\n","Epoch 1/50\n","131/131 [==============================] - 8s 48ms/step - loss: 0.5817 - accuracy: 0.2604 - precision_m: 0.5247 - recall_m: 0.1732 - f1_m: 0.2454 - val_loss: 0.5002 - val_accuracy: 0.3273 - val_precision_m: 0.5824 - val_recall_m: 0.3934 - val_f1_m: 0.4681\n","Epoch 2/50\n","131/131 [==============================] - 5s 39ms/step - loss: 0.5511 - accuracy: 0.2690 - precision_m: 0.5303 - recall_m: 0.1962 - f1_m: 0.2773 - val_loss: 0.5027 - val_accuracy: 0.3273 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00 - val_f1_m: 0.0000e+00\n","Epoch 3/50\n","131/131 [==============================] - 5s 39ms/step - loss: 0.5484 - accuracy: 0.2703 - precision_m: 0.5367 - recall_m: 0.1944 - f1_m: 0.2793 - val_loss: 0.4977 - val_accuracy: 0.3273 - val_precision_m: 0.5824 - val_recall_m: 0.3934 - val_f1_m: 0.4681\n","Epoch 4/50\n","131/131 [==============================] - 5s 40ms/step - loss: 0.5536 - accuracy: 0.2619 - precision_m: 0.5104 - recall_m: 0.2110 - f1_m: 0.2957 - val_loss: 0.4962 - val_accuracy: 0.3273 - val_precision_m: 0.5824 - val_recall_m: 0.3934 - val_f1_m: 0.4681\n","Epoch 5/50\n","131/131 [==============================] - 5s 40ms/step - loss: 0.5505 - accuracy: 0.2597 - precision_m: 0.5047 - recall_m: 0.2211 - f1_m: 0.3047 - val_loss: 0.4999 - val_accuracy: 0.3273 - val_precision_m: 0.5824 - val_recall_m: 0.3934 - val_f1_m: 0.4681\n","Epoch 6/50\n","131/131 [==============================] - 5s 40ms/step - loss: 0.5474 - accuracy: 0.2650 - precision_m: 0.5166 - recall_m: 0.2159 - f1_m: 0.3015 - val_loss: 0.4996 - val_accuracy: 0.3273 - val_precision_m: 0.5824 - val_recall_m: 0.3934 - val_f1_m: 0.4681\n","Epoch 7/50\n","131/131 [==============================] - 5s 40ms/step - loss: 0.5496 - accuracy: 0.2693 - precision_m: 0.5286 - recall_m: 0.2228 - f1_m: 0.3052 - val_loss: 0.4973 - val_accuracy: 0.3273 - val_precision_m: 0.5824 - val_recall_m: 0.3934 - val_f1_m: 0.4681\n","Epoch 8/50\n","131/131 [==============================] - 5s 39ms/step - loss: 0.5490 - accuracy: 0.2709 - precision_m: 0.5092 - recall_m: 0.2668 - f1_m: 0.3483 - val_loss: 0.4998 - val_accuracy: 0.3273 - val_precision_m: 0.5824 - val_recall_m: 0.3934 - val_f1_m: 0.4681\n","Epoch 9/50\n","131/131 [==============================] - 5s 40ms/step - loss: 0.5473 - accuracy: 0.2688 - precision_m: 0.5170 - recall_m: 0.2575 - f1_m: 0.3400 - val_loss: 0.5060 - val_accuracy: 0.3273 - val_precision_m: 0.5824 - val_recall_m: 0.3934 - val_f1_m: 0.4681\n","Epoch 10/50\n","131/131 [==============================] - 5s 39ms/step - loss: 0.5452 - accuracy: 0.2708 - precision_m: 0.5202 - recall_m: 0.2098 - f1_m: 0.2941 - val_loss: 0.5082 - val_accuracy: 0.3273 - val_precision_m: 0.5824 - val_recall_m: 0.3934 - val_f1_m: 0.4681\n","Epoch 11/50\n","131/131 [==============================] - 5s 39ms/step - loss: 0.5475 - accuracy: 0.2724 - precision_m: 0.5154 - recall_m: 0.2338 - f1_m: 0.3182 - val_loss: 0.5041 - val_accuracy: 0.3273 - val_precision_m: 0.5824 - val_recall_m: 0.3934 - val_f1_m: 0.4681\n","Epoch 00011: early stopping\n","Score for fold 1: loss of 0.641474187374115; accuracy of 15.566577017307281% ;precision_m of 0.5127865076065063 ;recall_m of 0.2593536674976349 ;            f1_m of 0.34322670102119446\n","Epoch 1/50\n","131/131 [==============================] - 7s 44ms/step - loss: 0.6285 - accuracy: 0.2130 - precision_m: 0.5573 - recall_m: 0.1826 - f1_m: 0.2659 - val_loss: 0.5213 - val_accuracy: 0.3279 - val_precision_m: 0.5827 - val_recall_m: 0.3938 - val_f1_m: 0.4685\n","Epoch 2/50\n","131/131 [==============================] - 5s 39ms/step - loss: 0.5917 - accuracy: 0.2192 - precision_m: 0.5276 - recall_m: 0.2053 - f1_m: 0.2913 - val_loss: 0.5335 - val_accuracy: 0.3279 - val_precision_m: 0.5827 - val_recall_m: 0.3938 - val_f1_m: 0.4685\n","Epoch 3/50\n","131/131 [==============================] - 5s 39ms/step - loss: 0.5931 - accuracy: 0.2117 - precision_m: 0.5204 - recall_m: 0.1892 - f1_m: 0.2684 - val_loss: 0.5189 - val_accuracy: 0.3279 - val_precision_m: 0.5827 - val_recall_m: 0.3938 - val_f1_m: 0.4685\n","Epoch 4/50\n","131/131 [==============================] - 5s 39ms/step - loss: 0.5899 - accuracy: 0.2136 - precision_m: 0.5214 - recall_m: 0.2352 - f1_m: 0.3205 - val_loss: 0.5341 - val_accuracy: 0.3279 - val_precision_m: 0.5827 - val_recall_m: 0.3938 - val_f1_m: 0.4685\n","Epoch 5/50\n","131/131 [==============================] - 5s 39ms/step - loss: 0.5943 - accuracy: 0.2060 - precision_m: 0.5285 - recall_m: 0.2049 - f1_m: 0.2876 - val_loss: 0.5295 - val_accuracy: 0.3279 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00 - val_f1_m: 0.0000e+00\n","Epoch 6/50\n","131/131 [==============================] - 5s 39ms/step - loss: 0.5938 - accuracy: 0.2148 - precision_m: 0.5133 - recall_m: 0.1509 - f1_m: 0.2236 - val_loss: 0.5303 - val_accuracy: 0.3279 - val_precision_m: 0.5827 - val_recall_m: 0.3938 - val_f1_m: 0.4685\n","Epoch 7/50\n","131/131 [==============================] - 5s 40ms/step - loss: 0.5881 - accuracy: 0.2166 - precision_m: 0.5205 - recall_m: 0.2366 - f1_m: 0.3226 - val_loss: 0.5173 - val_accuracy: 0.3279 - val_precision_m: 0.5827 - val_recall_m: 0.3938 - val_f1_m: 0.4685\n","Epoch 8/50\n","131/131 [==============================] - 5s 39ms/step - loss: 0.5908 - accuracy: 0.2074 - precision_m: 0.5243 - recall_m: 0.2607 - f1_m: 0.3462 - val_loss: 0.5147 - val_accuracy: 0.3279 - val_precision_m: 0.5827 - val_recall_m: 0.3938 - val_f1_m: 0.4685\n","Epoch 9/50\n","131/131 [==============================] - 5s 40ms/step - loss: 0.5902 - accuracy: 0.2112 - precision_m: 0.5185 - recall_m: 0.2569 - f1_m: 0.3427 - val_loss: 0.5194 - val_accuracy: 0.3279 - val_precision_m: 0.5827 - val_recall_m: 0.3938 - val_f1_m: 0.4685\n","Epoch 10/50\n","131/131 [==============================] - 5s 40ms/step - loss: 0.5950 - accuracy: 0.2008 - precision_m: 0.5157 - recall_m: 0.1901 - f1_m: 0.2730 - val_loss: 0.5242 - val_accuracy: 0.3279 - val_precision_m: 0.5827 - val_recall_m: 0.3938 - val_f1_m: 0.4685\n","Epoch 11/50\n","131/131 [==============================] - 5s 39ms/step - loss: 0.5896 - accuracy: 0.2132 - precision_m: 0.5251 - recall_m: 0.2607 - f1_m: 0.3473 - val_loss: 0.5188 - val_accuracy: 0.3279 - val_precision_m: 0.5827 - val_recall_m: 0.3938 - val_f1_m: 0.4685\n","Epoch 00011: early stopping\n","Score for fold 2: loss of 0.5656344890594482; accuracy of 25.076335668563843% ;precision_m of 0.5106163024902344 ;recall_m of 0.3112577795982361 ;            f1_m of 0.3850182890892029\n","Epoch 1/50\n","131/131 [==============================] - 7s 42ms/step - loss: 0.6522 - accuracy: 0.2036 - precision_m: 0.4577 - recall_m: 0.1507 - f1_m: 0.2187 - val_loss: 0.5620 - val_accuracy: 0.2822 - val_precision_m: 0.5127 - val_recall_m: 0.3279 - val_f1_m: 0.3987\n","Epoch 2/50\n","131/131 [==============================] - 5s 37ms/step - loss: 0.6083 - accuracy: 0.1816 - precision_m: 0.5196 - recall_m: 0.1879 - f1_m: 0.2666 - val_loss: 0.5661 - val_accuracy: 0.2822 - val_precision_m: 0.5127 - val_recall_m: 0.3279 - val_f1_m: 0.3987\n","Epoch 3/50\n","131/131 [==============================] - 5s 37ms/step - loss: 0.6045 - accuracy: 0.1958 - precision_m: 0.5121 - recall_m: 0.1756 - f1_m: 0.2575 - val_loss: 0.5620 - val_accuracy: 0.2822 - val_precision_m: 0.5127 - val_recall_m: 0.3279 - val_f1_m: 0.3987\n","Epoch 4/50\n","131/131 [==============================] - 5s 37ms/step - loss: 0.6049 - accuracy: 0.1901 - precision_m: 0.5258 - recall_m: 0.1901 - f1_m: 0.2755 - val_loss: 0.5714 - val_accuracy: 0.2822 - val_precision_m: 0.5127 - val_recall_m: 0.3279 - val_f1_m: 0.3987\n","Epoch 5/50\n","131/131 [==============================] - 5s 38ms/step - loss: 0.6070 - accuracy: 0.1823 - precision_m: 0.4964 - recall_m: 0.1700 - f1_m: 0.2507 - val_loss: 0.5581 - val_accuracy: 0.2822 - val_precision_m: 0.5127 - val_recall_m: 0.3279 - val_f1_m: 0.3987\n","Epoch 6/50\n","131/131 [==============================] - 5s 37ms/step - loss: 0.6076 - accuracy: 0.1807 - precision_m: 0.5109 - recall_m: 0.1830 - f1_m: 0.2669 - val_loss: 0.5574 - val_accuracy: 0.2822 - val_precision_m: 0.5127 - val_recall_m: 0.3279 - val_f1_m: 0.3987\n","Epoch 7/50\n","131/131 [==============================] - 5s 37ms/step - loss: 0.6051 - accuracy: 0.1896 - precision_m: 0.5054 - recall_m: 0.2152 - f1_m: 0.2993 - val_loss: 0.5574 - val_accuracy: 0.2822 - val_precision_m: 0.5127 - val_recall_m: 0.3279 - val_f1_m: 0.3987\n","Epoch 8/50\n","131/131 [==============================] - 5s 37ms/step - loss: 0.6030 - accuracy: 0.1888 - precision_m: 0.5190 - recall_m: 0.2325 - f1_m: 0.3196 - val_loss: 0.5605 - val_accuracy: 0.2822 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00 - val_f1_m: 0.0000e+00\n","Epoch 9/50\n","131/131 [==============================] - 5s 38ms/step - loss: 0.6065 - accuracy: 0.1798 - precision_m: 0.4949 - recall_m: 0.1366 - f1_m: 0.2103 - val_loss: 0.5605 - val_accuracy: 0.2822 - val_precision_m: 0.5127 - val_recall_m: 0.3279 - val_f1_m: 0.3987\n","Epoch 10/50\n","131/131 [==============================] - 5s 37ms/step - loss: 0.6051 - accuracy: 0.1795 - precision_m: 0.5166 - recall_m: 0.2225 - f1_m: 0.3093 - val_loss: 0.5615 - val_accuracy: 0.2822 - val_precision_m: 0.5127 - val_recall_m: 0.3279 - val_f1_m: 0.3987\n","Epoch 11/50\n","131/131 [==============================] - 5s 38ms/step - loss: 0.6089 - accuracy: 0.1794 - precision_m: 0.5220 - recall_m: 0.2194 - f1_m: 0.3075 - val_loss: 0.5567 - val_accuracy: 0.2822 - val_precision_m: 0.5127 - val_recall_m: 0.3279 - val_f1_m: 0.3987\n","Epoch 00011: early stopping\n","Score for fold 3: loss of 0.5336447954177856; accuracy of 31.068703532218933% ;precision_m of 0.5502504706382751 ;recall_m of 0.36772269010543823 ;            f1_m of 0.43958553671836853\n","Epoch 1/50\n","131/131 [==============================] - 7s 45ms/step - loss: 0.5894 - accuracy: 0.2514 - precision_m: 0.4416 - recall_m: 0.1743 - f1_m: 0.2398 - val_loss: 0.5045 - val_accuracy: 0.3273 - val_precision_m: 0.5824 - val_recall_m: 0.3934 - val_f1_m: 0.4681\n","Epoch 2/50\n","131/131 [==============================] - 5s 41ms/step - loss: 0.5514 - accuracy: 0.2756 - precision_m: 0.5215 - recall_m: 0.1980 - f1_m: 0.2803 - val_loss: 0.5007 - val_accuracy: 0.3273 - val_precision_m: 0.5824 - val_recall_m: 0.3934 - val_f1_m: 0.4681\n","Epoch 3/50\n","131/131 [==============================] - 5s 41ms/step - loss: 0.5530 - accuracy: 0.2611 - precision_m: 0.5106 - recall_m: 0.2041 - f1_m: 0.2873 - val_loss: 0.4982 - val_accuracy: 0.3273 - val_precision_m: 0.5824 - val_recall_m: 0.3934 - val_f1_m: 0.4681\n","Epoch 4/50\n","131/131 [==============================] - 5s 41ms/step - loss: 0.5504 - accuracy: 0.2674 - precision_m: 0.5210 - recall_m: 0.1970 - f1_m: 0.2822 - val_loss: 0.5025 - val_accuracy: 0.3273 - val_precision_m: 0.5824 - val_recall_m: 0.3934 - val_f1_m: 0.4681\n","Epoch 5/50\n","131/131 [==============================] - 5s 41ms/step - loss: 0.5471 - accuracy: 0.2662 - precision_m: 0.5092 - recall_m: 0.2112 - f1_m: 0.2952 - val_loss: 0.4965 - val_accuracy: 0.3273 - val_precision_m: 0.5824 - val_recall_m: 0.3934 - val_f1_m: 0.4681\n","Epoch 6/50\n","131/131 [==============================] - 5s 41ms/step - loss: 0.5496 - accuracy: 0.2740 - precision_m: 0.5230 - recall_m: 0.2678 - f1_m: 0.3509 - val_loss: 0.5034 - val_accuracy: 0.3273 - val_precision_m: 0.5824 - val_recall_m: 0.3934 - val_f1_m: 0.4681\n","Epoch 7/50\n","131/131 [==============================] - 5s 41ms/step - loss: 0.5448 - accuracy: 0.2790 - precision_m: 0.5286 - recall_m: 0.2421 - f1_m: 0.3286 - val_loss: 0.5040 - val_accuracy: 0.3273 - val_precision_m: 0.5824 - val_recall_m: 0.3934 - val_f1_m: 0.4681\n","Epoch 8/50\n","131/131 [==============================] - 5s 41ms/step - loss: 0.5497 - accuracy: 0.2648 - precision_m: 0.5114 - recall_m: 0.2096 - f1_m: 0.2912 - val_loss: 0.4998 - val_accuracy: 0.3273 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00 - val_f1_m: 0.0000e+00\n","Epoch 9/50\n","131/131 [==============================] - 5s 41ms/step - loss: 0.5500 - accuracy: 0.2562 - precision_m: 0.5032 - recall_m: 0.1985 - f1_m: 0.2781 - val_loss: 0.5015 - val_accuracy: 0.3273 - val_precision_m: 0.5824 - val_recall_m: 0.3934 - val_f1_m: 0.4681\n","Epoch 10/50\n","131/131 [==============================] - 5s 41ms/step - loss: 0.5503 - accuracy: 0.2588 - precision_m: 0.5096 - recall_m: 0.2645 - f1_m: 0.3461 - val_loss: 0.5024 - val_accuracy: 0.3273 - val_precision_m: 0.5824 - val_recall_m: 0.3934 - val_f1_m: 0.4681\n","Epoch 11/50\n","131/131 [==============================] - 5s 41ms/step - loss: 0.5415 - accuracy: 0.2731 - precision_m: 0.5275 - recall_m: 0.2934 - f1_m: 0.3748 - val_loss: 0.5021 - val_accuracy: 0.3273 - val_precision_m: 0.5824 - val_recall_m: 0.3934 - val_f1_m: 0.4681\n","Epoch 00011: early stopping\n","Score for fold 1: loss of 0.646962583065033; accuracy of 15.566577017307281% ;precision_m of 0.5129217505455017 ;recall_m of 0.2593536674976349 ;            f1_m of 0.3432560861110687\n","Epoch 1/50\n","131/131 [==============================] - 7s 45ms/step - loss: 0.6213 - accuracy: 0.2339 - precision_m: 0.4595 - recall_m: 0.1389 - f1_m: 0.1988 - val_loss: 0.5220 - val_accuracy: 0.3279 - val_precision_m: 0.5827 - val_recall_m: 0.3938 - val_f1_m: 0.4685\n","Epoch 2/50\n","131/131 [==============================] - 5s 41ms/step - loss: 0.5919 - accuracy: 0.2128 - precision_m: 0.5286 - recall_m: 0.2209 - f1_m: 0.3074 - val_loss: 0.5339 - val_accuracy: 0.3279 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00 - val_f1_m: 0.0000e+00\n","Epoch 3/50\n","131/131 [==============================] - 5s 41ms/step - loss: 0.5965 - accuracy: 0.2100 - precision_m: 0.5244 - recall_m: 0.1945 - f1_m: 0.2788 - val_loss: 0.5135 - val_accuracy: 0.3270 - val_precision_m: 0.0101 - val_recall_m: 8.4175e-04 - val_f1_m: 0.0016\n","Epoch 4/50\n","131/131 [==============================] - 5s 41ms/step - loss: 0.5964 - accuracy: 0.2104 - precision_m: 0.5364 - recall_m: 0.1731 - f1_m: 0.2514 - val_loss: 0.5195 - val_accuracy: 0.3279 - val_precision_m: 0.5827 - val_recall_m: 0.3938 - val_f1_m: 0.4685\n","Epoch 5/50\n","131/131 [==============================] - 5s 41ms/step - loss: 0.5938 - accuracy: 0.2169 - precision_m: 0.5070 - recall_m: 0.1800 - f1_m: 0.2631 - val_loss: 0.5174 - val_accuracy: 0.3279 - val_precision_m: 0.5827 - val_recall_m: 0.3938 - val_f1_m: 0.4685\n","Epoch 6/50\n","131/131 [==============================] - 5s 40ms/step - loss: 0.5923 - accuracy: 0.2079 - precision_m: 0.5085 - recall_m: 0.2143 - f1_m: 0.2976 - val_loss: 0.5247 - val_accuracy: 0.3279 - val_precision_m: 0.5827 - val_recall_m: 0.3938 - val_f1_m: 0.4685\n","Epoch 7/50\n","131/131 [==============================] - 5s 41ms/step - loss: 0.5929 - accuracy: 0.2096 - precision_m: 0.5224 - recall_m: 0.2382 - f1_m: 0.3256 - val_loss: 0.5322 - val_accuracy: 0.3279 - val_precision_m: 0.5827 - val_recall_m: 0.3938 - val_f1_m: 0.4685\n","Epoch 8/50\n","131/131 [==============================] - 5s 41ms/step - loss: 0.5958 - accuracy: 0.2002 - precision_m: 0.5150 - recall_m: 0.2445 - f1_m: 0.3305 - val_loss: 0.5205 - val_accuracy: 0.3279 - val_precision_m: 0.5827 - val_recall_m: 0.3938 - val_f1_m: 0.4685\n","Epoch 9/50\n","131/131 [==============================] - 5s 41ms/step - loss: 0.5910 - accuracy: 0.2111 - precision_m: 0.5193 - recall_m: 0.2273 - f1_m: 0.3144 - val_loss: 0.5214 - val_accuracy: 0.3279 - val_precision_m: 0.5827 - val_recall_m: 0.3938 - val_f1_m: 0.4685\n","Epoch 10/50\n","131/131 [==============================] - 5s 41ms/step - loss: 0.5948 - accuracy: 0.2116 - precision_m: 0.4980 - recall_m: 0.1845 - f1_m: 0.2650 - val_loss: 0.5149 - val_accuracy: 0.3279 - val_precision_m: 0.5827 - val_recall_m: 0.3938 - val_f1_m: 0.4685\n","Epoch 11/50\n","131/131 [==============================] - 5s 41ms/step - loss: 0.5890 - accuracy: 0.2184 - precision_m: 0.5205 - recall_m: 0.2705 - f1_m: 0.3551 - val_loss: 0.5201 - val_accuracy: 0.3279 - val_precision_m: 0.5827 - val_recall_m: 0.3938 - val_f1_m: 0.4685\n","Epoch 00011: early stopping\n","Score for fold 2: loss of 0.5666448473930359; accuracy of 25.076335668563843% ;precision_m of 0.5106163024902344 ;recall_m of 0.3112577795982361 ;            f1_m of 0.3850182890892029\n","Epoch 1/50\n","131/131 [==============================] - 8s 46ms/step - loss: 0.6270 - accuracy: 0.1876 - precision_m: 0.4490 - recall_m: 0.1389 - f1_m: 0.2011 - val_loss: 0.5642 - val_accuracy: 0.2822 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00 - val_f1_m: 0.0000e+00\n","Epoch 2/50\n","131/131 [==============================] - 5s 41ms/step - loss: 0.6075 - accuracy: 0.1800 - precision_m: 0.5001 - recall_m: 0.1241 - f1_m: 0.1934 - val_loss: 0.5582 - val_accuracy: 0.2822 - val_precision_m: 0.5127 - val_recall_m: 0.3279 - val_f1_m: 0.3987\n","Epoch 3/50\n","131/131 [==============================] - 5s 41ms/step - loss: 0.6077 - accuracy: 0.1875 - precision_m: 0.5192 - recall_m: 0.2096 - f1_m: 0.2956 - val_loss: 0.5617 - val_accuracy: 0.2822 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00 - val_f1_m: 0.0000e+00\n","Epoch 4/50\n","131/131 [==============================] - 5s 41ms/step - loss: 0.6079 - accuracy: 0.1791 - precision_m: 0.5095 - recall_m: 0.1429 - f1_m: 0.2166 - val_loss: 0.5617 - val_accuracy: 0.2822 - val_precision_m: 0.5127 - val_recall_m: 0.3279 - val_f1_m: 0.3987\n","Epoch 5/50\n","131/131 [==============================] - 5s 41ms/step - loss: 0.6045 - accuracy: 0.1787 - precision_m: 0.5210 - recall_m: 0.2268 - f1_m: 0.3133 - val_loss: 0.5687 - val_accuracy: 0.2822 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00 - val_f1_m: 0.0000e+00\n","Epoch 6/50\n","131/131 [==============================] - 5s 41ms/step - loss: 0.6048 - accuracy: 0.1903 - precision_m: 0.5178 - recall_m: 0.1812 - f1_m: 0.2666 - val_loss: 0.5554 - val_accuracy: 0.2822 - val_precision_m: 0.5127 - val_recall_m: 0.3279 - val_f1_m: 0.3987\n","Epoch 7/50\n","131/131 [==============================] - 5s 41ms/step - loss: 0.6034 - accuracy: 0.1834 - precision_m: 0.5243 - recall_m: 0.2128 - f1_m: 0.2998 - val_loss: 0.5645 - val_accuracy: 0.2822 - val_precision_m: 0.5127 - val_recall_m: 0.3279 - val_f1_m: 0.3987\n","Epoch 8/50\n","131/131 [==============================] - 5s 42ms/step - loss: 0.6016 - accuracy: 0.1926 - precision_m: 0.5398 - recall_m: 0.2113 - f1_m: 0.2967 - val_loss: 0.5628 - val_accuracy: 0.2822 - val_precision_m: 0.5127 - val_recall_m: 0.3279 - val_f1_m: 0.3987\n","Epoch 9/50\n","131/131 [==============================] - 5s 41ms/step - loss: 0.6078 - accuracy: 0.1799 - precision_m: 0.4983 - recall_m: 0.1786 - f1_m: 0.2597 - val_loss: 0.5561 - val_accuracy: 0.2822 - val_precision_m: 0.5127 - val_recall_m: 0.3279 - val_f1_m: 0.3987\n","Epoch 10/50\n","131/131 [==============================] - 5s 41ms/step - loss: 0.6018 - accuracy: 0.1832 - precision_m: 0.5127 - recall_m: 0.2235 - f1_m: 0.3053 - val_loss: 0.5527 - val_accuracy: 0.2822 - val_precision_m: 0.5127 - val_recall_m: 0.3279 - val_f1_m: 0.3987\n","Epoch 11/50\n","131/131 [==============================] - 5s 41ms/step - loss: 0.6051 - accuracy: 0.1856 - precision_m: 0.5032 - recall_m: 0.2243 - f1_m: 0.3092 - val_loss: 0.5646 - val_accuracy: 0.2822 - val_precision_m: 0.5127 - val_recall_m: 0.3279 - val_f1_m: 0.3987\n","Epoch 12/50\n","131/131 [==============================] - 5s 41ms/step - loss: 0.6106 - accuracy: 0.1784 - precision_m: 0.5248 - recall_m: 0.1665 - f1_m: 0.2505 - val_loss: 0.5549 - val_accuracy: 0.2822 - val_precision_m: 0.5127 - val_recall_m: 0.3279 - val_f1_m: 0.3987\n","Epoch 00012: early stopping\n","Score for fold 3: loss of 0.5300112962722778; accuracy of 31.068703532218933% ;precision_m of 0.5502504706382751 ;recall_m of 0.36772269010543823 ;            f1_m of 0.43958553671836853\n","Epoch 1/50\n","131/131 [==============================] - 6s 38ms/step - loss: 0.5895 - accuracy: 0.2623 - precision_m: 0.4885 - recall_m: 0.1659 - f1_m: 0.2294 - val_loss: 0.4985 - val_accuracy: 0.3254 - val_precision_m: 0.5794 - val_recall_m: 0.3947 - val_f1_m: 0.4681\n","Epoch 2/50\n","131/131 [==============================] - 4s 34ms/step - loss: 0.5534 - accuracy: 0.2792 - precision_m: 0.5188 - recall_m: 0.2262 - f1_m: 0.3098 - val_loss: 0.4992 - val_accuracy: 0.3273 - val_precision_m: 0.5824 - val_recall_m: 0.3934 - val_f1_m: 0.4681\n","Epoch 3/50\n","131/131 [==============================] - 4s 33ms/step - loss: 0.5509 - accuracy: 0.2736 - precision_m: 0.5052 - recall_m: 0.1915 - f1_m: 0.2713 - val_loss: 0.5018 - val_accuracy: 0.3273 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00 - val_f1_m: 0.0000e+00\n","Epoch 4/50\n","131/131 [==============================] - 4s 33ms/step - loss: 0.5456 - accuracy: 0.2783 - precision_m: 0.5308 - recall_m: 0.2241 - f1_m: 0.3096 - val_loss: 0.5076 - val_accuracy: 0.3273 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00 - val_f1_m: 0.0000e+00\n","Epoch 5/50\n","131/131 [==============================] - 4s 33ms/step - loss: 0.5451 - accuracy: 0.2747 - precision_m: 0.5196 - recall_m: 0.2328 - f1_m: 0.3171 - val_loss: 0.5013 - val_accuracy: 0.3273 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00 - val_f1_m: 0.0000e+00\n","Epoch 6/50\n","131/131 [==============================] - 4s 33ms/step - loss: 0.5458 - accuracy: 0.2739 - precision_m: 0.5085 - recall_m: 0.2181 - f1_m: 0.2977 - val_loss: 0.5042 - val_accuracy: 0.3273 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00 - val_f1_m: 0.0000e+00\n","Epoch 7/50\n","131/131 [==============================] - 4s 33ms/step - loss: 0.5426 - accuracy: 0.2783 - precision_m: 0.5101 - recall_m: 0.1938 - f1_m: 0.2679 - val_loss: 0.4983 - val_accuracy: 0.3273 - val_precision_m: 0.5824 - val_recall_m: 0.3934 - val_f1_m: 0.4681\n","Epoch 8/50\n","131/131 [==============================] - 4s 33ms/step - loss: 0.5460 - accuracy: 0.2768 - precision_m: 0.5060 - recall_m: 0.2544 - f1_m: 0.3367 - val_loss: 0.5012 - val_accuracy: 0.3273 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00 - val_f1_m: 0.0000e+00\n","Epoch 9/50\n","131/131 [==============================] - 4s 33ms/step - loss: 0.5462 - accuracy: 0.2677 - precision_m: 0.5049 - recall_m: 0.1916 - f1_m: 0.2687 - val_loss: 0.5056 - val_accuracy: 0.3273 - val_precision_m: 0.5824 - val_recall_m: 0.3934 - val_f1_m: 0.4681\n","Epoch 10/50\n","131/131 [==============================] - 4s 33ms/step - loss: 0.5453 - accuracy: 0.2710 - precision_m: 0.5229 - recall_m: 0.2822 - f1_m: 0.3629 - val_loss: 0.5005 - val_accuracy: 0.3273 - val_precision_m: 0.5824 - val_recall_m: 0.3934 - val_f1_m: 0.4681\n","Epoch 11/50\n","131/131 [==============================] - 4s 33ms/step - loss: 0.5470 - accuracy: 0.2689 - precision_m: 0.5208 - recall_m: 0.2512 - f1_m: 0.3317 - val_loss: 0.5052 - val_accuracy: 0.3273 - val_precision_m: 0.5824 - val_recall_m: 0.3934 - val_f1_m: 0.4681\n","Epoch 12/50\n","131/131 [==============================] - 4s 33ms/step - loss: 0.5449 - accuracy: 0.2739 - precision_m: 0.5434 - recall_m: 0.2382 - f1_m: 0.3236 - val_loss: 0.5048 - val_accuracy: 0.3273 - val_precision_m: 0.5824 - val_recall_m: 0.3934 - val_f1_m: 0.4681\n","Epoch 00012: early stopping\n","Score for fold 1: loss of 0.6418319344520569; accuracy of 15.566577017307281% ;precision_m of 0.5127865076065063 ;recall_m of 0.2593536674976349 ;            f1_m of 0.34322670102119446\n","Epoch 1/50\n","131/131 [==============================] - 6s 37ms/step - loss: 0.6207 - accuracy: 0.2218 - precision_m: 0.4817 - recall_m: 0.2026 - f1_m: 0.2720 - val_loss: 0.5193 - val_accuracy: 0.3279 - val_precision_m: 0.5827 - val_recall_m: 0.3938 - val_f1_m: 0.4685\n","Epoch 2/50\n","131/131 [==============================] - 4s 33ms/step - loss: 0.5914 - accuracy: 0.2084 - precision_m: 0.5217 - recall_m: 0.2018 - f1_m: 0.2873 - val_loss: 0.5364 - val_accuracy: 0.3279 - val_precision_m: 0.5827 - val_recall_m: 0.3938 - val_f1_m: 0.4685\n","Epoch 3/50\n","131/131 [==============================] - 4s 33ms/step - loss: 0.5920 - accuracy: 0.2176 - precision_m: 0.5201 - recall_m: 0.2040 - f1_m: 0.2887 - val_loss: 0.5367 - val_accuracy: 0.3279 - val_precision_m: 0.5827 - val_recall_m: 0.3938 - val_f1_m: 0.4685\n","Epoch 4/50\n","131/131 [==============================] - 4s 33ms/step - loss: 0.5948 - accuracy: 0.2086 - precision_m: 0.5190 - recall_m: 0.2102 - f1_m: 0.2947 - val_loss: 0.5193 - val_accuracy: 0.3279 - val_precision_m: 0.5827 - val_recall_m: 0.3938 - val_f1_m: 0.4685\n","Epoch 5/50\n","131/131 [==============================] - 4s 33ms/step - loss: 0.5932 - accuracy: 0.2015 - precision_m: 0.5173 - recall_m: 0.1923 - f1_m: 0.2769 - val_loss: 0.5182 - val_accuracy: 0.3279 - val_precision_m: 0.5827 - val_recall_m: 0.3938 - val_f1_m: 0.4685\n","Epoch 6/50\n","131/131 [==============================] - 4s 34ms/step - loss: 0.5920 - accuracy: 0.2149 - precision_m: 0.5251 - recall_m: 0.2436 - f1_m: 0.3310 - val_loss: 0.5202 - val_accuracy: 0.3279 - val_precision_m: 0.5827 - val_recall_m: 0.3938 - val_f1_m: 0.4685\n","Epoch 7/50\n","131/131 [==============================] - 4s 33ms/step - loss: 0.5936 - accuracy: 0.1999 - precision_m: 0.5103 - recall_m: 0.2131 - f1_m: 0.2994 - val_loss: 0.5166 - val_accuracy: 0.3279 - val_precision_m: 0.5827 - val_recall_m: 0.3938 - val_f1_m: 0.4685\n","Epoch 8/50\n","131/131 [==============================] - 4s 33ms/step - loss: 0.5926 - accuracy: 0.2091 - precision_m: 0.5200 - recall_m: 0.2215 - f1_m: 0.3072 - val_loss: 0.5207 - val_accuracy: 0.3279 - val_precision_m: 0.5827 - val_recall_m: 0.3938 - val_f1_m: 0.4685\n","Epoch 9/50\n","131/131 [==============================] - 4s 33ms/step - loss: 0.5897 - accuracy: 0.2029 - precision_m: 0.5245 - recall_m: 0.2499 - f1_m: 0.3369 - val_loss: 0.5140 - val_accuracy: 0.3279 - val_precision_m: 0.5827 - val_recall_m: 0.3938 - val_f1_m: 0.4685\n","Epoch 10/50\n","131/131 [==============================] - 4s 33ms/step - loss: 0.5891 - accuracy: 0.2086 - precision_m: 0.4980 - recall_m: 0.1903 - f1_m: 0.2730 - val_loss: 0.5241 - val_accuracy: 0.3279 - val_precision_m: 0.5827 - val_recall_m: 0.3938 - val_f1_m: 0.4685\n","Epoch 11/50\n","131/131 [==============================] - 4s 33ms/step - loss: 0.5928 - accuracy: 0.2083 - precision_m: 0.5215 - recall_m: 0.2587 - f1_m: 0.3432 - val_loss: 0.5251 - val_accuracy: 0.3279 - val_precision_m: 0.5827 - val_recall_m: 0.3938 - val_f1_m: 0.4685\n","Epoch 00011: early stopping\n","Score for fold 2: loss of 0.5681454539299011; accuracy of 25.076335668563843% ;precision_m of 0.5106163024902344 ;recall_m of 0.3112577795982361 ;            f1_m of 0.3850182890892029\n","Epoch 1/50\n","131/131 [==============================] - 6s 37ms/step - loss: 0.6369 - accuracy: 0.1832 - precision_m: 0.4809 - recall_m: 0.1733 - f1_m: 0.2463 - val_loss: 0.5638 - val_accuracy: 0.2822 - val_precision_m: 0.5127 - val_recall_m: 0.3279 - val_f1_m: 0.3987\n","Epoch 2/50\n","131/131 [==============================] - 4s 34ms/step - loss: 0.6100 - accuracy: 0.1792 - precision_m: 0.5063 - recall_m: 0.1480 - f1_m: 0.2231 - val_loss: 0.5634 - val_accuracy: 0.2822 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00 - val_f1_m: 0.0000e+00\n","Epoch 3/50\n","131/131 [==============================] - 4s 34ms/step - loss: 0.6065 - accuracy: 0.1822 - precision_m: 0.5365 - recall_m: 0.1297 - f1_m: 0.1968 - val_loss: 0.5588 - val_accuracy: 0.2822 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00 - val_f1_m: 0.0000e+00\n","Epoch 4/50\n","131/131 [==============================] - 4s 34ms/step - loss: 0.6056 - accuracy: 0.1833 - precision_m: 0.5174 - recall_m: 0.1873 - f1_m: 0.2708 - val_loss: 0.5567 - val_accuracy: 0.2822 - val_precision_m: 0.5127 - val_recall_m: 0.3279 - val_f1_m: 0.3987\n","Epoch 5/50\n","131/131 [==============================] - 4s 34ms/step - loss: 0.6109 - accuracy: 0.1754 - precision_m: 0.5097 - recall_m: 0.1935 - f1_m: 0.2787 - val_loss: 0.5517 - val_accuracy: 0.2822 - val_precision_m: 0.5127 - val_recall_m: 0.3279 - val_f1_m: 0.3987\n","Epoch 6/50\n","131/131 [==============================] - 4s 34ms/step - loss: 0.6059 - accuracy: 0.1811 - precision_m: 0.5187 - recall_m: 0.2013 - f1_m: 0.2860 - val_loss: 0.5684 - val_accuracy: 0.2822 - val_precision_m: 0.5127 - val_recall_m: 0.3279 - val_f1_m: 0.3987\n","Epoch 7/50\n","131/131 [==============================] - 4s 33ms/step - loss: 0.6075 - accuracy: 0.1855 - precision_m: 0.5075 - recall_m: 0.1902 - f1_m: 0.2708 - val_loss: 0.5561 - val_accuracy: 0.2822 - val_precision_m: 0.5127 - val_recall_m: 0.3279 - val_f1_m: 0.3987\n","Epoch 8/50\n","131/131 [==============================] - 4s 34ms/step - loss: 0.6073 - accuracy: 0.1824 - precision_m: 0.5166 - recall_m: 0.2118 - f1_m: 0.2970 - val_loss: 0.5582 - val_accuracy: 0.2822 - val_precision_m: 0.5127 - val_recall_m: 0.3279 - val_f1_m: 0.3987\n","Epoch 9/50\n","131/131 [==============================] - 4s 34ms/step - loss: 0.6078 - accuracy: 0.1804 - precision_m: 0.5113 - recall_m: 0.1737 - f1_m: 0.2562 - val_loss: 0.5635 - val_accuracy: 0.2822 - val_precision_m: 0.5127 - val_recall_m: 0.3279 - val_f1_m: 0.3987\n","Epoch 10/50\n","131/131 [==============================] - 4s 34ms/step - loss: 0.6039 - accuracy: 0.1963 - precision_m: 0.5236 - recall_m: 0.2013 - f1_m: 0.2872 - val_loss: 0.5578 - val_accuracy: 0.2822 - val_precision_m: 0.5127 - val_recall_m: 0.3279 - val_f1_m: 0.3987\n","Epoch 11/50\n","131/131 [==============================] - 4s 34ms/step - loss: 0.6035 - accuracy: 0.1822 - precision_m: 0.5195 - recall_m: 0.2289 - f1_m: 0.3153 - val_loss: 0.5638 - val_accuracy: 0.2822 - val_precision_m: 0.5127 - val_recall_m: 0.3279 - val_f1_m: 0.3987\n","Epoch 00011: early stopping\n","Score for fold 3: loss of 0.5432537198066711; accuracy of 31.068703532218933% ;precision_m of 0.5502504706382751 ;recall_m of 0.36772269010543823 ;            f1_m of 0.43958553671836853\n","Epoch 1/50\n","131/131 [==============================] - 8s 42ms/step - loss: 0.5846 - accuracy: 0.2760 - precision_m: 0.4886 - recall_m: 0.1878 - f1_m: 0.2633 - val_loss: 0.5024 - val_accuracy: 0.3273 - val_precision_m: 0.5824 - val_recall_m: 0.3934 - val_f1_m: 0.4681\n","Epoch 2/50\n","131/131 [==============================] - 5s 38ms/step - loss: 0.5468 - accuracy: 0.2735 - precision_m: 0.5269 - recall_m: 0.2641 - f1_m: 0.3495 - val_loss: 0.5001 - val_accuracy: 0.3273 - val_precision_m: 0.5824 - val_recall_m: 0.3934 - val_f1_m: 0.4681\n","Epoch 3/50\n","131/131 [==============================] - 5s 38ms/step - loss: 0.5452 - accuracy: 0.2570 - precision_m: 0.5258 - recall_m: 0.2212 - f1_m: 0.3089 - val_loss: 0.4977 - val_accuracy: 0.3273 - val_precision_m: 0.5824 - val_recall_m: 0.3934 - val_f1_m: 0.4681\n","Epoch 4/50\n","131/131 [==============================] - 5s 37ms/step - loss: 0.5467 - accuracy: 0.2765 - precision_m: 0.5061 - recall_m: 0.2388 - f1_m: 0.3223 - val_loss: 0.4998 - val_accuracy: 0.3273 - val_precision_m: 0.5824 - val_recall_m: 0.3934 - val_f1_m: 0.4681\n","Epoch 5/50\n","131/131 [==============================] - 5s 37ms/step - loss: 0.5471 - accuracy: 0.2744 - precision_m: 0.5280 - recall_m: 0.2595 - f1_m: 0.3454 - val_loss: 0.4998 - val_accuracy: 0.3273 - val_precision_m: 0.5824 - val_recall_m: 0.3934 - val_f1_m: 0.4681\n","Epoch 6/50\n","131/131 [==============================] - 5s 37ms/step - loss: 0.5475 - accuracy: 0.2626 - precision_m: 0.5122 - recall_m: 0.2104 - f1_m: 0.2945 - val_loss: 0.5036 - val_accuracy: 0.3273 - val_precision_m: 0.5824 - val_recall_m: 0.3934 - val_f1_m: 0.4681\n","Epoch 7/50\n","131/131 [==============================] - 5s 37ms/step - loss: 0.5420 - accuracy: 0.2787 - precision_m: 0.5227 - recall_m: 0.2395 - f1_m: 0.3212 - val_loss: 0.5020 - val_accuracy: 0.3273 - val_precision_m: 0.5824 - val_recall_m: 0.3934 - val_f1_m: 0.4681\n","Epoch 8/50\n","131/131 [==============================] - 5s 38ms/step - loss: 0.5487 - accuracy: 0.2664 - precision_m: 0.5005 - recall_m: 0.2225 - f1_m: 0.3032 - val_loss: 0.4988 - val_accuracy: 0.3273 - val_precision_m: 0.5824 - val_recall_m: 0.3934 - val_f1_m: 0.4681\n","Epoch 9/50\n","131/131 [==============================] - 5s 37ms/step - loss: 0.5442 - accuracy: 0.2786 - precision_m: 0.5229 - recall_m: 0.2747 - f1_m: 0.3561 - val_loss: 0.5015 - val_accuracy: 0.3273 - val_precision_m: 0.5824 - val_recall_m: 0.3934 - val_f1_m: 0.4681\n","Epoch 10/50\n","131/131 [==============================] - 5s 37ms/step - loss: 0.5530 - accuracy: 0.2597 - precision_m: 0.5170 - recall_m: 0.2400 - f1_m: 0.3255 - val_loss: 0.4978 - val_accuracy: 0.3273 - val_precision_m: 0.5824 - val_recall_m: 0.3934 - val_f1_m: 0.4681\n","Epoch 11/50\n","131/131 [==============================] - 5s 37ms/step - loss: 0.5445 - accuracy: 0.2735 - precision_m: 0.5279 - recall_m: 0.2657 - f1_m: 0.3506 - val_loss: 0.5033 - val_accuracy: 0.3273 - val_precision_m: 0.5824 - val_recall_m: 0.3934 - val_f1_m: 0.4681\n","Epoch 00011: early stopping\n","Score for fold 1: loss of 0.6461405754089355; accuracy of 15.566577017307281% ;precision_m of 0.5127865076065063 ;recall_m of 0.2593536674976349 ;            f1_m of 0.34322670102119446\n","Epoch 1/50\n","131/131 [==============================] - 7s 41ms/step - loss: 0.6279 - accuracy: 0.2166 - precision_m: 0.4914 - recall_m: 0.1878 - f1_m: 0.2656 - val_loss: 0.5244 - val_accuracy: 0.3279 - val_precision_m: 0.5827 - val_recall_m: 0.3938 - val_f1_m: 0.4685\n","Epoch 2/50\n","131/131 [==============================] - 5s 37ms/step - loss: 0.5926 - accuracy: 0.2043 - precision_m: 0.5356 - recall_m: 0.2110 - f1_m: 0.2982 - val_loss: 0.5210 - val_accuracy: 0.3279 - val_precision_m: 0.5827 - val_recall_m: 0.3938 - val_f1_m: 0.4685\n","Epoch 3/50\n","131/131 [==============================] - 5s 37ms/step - loss: 0.5899 - accuracy: 0.2133 - precision_m: 0.5326 - recall_m: 0.2332 - f1_m: 0.3195 - val_loss: 0.5216 - val_accuracy: 0.3279 - val_precision_m: 0.5827 - val_recall_m: 0.3938 - val_f1_m: 0.4685\n","Epoch 4/50\n","131/131 [==============================] - 5s 38ms/step - loss: 0.5942 - accuracy: 0.2023 - precision_m: 0.5305 - recall_m: 0.1966 - f1_m: 0.2821 - val_loss: 0.5212 - val_accuracy: 0.3279 - val_precision_m: 0.5827 - val_recall_m: 0.3938 - val_f1_m: 0.4685\n","Epoch 5/50\n","131/131 [==============================] - 5s 37ms/step - loss: 0.5910 - accuracy: 0.2210 - precision_m: 0.5247 - recall_m: 0.2117 - f1_m: 0.2991 - val_loss: 0.5218 - val_accuracy: 0.3279 - val_precision_m: 0.5827 - val_recall_m: 0.3938 - val_f1_m: 0.4685\n","Epoch 6/50\n","131/131 [==============================] - 5s 37ms/step - loss: 0.5947 - accuracy: 0.2066 - precision_m: 0.5313 - recall_m: 0.2065 - f1_m: 0.2929 - val_loss: 0.5138 - val_accuracy: 0.3279 - val_precision_m: 0.5827 - val_recall_m: 0.3938 - val_f1_m: 0.4685\n","Epoch 7/50\n","131/131 [==============================] - 5s 37ms/step - loss: 0.5873 - accuracy: 0.2175 - precision_m: 0.5248 - recall_m: 0.2558 - f1_m: 0.3428 - val_loss: 0.5214 - val_accuracy: 0.3279 - val_precision_m: 0.5827 - val_recall_m: 0.3938 - val_f1_m: 0.4685\n","Epoch 8/50\n","131/131 [==============================] - 5s 37ms/step - loss: 0.5900 - accuracy: 0.2174 - precision_m: 0.5155 - recall_m: 0.2427 - f1_m: 0.3287 - val_loss: 0.5254 - val_accuracy: 0.3279 - val_precision_m: 0.5827 - val_recall_m: 0.3938 - val_f1_m: 0.4685\n","Epoch 9/50\n","131/131 [==============================] - 5s 37ms/step - loss: 0.5900 - accuracy: 0.2152 - precision_m: 0.5177 - recall_m: 0.2348 - f1_m: 0.3208 - val_loss: 0.5173 - val_accuracy: 0.3279 - val_precision_m: 0.5827 - val_recall_m: 0.3938 - val_f1_m: 0.4685\n","Epoch 10/50\n","131/131 [==============================] - 5s 37ms/step - loss: 0.5937 - accuracy: 0.2035 - precision_m: 0.5208 - recall_m: 0.2392 - f1_m: 0.3269 - val_loss: 0.5295 - val_accuracy: 0.3279 - val_precision_m: 0.5827 - val_recall_m: 0.3938 - val_f1_m: 0.4685\n","Epoch 11/50\n","131/131 [==============================] - 5s 37ms/step - loss: 0.5859 - accuracy: 0.2120 - precision_m: 0.5251 - recall_m: 0.2485 - f1_m: 0.3360 - val_loss: 0.5152 - val_accuracy: 0.3279 - val_precision_m: 0.5827 - val_recall_m: 0.3938 - val_f1_m: 0.4685\n","Epoch 00011: early stopping\n","Score for fold 2: loss of 0.5638110041618347; accuracy of 25.076335668563843% ;precision_m of 0.5106163024902344 ;recall_m of 0.3112577795982361 ;            f1_m of 0.3850182890892029\n","Epoch 1/50\n","131/131 [==============================] - 7s 42ms/step - loss: 0.6456 - accuracy: 0.1906 - precision_m: 0.4549 - recall_m: 0.1833 - f1_m: 0.2502 - val_loss: 0.5530 - val_accuracy: 0.2822 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00 - val_f1_m: 0.0000e+00\n","Epoch 2/50\n","131/131 [==============================] - 5s 38ms/step - loss: 0.6090 - accuracy: 0.1786 - precision_m: 0.4515 - recall_m: 0.1126 - f1_m: 0.1730 - val_loss: 0.5620 - val_accuracy: 0.2822 - val_precision_m: 0.5127 - val_recall_m: 0.3279 - val_f1_m: 0.3987\n","Epoch 3/50\n","131/131 [==============================] - 5s 37ms/step - loss: 0.6065 - accuracy: 0.1784 - precision_m: 0.5226 - recall_m: 0.1903 - f1_m: 0.2751 - val_loss: 0.5563 - val_accuracy: 0.2822 - val_precision_m: 0.5127 - val_recall_m: 0.3279 - val_f1_m: 0.3987\n","Epoch 4/50\n","131/131 [==============================] - 5s 38ms/step - loss: 0.6045 - accuracy: 0.1872 - precision_m: 0.5121 - recall_m: 0.2036 - f1_m: 0.2885 - val_loss: 0.5628 - val_accuracy: 0.2822 - val_precision_m: 0.5127 - val_recall_m: 0.3279 - val_f1_m: 0.3987\n","Epoch 5/50\n","131/131 [==============================] - 5s 37ms/step - loss: 0.6068 - accuracy: 0.1924 - precision_m: 0.5026 - recall_m: 0.1841 - f1_m: 0.2673 - val_loss: 0.5653 - val_accuracy: 0.2822 - val_precision_m: 0.5127 - val_recall_m: 0.3279 - val_f1_m: 0.3987\n","Epoch 6/50\n","131/131 [==============================] - 5s 38ms/step - loss: 0.6057 - accuracy: 0.1866 - precision_m: 0.5156 - recall_m: 0.1817 - f1_m: 0.2662 - val_loss: 0.5568 - val_accuracy: 0.2822 - val_precision_m: 0.5127 - val_recall_m: 0.3279 - val_f1_m: 0.3987\n","Epoch 7/50\n","131/131 [==============================] - 5s 38ms/step - loss: 0.6059 - accuracy: 0.1834 - precision_m: 0.5157 - recall_m: 0.1970 - f1_m: 0.2818 - val_loss: 0.5546 - val_accuracy: 0.2822 - val_precision_m: 0.5127 - val_recall_m: 0.3279 - val_f1_m: 0.3987\n","Epoch 8/50\n","131/131 [==============================] - 5s 38ms/step - loss: 0.6039 - accuracy: 0.1811 - precision_m: 0.5090 - recall_m: 0.1625 - f1_m: 0.2400 - val_loss: 0.5580 - val_accuracy: 0.2822 - val_precision_m: 0.5127 - val_recall_m: 0.3279 - val_f1_m: 0.3987\n","Epoch 9/50\n","131/131 [==============================] - 5s 37ms/step - loss: 0.6056 - accuracy: 0.1840 - precision_m: 0.4967 - recall_m: 0.1858 - f1_m: 0.2670 - val_loss: 0.5585 - val_accuracy: 0.2822 - val_precision_m: 0.5127 - val_recall_m: 0.3279 - val_f1_m: 0.3987\n","Epoch 10/50\n","131/131 [==============================] - 5s 37ms/step - loss: 0.6046 - accuracy: 0.1861 - precision_m: 0.5039 - recall_m: 0.1905 - f1_m: 0.2725 - val_loss: 0.5608 - val_accuracy: 0.2822 - val_precision_m: 0.5127 - val_recall_m: 0.3279 - val_f1_m: 0.3987\n","Epoch 11/50\n","131/131 [==============================] - 5s 38ms/step - loss: 0.6058 - accuracy: 0.1658 - precision_m: 0.5135 - recall_m: 0.1880 - f1_m: 0.2718 - val_loss: 0.5542 - val_accuracy: 0.2822 - val_precision_m: 0.5127 - val_recall_m: 0.3279 - val_f1_m: 0.3987\n","Epoch 12/50\n","131/131 [==============================] - 5s 38ms/step - loss: 0.6035 - accuracy: 0.1888 - precision_m: 0.5159 - recall_m: 0.2280 - f1_m: 0.3151 - val_loss: 0.5589 - val_accuracy: 0.2822 - val_precision_m: 0.5127 - val_recall_m: 0.3279 - val_f1_m: 0.3987\n","Epoch 00012: early stopping\n","Score for fold 3: loss of 0.5366129279136658; accuracy of 31.068703532218933% ;precision_m of 0.5502504706382751 ;recall_m of 0.36772269010543823 ;            f1_m of 0.43958553671836853\n","Epoch 1/50\n","131/131 [==============================] - 7s 45ms/step - loss: 0.5936 - accuracy: 0.2519 - precision_m: 0.5078 - recall_m: 0.1475 - f1_m: 0.2176 - val_loss: 0.5053 - val_accuracy: 0.3273 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00 - val_f1_m: 0.0000e+00\n","Epoch 2/50\n","131/131 [==============================] - 5s 41ms/step - loss: 0.5528 - accuracy: 0.2648 - precision_m: 0.5003 - recall_m: 0.1708 - f1_m: 0.2439 - val_loss: 0.4990 - val_accuracy: 0.3273 - val_precision_m: 0.5824 - val_recall_m: 0.3934 - val_f1_m: 0.4681\n","Epoch 3/50\n","131/131 [==============================] - 5s 40ms/step - loss: 0.5456 - accuracy: 0.2825 - precision_m: 0.5116 - recall_m: 0.2255 - f1_m: 0.3081 - val_loss: 0.5075 - val_accuracy: 0.3273 - val_precision_m: 0.5824 - val_recall_m: 0.3934 - val_f1_m: 0.4681\n","Epoch 4/50\n","131/131 [==============================] - 5s 41ms/step - loss: 0.5497 - accuracy: 0.2711 - precision_m: 0.5211 - recall_m: 0.2489 - f1_m: 0.3324 - val_loss: 0.4979 - val_accuracy: 0.3273 - val_precision_m: 0.5824 - val_recall_m: 0.3934 - val_f1_m: 0.4681\n","Epoch 5/50\n","131/131 [==============================] - 5s 41ms/step - loss: 0.5452 - accuracy: 0.2703 - precision_m: 0.5224 - recall_m: 0.2328 - f1_m: 0.3188 - val_loss: 0.5057 - val_accuracy: 0.3273 - val_precision_m: 0.5824 - val_recall_m: 0.3934 - val_f1_m: 0.4681\n","Epoch 6/50\n","131/131 [==============================] - 5s 41ms/step - loss: 0.5488 - accuracy: 0.2710 - precision_m: 0.5216 - recall_m: 0.2308 - f1_m: 0.3165 - val_loss: 0.5021 - val_accuracy: 0.3273 - val_precision_m: 0.5824 - val_recall_m: 0.3934 - val_f1_m: 0.4681\n","Epoch 7/50\n","131/131 [==============================] - 5s 41ms/step - loss: 0.5468 - accuracy: 0.2648 - precision_m: 0.5237 - recall_m: 0.2567 - f1_m: 0.3420 - val_loss: 0.5020 - val_accuracy: 0.3273 - val_precision_m: 0.5824 - val_recall_m: 0.3934 - val_f1_m: 0.4681\n","Epoch 8/50\n","131/131 [==============================] - 5s 41ms/step - loss: 0.5507 - accuracy: 0.2587 - precision_m: 0.5010 - recall_m: 0.1607 - f1_m: 0.2378 - val_loss: 0.5010 - val_accuracy: 0.3273 - val_precision_m: 0.5824 - val_recall_m: 0.3934 - val_f1_m: 0.4681\n","Epoch 9/50\n","131/131 [==============================] - 5s 40ms/step - loss: 0.5471 - accuracy: 0.2669 - precision_m: 0.5231 - recall_m: 0.2728 - f1_m: 0.3564 - val_loss: 0.4964 - val_accuracy: 0.3273 - val_precision_m: 0.5824 - val_recall_m: 0.3934 - val_f1_m: 0.4681\n","Epoch 10/50\n","131/131 [==============================] - 5s 41ms/step - loss: 0.5481 - accuracy: 0.2687 - precision_m: 0.5187 - recall_m: 0.2751 - f1_m: 0.3581 - val_loss: 0.5057 - val_accuracy: 0.3273 - val_precision_m: 0.5824 - val_recall_m: 0.3934 - val_f1_m: 0.4681\n","Epoch 11/50\n","131/131 [==============================] - 5s 41ms/step - loss: 0.5459 - accuracy: 0.2737 - precision_m: 0.5302 - recall_m: 0.2510 - f1_m: 0.3369 - val_loss: 0.5049 - val_accuracy: 0.3273 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00 - val_f1_m: 0.0000e+00\n","Epoch 12/50\n","131/131 [==============================] - 5s 40ms/step - loss: 0.5494 - accuracy: 0.2632 - precision_m: 0.5226 - recall_m: 0.1567 - f1_m: 0.2316 - val_loss: 0.4999 - val_accuracy: 0.3273 - val_precision_m: 0.5824 - val_recall_m: 0.3934 - val_f1_m: 0.4681\n","Epoch 00012: early stopping\n","Score for fold 1: loss of 0.6522527933120728; accuracy of 15.566577017307281% ;precision_m of 0.5127865076065063 ;recall_m of 0.2593536674976349 ;            f1_m of 0.34322670102119446\n","Epoch 1/50\n","131/131 [==============================] - 8s 49ms/step - loss: 0.6334 - accuracy: 0.2143 - precision_m: 0.4360 - recall_m: 0.1599 - f1_m: 0.2221 - val_loss: 0.5292 - val_accuracy: 0.3279 - val_precision_m: 0.5827 - val_recall_m: 0.3938 - val_f1_m: 0.4685\n","Epoch 2/50\n","131/131 [==============================] - 5s 41ms/step - loss: 0.5942 - accuracy: 0.2133 - precision_m: 0.5078 - recall_m: 0.1947 - f1_m: 0.2780 - val_loss: 0.5188 - val_accuracy: 0.3279 - val_precision_m: 0.5827 - val_recall_m: 0.3938 - val_f1_m: 0.4685\n","Epoch 3/50\n","131/131 [==============================] - 5s 41ms/step - loss: 0.5919 - accuracy: 0.2127 - precision_m: 0.5189 - recall_m: 0.2129 - f1_m: 0.2987 - val_loss: 0.5190 - val_accuracy: 0.3279 - val_precision_m: 0.5827 - val_recall_m: 0.3938 - val_f1_m: 0.4685\n","Epoch 4/50\n","131/131 [==============================] - 5s 41ms/step - loss: 0.5938 - accuracy: 0.1987 - precision_m: 0.5256 - recall_m: 0.2074 - f1_m: 0.2939 - val_loss: 0.5200 - val_accuracy: 0.3279 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00 - val_f1_m: 0.0000e+00\n","Epoch 5/50\n","131/131 [==============================] - 5s 41ms/step - loss: 0.5914 - accuracy: 0.2133 - precision_m: 0.5221 - recall_m: 0.1978 - f1_m: 0.2801 - val_loss: 0.5189 - val_accuracy: 0.3279 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00 - val_f1_m: 0.0000e+00\n","Epoch 6/50\n","131/131 [==============================] - 5s 41ms/step - loss: 0.5897 - accuracy: 0.2093 - precision_m: 0.5311 - recall_m: 0.1911 - f1_m: 0.2766 - val_loss: 0.5197 - val_accuracy: 0.3279 - val_precision_m: 0.5827 - val_recall_m: 0.3938 - val_f1_m: 0.4685\n","Epoch 7/50\n","131/131 [==============================] - 5s 41ms/step - loss: 0.5866 - accuracy: 0.2140 - precision_m: 0.5225 - recall_m: 0.2418 - f1_m: 0.3273 - val_loss: 0.5184 - val_accuracy: 0.3279 - val_precision_m: 0.5827 - val_recall_m: 0.3938 - val_f1_m: 0.4685\n","Epoch 8/50\n","131/131 [==============================] - 5s 41ms/step - loss: 0.5904 - accuracy: 0.2097 - precision_m: 0.5247 - recall_m: 0.2463 - f1_m: 0.3340 - val_loss: 0.5235 - val_accuracy: 0.3279 - val_precision_m: 0.5827 - val_recall_m: 0.3938 - val_f1_m: 0.4685\n","Epoch 9/50\n","131/131 [==============================] - 5s 41ms/step - loss: 0.5922 - accuracy: 0.2151 - precision_m: 0.5383 - recall_m: 0.2159 - f1_m: 0.3040 - val_loss: 0.5157 - val_accuracy: 0.3279 - val_precision_m: 0.5827 - val_recall_m: 0.3938 - val_f1_m: 0.4685\n","Epoch 10/50\n","131/131 [==============================] - 5s 41ms/step - loss: 0.5916 - accuracy: 0.2088 - precision_m: 0.5196 - recall_m: 0.2402 - f1_m: 0.3253 - val_loss: 0.5173 - val_accuracy: 0.3279 - val_precision_m: 0.5827 - val_recall_m: 0.3938 - val_f1_m: 0.4685\n","Epoch 11/50\n","131/131 [==============================] - 5s 42ms/step - loss: 0.5900 - accuracy: 0.2185 - precision_m: 0.5276 - recall_m: 0.2697 - f1_m: 0.3554 - val_loss: 0.5186 - val_accuracy: 0.3279 - val_precision_m: 0.5827 - val_recall_m: 0.3938 - val_f1_m: 0.4685\n","Epoch 00011: early stopping\n","Score for fold 2: loss of 0.565650224685669; accuracy of 25.076335668563843% ;precision_m of 0.5106163024902344 ;recall_m of 0.3112577795982361 ;            f1_m of 0.3850182890892029\n","Epoch 1/50\n","131/131 [==============================] - 7s 45ms/step - loss: 0.6285 - accuracy: 0.1985 - precision_m: 0.4237 - recall_m: 0.1341 - f1_m: 0.1950 - val_loss: 0.5654 - val_accuracy: 0.2822 - val_precision_m: 0.5127 - val_recall_m: 0.3279 - val_f1_m: 0.3987\n","Epoch 2/50\n","131/131 [==============================] - 5s 41ms/step - loss: 0.6056 - accuracy: 0.1958 - precision_m: 0.5097 - recall_m: 0.1563 - f1_m: 0.2337 - val_loss: 0.5642 - val_accuracy: 0.2822 - val_precision_m: 0.5127 - val_recall_m: 0.3279 - val_f1_m: 0.3987\n","Epoch 3/50\n","131/131 [==============================] - 5s 41ms/step - loss: 0.6084 - accuracy: 0.1735 - precision_m: 0.5148 - recall_m: 0.2149 - f1_m: 0.3009 - val_loss: 0.5556 - val_accuracy: 0.2822 - val_precision_m: 0.5127 - val_recall_m: 0.3279 - val_f1_m: 0.3987\n","Epoch 4/50\n","131/131 [==============================] - 5s 41ms/step - loss: 0.6076 - accuracy: 0.1881 - precision_m: 0.5115 - recall_m: 0.1891 - f1_m: 0.2722 - val_loss: 0.5614 - val_accuracy: 0.2822 - val_precision_m: 0.5127 - val_recall_m: 0.3279 - val_f1_m: 0.3987\n","Epoch 5/50\n","131/131 [==============================] - 5s 41ms/step - loss: 0.6053 - accuracy: 0.1817 - precision_m: 0.4956 - recall_m: 0.1810 - f1_m: 0.2599 - val_loss: 0.5579 - val_accuracy: 0.2822 - val_precision_m: 0.5127 - val_recall_m: 0.3279 - val_f1_m: 0.3987\n","Epoch 6/50\n","131/131 [==============================] - 5s 41ms/step - loss: 0.6036 - accuracy: 0.1819 - precision_m: 0.5034 - recall_m: 0.1425 - f1_m: 0.2142 - val_loss: 0.5631 - val_accuracy: 0.2822 - val_precision_m: 0.5127 - val_recall_m: 0.3279 - val_f1_m: 0.3987\n","Epoch 7/50\n","131/131 [==============================] - 5s 41ms/step - loss: 0.6048 - accuracy: 0.1830 - precision_m: 0.5181 - recall_m: 0.2271 - f1_m: 0.3127 - val_loss: 0.5596 - val_accuracy: 0.2822 - val_precision_m: 0.5127 - val_recall_m: 0.3279 - val_f1_m: 0.3987\n","Epoch 8/50\n","131/131 [==============================] - 5s 41ms/step - loss: 0.6050 - accuracy: 0.1892 - precision_m: 0.5263 - recall_m: 0.2272 - f1_m: 0.3144 - val_loss: 0.5568 - val_accuracy: 0.2822 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00 - val_f1_m: 0.0000e+00\n","Epoch 9/50\n","131/131 [==============================] - 5s 41ms/step - loss: 0.6049 - accuracy: 0.1866 - precision_m: 0.5090 - recall_m: 0.1164 - f1_m: 0.1817 - val_loss: 0.5607 - val_accuracy: 0.2822 - val_precision_m: 0.5127 - val_recall_m: 0.3279 - val_f1_m: 0.3987\n","Epoch 10/50\n","131/131 [==============================] - 5s 41ms/step - loss: 0.6058 - accuracy: 0.1861 - precision_m: 0.5101 - recall_m: 0.2277 - f1_m: 0.3121 - val_loss: 0.5565 - val_accuracy: 0.2822 - val_precision_m: 0.5127 - val_recall_m: 0.3279 - val_f1_m: 0.3987\n","Epoch 11/50\n","131/131 [==============================] - 5s 41ms/step - loss: 0.6084 - accuracy: 0.1704 - precision_m: 0.4989 - recall_m: 0.1938 - f1_m: 0.2769 - val_loss: 0.5587 - val_accuracy: 0.2822 - val_precision_m: 0.5127 - val_recall_m: 0.3279 - val_f1_m: 0.3987\n","Epoch 00011: early stopping\n","Score for fold 3: loss of 0.5364972949028015; accuracy of 31.068703532218933% ;precision_m of 0.5502504706382751 ;recall_m of 0.36772269010543823 ;            f1_m of 0.43958553671836853\n","Epoch 1/50\n","131/131 [==============================] - 8s 42ms/step - loss: 0.5760 - accuracy: 0.2565 - precision_m: 0.5085 - recall_m: 0.1681 - f1_m: 0.2335 - val_loss: 0.5079 - val_accuracy: 0.3273 - val_precision_m: 0.5824 - val_recall_m: 0.3934 - val_f1_m: 0.4681\n","Epoch 2/50\n","131/131 [==============================] - 5s 37ms/step - loss: 0.5495 - accuracy: 0.2634 - precision_m: 0.4915 - recall_m: 0.2003 - f1_m: 0.2709 - val_loss: 0.5110 - val_accuracy: 0.3273 - val_precision_m: 0.5824 - val_recall_m: 0.3934 - val_f1_m: 0.4681\n","Epoch 3/50\n","131/131 [==============================] - 5s 37ms/step - loss: 0.5461 - accuracy: 0.2753 - precision_m: 0.5169 - recall_m: 0.2359 - f1_m: 0.3173 - val_loss: 0.4989 - val_accuracy: 0.3273 - val_precision_m: 0.5824 - val_recall_m: 0.3934 - val_f1_m: 0.4681\n","Epoch 4/50\n","131/131 [==============================] - 5s 37ms/step - loss: 0.5427 - accuracy: 0.2713 - precision_m: 0.5113 - recall_m: 0.2580 - f1_m: 0.3359 - val_loss: 0.4982 - val_accuracy: 0.3273 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00 - val_f1_m: 0.0000e+00\n","Epoch 5/50\n","131/131 [==============================] - 5s 37ms/step - loss: 0.5487 - accuracy: 0.2637 - precision_m: 0.5170 - recall_m: 0.2468 - f1_m: 0.3279 - val_loss: 0.4999 - val_accuracy: 0.3273 - val_precision_m: 0.5824 - val_recall_m: 0.3934 - val_f1_m: 0.4681\n","Epoch 6/50\n","131/131 [==============================] - 5s 37ms/step - loss: 0.5395 - accuracy: 0.2853 - precision_m: 0.5361 - recall_m: 0.2713 - f1_m: 0.3550 - val_loss: 0.5015 - val_accuracy: 0.3273 - val_precision_m: 0.5824 - val_recall_m: 0.3934 - val_f1_m: 0.4681\n","Epoch 7/50\n","131/131 [==============================] - 5s 37ms/step - loss: 0.5484 - accuracy: 0.2684 - precision_m: 0.4970 - recall_m: 0.2232 - f1_m: 0.3038 - val_loss: 0.4999 - val_accuracy: 0.3273 - val_precision_m: 0.5824 - val_recall_m: 0.3934 - val_f1_m: 0.4681\n","Epoch 8/50\n","131/131 [==============================] - 5s 37ms/step - loss: 0.5469 - accuracy: 0.2656 - precision_m: 0.5094 - recall_m: 0.2114 - f1_m: 0.2906 - val_loss: 0.5034 - val_accuracy: 0.3273 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00 - val_f1_m: 0.0000e+00\n","Epoch 9/50\n","131/131 [==============================] - 5s 37ms/step - loss: 0.5455 - accuracy: 0.2713 - precision_m: 0.5210 - recall_m: 0.2277 - f1_m: 0.3089 - val_loss: 0.5009 - val_accuracy: 0.3273 - val_precision_m: 0.5824 - val_recall_m: 0.3934 - val_f1_m: 0.4681\n","Epoch 10/50\n","131/131 [==============================] - 5s 37ms/step - loss: 0.5518 - accuracy: 0.2624 - precision_m: 0.5120 - recall_m: 0.2433 - f1_m: 0.3249 - val_loss: 0.4986 - val_accuracy: 0.3273 - val_precision_m: 0.5824 - val_recall_m: 0.3934 - val_f1_m: 0.4681\n","Epoch 11/50\n","131/131 [==============================] - 5s 37ms/step - loss: 0.5446 - accuracy: 0.2696 - precision_m: 0.5308 - recall_m: 0.2721 - f1_m: 0.3525 - val_loss: 0.5004 - val_accuracy: 0.3273 - val_precision_m: 0.5824 - val_recall_m: 0.3934 - val_f1_m: 0.4681\n","Epoch 00011: early stopping\n","Score for fold 1: loss of 0.651780903339386; accuracy of 15.566577017307281% ;precision_m of 0.5127865076065063 ;recall_m of 0.2593536674976349 ;            f1_m of 0.34322670102119446\n","Epoch 1/50\n","131/131 [==============================] - 8s 42ms/step - loss: 0.6110 - accuracy: 0.2219 - precision_m: 0.4050 - recall_m: 0.1316 - f1_m: 0.1883 - val_loss: 0.5312 - val_accuracy: 0.3279 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00 - val_f1_m: 0.0000e+00\n","Epoch 2/50\n","131/131 [==============================] - 5s 36ms/step - loss: 0.5965 - accuracy: 0.1972 - precision_m: 0.4394 - recall_m: 0.1354 - f1_m: 0.1937 - val_loss: 0.5213 - val_accuracy: 0.3279 - val_precision_m: 0.5827 - val_recall_m: 0.3938 - val_f1_m: 0.4685\n","Epoch 3/50\n","131/131 [==============================] - 5s 36ms/step - loss: 0.5969 - accuracy: 0.1963 - precision_m: 0.5291 - recall_m: 0.1943 - f1_m: 0.2720 - val_loss: 0.5222 - val_accuracy: 0.3279 - val_precision_m: 0.5827 - val_recall_m: 0.3938 - val_f1_m: 0.4685\n","Epoch 4/50\n","131/131 [==============================] - 5s 37ms/step - loss: 0.5936 - accuracy: 0.2092 - precision_m: 0.5193 - recall_m: 0.2126 - f1_m: 0.2941 - val_loss: 0.5081 - val_accuracy: 0.3279 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00 - val_f1_m: 0.0000e+00\n","Epoch 5/50\n","131/131 [==============================] - 5s 37ms/step - loss: 0.5986 - accuracy: 0.2074 - precision_m: 0.5128 - recall_m: 0.1969 - f1_m: 0.2778 - val_loss: 0.5252 - val_accuracy: 0.3279 - val_precision_m: 0.5827 - val_recall_m: 0.3938 - val_f1_m: 0.4685\n","Epoch 6/50\n","131/131 [==============================] - 5s 37ms/step - loss: 0.5920 - accuracy: 0.2053 - precision_m: 0.5133 - recall_m: 0.2075 - f1_m: 0.2908 - val_loss: 0.5261 - val_accuracy: 0.3279 - val_precision_m: 0.5827 - val_recall_m: 0.3938 - val_f1_m: 0.4685\n","Epoch 7/50\n","131/131 [==============================] - 5s 38ms/step - loss: 0.5941 - accuracy: 0.2038 - precision_m: 0.5150 - recall_m: 0.2004 - f1_m: 0.2836 - val_loss: 0.5255 - val_accuracy: 0.3279 - val_precision_m: 0.5827 - val_recall_m: 0.3938 - val_f1_m: 0.4685\n","Epoch 8/50\n","131/131 [==============================] - 5s 37ms/step - loss: 0.5906 - accuracy: 0.2183 - precision_m: 0.5210 - recall_m: 0.2302 - f1_m: 0.3172 - val_loss: 0.5200 - val_accuracy: 0.3279 - val_precision_m: 0.5827 - val_recall_m: 0.3938 - val_f1_m: 0.4685\n","Epoch 9/50\n","131/131 [==============================] - 5s 38ms/step - loss: 0.5934 - accuracy: 0.2026 - precision_m: 0.5010 - recall_m: 0.1887 - f1_m: 0.2669 - val_loss: 0.5227 - val_accuracy: 0.3279 - val_precision_m: 0.5827 - val_recall_m: 0.3938 - val_f1_m: 0.4685\n","Epoch 10/50\n","131/131 [==============================] - 5s 37ms/step - loss: 0.5867 - accuracy: 0.2165 - precision_m: 0.5243 - recall_m: 0.2421 - f1_m: 0.3250 - val_loss: 0.5247 - val_accuracy: 0.3279 - val_precision_m: 0.5827 - val_recall_m: 0.3938 - val_f1_m: 0.4685\n","Epoch 11/50\n","131/131 [==============================] - 5s 37ms/step - loss: 0.5943 - accuracy: 0.2040 - precision_m: 0.5207 - recall_m: 0.1944 - f1_m: 0.2764 - val_loss: 0.5187 - val_accuracy: 0.3279 - val_precision_m: 0.5827 - val_recall_m: 0.3938 - val_f1_m: 0.4685\n","Epoch 12/50\n","131/131 [==============================] - 5s 37ms/step - loss: 0.5925 - accuracy: 0.2146 - precision_m: 0.5195 - recall_m: 0.2244 - f1_m: 0.3083 - val_loss: 0.5118 - val_accuracy: 0.3279 - val_precision_m: 0.5827 - val_recall_m: 0.3938 - val_f1_m: 0.4685\n","Epoch 00012: early stopping\n","Score for fold 2: loss of 0.566263735294342; accuracy of 25.076335668563843% ;precision_m of 0.5106163024902344 ;recall_m of 0.3112577795982361 ;            f1_m of 0.3850182890892029\n","Epoch 1/50\n","131/131 [==============================] - 8s 42ms/step - loss: 0.6183 - accuracy: 0.1921 - precision_m: 0.4507 - recall_m: 0.1620 - f1_m: 0.2281 - val_loss: 0.5545 - val_accuracy: 0.2822 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00 - val_f1_m: 0.0000e+00\n","Epoch 2/50\n","131/131 [==============================] - 5s 37ms/step - loss: 0.6075 - accuracy: 0.1871 - precision_m: 0.5141 - recall_m: 0.1450 - f1_m: 0.2157 - val_loss: 0.5612 - val_accuracy: 0.2822 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00 - val_f1_m: 0.0000e+00\n","Epoch 3/50\n","131/131 [==============================] - 5s 37ms/step - loss: 0.6091 - accuracy: 0.1839 - precision_m: 0.5225 - recall_m: 0.1594 - f1_m: 0.2307 - val_loss: 0.5603 - val_accuracy: 0.2822 - val_precision_m: 0.5127 - val_recall_m: 0.3279 - val_f1_m: 0.3987\n","Epoch 4/50\n","131/131 [==============================] - 5s 37ms/step - loss: 0.6078 - accuracy: 0.1829 - precision_m: 0.5050 - recall_m: 0.1969 - f1_m: 0.2755 - val_loss: 0.5623 - val_accuracy: 0.2822 - val_precision_m: 0.5127 - val_recall_m: 0.3279 - val_f1_m: 0.3987\n","Epoch 5/50\n","131/131 [==============================] - 5s 37ms/step - loss: 0.6062 - accuracy: 0.1846 - precision_m: 0.4578 - recall_m: 0.1778 - f1_m: 0.2468 - val_loss: 0.5604 - val_accuracy: 0.2822 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00 - val_f1_m: 0.0000e+00\n","Epoch 6/50\n","131/131 [==============================] - 5s 37ms/step - loss: 0.6048 - accuracy: 0.1874 - precision_m: 0.4705 - recall_m: 0.1669 - f1_m: 0.2403 - val_loss: 0.5590 - val_accuracy: 0.2822 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00 - val_f1_m: 0.0000e+00\n","Epoch 7/50\n","131/131 [==============================] - 5s 37ms/step - loss: 0.6048 - accuracy: 0.1821 - precision_m: 0.5165 - recall_m: 0.1553 - f1_m: 0.2278 - val_loss: 0.5607 - val_accuracy: 0.2822 - val_precision_m: 0.5127 - val_recall_m: 0.3279 - val_f1_m: 0.3987\n","Epoch 8/50\n","131/131 [==============================] - 5s 37ms/step - loss: 0.6045 - accuracy: 0.1849 - precision_m: 0.5269 - recall_m: 0.2012 - f1_m: 0.2834 - val_loss: 0.5609 - val_accuracy: 0.2822 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00 - val_f1_m: 0.0000e+00\n","Epoch 9/50\n","131/131 [==============================] - 5s 37ms/step - loss: 0.6055 - accuracy: 0.1794 - precision_m: 0.3901 - recall_m: 0.1299 - f1_m: 0.1876 - val_loss: 0.5588 - val_accuracy: 0.2822 - val_precision_m: 0.5127 - val_recall_m: 0.3279 - val_f1_m: 0.3987\n","Epoch 10/50\n","131/131 [==============================] - 5s 37ms/step - loss: 0.6043 - accuracy: 0.1929 - precision_m: 0.5258 - recall_m: 0.2279 - f1_m: 0.3137 - val_loss: 0.5580 - val_accuracy: 0.2822 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00 - val_f1_m: 0.0000e+00\n","Epoch 11/50\n","131/131 [==============================] - 5s 37ms/step - loss: 0.6053 - accuracy: 0.1846 - precision_m: 0.5391 - recall_m: 0.1199 - f1_m: 0.1885 - val_loss: 0.5576 - val_accuracy: 0.2822 - val_precision_m: 0.5127 - val_recall_m: 0.3279 - val_f1_m: 0.3987\n","Epoch 12/50\n","131/131 [==============================] - 5s 37ms/step - loss: 0.6063 - accuracy: 0.1720 - precision_m: 0.5077 - recall_m: 0.2033 - f1_m: 0.2852 - val_loss: 0.5604 - val_accuracy: 0.2822 - val_precision_m: 0.5127 - val_recall_m: 0.3279 - val_f1_m: 0.3987\n","Epoch 13/50\n","131/131 [==============================] - 5s 37ms/step - loss: 0.6085 - accuracy: 0.1809 - precision_m: 0.5153 - recall_m: 0.1939 - f1_m: 0.2729 - val_loss: 0.5550 - val_accuracy: 0.2822 - val_precision_m: 0.5127 - val_recall_m: 0.3279 - val_f1_m: 0.3987\n","Epoch 00013: early stopping\n","Score for fold 3: loss of 0.5295855402946472; accuracy of 31.068703532218933% ;precision_m of 0.5502504706382751 ;recall_m of 0.36772269010543823 ;            f1_m of 0.43958553671836853\n","Epoch 1/50\n","131/131 [==============================] - 8s 45ms/step - loss: 0.5764 - accuracy: 0.2643 - precision_m: 0.4873 - recall_m: 0.1776 - f1_m: 0.2437 - val_loss: 0.5020 - val_accuracy: 0.3273 - val_precision_m: 0.5824 - val_recall_m: 0.3934 - val_f1_m: 0.4681\n","Epoch 2/50\n","131/131 [==============================] - 5s 39ms/step - loss: 0.5480 - accuracy: 0.2739 - precision_m: 0.5062 - recall_m: 0.2189 - f1_m: 0.2939 - val_loss: 0.5041 - val_accuracy: 0.3273 - val_precision_m: 0.5824 - val_recall_m: 0.3934 - val_f1_m: 0.4681\n","Epoch 3/50\n","131/131 [==============================] - 5s 39ms/step - loss: 0.5453 - accuracy: 0.2792 - precision_m: 0.5298 - recall_m: 0.2539 - f1_m: 0.3371 - val_loss: 0.5007 - val_accuracy: 0.3273 - val_precision_m: 0.5824 - val_recall_m: 0.3934 - val_f1_m: 0.4681\n","Epoch 4/50\n","131/131 [==============================] - 5s 39ms/step - loss: 0.5453 - accuracy: 0.2742 - precision_m: 0.5246 - recall_m: 0.2469 - f1_m: 0.3253 - val_loss: 0.5062 - val_accuracy: 0.3273 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00 - val_f1_m: 0.0000e+00\n","Epoch 5/50\n","131/131 [==============================] - 5s 39ms/step - loss: 0.5467 - accuracy: 0.2623 - precision_m: 0.4931 - recall_m: 0.1570 - f1_m: 0.2265 - val_loss: 0.5049 - val_accuracy: 0.3273 - val_precision_m: 0.5824 - val_recall_m: 0.3934 - val_f1_m: 0.4681\n","Epoch 6/50\n","131/131 [==============================] - 5s 39ms/step - loss: 0.5452 - accuracy: 0.2745 - precision_m: 0.5268 - recall_m: 0.2703 - f1_m: 0.3526 - val_loss: 0.5049 - val_accuracy: 0.3273 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00 - val_f1_m: 0.0000e+00\n","Epoch 7/50\n","131/131 [==============================] - 5s 39ms/step - loss: 0.5452 - accuracy: 0.2695 - precision_m: 0.5096 - recall_m: 0.1929 - f1_m: 0.2654 - val_loss: 0.4986 - val_accuracy: 0.3273 - val_precision_m: 0.5824 - val_recall_m: 0.3934 - val_f1_m: 0.4681\n","Epoch 8/50\n","131/131 [==============================] - 5s 39ms/step - loss: 0.5502 - accuracy: 0.2701 - precision_m: 0.5098 - recall_m: 0.2265 - f1_m: 0.3081 - val_loss: 0.5020 - val_accuracy: 0.3273 - val_precision_m: 0.5824 - val_recall_m: 0.3934 - val_f1_m: 0.4681\n","Epoch 9/50\n","131/131 [==============================] - 5s 39ms/step - loss: 0.5474 - accuracy: 0.2625 - precision_m: 0.5284 - recall_m: 0.2342 - f1_m: 0.3132 - val_loss: 0.5019 - val_accuracy: 0.3273 - val_precision_m: 0.5824 - val_recall_m: 0.3934 - val_f1_m: 0.4681\n","Epoch 10/50\n","131/131 [==============================] - 5s 39ms/step - loss: 0.5479 - accuracy: 0.2575 - precision_m: 0.5121 - recall_m: 0.2430 - f1_m: 0.3256 - val_loss: 0.5035 - val_accuracy: 0.3273 - val_precision_m: 0.5824 - val_recall_m: 0.3934 - val_f1_m: 0.4681\n","Epoch 11/50\n","131/131 [==============================] - 5s 39ms/step - loss: 0.5470 - accuracy: 0.2647 - precision_m: 0.5109 - recall_m: 0.2219 - f1_m: 0.2986 - val_loss: 0.4984 - val_accuracy: 0.3273 - val_precision_m: 0.5824 - val_recall_m: 0.3934 - val_f1_m: 0.4681\n","Epoch 00011: early stopping\n","Score for fold 1: loss of 0.6511787176132202; accuracy of 15.566577017307281% ;precision_m of 0.5127865076065063 ;recall_m of 0.2593536674976349 ;            f1_m of 0.34322670102119446\n","Epoch 1/50\n","131/131 [==============================] - 8s 45ms/step - loss: 0.6110 - accuracy: 0.2165 - precision_m: 0.4765 - recall_m: 0.1663 - f1_m: 0.2329 - val_loss: 0.5330 - val_accuracy: 0.3279 - val_precision_m: 0.5827 - val_recall_m: 0.3938 - val_f1_m: 0.4685\n","Epoch 2/50\n","131/131 [==============================] - 5s 39ms/step - loss: 0.5979 - accuracy: 0.2028 - precision_m: 0.4334 - recall_m: 0.1581 - f1_m: 0.2163 - val_loss: 0.5129 - val_accuracy: 0.3279 - val_precision_m: 0.5827 - val_recall_m: 0.3938 - val_f1_m: 0.4685\n","Epoch 3/50\n","131/131 [==============================] - 5s 39ms/step - loss: 0.5930 - accuracy: 0.2175 - precision_m: 0.5367 - recall_m: 0.2319 - f1_m: 0.3094 - val_loss: 0.5180 - val_accuracy: 0.3279 - val_precision_m: 0.5827 - val_recall_m: 0.3938 - val_f1_m: 0.4685\n","Epoch 4/50\n","131/131 [==============================] - 5s 39ms/step - loss: 0.5973 - accuracy: 0.1979 - precision_m: 0.5052 - recall_m: 0.1916 - f1_m: 0.2662 - val_loss: 0.5273 - val_accuracy: 0.3279 - val_precision_m: 0.5827 - val_recall_m: 0.3938 - val_f1_m: 0.4685\n","Epoch 5/50\n","131/131 [==============================] - 5s 39ms/step - loss: 0.5950 - accuracy: 0.2006 - precision_m: 0.5276 - recall_m: 0.1851 - f1_m: 0.2608 - val_loss: 0.5118 - val_accuracy: 0.3279 - val_precision_m: 0.5827 - val_recall_m: 0.3938 - val_f1_m: 0.4685\n","Epoch 6/50\n","131/131 [==============================] - 5s 39ms/step - loss: 0.5907 - accuracy: 0.2091 - precision_m: 0.5296 - recall_m: 0.2381 - f1_m: 0.3241 - val_loss: 0.5202 - val_accuracy: 0.3279 - val_precision_m: 0.5827 - val_recall_m: 0.3938 - val_f1_m: 0.4685\n","Epoch 7/50\n","131/131 [==============================] - 5s 39ms/step - loss: 0.5891 - accuracy: 0.2127 - precision_m: 0.5253 - recall_m: 0.2446 - f1_m: 0.3306 - val_loss: 0.5249 - val_accuracy: 0.3279 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00 - val_f1_m: 0.0000e+00\n","Epoch 8/50\n","131/131 [==============================] - 5s 39ms/step - loss: 0.5938 - accuracy: 0.2021 - precision_m: 0.5233 - recall_m: 0.1633 - f1_m: 0.2413 - val_loss: 0.5163 - val_accuracy: 0.3279 - val_precision_m: 0.5827 - val_recall_m: 0.3938 - val_f1_m: 0.4685\n","Epoch 9/50\n","131/131 [==============================] - 5s 39ms/step - loss: 0.5934 - accuracy: 0.2037 - precision_m: 0.5190 - recall_m: 0.1809 - f1_m: 0.2601 - val_loss: 0.5129 - val_accuracy: 0.3279 - val_precision_m: 0.5827 - val_recall_m: 0.3938 - val_f1_m: 0.4685\n","Epoch 10/50\n","131/131 [==============================] - 5s 39ms/step - loss: 0.5898 - accuracy: 0.2118 - precision_m: 0.5126 - recall_m: 0.2302 - f1_m: 0.3141 - val_loss: 0.5230 - val_accuracy: 0.3279 - val_precision_m: 0.5827 - val_recall_m: 0.3938 - val_f1_m: 0.4685\n","Epoch 11/50\n","131/131 [==============================] - 5s 39ms/step - loss: 0.5937 - accuracy: 0.2065 - precision_m: 0.5060 - recall_m: 0.1910 - f1_m: 0.2684 - val_loss: 0.5229 - val_accuracy: 0.3279 - val_precision_m: 0.5827 - val_recall_m: 0.3938 - val_f1_m: 0.4685\n","Epoch 00011: early stopping\n","Score for fold 2: loss of 0.5674834251403809; accuracy of 25.076335668563843% ;precision_m of 0.5106163024902344 ;recall_m of 0.3112577795982361 ;            f1_m of 0.3850182890892029\n","Epoch 1/50\n","131/131 [==============================] - 8s 45ms/step - loss: 0.6254 - accuracy: 0.1925 - precision_m: 0.4748 - recall_m: 0.1397 - f1_m: 0.2042 - val_loss: 0.5558 - val_accuracy: 0.2822 - val_precision_m: 0.5127 - val_recall_m: 0.3279 - val_f1_m: 0.3987\n","Epoch 2/50\n","131/131 [==============================] - 5s 39ms/step - loss: 0.6089 - accuracy: 0.1746 - precision_m: 0.5066 - recall_m: 0.1383 - f1_m: 0.2005 - val_loss: 0.5769 - val_accuracy: 0.2822 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00 - val_f1_m: 0.0000e+00\n","Epoch 3/50\n","131/131 [==============================] - 5s 39ms/step - loss: 0.6083 - accuracy: 0.1835 - precision_m: 0.5177 - recall_m: 0.1545 - f1_m: 0.2330 - val_loss: 0.5567 - val_accuracy: 0.2822 - val_precision_m: 0.5127 - val_recall_m: 0.3279 - val_f1_m: 0.3987\n","Epoch 4/50\n","131/131 [==============================] - 5s 39ms/step - loss: 0.6054 - accuracy: 0.1824 - precision_m: 0.5053 - recall_m: 0.1728 - f1_m: 0.2482 - val_loss: 0.5623 - val_accuracy: 0.2822 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00 - val_f1_m: 0.0000e+00\n","Epoch 5/50\n","131/131 [==============================] - 5s 39ms/step - loss: 0.6039 - accuracy: 0.1829 - precision_m: 0.4434 - recall_m: 0.1152 - f1_m: 0.1746 - val_loss: 0.5618 - val_accuracy: 0.2822 - val_precision_m: 0.5127 - val_recall_m: 0.3279 - val_f1_m: 0.3987\n","Epoch 6/50\n","131/131 [==============================] - 5s 39ms/step - loss: 0.6067 - accuracy: 0.1864 - precision_m: 0.5250 - recall_m: 0.2183 - f1_m: 0.3023 - val_loss: 0.5603 - val_accuracy: 0.2822 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00 - val_f1_m: 0.0000e+00\n","Epoch 7/50\n","131/131 [==============================] - 5s 39ms/step - loss: 0.6041 - accuracy: 0.1833 - precision_m: 0.5385 - recall_m: 0.1271 - f1_m: 0.1864 - val_loss: 0.5578 - val_accuracy: 0.2822 - val_precision_m: 0.5127 - val_recall_m: 0.3279 - val_f1_m: 0.3987\n","Epoch 8/50\n","131/131 [==============================] - 5s 39ms/step - loss: 0.6059 - accuracy: 0.1781 - precision_m: 0.5145 - recall_m: 0.1914 - f1_m: 0.2751 - val_loss: 0.5597 - val_accuracy: 0.2822 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00 - val_f1_m: 0.0000e+00\n","Epoch 9/50\n","131/131 [==============================] - 5s 39ms/step - loss: 0.6049 - accuracy: 0.1828 - precision_m: 0.5225 - recall_m: 0.1987 - f1_m: 0.2806 - val_loss: 0.5732 - val_accuracy: 0.2822 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00 - val_f1_m: 0.0000e+00\n","Epoch 10/50\n","131/131 [==============================] - 5s 39ms/step - loss: 0.6064 - accuracy: 0.1864 - precision_m: 0.4712 - recall_m: 0.1293 - f1_m: 0.1868 - val_loss: 0.5577 - val_accuracy: 0.2822 - val_precision_m: 0.5127 - val_recall_m: 0.3279 - val_f1_m: 0.3987\n","Epoch 11/50\n","131/131 [==============================] - 5s 39ms/step - loss: 0.6049 - accuracy: 0.1769 - precision_m: 0.5041 - recall_m: 0.1948 - f1_m: 0.2756 - val_loss: 0.5596 - val_accuracy: 0.2822 - val_precision_m: 0.5127 - val_recall_m: 0.3279 - val_f1_m: 0.3987\n","Epoch 00011: early stopping\n","Score for fold 3: loss of 0.5354101061820984; accuracy of 31.068703532218933% ;precision_m of 0.5502504706382751 ;recall_m of 0.36772269010543823 ;            f1_m of 0.43958553671836853\n","Epoch 1/50\n","131/131 [==============================] - 8s 47ms/step - loss: 0.5781 - accuracy: 0.2598 - precision_m: 0.4647 - recall_m: 0.1824 - f1_m: 0.2430 - val_loss: 0.5087 - val_accuracy: 0.3273 - val_precision_m: 0.5824 - val_recall_m: 0.3934 - val_f1_m: 0.4681\n","Epoch 2/50\n","131/131 [==============================] - 5s 41ms/step - loss: 0.5476 - accuracy: 0.2683 - precision_m: 0.5166 - recall_m: 0.1674 - f1_m: 0.2390 - val_loss: 0.4974 - val_accuracy: 0.3273 - val_precision_m: 0.5824 - val_recall_m: 0.3934 - val_f1_m: 0.4681\n","Epoch 3/50\n","131/131 [==============================] - 5s 42ms/step - loss: 0.5472 - accuracy: 0.2699 - precision_m: 0.5166 - recall_m: 0.2301 - f1_m: 0.3132 - val_loss: 0.5018 - val_accuracy: 0.3273 - val_precision_m: 0.5824 - val_recall_m: 0.3934 - val_f1_m: 0.4681\n","Epoch 4/50\n","131/131 [==============================] - 5s 42ms/step - loss: 0.5479 - accuracy: 0.2740 - precision_m: 0.5187 - recall_m: 0.2254 - f1_m: 0.3062 - val_loss: 0.5018 - val_accuracy: 0.3273 - val_precision_m: 0.5824 - val_recall_m: 0.3934 - val_f1_m: 0.4681\n","Epoch 5/50\n","131/131 [==============================] - 5s 42ms/step - loss: 0.5497 - accuracy: 0.2694 - precision_m: 0.5199 - recall_m: 0.2441 - f1_m: 0.3237 - val_loss: 0.5054 - val_accuracy: 0.3273 - val_precision_m: 0.5824 - val_recall_m: 0.3934 - val_f1_m: 0.4681\n","Epoch 6/50\n","131/131 [==============================] - 6s 42ms/step - loss: 0.5462 - accuracy: 0.2658 - precision_m: 0.5026 - recall_m: 0.1912 - f1_m: 0.2641 - val_loss: 0.4992 - val_accuracy: 0.3273 - val_precision_m: 0.5824 - val_recall_m: 0.3934 - val_f1_m: 0.4681\n","Epoch 7/50\n","131/131 [==============================] - 5s 41ms/step - loss: 0.5433 - accuracy: 0.2715 - precision_m: 0.5170 - recall_m: 0.2794 - f1_m: 0.3592 - val_loss: 0.5037 - val_accuracy: 0.3273 - val_precision_m: 0.5824 - val_recall_m: 0.3934 - val_f1_m: 0.4681\n","Epoch 8/50\n","131/131 [==============================] - 5s 42ms/step - loss: 0.5454 - accuracy: 0.2673 - precision_m: 0.5283 - recall_m: 0.2691 - f1_m: 0.3462 - val_loss: 0.4956 - val_accuracy: 0.3273 - val_precision_m: 0.5824 - val_recall_m: 0.3934 - val_f1_m: 0.4681\n","Epoch 9/50\n","131/131 [==============================] - 5s 42ms/step - loss: 0.5499 - accuracy: 0.2655 - precision_m: 0.5184 - recall_m: 0.2766 - f1_m: 0.3589 - val_loss: 0.5007 - val_accuracy: 0.3273 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00 - val_f1_m: 0.0000e+00\n","Epoch 10/50\n","131/131 [==============================] - 5s 42ms/step - loss: 0.5443 - accuracy: 0.2730 - precision_m: 0.5165 - recall_m: 0.2114 - f1_m: 0.2927 - val_loss: 0.4972 - val_accuracy: 0.3273 - val_precision_m: 0.5824 - val_recall_m: 0.3934 - val_f1_m: 0.4681\n","Epoch 11/50\n","131/131 [==============================] - 5s 41ms/step - loss: 0.5378 - accuracy: 0.2922 - precision_m: 0.5251 - recall_m: 0.3015 - f1_m: 0.3798 - val_loss: 0.5001 - val_accuracy: 0.3273 - val_precision_m: 0.5824 - val_recall_m: 0.3934 - val_f1_m: 0.4681\n","Epoch 00011: early stopping\n","Score for fold 1: loss of 0.6535155773162842; accuracy of 15.566577017307281% ;precision_m of 0.5127865076065063 ;recall_m of 0.2593536674976349 ;            f1_m of 0.34322670102119446\n","Epoch 1/50\n","131/131 [==============================] - 8s 48ms/step - loss: 0.6110 - accuracy: 0.2105 - precision_m: 0.5021 - recall_m: 0.1979 - f1_m: 0.2779 - val_loss: 0.5307 - val_accuracy: 0.3279 - val_precision_m: 0.5827 - val_recall_m: 0.3938 - val_f1_m: 0.4685\n","Epoch 2/50\n","131/131 [==============================] - 5s 42ms/step - loss: 0.5930 - accuracy: 0.2225 - precision_m: 0.5381 - recall_m: 0.2237 - f1_m: 0.3097 - val_loss: 0.5301 - val_accuracy: 0.3279 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00 - val_f1_m: 0.0000e+00\n","Epoch 3/50\n","131/131 [==============================] - 5s 41ms/step - loss: 0.5968 - accuracy: 0.2112 - precision_m: 0.5043 - recall_m: 0.1717 - f1_m: 0.2453 - val_loss: 0.5276 - val_accuracy: 0.3279 - val_precision_m: 0.5827 - val_recall_m: 0.3938 - val_f1_m: 0.4685\n","Epoch 4/50\n","131/131 [==============================] - 5s 41ms/step - loss: 0.5956 - accuracy: 0.2139 - precision_m: 0.5246 - recall_m: 0.2377 - f1_m: 0.3227 - val_loss: 0.5167 - val_accuracy: 0.3279 - val_precision_m: 0.5827 - val_recall_m: 0.3938 - val_f1_m: 0.4685\n","Epoch 5/50\n","131/131 [==============================] - 5s 41ms/step - loss: 0.5867 - accuracy: 0.2138 - precision_m: 0.5332 - recall_m: 0.2366 - f1_m: 0.3238 - val_loss: 0.5206 - val_accuracy: 0.3279 - val_precision_m: 0.5827 - val_recall_m: 0.3938 - val_f1_m: 0.4685\n","Epoch 6/50\n","131/131 [==============================] - 5s 41ms/step - loss: 0.5916 - accuracy: 0.2056 - precision_m: 0.5344 - recall_m: 0.2171 - f1_m: 0.3019 - val_loss: 0.5203 - val_accuracy: 0.3279 - val_precision_m: 0.5827 - val_recall_m: 0.3938 - val_f1_m: 0.4685\n","Epoch 7/50\n","131/131 [==============================] - 5s 42ms/step - loss: 0.5918 - accuracy: 0.2114 - precision_m: 0.5290 - recall_m: 0.2401 - f1_m: 0.3253 - val_loss: 0.5116 - val_accuracy: 0.3279 - val_precision_m: 0.5827 - val_recall_m: 0.3938 - val_f1_m: 0.4685\n","Epoch 8/50\n","131/131 [==============================] - 5s 41ms/step - loss: 0.5928 - accuracy: 0.2079 - precision_m: 0.5206 - recall_m: 0.2450 - f1_m: 0.3298 - val_loss: 0.5202 - val_accuracy: 0.3279 - val_precision_m: 0.5827 - val_recall_m: 0.3938 - val_f1_m: 0.4685\n","Epoch 9/50\n","131/131 [==============================] - 5s 41ms/step - loss: 0.5948 - accuracy: 0.1965 - precision_m: 0.5247 - recall_m: 0.1956 - f1_m: 0.2762 - val_loss: 0.5129 - val_accuracy: 0.3279 - val_precision_m: 0.5827 - val_recall_m: 0.3938 - val_f1_m: 0.4685\n","Epoch 10/50\n","131/131 [==============================] - 5s 42ms/step - loss: 0.5919 - accuracy: 0.2032 - precision_m: 0.5121 - recall_m: 0.2020 - f1_m: 0.2812 - val_loss: 0.5176 - val_accuracy: 0.3279 - val_precision_m: 0.5827 - val_recall_m: 0.3938 - val_f1_m: 0.4685\n","Epoch 11/50\n","131/131 [==============================] - 5s 41ms/step - loss: 0.5903 - accuracy: 0.2168 - precision_m: 0.5336 - recall_m: 0.2481 - f1_m: 0.3281 - val_loss: 0.5203 - val_accuracy: 0.3279 - val_precision_m: 0.5827 - val_recall_m: 0.3938 - val_f1_m: 0.4685\n","Epoch 00011: early stopping\n","Score for fold 2: loss of 0.5673454999923706; accuracy of 25.076335668563843% ;precision_m of 0.5106163024902344 ;recall_m of 0.3112577795982361 ;            f1_m of 0.3850182890892029\n","Epoch 1/50\n","131/131 [==============================] - 8s 47ms/step - loss: 0.6206 - accuracy: 0.1848 - precision_m: 0.4950 - recall_m: 0.1766 - f1_m: 0.2457 - val_loss: 0.5574 - val_accuracy: 0.2822 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00 - val_f1_m: 0.0000e+00\n","Epoch 2/50\n","131/131 [==============================] - 5s 41ms/step - loss: 0.6080 - accuracy: 0.1794 - precision_m: 0.5129 - recall_m: 0.2018 - f1_m: 0.2844 - val_loss: 0.5746 - val_accuracy: 0.2822 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00 - val_f1_m: 0.0000e+00\n","Epoch 3/50\n","131/131 [==============================] - 5s 41ms/step - loss: 0.6069 - accuracy: 0.1907 - precision_m: 0.5081 - recall_m: 0.1623 - f1_m: 0.2314 - val_loss: 0.5556 - val_accuracy: 0.2822 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00 - val_f1_m: 0.0000e+00\n","Epoch 4/50\n","131/131 [==============================] - 5s 41ms/step - loss: 0.6076 - accuracy: 0.1738 - precision_m: 0.5196 - recall_m: 0.1989 - f1_m: 0.2769 - val_loss: 0.5508 - val_accuracy: 0.2822 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00 - val_f1_m: 0.0000e+00\n","Epoch 5/50\n","131/131 [==============================] - 5s 42ms/step - loss: 0.6040 - accuracy: 0.1880 - precision_m: 0.5321 - recall_m: 0.1716 - f1_m: 0.2457 - val_loss: 0.5674 - val_accuracy: 0.2822 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00 - val_f1_m: 0.0000e+00\n","Epoch 6/50\n","131/131 [==============================] - 5s 41ms/step - loss: 0.6068 - accuracy: 0.1818 - precision_m: 0.5016 - recall_m: 0.1571 - f1_m: 0.2288 - val_loss: 0.5613 - val_accuracy: 0.2822 - val_precision_m: 0.5127 - val_recall_m: 0.3279 - val_f1_m: 0.3987\n","Epoch 7/50\n","131/131 [==============================] - 5s 41ms/step - loss: 0.6038 - accuracy: 0.1859 - precision_m: 0.5167 - recall_m: 0.1739 - f1_m: 0.2540 - val_loss: 0.5599 - val_accuracy: 0.2822 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00 - val_f1_m: 0.0000e+00\n","Epoch 8/50\n","131/131 [==============================] - 5s 42ms/step - loss: 0.6067 - accuracy: 0.1754 - precision_m: 0.5423 - recall_m: 0.1339 - f1_m: 0.1885 - val_loss: 0.5626 - val_accuracy: 0.2822 - val_precision_m: 0.5127 - val_recall_m: 0.3279 - val_f1_m: 0.3987\n","Epoch 9/50\n","131/131 [==============================] - 5s 41ms/step - loss: 0.6068 - accuracy: 0.1858 - precision_m: 0.5211 - recall_m: 0.2341 - f1_m: 0.3180 - val_loss: 0.5598 - val_accuracy: 0.2822 - val_precision_m: 0.5127 - val_recall_m: 0.3279 - val_f1_m: 0.3987\n","Epoch 10/50\n","131/131 [==============================] - 5s 41ms/step - loss: 0.6046 - accuracy: 0.1802 - precision_m: 0.4998 - recall_m: 0.1714 - f1_m: 0.2502 - val_loss: 0.5638 - val_accuracy: 0.2822 - val_precision_m: 0.5127 - val_recall_m: 0.3279 - val_f1_m: 0.3987\n","Epoch 11/50\n","131/131 [==============================] - 5s 42ms/step - loss: 0.6059 - accuracy: 0.1840 - precision_m: 0.5147 - recall_m: 0.2199 - f1_m: 0.3017 - val_loss: 0.5609 - val_accuracy: 0.2822 - val_precision_m: 0.5127 - val_recall_m: 0.3279 - val_f1_m: 0.3987\n","Epoch 12/50\n","131/131 [==============================] - 5s 41ms/step - loss: 0.6080 - accuracy: 0.1802 - precision_m: 0.5125 - recall_m: 0.1300 - f1_m: 0.1868 - val_loss: 0.5597 - val_accuracy: 0.2822 - val_precision_m: 0.5127 - val_recall_m: 0.3279 - val_f1_m: 0.3987\n","Epoch 13/50\n","131/131 [==============================] - 5s 42ms/step - loss: 0.6025 - accuracy: 0.1840 - precision_m: 0.5100 - recall_m: 0.1985 - f1_m: 0.2789 - val_loss: 0.5597 - val_accuracy: 0.2822 - val_precision_m: 0.5127 - val_recall_m: 0.3279 - val_f1_m: 0.3987\n","Epoch 14/50\n","131/131 [==============================] - 5s 42ms/step - loss: 0.6055 - accuracy: 0.1905 - precision_m: 0.5184 - recall_m: 0.2138 - f1_m: 0.3001 - val_loss: 0.5621 - val_accuracy: 0.2822 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00 - val_f1_m: 0.0000e+00\n","Epoch 15/50\n","131/131 [==============================] - 5s 41ms/step - loss: 0.6067 - accuracy: 0.1871 - precision_m: 0.4878 - recall_m: 0.1085 - f1_m: 0.1657 - val_loss: 0.5594 - val_accuracy: 0.2822 - val_precision_m: 0.5127 - val_recall_m: 0.3279 - val_f1_m: 0.3987\n","Epoch 16/50\n","131/131 [==============================] - 5s 42ms/step - loss: 0.6035 - accuracy: 0.1868 - precision_m: 0.5009 - recall_m: 0.1901 - f1_m: 0.2682 - val_loss: 0.5646 - val_accuracy: 0.2822 - val_precision_m: 0.5127 - val_recall_m: 0.3279 - val_f1_m: 0.3987\n","Epoch 00016: early stopping\n","Score for fold 3: loss of 0.5431152582168579; accuracy of 31.068703532218933% ;precision_m of 0.5502504706382751 ;recall_m of 0.36772269010543823 ;            f1_m of 0.43958553671836853\n","Epoch 1/50\n","131/131 [==============================] - 8s 42ms/step - loss: 0.5800 - accuracy: 0.2522 - precision_m: 0.4535 - recall_m: 0.1734 - f1_m: 0.2334 - val_loss: 0.5008 - val_accuracy: 0.3273 - val_precision_m: 0.5824 - val_recall_m: 0.3934 - val_f1_m: 0.4681\n","Epoch 2/50\n","131/131 [==============================] - 5s 37ms/step - loss: 0.5501 - accuracy: 0.2644 - precision_m: 0.4889 - recall_m: 0.1824 - f1_m: 0.2522 - val_loss: 0.5077 - val_accuracy: 0.3273 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00 - val_f1_m: 0.0000e+00\n","Epoch 3/50\n","131/131 [==============================] - 5s 37ms/step - loss: 0.5510 - accuracy: 0.2656 - precision_m: 0.5108 - recall_m: 0.1705 - f1_m: 0.2308 - val_loss: 0.4998 - val_accuracy: 0.3273 - val_precision_m: 0.5824 - val_recall_m: 0.3934 - val_f1_m: 0.4681\n","Epoch 4/50\n","131/131 [==============================] - 5s 37ms/step - loss: 0.5501 - accuracy: 0.2669 - precision_m: 0.4830 - recall_m: 0.1756 - f1_m: 0.2436 - val_loss: 0.5027 - val_accuracy: 0.3273 - val_precision_m: 0.5824 - val_recall_m: 0.3934 - val_f1_m: 0.4681\n","Epoch 5/50\n","131/131 [==============================] - 5s 37ms/step - loss: 0.5454 - accuracy: 0.2816 - precision_m: 0.4866 - recall_m: 0.2668 - f1_m: 0.3376 - val_loss: 0.4967 - val_accuracy: 0.3273 - val_precision_m: 0.5824 - val_recall_m: 0.3934 - val_f1_m: 0.4681\n","Epoch 6/50\n","131/131 [==============================] - 5s 37ms/step - loss: 0.5454 - accuracy: 0.2738 - precision_m: 0.5102 - recall_m: 0.2526 - f1_m: 0.3278 - val_loss: 0.5000 - val_accuracy: 0.3273 - val_precision_m: 0.5824 - val_recall_m: 0.3934 - val_f1_m: 0.4681\n","Epoch 7/50\n","131/131 [==============================] - 5s 37ms/step - loss: 0.5460 - accuracy: 0.2688 - precision_m: 0.5134 - recall_m: 0.1828 - f1_m: 0.2623 - val_loss: 0.5018 - val_accuracy: 0.3273 - val_precision_m: 0.5824 - val_recall_m: 0.3934 - val_f1_m: 0.4681\n","Epoch 8/50\n","131/131 [==============================] - 5s 37ms/step - loss: 0.5502 - accuracy: 0.2635 - precision_m: 0.5175 - recall_m: 0.2762 - f1_m: 0.3550 - val_loss: 0.5028 - val_accuracy: 0.3273 - val_precision_m: 0.5824 - val_recall_m: 0.3934 - val_f1_m: 0.4681\n","Epoch 9/50\n","131/131 [==============================] - 5s 37ms/step - loss: 0.5466 - accuracy: 0.2750 - precision_m: 0.5145 - recall_m: 0.2176 - f1_m: 0.2902 - val_loss: 0.4977 - val_accuracy: 0.3273 - val_precision_m: 0.5824 - val_recall_m: 0.3934 - val_f1_m: 0.4681\n","Epoch 10/50\n","131/131 [==============================] - 5s 36ms/step - loss: 0.5465 - accuracy: 0.2756 - precision_m: 0.5202 - recall_m: 0.2508 - f1_m: 0.3323 - val_loss: 0.4988 - val_accuracy: 0.3273 - val_precision_m: 0.5824 - val_recall_m: 0.3934 - val_f1_m: 0.4681\n","Epoch 11/50\n","131/131 [==============================] - 5s 37ms/step - loss: 0.5447 - accuracy: 0.2716 - precision_m: 0.5275 - recall_m: 0.2528 - f1_m: 0.3278 - val_loss: 0.5007 - val_accuracy: 0.3273 - val_precision_m: 0.5824 - val_recall_m: 0.3934 - val_f1_m: 0.4681\n","Epoch 00011: early stopping\n","Score for fold 1: loss of 0.6542403101921082; accuracy of 15.566577017307281% ;precision_m of 0.5127865076065063 ;recall_m of 0.2593536674976349 ;            f1_m of 0.34322670102119446\n","Epoch 1/50\n","131/131 [==============================] - 8s 46ms/step - loss: 0.6062 - accuracy: 0.2260 - precision_m: 0.4605 - recall_m: 0.1725 - f1_m: 0.2422 - val_loss: 0.5256 - val_accuracy: 0.3279 - val_precision_m: 0.5827 - val_recall_m: 0.3938 - val_f1_m: 0.4685\n","Epoch 2/50\n","131/131 [==============================] - 5s 37ms/step - loss: 0.5962 - accuracy: 0.2045 - precision_m: 0.5208 - recall_m: 0.1982 - f1_m: 0.2771 - val_loss: 0.5252 - val_accuracy: 0.3279 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00 - val_f1_m: 0.0000e+00\n","Epoch 3/50\n","131/131 [==============================] - 5s 37ms/step - loss: 0.5940 - accuracy: 0.2077 - precision_m: 0.5340 - recall_m: 0.1791 - f1_m: 0.2560 - val_loss: 0.5273 - val_accuracy: 0.3279 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00 - val_f1_m: 0.0000e+00\n","Epoch 4/50\n","131/131 [==============================] - 5s 37ms/step - loss: 0.5887 - accuracy: 0.2136 - precision_m: 0.5264 - recall_m: 0.2263 - f1_m: 0.3107 - val_loss: 0.5219 - val_accuracy: 0.3279 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00 - val_f1_m: 0.0000e+00\n","Epoch 5/50\n","131/131 [==============================] - 5s 37ms/step - loss: 0.5880 - accuracy: 0.2173 - precision_m: 0.5284 - recall_m: 0.2040 - f1_m: 0.2868 - val_loss: 0.5318 - val_accuracy: 0.3279 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00 - val_f1_m: 0.0000e+00\n","Epoch 6/50\n","131/131 [==============================] - 5s 37ms/step - loss: 0.5892 - accuracy: 0.2102 - precision_m: 0.5371 - recall_m: 0.1944 - f1_m: 0.2734 - val_loss: 0.5263 - val_accuracy: 0.3279 - val_precision_m: 0.5827 - val_recall_m: 0.3938 - val_f1_m: 0.4685\n","Epoch 7/50\n","131/131 [==============================] - 5s 37ms/step - loss: 0.5906 - accuracy: 0.2153 - precision_m: 0.5241 - recall_m: 0.2286 - f1_m: 0.3099 - val_loss: 0.5121 - val_accuracy: 0.3279 - val_precision_m: 0.5827 - val_recall_m: 0.3938 - val_f1_m: 0.4685\n","Epoch 8/50\n","131/131 [==============================] - 5s 37ms/step - loss: 0.5952 - accuracy: 0.2045 - precision_m: 0.5115 - recall_m: 0.1786 - f1_m: 0.2556 - val_loss: 0.5132 - val_accuracy: 0.3279 - val_precision_m: 0.5827 - val_recall_m: 0.3938 - val_f1_m: 0.4685\n","Epoch 9/50\n","131/131 [==============================] - 5s 37ms/step - loss: 0.5949 - accuracy: 0.1981 - precision_m: 0.5165 - recall_m: 0.2222 - f1_m: 0.3058 - val_loss: 0.5176 - val_accuracy: 0.3279 - val_precision_m: 0.5827 - val_recall_m: 0.3938 - val_f1_m: 0.4685\n","Epoch 10/50\n","131/131 [==============================] - 5s 37ms/step - loss: 0.5907 - accuracy: 0.2106 - precision_m: 0.5298 - recall_m: 0.2390 - f1_m: 0.3247 - val_loss: 0.5148 - val_accuracy: 0.3279 - val_precision_m: 0.5827 - val_recall_m: 0.3938 - val_f1_m: 0.4685\n","Epoch 11/50\n","131/131 [==============================] - 5s 37ms/step - loss: 0.5957 - accuracy: 0.2008 - precision_m: 0.4581 - recall_m: 0.1873 - f1_m: 0.2555 - val_loss: 0.5214 - val_accuracy: 0.3279 - val_precision_m: 0.5827 - val_recall_m: 0.3938 - val_f1_m: 0.4685\n","Epoch 00011: early stopping\n","Score for fold 2: loss of 0.5675931572914124; accuracy of 25.076335668563843% ;precision_m of 0.5106163024902344 ;recall_m of 0.3112577795982361 ;            f1_m of 0.3850182890892029\n","Epoch 1/50\n","131/131 [==============================] - 8s 43ms/step - loss: 0.6247 - accuracy: 0.1926 - precision_m: 0.3998 - recall_m: 0.1651 - f1_m: 0.2257 - val_loss: 0.5618 - val_accuracy: 0.2822 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00 - val_f1_m: 0.0000e+00\n","Epoch 2/50\n","131/131 [==============================] - 5s 37ms/step - loss: 0.6095 - accuracy: 0.1891 - precision_m: 0.5320 - recall_m: 0.1554 - f1_m: 0.2284 - val_loss: 0.5541 - val_accuracy: 0.2822 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00 - val_f1_m: 0.0000e+00\n","Epoch 3/50\n","131/131 [==============================] - 5s 37ms/step - loss: 0.6073 - accuracy: 0.1874 - precision_m: 0.5083 - recall_m: 0.1724 - f1_m: 0.2496 - val_loss: 0.5616 - val_accuracy: 0.2822 - val_precision_m: 0.5127 - val_recall_m: 0.3279 - val_f1_m: 0.3987\n","Epoch 4/50\n","131/131 [==============================] - 5s 37ms/step - loss: 0.6097 - accuracy: 0.1834 - precision_m: 0.4984 - recall_m: 0.1871 - f1_m: 0.2649 - val_loss: 0.5568 - val_accuracy: 0.2822 - val_precision_m: 0.5127 - val_recall_m: 0.3279 - val_f1_m: 0.3987\n","Epoch 5/50\n","131/131 [==============================] - 5s 36ms/step - loss: 0.6074 - accuracy: 0.1819 - precision_m: 0.5226 - recall_m: 0.2058 - f1_m: 0.2851 - val_loss: 0.5562 - val_accuracy: 0.2822 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00 - val_f1_m: 0.0000e+00\n","Epoch 6/50\n","131/131 [==============================] - 5s 37ms/step - loss: 0.6028 - accuracy: 0.1899 - precision_m: 0.5085 - recall_m: 0.1907 - f1_m: 0.2718 - val_loss: 0.5530 - val_accuracy: 0.2822 - val_precision_m: 0.5127 - val_recall_m: 0.3279 - val_f1_m: 0.3987\n","Epoch 7/50\n","131/131 [==============================] - 5s 37ms/step - loss: 0.6040 - accuracy: 0.1834 - precision_m: 0.5116 - recall_m: 0.2076 - f1_m: 0.2868 - val_loss: 0.5654 - val_accuracy: 0.2822 - val_precision_m: 0.5127 - val_recall_m: 0.3279 - val_f1_m: 0.3987\n","Epoch 8/50\n","131/131 [==============================] - 5s 37ms/step - loss: 0.6069 - accuracy: 0.1829 - precision_m: 0.5016 - recall_m: 0.2265 - f1_m: 0.3068 - val_loss: 0.5573 - val_accuracy: 0.2822 - val_precision_m: 0.5127 - val_recall_m: 0.3279 - val_f1_m: 0.3987\n","Epoch 9/50\n","131/131 [==============================] - 5s 37ms/step - loss: 0.5999 - accuracy: 0.1906 - precision_m: 0.5036 - recall_m: 0.1851 - f1_m: 0.2627 - val_loss: 0.5607 - val_accuracy: 0.2822 - val_precision_m: 0.5127 - val_recall_m: 0.3279 - val_f1_m: 0.3987\n","Epoch 10/50\n","131/131 [==============================] - 5s 37ms/step - loss: 0.6033 - accuracy: 0.1971 - precision_m: 0.5067 - recall_m: 0.1608 - f1_m: 0.2354 - val_loss: 0.5590 - val_accuracy: 0.2822 - val_precision_m: 0.5127 - val_recall_m: 0.3279 - val_f1_m: 0.3987\n","Epoch 11/50\n","131/131 [==============================] - 5s 37ms/step - loss: 0.6075 - accuracy: 0.1812 - precision_m: 0.5023 - recall_m: 0.1900 - f1_m: 0.2620 - val_loss: 0.5627 - val_accuracy: 0.2822 - val_precision_m: 0.5127 - val_recall_m: 0.3279 - val_f1_m: 0.3987\n","Epoch 12/50\n","131/131 [==============================] - 5s 37ms/step - loss: 0.6032 - accuracy: 0.2031 - precision_m: 0.5291 - recall_m: 0.2365 - f1_m: 0.3175 - val_loss: 0.5593 - val_accuracy: 0.2822 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00 - val_f1_m: 0.0000e+00\n","Epoch 13/50\n","131/131 [==============================] - 5s 37ms/step - loss: 0.6059 - accuracy: 0.1787 - precision_m: 0.5017 - recall_m: 0.1833 - f1_m: 0.2573 - val_loss: 0.5627 - val_accuracy: 0.2822 - val_precision_m: 0.5127 - val_recall_m: 0.3279 - val_f1_m: 0.3987\n","Epoch 00013: early stopping\n","Score for fold 3: loss of 0.5417149066925049; accuracy of 31.068703532218933% ;precision_m of 0.5502504706382751 ;recall_m of 0.36772269010543823 ;            f1_m of 0.43958553671836853\n","Epoch 1/50\n","131/131 [==============================] - 8s 45ms/step - loss: 0.5743 - accuracy: 0.2676 - precision_m: 0.4566 - recall_m: 0.1731 - f1_m: 0.2340 - val_loss: 0.4998 - val_accuracy: 0.3273 - val_precision_m: 0.5824 - val_recall_m: 0.3934 - val_f1_m: 0.4681\n","Epoch 2/50\n","131/131 [==============================] - 5s 39ms/step - loss: 0.5426 - accuracy: 0.2804 - precision_m: 0.5267 - recall_m: 0.2440 - f1_m: 0.3241 - val_loss: 0.5042 - val_accuracy: 0.3273 - val_precision_m: 0.5824 - val_recall_m: 0.3934 - val_f1_m: 0.4681\n","Epoch 3/50\n","131/131 [==============================] - 5s 40ms/step - loss: 0.5510 - accuracy: 0.2676 - precision_m: 0.5128 - recall_m: 0.2108 - f1_m: 0.2927 - val_loss: 0.5040 - val_accuracy: 0.3273 - val_precision_m: 0.5824 - val_recall_m: 0.3934 - val_f1_m: 0.4681\n","Epoch 4/50\n","131/131 [==============================] - 5s 40ms/step - loss: 0.5456 - accuracy: 0.2681 - precision_m: 0.5173 - recall_m: 0.1953 - f1_m: 0.2747 - val_loss: 0.5085 - val_accuracy: 0.3273 - val_precision_m: 0.5824 - val_recall_m: 0.3934 - val_f1_m: 0.4681\n","Epoch 5/50\n","131/131 [==============================] - 5s 39ms/step - loss: 0.5498 - accuracy: 0.2617 - precision_m: 0.4986 - recall_m: 0.2224 - f1_m: 0.2984 - val_loss: 0.5076 - val_accuracy: 0.3273 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00 - val_f1_m: 0.0000e+00\n","Epoch 6/50\n","131/131 [==============================] - 5s 39ms/step - loss: 0.5496 - accuracy: 0.2627 - precision_m: 0.5121 - recall_m: 0.2034 - f1_m: 0.2814 - val_loss: 0.5020 - val_accuracy: 0.3273 - val_precision_m: 0.5824 - val_recall_m: 0.3934 - val_f1_m: 0.4681\n","Epoch 7/50\n","131/131 [==============================] - 5s 39ms/step - loss: 0.5468 - accuracy: 0.2687 - precision_m: 0.5101 - recall_m: 0.1779 - f1_m: 0.2515 - val_loss: 0.4989 - val_accuracy: 0.3273 - val_precision_m: 0.5824 - val_recall_m: 0.3934 - val_f1_m: 0.4681\n","Epoch 8/50\n","131/131 [==============================] - 5s 39ms/step - loss: 0.5467 - accuracy: 0.2700 - precision_m: 0.5141 - recall_m: 0.2469 - f1_m: 0.3297 - val_loss: 0.4997 - val_accuracy: 0.3273 - val_precision_m: 0.5824 - val_recall_m: 0.3934 - val_f1_m: 0.4681\n","Epoch 9/50\n","131/131 [==============================] - 5s 39ms/step - loss: 0.5434 - accuracy: 0.2783 - precision_m: 0.5257 - recall_m: 0.2852 - f1_m: 0.3662 - val_loss: 0.5020 - val_accuracy: 0.3273 - val_precision_m: 0.5824 - val_recall_m: 0.3934 - val_f1_m: 0.4681\n","Epoch 10/50\n","131/131 [==============================] - 5s 39ms/step - loss: 0.5415 - accuracy: 0.2798 - precision_m: 0.5315 - recall_m: 0.2289 - f1_m: 0.3154 - val_loss: 0.4989 - val_accuracy: 0.3273 - val_precision_m: 0.5824 - val_recall_m: 0.3934 - val_f1_m: 0.4681\n","Epoch 11/50\n","131/131 [==============================] - 5s 39ms/step - loss: 0.5499 - accuracy: 0.2582 - precision_m: 0.5072 - recall_m: 0.2280 - f1_m: 0.3073 - val_loss: 0.4983 - val_accuracy: 0.3273 - val_precision_m: 0.5824 - val_recall_m: 0.3934 - val_f1_m: 0.4681\n","Epoch 00011: early stopping\n","Score for fold 1: loss of 0.6518191695213318; accuracy of 15.566577017307281% ;precision_m of 0.5127865076065063 ;recall_m of 0.2593536674976349 ;            f1_m of 0.34322670102119446\n","Epoch 1/50\n","131/131 [==============================] - 8s 45ms/step - loss: 0.6114 - accuracy: 0.2042 - precision_m: 0.4927 - recall_m: 0.2005 - f1_m: 0.2761 - val_loss: 0.5303 - val_accuracy: 0.3279 - val_precision_m: 0.5827 - val_recall_m: 0.3938 - val_f1_m: 0.4685\n","Epoch 2/50\n","131/131 [==============================] - 5s 39ms/step - loss: 0.5931 - accuracy: 0.2173 - precision_m: 0.5435 - recall_m: 0.2079 - f1_m: 0.2885 - val_loss: 0.5104 - val_accuracy: 0.3279 - val_precision_m: 0.5827 - val_recall_m: 0.3938 - val_f1_m: 0.4685\n","Epoch 3/50\n","131/131 [==============================] - 5s 39ms/step - loss: 0.5909 - accuracy: 0.2162 - precision_m: 0.5251 - recall_m: 0.2206 - f1_m: 0.3014 - val_loss: 0.5333 - val_accuracy: 0.3279 - val_precision_m: 0.5827 - val_recall_m: 0.3938 - val_f1_m: 0.4685\n","Epoch 4/50\n","131/131 [==============================] - 5s 39ms/step - loss: 0.5918 - accuracy: 0.2232 - precision_m: 0.5175 - recall_m: 0.2187 - f1_m: 0.3015 - val_loss: 0.5287 - val_accuracy: 0.3279 - val_precision_m: 0.5827 - val_recall_m: 0.3938 - val_f1_m: 0.4685\n","Epoch 5/50\n","131/131 [==============================] - 5s 39ms/step - loss: 0.5961 - accuracy: 0.2095 - precision_m: 0.5035 - recall_m: 0.1761 - f1_m: 0.2498 - val_loss: 0.5064 - val_accuracy: 0.3279 - val_precision_m: 0.5827 - val_recall_m: 0.3938 - val_f1_m: 0.4685\n","Epoch 6/50\n","131/131 [==============================] - 5s 39ms/step - loss: 0.5937 - accuracy: 0.2079 - precision_m: 0.5126 - recall_m: 0.2185 - f1_m: 0.3018 - val_loss: 0.5261 - val_accuracy: 0.3279 - val_precision_m: 0.5827 - val_recall_m: 0.3938 - val_f1_m: 0.4685\n","Epoch 7/50\n","131/131 [==============================] - 5s 39ms/step - loss: 0.5898 - accuracy: 0.2085 - precision_m: 0.5184 - recall_m: 0.2267 - f1_m: 0.3117 - val_loss: 0.5173 - val_accuracy: 0.3279 - val_precision_m: 0.5827 - val_recall_m: 0.3938 - val_f1_m: 0.4685\n","Epoch 8/50\n","131/131 [==============================] - 5s 39ms/step - loss: 0.5867 - accuracy: 0.2251 - precision_m: 0.5334 - recall_m: 0.2708 - f1_m: 0.3561 - val_loss: 0.5283 - val_accuracy: 0.3279 - val_precision_m: 0.5827 - val_recall_m: 0.3938 - val_f1_m: 0.4685\n","Epoch 9/50\n","131/131 [==============================] - 5s 39ms/step - loss: 0.5955 - accuracy: 0.2020 - precision_m: 0.5072 - recall_m: 0.2046 - f1_m: 0.2864 - val_loss: 0.5217 - val_accuracy: 0.3279 - val_precision_m: 0.5827 - val_recall_m: 0.3938 - val_f1_m: 0.4685\n","Epoch 10/50\n","131/131 [==============================] - 5s 39ms/step - loss: 0.5937 - accuracy: 0.2088 - precision_m: 0.5177 - recall_m: 0.2311 - f1_m: 0.3144 - val_loss: 0.5273 - val_accuracy: 0.3279 - val_precision_m: 0.5827 - val_recall_m: 0.3938 - val_f1_m: 0.4685\n","Epoch 11/50\n","131/131 [==============================] - 5s 39ms/step - loss: 0.5925 - accuracy: 0.2105 - precision_m: 0.5143 - recall_m: 0.2177 - f1_m: 0.3026 - val_loss: 0.5240 - val_accuracy: 0.3279 - val_precision_m: 0.5827 - val_recall_m: 0.3938 - val_f1_m: 0.4685\n","Epoch 00011: early stopping\n","Score for fold 2: loss of 0.567862331867218; accuracy of 25.076335668563843% ;precision_m of 0.5106163024902344 ;recall_m of 0.3112577795982361 ;            f1_m of 0.3850182890892029\n","Epoch 1/50\n","131/131 [==============================] - 8s 45ms/step - loss: 0.6233 - accuracy: 0.1889 - precision_m: 0.4937 - recall_m: 0.1740 - f1_m: 0.2422 - val_loss: 0.5868 - val_accuracy: 0.2822 - val_precision_m: 0.5127 - val_recall_m: 0.3279 - val_f1_m: 0.3987\n","Epoch 2/50\n","131/131 [==============================] - 5s 40ms/step - loss: 0.6094 - accuracy: 0.1868 - precision_m: 0.5069 - recall_m: 0.1747 - f1_m: 0.2489 - val_loss: 0.5597 - val_accuracy: 0.2822 - val_precision_m: 0.5127 - val_recall_m: 0.3279 - val_f1_m: 0.3987\n","Epoch 3/50\n","131/131 [==============================] - 5s 39ms/step - loss: 0.6053 - accuracy: 0.1968 - precision_m: 0.5118 - recall_m: 0.2140 - f1_m: 0.2967 - val_loss: 0.5582 - val_accuracy: 0.2822 - val_precision_m: 0.5127 - val_recall_m: 0.3279 - val_f1_m: 0.3987\n","Epoch 4/50\n","131/131 [==============================] - 5s 39ms/step - loss: 0.6082 - accuracy: 0.1795 - precision_m: 0.4692 - recall_m: 0.1407 - f1_m: 0.2006 - val_loss: 0.5617 - val_accuracy: 0.2822 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00 - val_f1_m: 0.0000e+00\n","Epoch 5/50\n","131/131 [==============================] - 5s 39ms/step - loss: 0.6094 - accuracy: 0.1705 - precision_m: 0.5127 - recall_m: 0.1505 - f1_m: 0.2240 - val_loss: 0.5738 - val_accuracy: 0.2822 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00 - val_f1_m: 0.0000e+00\n","Epoch 6/50\n","131/131 [==============================] - 5s 39ms/step - loss: 0.6105 - accuracy: 0.1726 - precision_m: 0.4964 - recall_m: 0.1471 - f1_m: 0.2190 - val_loss: 0.5618 - val_accuracy: 0.2822 - val_precision_m: 0.5127 - val_recall_m: 0.3279 - val_f1_m: 0.3987\n","Epoch 7/50\n","131/131 [==============================] - 5s 39ms/step - loss: 0.6069 - accuracy: 0.1829 - precision_m: 0.5028 - recall_m: 0.1797 - f1_m: 0.2554 - val_loss: 0.5589 - val_accuracy: 0.2822 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00 - val_f1_m: 0.0000e+00\n","Epoch 8/50\n","131/131 [==============================] - 5s 39ms/step - loss: 0.6025 - accuracy: 0.1929 - precision_m: 0.5111 - recall_m: 0.1844 - f1_m: 0.2638 - val_loss: 0.5584 - val_accuracy: 0.2822 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00 - val_f1_m: 0.0000e+00\n","Epoch 9/50\n","131/131 [==============================] - 5s 39ms/step - loss: 0.6080 - accuracy: 0.1813 - precision_m: 0.5261 - recall_m: 0.1996 - f1_m: 0.2849 - val_loss: 0.5618 - val_accuracy: 0.2822 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00 - val_f1_m: 0.0000e+00\n","Epoch 10/50\n","131/131 [==============================] - 5s 39ms/step - loss: 0.6047 - accuracy: 0.1851 - precision_m: 0.5043 - recall_m: 0.1303 - f1_m: 0.1949 - val_loss: 0.5573 - val_accuracy: 0.2822 - val_precision_m: 0.5127 - val_recall_m: 0.3279 - val_f1_m: 0.3987\n","Epoch 11/50\n","131/131 [==============================] - 5s 39ms/step - loss: 0.6078 - accuracy: 0.1744 - precision_m: 0.5026 - recall_m: 0.1938 - f1_m: 0.2749 - val_loss: 0.5548 - val_accuracy: 0.2822 - val_precision_m: 0.5127 - val_recall_m: 0.3279 - val_f1_m: 0.3987\n","Epoch 00011: early stopping\n","Score for fold 3: loss of 0.5307552218437195; accuracy of 31.068703532218933% ;precision_m of 0.5502504706382751 ;recall_m of 0.36772269010543823 ;            f1_m of 0.43958553671836853\n","Epoch 1/50\n","131/131 [==============================] - 8s 47ms/step - loss: 0.5743 - accuracy: 0.2700 - precision_m: 0.4562 - recall_m: 0.1906 - f1_m: 0.2543 - val_loss: 0.5041 - val_accuracy: 0.3273 - val_precision_m: 0.5824 - val_recall_m: 0.3934 - val_f1_m: 0.4681\n","Epoch 2/50\n","131/131 [==============================] - 5s 42ms/step - loss: 0.5509 - accuracy: 0.2724 - precision_m: 0.5205 - recall_m: 0.2120 - f1_m: 0.2922 - val_loss: 0.5132 - val_accuracy: 0.3273 - val_precision_m: 0.5824 - val_recall_m: 0.3934 - val_f1_m: 0.4681\n","Epoch 3/50\n","131/131 [==============================] - 5s 42ms/step - loss: 0.5483 - accuracy: 0.2696 - precision_m: 0.5114 - recall_m: 0.2158 - f1_m: 0.2897 - val_loss: 0.5010 - val_accuracy: 0.3273 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00 - val_f1_m: 0.0000e+00\n","Epoch 4/50\n","131/131 [==============================] - 5s 42ms/step - loss: 0.5493 - accuracy: 0.2716 - precision_m: 0.5176 - recall_m: 0.2281 - f1_m: 0.3117 - val_loss: 0.5007 - val_accuracy: 0.3273 - val_precision_m: 0.5824 - val_recall_m: 0.3934 - val_f1_m: 0.4681\n","Epoch 5/50\n","131/131 [==============================] - 5s 42ms/step - loss: 0.5432 - accuracy: 0.2770 - precision_m: 0.5276 - recall_m: 0.2409 - f1_m: 0.3220 - val_loss: 0.5045 - val_accuracy: 0.3273 - val_precision_m: 0.5824 - val_recall_m: 0.3934 - val_f1_m: 0.4681\n","Epoch 6/50\n","131/131 [==============================] - 5s 42ms/step - loss: 0.5460 - accuracy: 0.2712 - precision_m: 0.5343 - recall_m: 0.2313 - f1_m: 0.3174 - val_loss: 0.4994 - val_accuracy: 0.3273 - val_precision_m: 0.5824 - val_recall_m: 0.3934 - val_f1_m: 0.4681\n","Epoch 7/50\n","131/131 [==============================] - 5s 42ms/step - loss: 0.5495 - accuracy: 0.2692 - precision_m: 0.5035 - recall_m: 0.1756 - f1_m: 0.2509 - val_loss: 0.4977 - val_accuracy: 0.3273 - val_precision_m: 0.5824 - val_recall_m: 0.3934 - val_f1_m: 0.4681\n","Epoch 8/50\n","131/131 [==============================] - 5s 42ms/step - loss: 0.5471 - accuracy: 0.2600 - precision_m: 0.5122 - recall_m: 0.2711 - f1_m: 0.3519 - val_loss: 0.5010 - val_accuracy: 0.3273 - val_precision_m: 0.5824 - val_recall_m: 0.3934 - val_f1_m: 0.4681\n","Epoch 9/50\n","131/131 [==============================] - 5s 42ms/step - loss: 0.5447 - accuracy: 0.2727 - precision_m: 0.5248 - recall_m: 0.2499 - f1_m: 0.3312 - val_loss: 0.4988 - val_accuracy: 0.3273 - val_precision_m: 0.5824 - val_recall_m: 0.3934 - val_f1_m: 0.4681\n","Epoch 10/50\n","131/131 [==============================] - 5s 42ms/step - loss: 0.5460 - accuracy: 0.2649 - precision_m: 0.5041 - recall_m: 0.2070 - f1_m: 0.2859 - val_loss: 0.5012 - val_accuracy: 0.3273 - val_precision_m: 0.5824 - val_recall_m: 0.3934 - val_f1_m: 0.4681\n","Epoch 11/50\n","131/131 [==============================] - 5s 41ms/step - loss: 0.5410 - accuracy: 0.2848 - precision_m: 0.5368 - recall_m: 0.3055 - f1_m: 0.3866 - val_loss: 0.5024 - val_accuracy: 0.3273 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00 - val_f1_m: 0.0000e+00\n","Epoch 00011: early stopping\n","Score for fold 1: loss of 0.65293288230896; accuracy of 15.566577017307281% ;precision_m of 0.0 ;recall_m of 0.0 ;            f1_m of 0.0\n","Epoch 1/50\n","131/131 [==============================] - 8s 47ms/step - loss: 0.6148 - accuracy: 0.2052 - precision_m: 0.4801 - recall_m: 0.1625 - f1_m: 0.2320 - val_loss: 0.5220 - val_accuracy: 0.3279 - val_precision_m: 0.5827 - val_recall_m: 0.3938 - val_f1_m: 0.4685\n","Epoch 2/50\n","131/131 [==============================] - 5s 42ms/step - loss: 0.5924 - accuracy: 0.2079 - precision_m: 0.5105 - recall_m: 0.1609 - f1_m: 0.2264 - val_loss: 0.5074 - val_accuracy: 0.3279 - val_precision_m: 0.5827 - val_recall_m: 0.3938 - val_f1_m: 0.4685\n","Epoch 3/50\n","131/131 [==============================] - 5s 42ms/step - loss: 0.5945 - accuracy: 0.2115 - precision_m: 0.5242 - recall_m: 0.2240 - f1_m: 0.3090 - val_loss: 0.5222 - val_accuracy: 0.3279 - val_precision_m: 0.5827 - val_recall_m: 0.3938 - val_f1_m: 0.4685\n","Epoch 4/50\n","131/131 [==============================] - 5s 42ms/step - loss: 0.5896 - accuracy: 0.2167 - precision_m: 0.5292 - recall_m: 0.2486 - f1_m: 0.3336 - val_loss: 0.5404 - val_accuracy: 0.3279 - val_precision_m: 0.5827 - val_recall_m: 0.3938 - val_f1_m: 0.4685\n","Epoch 5/50\n","131/131 [==============================] - 5s 42ms/step - loss: 0.5874 - accuracy: 0.2287 - precision_m: 0.5259 - recall_m: 0.2097 - f1_m: 0.2904 - val_loss: 0.5206 - val_accuracy: 0.3279 - val_precision_m: 0.5827 - val_recall_m: 0.3938 - val_f1_m: 0.4685\n","Epoch 6/50\n","131/131 [==============================] - 5s 42ms/step - loss: 0.5891 - accuracy: 0.2047 - precision_m: 0.5214 - recall_m: 0.2439 - f1_m: 0.3270 - val_loss: 0.5180 - val_accuracy: 0.3279 - val_precision_m: 0.5827 - val_recall_m: 0.3938 - val_f1_m: 0.4685\n","Epoch 7/50\n","131/131 [==============================] - 5s 41ms/step - loss: 0.5876 - accuracy: 0.2183 - precision_m: 0.5314 - recall_m: 0.2427 - f1_m: 0.3255 - val_loss: 0.5239 - val_accuracy: 0.3279 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00 - val_f1_m: 0.0000e+00\n","Epoch 8/50\n","131/131 [==============================] - 5s 42ms/step - loss: 0.5912 - accuracy: 0.2164 - precision_m: 0.5181 - recall_m: 0.1819 - f1_m: 0.2616 - val_loss: 0.5206 - val_accuracy: 0.3279 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00 - val_f1_m: 0.0000e+00\n","Epoch 9/50\n","131/131 [==============================] - 5s 42ms/step - loss: 0.5939 - accuracy: 0.2009 - precision_m: 0.5208 - recall_m: 0.1943 - f1_m: 0.2774 - val_loss: 0.5186 - val_accuracy: 0.3279 - val_precision_m: 0.5827 - val_recall_m: 0.3938 - val_f1_m: 0.4685\n","Epoch 10/50\n","131/131 [==============================] - 5s 41ms/step - loss: 0.5914 - accuracy: 0.2045 - precision_m: 0.5226 - recall_m: 0.2451 - f1_m: 0.3304 - val_loss: 0.5234 - val_accuracy: 0.3279 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00 - val_f1_m: 0.0000e+00\n","Epoch 11/50\n","131/131 [==============================] - 5s 42ms/step - loss: 0.5938 - accuracy: 0.2006 - precision_m: 0.5220 - recall_m: 0.1829 - f1_m: 0.2642 - val_loss: 0.5184 - val_accuracy: 0.3279 - val_precision_m: 0.5827 - val_recall_m: 0.3938 - val_f1_m: 0.4685\n","Epoch 00011: early stopping\n","Score for fold 2: loss of 0.5671349763870239; accuracy of 25.076335668563843% ;precision_m of 0.5106163024902344 ;recall_m of 0.3112577795982361 ;            f1_m of 0.3850182890892029\n","Epoch 1/50\n","131/131 [==============================] - 8s 47ms/step - loss: 0.6212 - accuracy: 0.1915 - precision_m: 0.4587 - recall_m: 0.1590 - f1_m: 0.2209 - val_loss: 0.5582 - val_accuracy: 0.2822 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00 - val_f1_m: 0.0000e+00\n","Epoch 2/50\n","131/131 [==============================] - 5s 42ms/step - loss: 0.6100 - accuracy: 0.1771 - precision_m: 0.5295 - recall_m: 0.1575 - f1_m: 0.2266 - val_loss: 0.5681 - val_accuracy: 0.2822 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00 - val_f1_m: 0.0000e+00\n","Epoch 3/50\n","131/131 [==============================] - 5s 41ms/step - loss: 0.6115 - accuracy: 0.1757 - precision_m: 0.3745 - recall_m: 0.1046 - f1_m: 0.1511 - val_loss: 0.5608 - val_accuracy: 0.2822 - val_precision_m: 0.5127 - val_recall_m: 0.3279 - val_f1_m: 0.3987\n","Epoch 4/50\n","131/131 [==============================] - 5s 41ms/step - loss: 0.6047 - accuracy: 0.1920 - precision_m: 0.5091 - recall_m: 0.2293 - f1_m: 0.3128 - val_loss: 0.5741 - val_accuracy: 0.2822 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00 - val_f1_m: 0.0000e+00\n","Epoch 5/50\n","131/131 [==============================] - 5s 42ms/step - loss: 0.6100 - accuracy: 0.1712 - precision_m: 0.4363 - recall_m: 0.0801 - f1_m: 0.1226 - val_loss: 0.5571 - val_accuracy: 0.2822 - val_precision_m: 0.5127 - val_recall_m: 0.3279 - val_f1_m: 0.3987\n","Epoch 6/50\n","131/131 [==============================] - 5s 42ms/step - loss: 0.6028 - accuracy: 0.1969 - precision_m: 0.5280 - recall_m: 0.1938 - f1_m: 0.2774 - val_loss: 0.5580 - val_accuracy: 0.2822 - val_precision_m: 0.5127 - val_recall_m: 0.3279 - val_f1_m: 0.3987\n","Epoch 7/50\n","131/131 [==============================] - 5s 41ms/step - loss: 0.6105 - accuracy: 0.1774 - precision_m: 0.5043 - recall_m: 0.1774 - f1_m: 0.2572 - val_loss: 0.5568 - val_accuracy: 0.2822 - val_precision_m: 0.5127 - val_recall_m: 0.3279 - val_f1_m: 0.3987\n","Epoch 8/50\n","131/131 [==============================] - 5s 41ms/step - loss: 0.6055 - accuracy: 0.1919 - precision_m: 0.5173 - recall_m: 0.2101 - f1_m: 0.2901 - val_loss: 0.5570 - val_accuracy: 0.2822 - val_precision_m: 0.5127 - val_recall_m: 0.3279 - val_f1_m: 0.3987\n","Epoch 9/50\n","131/131 [==============================] - 5s 41ms/step - loss: 0.6078 - accuracy: 0.1840 - precision_m: 0.5079 - recall_m: 0.2093 - f1_m: 0.2854 - val_loss: 0.5596 - val_accuracy: 0.2822 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00 - val_f1_m: 0.0000e+00\n","Epoch 10/50\n","131/131 [==============================] - 5s 41ms/step - loss: 0.6048 - accuracy: 0.1894 - precision_m: 0.5158 - recall_m: 0.2100 - f1_m: 0.2879 - val_loss: 0.5656 - val_accuracy: 0.2822 - val_precision_m: 0.5127 - val_recall_m: 0.3279 - val_f1_m: 0.3987\n","Epoch 11/50\n","131/131 [==============================] - 5s 41ms/step - loss: 0.6100 - accuracy: 0.1691 - precision_m: 0.4931 - recall_m: 0.1734 - f1_m: 0.2511 - val_loss: 0.5555 - val_accuracy: 0.2822 - val_precision_m: 0.5127 - val_recall_m: 0.3279 - val_f1_m: 0.3987\n","Epoch 12/50\n","131/131 [==============================] - 5s 41ms/step - loss: 0.6067 - accuracy: 0.1873 - precision_m: 0.4800 - recall_m: 0.1989 - f1_m: 0.2693 - val_loss: 0.5613 - val_accuracy: 0.2822 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00 - val_f1_m: 0.0000e+00\n","Epoch 13/50\n","131/131 [==============================] - 5s 41ms/step - loss: 0.6053 - accuracy: 0.1815 - precision_m: 0.5108 - recall_m: 0.1695 - f1_m: 0.2397 - val_loss: 0.5557 - val_accuracy: 0.2822 - val_precision_m: 0.5127 - val_recall_m: 0.3279 - val_f1_m: 0.3987\n","Epoch 00013: early stopping\n","Score for fold 3: loss of 0.531890332698822; accuracy of 31.068703532218933% ;precision_m of 0.5502504706382751 ;recall_m of 0.36772269010543823 ;            f1_m of 0.43958553671836853\n","Epoch 1/50\n","131/131 [==============================] - 8s 42ms/step - loss: 0.5764 - accuracy: 0.2586 - precision_m: 0.4064 - recall_m: 0.1589 - f1_m: 0.2167 - val_loss: 0.4994 - val_accuracy: 0.3273 - val_precision_m: 0.5824 - val_recall_m: 0.3934 - val_f1_m: 0.4681\n","Epoch 2/50\n","131/131 [==============================] - 5s 36ms/step - loss: 0.5563 - accuracy: 0.2589 - precision_m: 0.4306 - recall_m: 0.1757 - f1_m: 0.2356 - val_loss: 0.4982 - val_accuracy: 0.3273 - val_precision_m: 0.5824 - val_recall_m: 0.3934 - val_f1_m: 0.4681\n","Epoch 3/50\n","131/131 [==============================] - 5s 37ms/step - loss: 0.5443 - accuracy: 0.2777 - precision_m: 0.5148 - recall_m: 0.2270 - f1_m: 0.3095 - val_loss: 0.5040 - val_accuracy: 0.3273 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00 - val_f1_m: 0.0000e+00\n","Epoch 4/50\n","131/131 [==============================] - 5s 37ms/step - loss: 0.5503 - accuracy: 0.2598 - precision_m: 0.5280 - recall_m: 0.2207 - f1_m: 0.3050 - val_loss: 0.5008 - val_accuracy: 0.3273 - val_precision_m: 0.5824 - val_recall_m: 0.3934 - val_f1_m: 0.4681\n","Epoch 5/50\n","131/131 [==============================] - 5s 37ms/step - loss: 0.5457 - accuracy: 0.2751 - precision_m: 0.5272 - recall_m: 0.2373 - f1_m: 0.3186 - val_loss: 0.5016 - val_accuracy: 0.3273 - val_precision_m: 0.5824 - val_recall_m: 0.3934 - val_f1_m: 0.4681\n","Epoch 6/50\n","131/131 [==============================] - 5s 37ms/step - loss: 0.5516 - accuracy: 0.2641 - precision_m: 0.4889 - recall_m: 0.1975 - f1_m: 0.2643 - val_loss: 0.5024 - val_accuracy: 0.3273 - val_precision_m: 0.5824 - val_recall_m: 0.3934 - val_f1_m: 0.4681\n","Epoch 7/50\n","131/131 [==============================] - 5s 37ms/step - loss: 0.5403 - accuracy: 0.2804 - precision_m: 0.5363 - recall_m: 0.2037 - f1_m: 0.2782 - val_loss: 0.4969 - val_accuracy: 0.3273 - val_precision_m: 0.5824 - val_recall_m: 0.3934 - val_f1_m: 0.4681\n","Epoch 8/50\n","131/131 [==============================] - 5s 37ms/step - loss: 0.5426 - accuracy: 0.2848 - precision_m: 0.5205 - recall_m: 0.2717 - f1_m: 0.3472 - val_loss: 0.4980 - val_accuracy: 0.3273 - val_precision_m: 0.5824 - val_recall_m: 0.3934 - val_f1_m: 0.4681\n","Epoch 9/50\n","131/131 [==============================] - 5s 37ms/step - loss: 0.5474 - accuracy: 0.2675 - precision_m: 0.5151 - recall_m: 0.2450 - f1_m: 0.3234 - val_loss: 0.4975 - val_accuracy: 0.3273 - val_precision_m: 0.5824 - val_recall_m: 0.3934 - val_f1_m: 0.4681\n","Epoch 10/50\n","131/131 [==============================] - 5s 37ms/step - loss: 0.5456 - accuracy: 0.2709 - precision_m: 0.5107 - recall_m: 0.2515 - f1_m: 0.3320 - val_loss: 0.4960 - val_accuracy: 0.3273 - val_precision_m: 0.5824 - val_recall_m: 0.3934 - val_f1_m: 0.4681\n","Epoch 11/50\n","131/131 [==============================] - 5s 37ms/step - loss: 0.5452 - accuracy: 0.2691 - precision_m: 0.5141 - recall_m: 0.2800 - f1_m: 0.3588 - val_loss: 0.4996 - val_accuracy: 0.3273 - val_precision_m: 0.5824 - val_recall_m: 0.3934 - val_f1_m: 0.4681\n","Epoch 00011: early stopping\n","Score for fold 1: loss of 0.6492792963981628; accuracy of 15.566577017307281% ;precision_m of 0.5127865076065063 ;recall_m of 0.2593536674976349 ;            f1_m of 0.34322670102119446\n","Epoch 1/50\n","131/131 [==============================] - 8s 47ms/step - loss: 0.6201 - accuracy: 0.2230 - precision_m: 0.4029 - recall_m: 0.1623 - f1_m: 0.2198 - val_loss: 0.5209 - val_accuracy: 0.3279 - val_precision_m: 0.5827 - val_recall_m: 0.3938 - val_f1_m: 0.4685\n","Epoch 2/50\n","131/131 [==============================] - 5s 37ms/step - loss: 0.5956 - accuracy: 0.2134 - precision_m: 0.5143 - recall_m: 0.2219 - f1_m: 0.3057 - val_loss: 0.5114 - val_accuracy: 0.3279 - val_precision_m: 0.5827 - val_recall_m: 0.3938 - val_f1_m: 0.4685\n","Epoch 3/50\n","131/131 [==============================] - 5s 37ms/step - loss: 0.5963 - accuracy: 0.2065 - precision_m: 0.5204 - recall_m: 0.2044 - f1_m: 0.2843 - val_loss: 0.5148 - val_accuracy: 0.3279 - val_precision_m: 0.5827 - val_recall_m: 0.3938 - val_f1_m: 0.4685\n","Epoch 4/50\n","131/131 [==============================] - 5s 37ms/step - loss: 0.5937 - accuracy: 0.2182 - precision_m: 0.5178 - recall_m: 0.2182 - f1_m: 0.3020 - val_loss: 0.5233 - val_accuracy: 0.3279 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00 - val_f1_m: 0.0000e+00\n","Epoch 5/50\n","131/131 [==============================] - 5s 37ms/step - loss: 0.5903 - accuracy: 0.2104 - precision_m: 0.5489 - recall_m: 0.1854 - f1_m: 0.2629 - val_loss: 0.5191 - val_accuracy: 0.3279 - val_precision_m: 0.5827 - val_recall_m: 0.3938 - val_f1_m: 0.4685\n","Epoch 6/50\n","131/131 [==============================] - 5s 37ms/step - loss: 0.5902 - accuracy: 0.2109 - precision_m: 0.5218 - recall_m: 0.2234 - f1_m: 0.3071 - val_loss: 0.5131 - val_accuracy: 0.3279 - val_precision_m: 0.5827 - val_recall_m: 0.3938 - val_f1_m: 0.4685\n","Epoch 7/50\n","131/131 [==============================] - 5s 37ms/step - loss: 0.5944 - accuracy: 0.2088 - precision_m: 0.5224 - recall_m: 0.2445 - f1_m: 0.3291 - val_loss: 0.5255 - val_accuracy: 0.3279 - val_precision_m: 0.5827 - val_recall_m: 0.3938 - val_f1_m: 0.4685\n","Epoch 8/50\n","131/131 [==============================] - 5s 37ms/step - loss: 0.5893 - accuracy: 0.2074 - precision_m: 0.5252 - recall_m: 0.2334 - f1_m: 0.3153 - val_loss: 0.5106 - val_accuracy: 0.3279 - val_precision_m: 0.5827 - val_recall_m: 0.3938 - val_f1_m: 0.4685\n","Epoch 9/50\n","131/131 [==============================] - 5s 37ms/step - loss: 0.5913 - accuracy: 0.2109 - precision_m: 0.5173 - recall_m: 0.2419 - f1_m: 0.3234 - val_loss: 0.5310 - val_accuracy: 0.3279 - val_precision_m: 0.5827 - val_recall_m: 0.3938 - val_f1_m: 0.4685\n","Epoch 10/50\n","131/131 [==============================] - 5s 37ms/step - loss: 0.5912 - accuracy: 0.2166 - precision_m: 0.5229 - recall_m: 0.2568 - f1_m: 0.3427 - val_loss: 0.5215 - val_accuracy: 0.3279 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00 - val_f1_m: 0.0000e+00\n","Epoch 11/50\n","131/131 [==============================] - 5s 37ms/step - loss: 0.5962 - accuracy: 0.2008 - precision_m: 0.4911 - recall_m: 0.1730 - f1_m: 0.2483 - val_loss: 0.5137 - val_accuracy: 0.3279 - val_precision_m: 0.5827 - val_recall_m: 0.3938 - val_f1_m: 0.4685\n","Epoch 00011: early stopping\n","Score for fold 2: loss of 0.5649359822273254; accuracy of 25.076335668563843% ;precision_m of 0.5106163024902344 ;recall_m of 0.3112577795982361 ;            f1_m of 0.3850182890892029\n","Epoch 1/50\n","131/131 [==============================] - 8s 43ms/step - loss: 0.6250 - accuracy: 0.1911 - precision_m: 0.4593 - recall_m: 0.1160 - f1_m: 0.1709 - val_loss: 0.5564 - val_accuracy: 0.2822 - val_precision_m: 0.5127 - val_recall_m: 0.3279 - val_f1_m: 0.3987\n","Epoch 2/50\n","131/131 [==============================] - 5s 37ms/step - loss: 0.6071 - accuracy: 0.1919 - precision_m: 0.5054 - recall_m: 0.1879 - f1_m: 0.2611 - val_loss: 0.5672 - val_accuracy: 0.2822 - val_precision_m: 0.5127 - val_recall_m: 0.3279 - val_f1_m: 0.3987\n","Epoch 3/50\n","131/131 [==============================] - 5s 37ms/step - loss: 0.6028 - accuracy: 0.1880 - precision_m: 0.5265 - recall_m: 0.2001 - f1_m: 0.2834 - val_loss: 0.5590 - val_accuracy: 0.2822 - val_precision_m: 0.5127 - val_recall_m: 0.3279 - val_f1_m: 0.3987\n","Epoch 4/50\n","131/131 [==============================] - 5s 37ms/step - loss: 0.6085 - accuracy: 0.1826 - precision_m: 0.5216 - recall_m: 0.1922 - f1_m: 0.2680 - val_loss: 0.5583 - val_accuracy: 0.2822 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00 - val_f1_m: 0.0000e+00\n","Epoch 5/50\n","131/131 [==============================] - 5s 37ms/step - loss: 0.6055 - accuracy: 0.1879 - precision_m: 0.5035 - recall_m: 0.1667 - f1_m: 0.2391 - val_loss: 0.5600 - val_accuracy: 0.2822 - val_precision_m: 0.5127 - val_recall_m: 0.3279 - val_f1_m: 0.3987\n","Epoch 6/50\n","131/131 [==============================] - 5s 37ms/step - loss: 0.6061 - accuracy: 0.1862 - precision_m: 0.5208 - recall_m: 0.2229 - f1_m: 0.3046 - val_loss: 0.5728 - val_accuracy: 0.2822 - val_precision_m: 0.5127 - val_recall_m: 0.3279 - val_f1_m: 0.3987\n","Epoch 7/50\n","131/131 [==============================] - 5s 37ms/step - loss: 0.6053 - accuracy: 0.1870 - precision_m: 0.5113 - recall_m: 0.1513 - f1_m: 0.2242 - val_loss: 0.5650 - val_accuracy: 0.2822 - val_precision_m: 0.5127 - val_recall_m: 0.3279 - val_f1_m: 0.3987\n","Epoch 8/50\n","131/131 [==============================] - 5s 37ms/step - loss: 0.6057 - accuracy: 0.1888 - precision_m: 0.5158 - recall_m: 0.1918 - f1_m: 0.2704 - val_loss: 0.5489 - val_accuracy: 0.2822 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00 - val_f1_m: 0.0000e+00\n","Epoch 9/50\n","131/131 [==============================] - 5s 37ms/step - loss: 0.6110 - accuracy: 0.1798 - precision_m: 0.4789 - recall_m: 0.1250 - f1_m: 0.1894 - val_loss: 0.5607 - val_accuracy: 0.2822 - val_precision_m: 0.5127 - val_recall_m: 0.3279 - val_f1_m: 0.3987\n","Epoch 10/50\n","131/131 [==============================] - 5s 37ms/step - loss: 0.6077 - accuracy: 0.1829 - precision_m: 0.5298 - recall_m: 0.2139 - f1_m: 0.2925 - val_loss: 0.5639 - val_accuracy: 0.2822 - val_precision_m: 0.5127 - val_recall_m: 0.3279 - val_f1_m: 0.3987\n","Epoch 11/50\n","131/131 [==============================] - 5s 37ms/step - loss: 0.6096 - accuracy: 0.1778 - precision_m: 0.5082 - recall_m: 0.1508 - f1_m: 0.2179 - val_loss: 0.5520 - val_accuracy: 0.2822 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00 - val_f1_m: 0.0000e+00\n","Epoch 00011: early stopping\n","Score for fold 3: loss of 0.5261337757110596; accuracy of 31.068703532218933% ;precision_m of 0.0 ;recall_m of 0.0 ;            f1_m of 0.0\n","Epoch 1/50\n","131/131 [==============================] - 8s 45ms/step - loss: 0.5728 - accuracy: 0.2585 - precision_m: 0.4376 - recall_m: 0.1804 - f1_m: 0.2431 - val_loss: 0.5018 - val_accuracy: 0.3273 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00 - val_f1_m: 0.0000e+00\n","Epoch 2/50\n","131/131 [==============================] - 5s 40ms/step - loss: 0.5476 - accuracy: 0.2761 - precision_m: 0.5561 - recall_m: 0.2210 - f1_m: 0.3014 - val_loss: 0.5069 - val_accuracy: 0.3273 - val_precision_m: 0.5824 - val_recall_m: 0.3934 - val_f1_m: 0.4681\n","Epoch 3/50\n","131/131 [==============================] - 5s 39ms/step - loss: 0.5483 - accuracy: 0.2710 - precision_m: 0.5242 - recall_m: 0.2475 - f1_m: 0.3298 - val_loss: 0.5012 - val_accuracy: 0.3273 - val_precision_m: 0.5824 - val_recall_m: 0.3934 - val_f1_m: 0.4681\n","Epoch 4/50\n","131/131 [==============================] - 5s 40ms/step - loss: 0.5505 - accuracy: 0.2666 - precision_m: 0.5066 - recall_m: 0.2217 - f1_m: 0.3020 - val_loss: 0.5050 - val_accuracy: 0.3273 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00 - val_f1_m: 0.0000e+00\n","Epoch 5/50\n","131/131 [==============================] - 5s 40ms/step - loss: 0.5470 - accuracy: 0.2648 - precision_m: 0.4868 - recall_m: 0.1625 - f1_m: 0.2224 - val_loss: 0.5014 - val_accuracy: 0.3273 - val_precision_m: 0.5824 - val_recall_m: 0.3934 - val_f1_m: 0.4681\n","Epoch 6/50\n","131/131 [==============================] - 5s 40ms/step - loss: 0.5467 - accuracy: 0.2785 - precision_m: 0.5345 - recall_m: 0.2476 - f1_m: 0.3311 - val_loss: 0.4978 - val_accuracy: 0.3273 - val_precision_m: 0.5824 - val_recall_m: 0.3934 - val_f1_m: 0.4681\n","Epoch 7/50\n","131/131 [==============================] - 5s 40ms/step - loss: 0.5545 - accuracy: 0.2621 - precision_m: 0.4929 - recall_m: 0.1780 - f1_m: 0.2444 - val_loss: 0.5007 - val_accuracy: 0.3273 - val_precision_m: 0.5824 - val_recall_m: 0.3934 - val_f1_m: 0.4681\n","Epoch 8/50\n","131/131 [==============================] - 5s 40ms/step - loss: 0.5458 - accuracy: 0.2731 - precision_m: 0.5268 - recall_m: 0.2831 - f1_m: 0.3654 - val_loss: 0.5008 - val_accuracy: 0.3273 - val_precision_m: 0.5824 - val_recall_m: 0.3934 - val_f1_m: 0.4681\n","Epoch 9/50\n","131/131 [==============================] - 5s 39ms/step - loss: 0.5421 - accuracy: 0.2781 - precision_m: 0.5325 - recall_m: 0.2625 - f1_m: 0.3434 - val_loss: 0.5002 - val_accuracy: 0.3273 - val_precision_m: 0.5824 - val_recall_m: 0.3934 - val_f1_m: 0.4681\n","Epoch 10/50\n","131/131 [==============================] - 5s 39ms/step - loss: 0.5458 - accuracy: 0.2715 - precision_m: 0.5149 - recall_m: 0.2439 - f1_m: 0.3259 - val_loss: 0.5000 - val_accuracy: 0.3273 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00 - val_f1_m: 0.0000e+00\n","Epoch 11/50\n","131/131 [==============================] - 5s 39ms/step - loss: 0.5496 - accuracy: 0.2653 - precision_m: 0.4938 - recall_m: 0.2177 - f1_m: 0.2964 - val_loss: 0.5000 - val_accuracy: 0.3273 - val_precision_m: 0.5824 - val_recall_m: 0.3934 - val_f1_m: 0.4681\n","Epoch 12/50\n","131/131 [==============================] - 5s 39ms/step - loss: 0.5451 - accuracy: 0.2724 - precision_m: 0.5051 - recall_m: 0.2305 - f1_m: 0.3120 - val_loss: 0.5037 - val_accuracy: 0.3273 - val_precision_m: 0.5824 - val_recall_m: 0.3934 - val_f1_m: 0.4681\n","Epoch 00012: early stopping\n","Score for fold 1: loss of 0.6433901190757751; accuracy of 15.566577017307281% ;precision_m of 0.5127865076065063 ;recall_m of 0.2593536674976349 ;            f1_m of 0.34322670102119446\n","Epoch 1/50\n","131/131 [==============================] - 8s 50ms/step - loss: 0.6082 - accuracy: 0.2114 - precision_m: 0.4862 - recall_m: 0.1778 - f1_m: 0.2462 - val_loss: 0.5336 - val_accuracy: 0.3279 - val_precision_m: 0.5827 - val_recall_m: 0.3938 - val_f1_m: 0.4685\n","Epoch 2/50\n","131/131 [==============================] - 5s 39ms/step - loss: 0.5892 - accuracy: 0.2200 - precision_m: 0.5285 - recall_m: 0.2375 - f1_m: 0.3233 - val_loss: 0.5118 - val_accuracy: 0.3279 - val_precision_m: 0.5827 - val_recall_m: 0.3938 - val_f1_m: 0.4685\n","Epoch 3/50\n","131/131 [==============================] - 5s 39ms/step - loss: 0.5964 - accuracy: 0.2135 - precision_m: 0.5121 - recall_m: 0.2051 - f1_m: 0.2870 - val_loss: 0.5078 - val_accuracy: 0.3279 - val_precision_m: 0.5827 - val_recall_m: 0.3938 - val_f1_m: 0.4685\n","Epoch 4/50\n","131/131 [==============================] - 5s 39ms/step - loss: 0.5904 - accuracy: 0.2140 - precision_m: 0.5277 - recall_m: 0.2265 - f1_m: 0.3130 - val_loss: 0.5197 - val_accuracy: 0.3279 - val_precision_m: 0.5827 - val_recall_m: 0.3938 - val_f1_m: 0.4685\n","Epoch 5/50\n","131/131 [==============================] - 5s 39ms/step - loss: 0.5913 - accuracy: 0.2087 - precision_m: 0.4864 - recall_m: 0.1573 - f1_m: 0.2217 - val_loss: 0.5132 - val_accuracy: 0.3279 - val_precision_m: 0.5827 - val_recall_m: 0.3938 - val_f1_m: 0.4685\n","Epoch 6/50\n","131/131 [==============================] - 5s 39ms/step - loss: 0.5942 - accuracy: 0.2048 - precision_m: 0.5215 - recall_m: 0.2240 - f1_m: 0.3064 - val_loss: 0.5157 - val_accuracy: 0.3279 - val_precision_m: 0.5827 - val_recall_m: 0.3938 - val_f1_m: 0.4685\n","Epoch 7/50\n","131/131 [==============================] - 5s 39ms/step - loss: 0.5934 - accuracy: 0.2122 - precision_m: 0.5264 - recall_m: 0.2575 - f1_m: 0.3434 - val_loss: 0.5118 - val_accuracy: 0.3279 - val_precision_m: 0.5827 - val_recall_m: 0.3938 - val_f1_m: 0.4685\n","Epoch 8/50\n","131/131 [==============================] - 5s 39ms/step - loss: 0.5921 - accuracy: 0.2114 - precision_m: 0.5111 - recall_m: 0.1943 - f1_m: 0.2714 - val_loss: 0.5215 - val_accuracy: 0.3279 - val_precision_m: 0.5827 - val_recall_m: 0.3938 - val_f1_m: 0.4685\n","Epoch 9/50\n","131/131 [==============================] - 5s 39ms/step - loss: 0.5893 - accuracy: 0.2114 - precision_m: 0.5207 - recall_m: 0.2431 - f1_m: 0.3247 - val_loss: 0.5257 - val_accuracy: 0.3279 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00 - val_f1_m: 0.0000e+00\n","Epoch 10/50\n","131/131 [==============================] - 5s 39ms/step - loss: 0.5875 - accuracy: 0.2167 - precision_m: 0.4993 - recall_m: 0.2145 - f1_m: 0.2925 - val_loss: 0.5262 - val_accuracy: 0.3279 - val_precision_m: 0.5827 - val_recall_m: 0.3938 - val_f1_m: 0.4685\n","Epoch 11/50\n","131/131 [==============================] - 5s 39ms/step - loss: 0.5911 - accuracy: 0.2027 - precision_m: 0.5045 - recall_m: 0.1917 - f1_m: 0.2706 - val_loss: 0.5107 - val_accuracy: 0.3279 - val_precision_m: 0.5827 - val_recall_m: 0.3938 - val_f1_m: 0.4685\n","Epoch 00011: early stopping\n","Score for fold 2: loss of 0.5620464086532593; accuracy of 25.076335668563843% ;precision_m of 0.5106163024902344 ;recall_m of 0.3112577795982361 ;            f1_m of 0.3850182890892029\n","Epoch 1/50\n","131/131 [==============================] - 8s 45ms/step - loss: 0.6204 - accuracy: 0.1942 - precision_m: 0.4491 - recall_m: 0.1792 - f1_m: 0.2443 - val_loss: 0.5735 - val_accuracy: 0.2822 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00 - val_f1_m: 0.0000e+00\n","Epoch 2/50\n","131/131 [==============================] - 5s 39ms/step - loss: 0.6107 - accuracy: 0.1853 - precision_m: 0.4860 - recall_m: 0.1468 - f1_m: 0.2098 - val_loss: 0.5568 - val_accuracy: 0.2822 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00 - val_f1_m: 0.0000e+00\n","Epoch 3/50\n","131/131 [==============================] - 5s 39ms/step - loss: 0.6111 - accuracy: 0.1875 - precision_m: 0.4891 - recall_m: 0.1351 - f1_m: 0.2018 - val_loss: 0.5476 - val_accuracy: 0.2822 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00 - val_f1_m: 0.0000e+00\n","Epoch 4/50\n","131/131 [==============================] - 5s 39ms/step - loss: 0.6051 - accuracy: 0.1805 - precision_m: 0.5264 - recall_m: 0.1479 - f1_m: 0.2174 - val_loss: 0.5663 - val_accuracy: 0.2822 - val_precision_m: 0.5127 - val_recall_m: 0.3279 - val_f1_m: 0.3987\n","Epoch 5/50\n","131/131 [==============================] - 5s 39ms/step - loss: 0.6090 - accuracy: 0.1877 - precision_m: 0.5314 - recall_m: 0.1904 - f1_m: 0.2666 - val_loss: 0.5592 - val_accuracy: 0.2822 - val_precision_m: 0.5127 - val_recall_m: 0.3279 - val_f1_m: 0.3987\n","Epoch 6/50\n","131/131 [==============================] - 5s 39ms/step - loss: 0.6073 - accuracy: 0.1881 - precision_m: 0.5177 - recall_m: 0.1975 - f1_m: 0.2778 - val_loss: 0.5614 - val_accuracy: 0.2822 - val_precision_m: 0.5127 - val_recall_m: 0.3279 - val_f1_m: 0.3987\n","Epoch 7/50\n","131/131 [==============================] - 5s 39ms/step - loss: 0.6047 - accuracy: 0.1948 - precision_m: 0.5202 - recall_m: 0.2085 - f1_m: 0.2893 - val_loss: 0.5574 - val_accuracy: 0.2822 - val_precision_m: 0.5127 - val_recall_m: 0.3279 - val_f1_m: 0.3987\n","Epoch 8/50\n","131/131 [==============================] - 5s 39ms/step - loss: 0.6087 - accuracy: 0.1845 - precision_m: 0.5120 - recall_m: 0.2207 - f1_m: 0.3051 - val_loss: 0.5619 - val_accuracy: 0.2822 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00 - val_f1_m: 0.0000e+00\n","Epoch 9/50\n","131/131 [==============================] - 5s 39ms/step - loss: 0.6073 - accuracy: 0.1793 - precision_m: 0.5316 - recall_m: 0.1905 - f1_m: 0.2695 - val_loss: 0.5566 - val_accuracy: 0.2822 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00 - val_f1_m: 0.0000e+00\n","Epoch 10/50\n","131/131 [==============================] - 5s 39ms/step - loss: 0.6058 - accuracy: 0.1737 - precision_m: 0.5058 - recall_m: 0.1603 - f1_m: 0.2309 - val_loss: 0.5614 - val_accuracy: 0.2822 - val_precision_m: 0.5127 - val_recall_m: 0.3279 - val_f1_m: 0.3987\n","Epoch 11/50\n","131/131 [==============================] - 5s 40ms/step - loss: 0.6064 - accuracy: 0.1749 - precision_m: 0.5021 - recall_m: 0.1548 - f1_m: 0.2220 - val_loss: 0.5572 - val_accuracy: 0.2822 - val_precision_m: 0.5127 - val_recall_m: 0.3279 - val_f1_m: 0.3987\n","Epoch 12/50\n","131/131 [==============================] - 5s 39ms/step - loss: 0.6046 - accuracy: 0.1846 - precision_m: 0.4846 - recall_m: 0.2155 - f1_m: 0.2900 - val_loss: 0.5650 - val_accuracy: 0.2822 - val_precision_m: 0.5127 - val_recall_m: 0.3279 - val_f1_m: 0.3987\n","Epoch 13/50\n","131/131 [==============================] - 5s 39ms/step - loss: 0.6095 - accuracy: 0.1853 - precision_m: 0.5116 - recall_m: 0.1851 - f1_m: 0.2649 - val_loss: 0.5560 - val_accuracy: 0.2822 - val_precision_m: 0.5127 - val_recall_m: 0.3279 - val_f1_m: 0.3987\n","Epoch 14/50\n","131/131 [==============================] - 5s 39ms/step - loss: 0.6082 - accuracy: 0.1733 - precision_m: 0.5084 - recall_m: 0.1748 - f1_m: 0.2517 - val_loss: 0.5652 - val_accuracy: 0.2822 - val_precision_m: 0.5127 - val_recall_m: 0.3279 - val_f1_m: 0.3987\n","Epoch 00014: early stopping\n","Score for fold 3: loss of 0.5432791709899902; accuracy of 31.068703532218933% ;precision_m of 0.5502504706382751 ;recall_m of 0.36772269010543823 ;            f1_m of 0.43958553671836853\n","Epoch 1/50\n","131/131 [==============================] - 8s 47ms/step - loss: 0.5742 - accuracy: 0.2467 - precision_m: 0.4814 - recall_m: 0.1530 - f1_m: 0.2142 - val_loss: 0.4971 - val_accuracy: 0.3273 - val_precision_m: 0.5824 - val_recall_m: 0.3934 - val_f1_m: 0.4681\n","Epoch 2/50\n","131/131 [==============================] - 5s 42ms/step - loss: 0.5534 - accuracy: 0.2596 - precision_m: 0.5338 - recall_m: 0.1762 - f1_m: 0.2471 - val_loss: 0.4994 - val_accuracy: 0.3273 - val_precision_m: 0.5824 - val_recall_m: 0.3934 - val_f1_m: 0.4681\n","Epoch 3/50\n","131/131 [==============================] - 5s 42ms/step - loss: 0.5483 - accuracy: 0.2682 - precision_m: 0.5161 - recall_m: 0.2211 - f1_m: 0.2970 - val_loss: 0.5012 - val_accuracy: 0.3273 - val_precision_m: 0.5824 - val_recall_m: 0.3934 - val_f1_m: 0.4681\n","Epoch 4/50\n","131/131 [==============================] - 5s 42ms/step - loss: 0.5515 - accuracy: 0.2620 - precision_m: 0.5163 - recall_m: 0.2173 - f1_m: 0.2974 - val_loss: 0.4995 - val_accuracy: 0.3273 - val_precision_m: 0.5824 - val_recall_m: 0.3934 - val_f1_m: 0.4681\n","Epoch 5/50\n","131/131 [==============================] - 6s 42ms/step - loss: 0.5466 - accuracy: 0.2706 - precision_m: 0.5143 - recall_m: 0.2271 - f1_m: 0.3054 - val_loss: 0.5016 - val_accuracy: 0.3273 - val_precision_m: 0.5824 - val_recall_m: 0.3934 - val_f1_m: 0.4681\n","Epoch 6/50\n","131/131 [==============================] - 5s 42ms/step - loss: 0.5486 - accuracy: 0.2728 - precision_m: 0.5189 - recall_m: 0.2399 - f1_m: 0.3231 - val_loss: 0.5049 - val_accuracy: 0.3273 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00 - val_f1_m: 0.0000e+00\n","Epoch 7/50\n","131/131 [==============================] - 5s 42ms/step - loss: 0.5479 - accuracy: 0.2733 - precision_m: 0.5207 - recall_m: 0.1922 - f1_m: 0.2640 - val_loss: 0.5015 - val_accuracy: 0.3273 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00 - val_f1_m: 0.0000e+00\n","Epoch 8/50\n","131/131 [==============================] - 5s 42ms/step - loss: 0.5476 - accuracy: 0.2619 - precision_m: 0.5092 - recall_m: 0.1895 - f1_m: 0.2689 - val_loss: 0.4998 - val_accuracy: 0.3273 - val_precision_m: 0.5824 - val_recall_m: 0.3934 - val_f1_m: 0.4681\n","Epoch 9/50\n","131/131 [==============================] - 5s 41ms/step - loss: 0.5464 - accuracy: 0.2715 - precision_m: 0.4913 - recall_m: 0.1920 - f1_m: 0.2682 - val_loss: 0.4979 - val_accuracy: 0.3273 - val_precision_m: 0.5824 - val_recall_m: 0.3934 - val_f1_m: 0.4681\n","Epoch 10/50\n","131/131 [==============================] - 5s 42ms/step - loss: 0.5464 - accuracy: 0.2613 - precision_m: 0.5157 - recall_m: 0.1850 - f1_m: 0.2581 - val_loss: 0.5020 - val_accuracy: 0.3273 - val_precision_m: 0.5824 - val_recall_m: 0.3934 - val_f1_m: 0.4681\n","Epoch 11/50\n","131/131 [==============================] - 5s 42ms/step - loss: 0.5482 - accuracy: 0.2707 - precision_m: 0.5163 - recall_m: 0.2381 - f1_m: 0.3167 - val_loss: 0.4976 - val_accuracy: 0.3273 - val_precision_m: 0.5824 - val_recall_m: 0.3934 - val_f1_m: 0.4681\n","Epoch 00011: early stopping\n","Score for fold 1: loss of 0.6609371304512024; accuracy of 15.566577017307281% ;precision_m of 0.5127865076065063 ;recall_m of 0.2593536674976349 ;            f1_m of 0.34322670102119446\n","Epoch 1/50\n","131/131 [==============================] - 8s 47ms/step - loss: 0.6085 - accuracy: 0.2146 - precision_m: 0.4985 - recall_m: 0.1782 - f1_m: 0.2520 - val_loss: 0.5091 - val_accuracy: 0.3279 - val_precision_m: 0.5827 - val_recall_m: 0.3938 - val_f1_m: 0.4685\n","Epoch 2/50\n","131/131 [==============================] - 5s 42ms/step - loss: 0.5894 - accuracy: 0.2142 - precision_m: 0.4974 - recall_m: 0.2083 - f1_m: 0.2824 - val_loss: 0.5397 - val_accuracy: 0.3279 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00 - val_f1_m: 0.0000e+00\n","Epoch 3/50\n","131/131 [==============================] - 5s 42ms/step - loss: 0.5961 - accuracy: 0.1989 - precision_m: 0.5241 - recall_m: 0.1892 - f1_m: 0.2686 - val_loss: 0.5376 - val_accuracy: 0.3279 - val_precision_m: 0.5827 - val_recall_m: 0.3938 - val_f1_m: 0.4685\n","Epoch 4/50\n","131/131 [==============================] - 5s 42ms/step - loss: 0.5899 - accuracy: 0.2057 - precision_m: 0.5273 - recall_m: 0.2197 - f1_m: 0.3021 - val_loss: 0.5166 - val_accuracy: 0.3279 - val_precision_m: 0.5827 - val_recall_m: 0.3938 - val_f1_m: 0.4685\n","Epoch 5/50\n","131/131 [==============================] - 5s 42ms/step - loss: 0.5926 - accuracy: 0.2119 - precision_m: 0.5327 - recall_m: 0.2164 - f1_m: 0.3034 - val_loss: 0.5178 - val_accuracy: 0.3279 - val_precision_m: 0.5827 - val_recall_m: 0.3938 - val_f1_m: 0.4685\n","Epoch 6/50\n","131/131 [==============================] - 5s 42ms/step - loss: 0.5916 - accuracy: 0.2111 - precision_m: 0.5279 - recall_m: 0.2221 - f1_m: 0.3043 - val_loss: 0.5245 - val_accuracy: 0.3279 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00 - val_f1_m: 0.0000e+00\n","Epoch 7/50\n","131/131 [==============================] - 5s 42ms/step - loss: 0.5935 - accuracy: 0.2094 - precision_m: 0.4748 - recall_m: 0.1366 - f1_m: 0.2005 - val_loss: 0.5225 - val_accuracy: 0.3279 - val_precision_m: 0.5827 - val_recall_m: 0.3938 - val_f1_m: 0.4685\n","Epoch 8/50\n","131/131 [==============================] - 5s 42ms/step - loss: 0.5948 - accuracy: 0.2001 - precision_m: 0.4957 - recall_m: 0.1600 - f1_m: 0.2278 - val_loss: 0.5111 - val_accuracy: 0.3279 - val_precision_m: 0.5827 - val_recall_m: 0.3938 - val_f1_m: 0.4685\n","Epoch 9/50\n","131/131 [==============================] - 6s 42ms/step - loss: 0.5922 - accuracy: 0.2099 - precision_m: 0.5098 - recall_m: 0.2315 - f1_m: 0.3160 - val_loss: 0.5283 - val_accuracy: 0.3279 - val_precision_m: 0.5827 - val_recall_m: 0.3938 - val_f1_m: 0.4685\n","Epoch 10/50\n","131/131 [==============================] - 5s 42ms/step - loss: 0.5927 - accuracy: 0.2007 - precision_m: 0.5098 - recall_m: 0.1915 - f1_m: 0.2745 - val_loss: 0.5183 - val_accuracy: 0.3279 - val_precision_m: 0.5827 - val_recall_m: 0.3938 - val_f1_m: 0.4685\n","Epoch 11/50\n","131/131 [==============================] - 5s 42ms/step - loss: 0.5904 - accuracy: 0.2134 - precision_m: 0.5121 - recall_m: 0.2403 - f1_m: 0.3245 - val_loss: 0.5171 - val_accuracy: 0.3279 - val_precision_m: 0.5827 - val_recall_m: 0.3938 - val_f1_m: 0.4685\n","Epoch 00011: early stopping\n","Score for fold 2: loss of 0.5647417902946472; accuracy of 25.076335668563843% ;precision_m of 0.5106163024902344 ;recall_m of 0.3112577795982361 ;            f1_m of 0.3850182890892029\n","Epoch 1/50\n","131/131 [==============================] - 8s 48ms/step - loss: 0.6232 - accuracy: 0.1982 - precision_m: 0.5153 - recall_m: 0.1706 - f1_m: 0.2471 - val_loss: 0.5674 - val_accuracy: 0.2822 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00 - val_f1_m: 0.0000e+00\n","Epoch 2/50\n","131/131 [==============================] - 5s 42ms/step - loss: 0.6106 - accuracy: 0.1782 - precision_m: 0.4958 - recall_m: 0.1624 - f1_m: 0.2375 - val_loss: 0.5566 - val_accuracy: 0.2822 - val_precision_m: 0.5127 - val_recall_m: 0.3279 - val_f1_m: 0.3987\n","Epoch 3/50\n","131/131 [==============================] - 5s 42ms/step - loss: 0.6095 - accuracy: 0.1780 - precision_m: 0.5059 - recall_m: 0.1894 - f1_m: 0.2667 - val_loss: 0.5568 - val_accuracy: 0.2822 - val_precision_m: 0.5127 - val_recall_m: 0.3279 - val_f1_m: 0.3987\n","Epoch 4/50\n","131/131 [==============================] - 6s 42ms/step - loss: 0.6077 - accuracy: 0.1845 - precision_m: 0.5029 - recall_m: 0.1589 - f1_m: 0.2322 - val_loss: 0.5646 - val_accuracy: 0.2822 - val_precision_m: 0.5127 - val_recall_m: 0.3279 - val_f1_m: 0.3987\n","Epoch 5/50\n","131/131 [==============================] - 6s 42ms/step - loss: 0.6071 - accuracy: 0.1837 - precision_m: 0.5301 - recall_m: 0.2310 - f1_m: 0.3171 - val_loss: 0.5598 - val_accuracy: 0.2822 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00 - val_f1_m: 0.0000e+00\n","Epoch 6/50\n","131/131 [==============================] - 5s 42ms/step - loss: 0.6047 - accuracy: 0.1826 - precision_m: 0.5746 - recall_m: 0.1503 - f1_m: 0.2207 - val_loss: 0.5612 - val_accuracy: 0.2822 - val_precision_m: 0.5127 - val_recall_m: 0.3279 - val_f1_m: 0.3987\n","Epoch 7/50\n","131/131 [==============================] - 6s 42ms/step - loss: 0.6036 - accuracy: 0.1841 - precision_m: 0.5117 - recall_m: 0.2120 - f1_m: 0.2964 - val_loss: 0.5536 - val_accuracy: 0.2822 - val_precision_m: 0.5127 - val_recall_m: 0.3279 - val_f1_m: 0.3987\n","Epoch 8/50\n","131/131 [==============================] - 5s 42ms/step - loss: 0.6050 - accuracy: 0.1915 - precision_m: 0.5210 - recall_m: 0.2336 - f1_m: 0.3201 - val_loss: 0.5594 - val_accuracy: 0.2822 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00 - val_f1_m: 0.0000e+00\n","Epoch 9/50\n","131/131 [==============================] - 5s 42ms/step - loss: 0.6031 - accuracy: 0.1792 - precision_m: 0.5142 - recall_m: 0.2075 - f1_m: 0.2915 - val_loss: 0.5649 - val_accuracy: 0.2822 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00 - val_f1_m: 0.0000e+00\n","Epoch 10/50\n","131/131 [==============================] - 5s 42ms/step - loss: 0.6084 - accuracy: 0.1789 - precision_m: 0.4604 - recall_m: 0.1166 - f1_m: 0.1682 - val_loss: 0.5530 - val_accuracy: 0.2822 - val_precision_m: 0.5127 - val_recall_m: 0.3279 - val_f1_m: 0.3987\n","Epoch 11/50\n","131/131 [==============================] - 6s 42ms/step - loss: 0.6048 - accuracy: 0.1806 - precision_m: 0.5227 - recall_m: 0.2202 - f1_m: 0.3023 - val_loss: 0.5548 - val_accuracy: 0.2822 - val_precision_m: 0.5127 - val_recall_m: 0.3279 - val_f1_m: 0.3987\n","Epoch 12/50\n","131/131 [==============================] - 5s 42ms/step - loss: 0.6038 - accuracy: 0.1882 - precision_m: 0.5197 - recall_m: 0.2413 - f1_m: 0.3272 - val_loss: 0.5572 - val_accuracy: 0.2822 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00 - val_f1_m: 0.0000e+00\n","Epoch 00012: early stopping\n","Score for fold 3: loss of 0.5358452200889587; accuracy of 31.068703532218933% ;precision_m of 0.0 ;recall_m of 0.0 ;            f1_m of 0.0\n","Epoch 1/50\n","131/131 [==============================] - 9s 49ms/step - loss: 0.5783 - accuracy: 0.2718 - precision_m: 0.4969 - recall_m: 0.1824 - f1_m: 0.2585 - val_loss: 0.5030 - val_accuracy: 0.3273 - val_precision_m: 0.5824 - val_recall_m: 0.3934 - val_f1_m: 0.4681\n","Epoch 2/50\n","131/131 [==============================] - 6s 43ms/step - loss: 0.5488 - accuracy: 0.2772 - precision_m: 0.5272 - recall_m: 0.2016 - f1_m: 0.2794 - val_loss: 0.5030 - val_accuracy: 0.3273 - val_precision_m: 0.5824 - val_recall_m: 0.3934 - val_f1_m: 0.4681\n","Epoch 3/50\n","131/131 [==============================] - 6s 42ms/step - loss: 0.5462 - accuracy: 0.2736 - precision_m: 0.5152 - recall_m: 0.2353 - f1_m: 0.3162 - val_loss: 0.5073 - val_accuracy: 0.3273 - val_precision_m: 0.5824 - val_recall_m: 0.3934 - val_f1_m: 0.4681\n","Epoch 4/50\n","131/131 [==============================] - 6s 43ms/step - loss: 0.5436 - accuracy: 0.2841 - precision_m: 0.5331 - recall_m: 0.2422 - f1_m: 0.3221 - val_loss: 0.5009 - val_accuracy: 0.3273 - val_precision_m: 0.5824 - val_recall_m: 0.3934 - val_f1_m: 0.4681\n","Epoch 5/50\n","131/131 [==============================] - 6s 43ms/step - loss: 0.5488 - accuracy: 0.2644 - precision_m: 0.5128 - recall_m: 0.2161 - f1_m: 0.2958 - val_loss: 0.4994 - val_accuracy: 0.3273 - val_precision_m: 0.5824 - val_recall_m: 0.3934 - val_f1_m: 0.4681\n","Epoch 6/50\n","131/131 [==============================] - 6s 43ms/step - loss: 0.5447 - accuracy: 0.2774 - precision_m: 0.5241 - recall_m: 0.2340 - f1_m: 0.3187 - val_loss: 0.5004 - val_accuracy: 0.3273 - val_precision_m: 0.5824 - val_recall_m: 0.3934 - val_f1_m: 0.4681\n","Epoch 7/50\n","131/131 [==============================] - 6s 42ms/step - loss: 0.5495 - accuracy: 0.2622 - precision_m: 0.5163 - recall_m: 0.1702 - f1_m: 0.2415 - val_loss: 0.5009 - val_accuracy: 0.3273 - val_precision_m: 0.5824 - val_recall_m: 0.3934 - val_f1_m: 0.4681\n","Epoch 8/50\n","131/131 [==============================] - 6s 43ms/step - loss: 0.5496 - accuracy: 0.2669 - precision_m: 0.5073 - recall_m: 0.2380 - f1_m: 0.3156 - val_loss: 0.5026 - val_accuracy: 0.3273 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00 - val_f1_m: 0.0000e+00\n","Epoch 9/50\n","131/131 [==============================] - 6s 42ms/step - loss: 0.5444 - accuracy: 0.2732 - precision_m: 0.4985 - recall_m: 0.2140 - f1_m: 0.2897 - val_loss: 0.4979 - val_accuracy: 0.3273 - val_precision_m: 0.5824 - val_recall_m: 0.3934 - val_f1_m: 0.4681\n","Epoch 10/50\n","131/131 [==============================] - 6s 43ms/step - loss: 0.5493 - accuracy: 0.2698 - precision_m: 0.5166 - recall_m: 0.2252 - f1_m: 0.3095 - val_loss: 0.4981 - val_accuracy: 0.3273 - val_precision_m: 0.5824 - val_recall_m: 0.3934 - val_f1_m: 0.4681\n","Epoch 11/50\n","131/131 [==============================] - 5s 42ms/step - loss: 0.5455 - accuracy: 0.2683 - precision_m: 0.5289 - recall_m: 0.2734 - f1_m: 0.3565 - val_loss: 0.5020 - val_accuracy: 0.3273 - val_precision_m: 0.5824 - val_recall_m: 0.3934 - val_f1_m: 0.4681\n","Epoch 00011: early stopping\n","Score for fold 1: loss of 0.6477416157722473; accuracy of 15.566577017307281% ;precision_m of 0.5127865076065063 ;recall_m of 0.2593536674976349 ;            f1_m of 0.34322670102119446\n","Epoch 1/50\n","131/131 [==============================] - 9s 53ms/step - loss: 0.6303 - accuracy: 0.2189 - precision_m: 0.5172 - recall_m: 0.1956 - f1_m: 0.2673 - val_loss: 0.5353 - val_accuracy: 0.3279 - val_precision_m: 0.5827 - val_recall_m: 0.3938 - val_f1_m: 0.4685\n","Epoch 2/50\n","131/131 [==============================] - 6s 42ms/step - loss: 0.5940 - accuracy: 0.2085 - precision_m: 0.4875 - recall_m: 0.1578 - f1_m: 0.2289 - val_loss: 0.5132 - val_accuracy: 0.3279 - val_precision_m: 0.5827 - val_recall_m: 0.3938 - val_f1_m: 0.4685\n","Epoch 3/50\n","131/131 [==============================] - 6s 43ms/step - loss: 0.5932 - accuracy: 0.2133 - precision_m: 0.5286 - recall_m: 0.2112 - f1_m: 0.2928 - val_loss: 0.5331 - val_accuracy: 0.3279 - val_precision_m: 0.5827 - val_recall_m: 0.3938 - val_f1_m: 0.4685\n","Epoch 4/50\n","131/131 [==============================] - 6s 42ms/step - loss: 0.5938 - accuracy: 0.2127 - precision_m: 0.5081 - recall_m: 0.1766 - f1_m: 0.2571 - val_loss: 0.5292 - val_accuracy: 0.3279 - val_precision_m: 0.5827 - val_recall_m: 0.3938 - val_f1_m: 0.4685\n","Epoch 5/50\n","131/131 [==============================] - 6s 43ms/step - loss: 0.5948 - accuracy: 0.2128 - precision_m: 0.5152 - recall_m: 0.1771 - f1_m: 0.2533 - val_loss: 0.5143 - val_accuracy: 0.3279 - val_precision_m: 0.5827 - val_recall_m: 0.3938 - val_f1_m: 0.4685\n","Epoch 6/50\n","131/131 [==============================] - 6s 43ms/step - loss: 0.5929 - accuracy: 0.2039 - precision_m: 0.5182 - recall_m: 0.2333 - f1_m: 0.3195 - val_loss: 0.5163 - val_accuracy: 0.3279 - val_precision_m: 0.5827 - val_recall_m: 0.3938 - val_f1_m: 0.4685\n","Epoch 7/50\n","131/131 [==============================] - 6s 44ms/step - loss: 0.5916 - accuracy: 0.2059 - precision_m: 0.5189 - recall_m: 0.2021 - f1_m: 0.2855 - val_loss: 0.5129 - val_accuracy: 0.3279 - val_precision_m: 0.5827 - val_recall_m: 0.3938 - val_f1_m: 0.4685\n","Epoch 8/50\n","131/131 [==============================] - 6s 43ms/step - loss: 0.5920 - accuracy: 0.2171 - precision_m: 0.5260 - recall_m: 0.2256 - f1_m: 0.3081 - val_loss: 0.5155 - val_accuracy: 0.3279 - val_precision_m: 0.5827 - val_recall_m: 0.3938 - val_f1_m: 0.4685\n","Epoch 9/50\n","131/131 [==============================] - 6s 43ms/step - loss: 0.6408 - accuracy: 0.2055 - precision_m: 0.5145 - recall_m: 0.1817 - f1_m: 0.2556 - val_loss: 0.5152 - val_accuracy: 0.3279 - val_precision_m: 0.5827 - val_recall_m: 0.3938 - val_f1_m: 0.4685\n","Epoch 10/50\n","131/131 [==============================] - 6s 42ms/step - loss: 0.5956 - accuracy: 0.1953 - precision_m: 0.5007 - recall_m: 0.1894 - f1_m: 0.2667 - val_loss: 0.5166 - val_accuracy: 0.3279 - val_precision_m: 0.5827 - val_recall_m: 0.3938 - val_f1_m: 0.4685\n","Epoch 11/50\n","131/131 [==============================] - 6s 43ms/step - loss: 0.5925 - accuracy: 0.2057 - precision_m: 0.5093 - recall_m: 0.1825 - f1_m: 0.2613 - val_loss: 0.5185 - val_accuracy: 0.3279 - val_precision_m: 0.5827 - val_recall_m: 0.3938 - val_f1_m: 0.4685\n","Epoch 00011: early stopping\n","Score for fold 2: loss of 0.5652515292167664; accuracy of 25.076335668563843% ;precision_m of 0.5106163024902344 ;recall_m of 0.3112577795982361 ;            f1_m of 0.3850182890892029\n","Epoch 1/50\n","131/131 [==============================] - 9s 49ms/step - loss: 0.6621 - accuracy: 0.2051 - precision_m: 0.4693 - recall_m: 0.1451 - f1_m: 0.1947 - val_loss: 0.5720 - val_accuracy: 0.2822 - val_precision_m: 0.5127 - val_recall_m: 0.3279 - val_f1_m: 0.3987\n","Epoch 2/50\n","131/131 [==============================] - 6s 42ms/step - loss: 0.6119 - accuracy: 0.1865 - precision_m: 0.4593 - recall_m: 0.1438 - f1_m: 0.2106 - val_loss: 0.5567 - val_accuracy: 0.2822 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00 - val_f1_m: 0.0000e+00\n","Epoch 3/50\n","131/131 [==============================] - 6s 43ms/step - loss: 0.6099 - accuracy: 0.1795 - precision_m: 0.4676 - recall_m: 0.1132 - f1_m: 0.1669 - val_loss: 0.5643 - val_accuracy: 0.2822 - val_precision_m: 0.5127 - val_recall_m: 0.3279 - val_f1_m: 0.3987\n","Epoch 4/50\n","131/131 [==============================] - 6s 43ms/step - loss: 0.6061 - accuracy: 0.1812 - precision_m: 0.5091 - recall_m: 0.1450 - f1_m: 0.2142 - val_loss: 0.5486 - val_accuracy: 0.2822 - val_precision_m: 0.5127 - val_recall_m: 0.3279 - val_f1_m: 0.3987\n","Epoch 5/50\n","131/131 [==============================] - 6s 43ms/step - loss: 0.6050 - accuracy: 0.1878 - precision_m: 0.4968 - recall_m: 0.1502 - f1_m: 0.2217 - val_loss: 0.5588 - val_accuracy: 0.2822 - val_precision_m: 0.5127 - val_recall_m: 0.3279 - val_f1_m: 0.3987\n","Epoch 6/50\n","131/131 [==============================] - 6s 43ms/step - loss: 0.6129 - accuracy: 0.1799 - precision_m: 0.4827 - recall_m: 0.1298 - f1_m: 0.1970 - val_loss: 0.5542 - val_accuracy: 0.2822 - val_precision_m: 0.5127 - val_recall_m: 0.3279 - val_f1_m: 0.3987\n","Epoch 7/50\n","131/131 [==============================] - 6s 43ms/step - loss: 0.6100 - accuracy: 0.1782 - precision_m: 0.5191 - recall_m: 0.1708 - f1_m: 0.2510 - val_loss: 0.5641 - val_accuracy: 0.2822 - val_precision_m: 0.5127 - val_recall_m: 0.3279 - val_f1_m: 0.3987\n","Epoch 8/50\n","131/131 [==============================] - 6s 43ms/step - loss: 0.6106 - accuracy: 0.1818 - precision_m: 0.5035 - recall_m: 0.1922 - f1_m: 0.2748 - val_loss: 0.5586 - val_accuracy: 0.2822 - val_precision_m: 0.5127 - val_recall_m: 0.3279 - val_f1_m: 0.3987\n","Epoch 9/50\n","131/131 [==============================] - 6s 43ms/step - loss: 0.6054 - accuracy: 0.1830 - precision_m: 0.5233 - recall_m: 0.2014 - f1_m: 0.2859 - val_loss: 0.5601 - val_accuracy: 0.2822 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00 - val_f1_m: 0.0000e+00\n","Epoch 10/50\n","131/131 [==============================] - 6s 43ms/step - loss: 0.6020 - accuracy: 0.1954 - precision_m: 0.5176 - recall_m: 0.1705 - f1_m: 0.2479 - val_loss: 0.5628 - val_accuracy: 0.2822 - val_precision_m: 0.5127 - val_recall_m: 0.3279 - val_f1_m: 0.3987\n","Epoch 11/50\n","131/131 [==============================] - 6s 43ms/step - loss: 0.6065 - accuracy: 0.1814 - precision_m: 0.5066 - recall_m: 0.1516 - f1_m: 0.2260 - val_loss: 0.5564 - val_accuracy: 0.2822 - val_precision_m: 0.5127 - val_recall_m: 0.3279 - val_f1_m: 0.3987\n","Epoch 00011: early stopping\n","Score for fold 3: loss of 0.5324959754943848; accuracy of 31.068703532218933% ;precision_m of 0.5502504706382751 ;recall_m of 0.36772269010543823 ;            f1_m of 0.43958553671836853\n","Epoch 1/50\n","131/131 [==============================] - 9s 51ms/step - loss: 0.5936 - accuracy: 0.2517 - precision_m: 0.4333 - recall_m: 0.2059 - f1_m: 0.2649 - val_loss: 0.5040 - val_accuracy: 0.3273 - val_precision_m: 0.5824 - val_recall_m: 0.3934 - val_f1_m: 0.4681\n","Epoch 2/50\n","131/131 [==============================] - 6s 45ms/step - loss: 0.5483 - accuracy: 0.2692 - precision_m: 0.5155 - recall_m: 0.1883 - f1_m: 0.2681 - val_loss: 0.5062 - val_accuracy: 0.3273 - val_precision_m: 0.5824 - val_recall_m: 0.3934 - val_f1_m: 0.4681\n","Epoch 3/50\n","131/131 [==============================] - 6s 45ms/step - loss: 0.5502 - accuracy: 0.2724 - precision_m: 0.4954 - recall_m: 0.1764 - f1_m: 0.2470 - val_loss: 0.5003 - val_accuracy: 0.3273 - val_precision_m: 0.5824 - val_recall_m: 0.3934 - val_f1_m: 0.4681\n","Epoch 4/50\n","131/131 [==============================] - 6s 46ms/step - loss: 0.5493 - accuracy: 0.2680 - precision_m: 0.5245 - recall_m: 0.2235 - f1_m: 0.3046 - val_loss: 0.5063 - val_accuracy: 0.3273 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00 - val_f1_m: 0.0000e+00\n","Epoch 5/50\n","131/131 [==============================] - 6s 46ms/step - loss: 0.5510 - accuracy: 0.2626 - precision_m: 0.4858 - recall_m: 0.1388 - f1_m: 0.1953 - val_loss: 0.5012 - val_accuracy: 0.3273 - val_precision_m: 0.5824 - val_recall_m: 0.3934 - val_f1_m: 0.4681\n","Epoch 6/50\n","131/131 [==============================] - 6s 46ms/step - loss: 0.5452 - accuracy: 0.2756 - precision_m: 0.5057 - recall_m: 0.2268 - f1_m: 0.2981 - val_loss: 0.5011 - val_accuracy: 0.3273 - val_precision_m: 0.5824 - val_recall_m: 0.3934 - val_f1_m: 0.4681\n","Epoch 7/50\n","131/131 [==============================] - 6s 45ms/step - loss: 0.5423 - accuracy: 0.2737 - precision_m: 0.5204 - recall_m: 0.2587 - f1_m: 0.3371 - val_loss: 0.4988 - val_accuracy: 0.3273 - val_precision_m: 0.5824 - val_recall_m: 0.3934 - val_f1_m: 0.4681\n","Epoch 8/50\n","131/131 [==============================] - 6s 46ms/step - loss: 0.5449 - accuracy: 0.2719 - precision_m: 0.5154 - recall_m: 0.2414 - f1_m: 0.3194 - val_loss: 0.4987 - val_accuracy: 0.3273 - val_precision_m: 0.5824 - val_recall_m: 0.3934 - val_f1_m: 0.4681\n","Epoch 9/50\n","131/131 [==============================] - 6s 45ms/step - loss: 0.5509 - accuracy: 0.2655 - precision_m: 0.4992 - recall_m: 0.2116 - f1_m: 0.2786 - val_loss: 0.5023 - val_accuracy: 0.3273 - val_precision_m: 0.5824 - val_recall_m: 0.3934 - val_f1_m: 0.4681\n","Epoch 10/50\n","131/131 [==============================] - 6s 45ms/step - loss: 0.5477 - accuracy: 0.2656 - precision_m: 0.5191 - recall_m: 0.2418 - f1_m: 0.3255 - val_loss: 0.4991 - val_accuracy: 0.3273 - val_precision_m: 0.5824 - val_recall_m: 0.3934 - val_f1_m: 0.4681\n","Epoch 11/50\n","131/131 [==============================] - 6s 45ms/step - loss: 0.5442 - accuracy: 0.2662 - precision_m: 0.5349 - recall_m: 0.2947 - f1_m: 0.3750 - val_loss: 0.5033 - val_accuracy: 0.3273 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00 - val_f1_m: 0.0000e+00\n","Epoch 00011: early stopping\n","Score for fold 1: loss of 0.6479007601737976; accuracy of 15.566577017307281% ;precision_m of 0.0 ;recall_m of 0.0 ;            f1_m of 0.0\n","Epoch 1/50\n","131/131 [==============================] - 10s 52ms/step - loss: 0.6274 - accuracy: 0.2095 - precision_m: 0.4933 - recall_m: 0.1791 - f1_m: 0.2403 - val_loss: 0.5232 - val_accuracy: 0.3279 - val_precision_m: 0.5827 - val_recall_m: 0.3938 - val_f1_m: 0.4685\n","Epoch 2/50\n","131/131 [==============================] - 6s 45ms/step - loss: 0.5925 - accuracy: 0.2080 - precision_m: 0.5070 - recall_m: 0.1834 - f1_m: 0.2652 - val_loss: 0.5195 - val_accuracy: 0.3279 - val_precision_m: 0.5827 - val_recall_m: 0.3938 - val_f1_m: 0.4685\n","Epoch 3/50\n","131/131 [==============================] - 6s 45ms/step - loss: 0.5876 - accuracy: 0.2184 - precision_m: 0.5180 - recall_m: 0.2311 - f1_m: 0.3157 - val_loss: 0.5188 - val_accuracy: 0.3279 - val_precision_m: 0.5827 - val_recall_m: 0.3938 - val_f1_m: 0.4685\n","Epoch 4/50\n","131/131 [==============================] - 6s 46ms/step - loss: 0.5908 - accuracy: 0.2147 - precision_m: 0.5310 - recall_m: 0.2527 - f1_m: 0.3386 - val_loss: 0.5190 - val_accuracy: 0.3279 - val_precision_m: 0.5827 - val_recall_m: 0.3938 - val_f1_m: 0.4685\n","Epoch 5/50\n","131/131 [==============================] - 6s 45ms/step - loss: 0.5879 - accuracy: 0.2103 - precision_m: 0.5236 - recall_m: 0.2201 - f1_m: 0.3040 - val_loss: 0.5131 - val_accuracy: 0.3279 - val_precision_m: 0.5827 - val_recall_m: 0.3938 - val_f1_m: 0.4685\n","Epoch 6/50\n","131/131 [==============================] - 6s 45ms/step - loss: 0.5881 - accuracy: 0.2142 - precision_m: 0.5260 - recall_m: 0.2384 - f1_m: 0.3243 - val_loss: 0.5221 - val_accuracy: 0.3279 - val_precision_m: 0.5827 - val_recall_m: 0.3938 - val_f1_m: 0.4685\n","Epoch 7/50\n","131/131 [==============================] - 6s 45ms/step - loss: 0.5951 - accuracy: 0.2116 - precision_m: 0.5179 - recall_m: 0.2121 - f1_m: 0.2942 - val_loss: 0.5195 - val_accuracy: 0.3279 - val_precision_m: 0.5827 - val_recall_m: 0.3938 - val_f1_m: 0.4685\n","Epoch 8/50\n","131/131 [==============================] - 6s 45ms/step - loss: 0.5912 - accuracy: 0.2073 - precision_m: 0.5362 - recall_m: 0.2237 - f1_m: 0.3095 - val_loss: 0.5158 - val_accuracy: 0.3279 - val_precision_m: 0.5827 - val_recall_m: 0.3938 - val_f1_m: 0.4685\n","Epoch 9/50\n","131/131 [==============================] - 6s 46ms/step - loss: 0.5894 - accuracy: 0.2105 - precision_m: 0.5174 - recall_m: 0.2248 - f1_m: 0.3119 - val_loss: 0.5116 - val_accuracy: 0.3279 - val_precision_m: 0.5827 - val_recall_m: 0.3938 - val_f1_m: 0.4685\n","Epoch 10/50\n","131/131 [==============================] - 6s 46ms/step - loss: 0.5954 - accuracy: 0.2050 - precision_m: 0.5056 - recall_m: 0.2189 - f1_m: 0.2984 - val_loss: 0.5219 - val_accuracy: 0.3279 - val_precision_m: 0.5827 - val_recall_m: 0.3938 - val_f1_m: 0.4685\n","Epoch 11/50\n","131/131 [==============================] - 6s 45ms/step - loss: 0.5934 - accuracy: 0.2096 - precision_m: 0.5275 - recall_m: 0.2566 - f1_m: 0.3411 - val_loss: 0.5218 - val_accuracy: 0.3279 - val_precision_m: 0.5827 - val_recall_m: 0.3938 - val_f1_m: 0.4685\n","Epoch 00011: early stopping\n","Score for fold 2: loss of 0.566992998123169; accuracy of 25.076335668563843% ;precision_m of 0.5106163024902344 ;recall_m of 0.3112577795982361 ;            f1_m of 0.3850182890892029\n","Epoch 1/50\n","131/131 [==============================] - 9s 51ms/step - loss: 0.6375 - accuracy: 0.1822 - precision_m: 0.5317 - recall_m: 0.1562 - f1_m: 0.2272 - val_loss: 0.5697 - val_accuracy: 0.2822 - val_precision_m: 0.5127 - val_recall_m: 0.3279 - val_f1_m: 0.3987\n","Epoch 2/50\n","131/131 [==============================] - 6s 45ms/step - loss: 0.6115 - accuracy: 0.1844 - precision_m: 0.5323 - recall_m: 0.1674 - f1_m: 0.2406 - val_loss: 0.5663 - val_accuracy: 0.2822 - val_precision_m: 0.5127 - val_recall_m: 0.3279 - val_f1_m: 0.3987\n","Epoch 3/50\n","131/131 [==============================] - 6s 45ms/step - loss: 0.6056 - accuracy: 0.1899 - precision_m: 0.5164 - recall_m: 0.1790 - f1_m: 0.2583 - val_loss: 0.5606 - val_accuracy: 0.2822 - val_precision_m: 0.5127 - val_recall_m: 0.3279 - val_f1_m: 0.3987\n","Epoch 4/50\n","131/131 [==============================] - 6s 45ms/step - loss: 0.6085 - accuracy: 0.1863 - precision_m: 0.5016 - recall_m: 0.1653 - f1_m: 0.2388 - val_loss: 0.5581 - val_accuracy: 0.2822 - val_precision_m: 0.5127 - val_recall_m: 0.3279 - val_f1_m: 0.3987\n","Epoch 5/50\n","131/131 [==============================] - 6s 46ms/step - loss: 0.6077 - accuracy: 0.1885 - precision_m: 0.5089 - recall_m: 0.1834 - f1_m: 0.2638 - val_loss: 0.5589 - val_accuracy: 0.2822 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00 - val_f1_m: 0.0000e+00\n","Epoch 6/50\n","131/131 [==============================] - 6s 45ms/step - loss: 0.6091 - accuracy: 0.1779 - precision_m: 0.5097 - recall_m: 0.1354 - f1_m: 0.2064 - val_loss: 0.5545 - val_accuracy: 0.2822 - val_precision_m: 0.5127 - val_recall_m: 0.3279 - val_f1_m: 0.3987\n","Epoch 7/50\n","131/131 [==============================] - 6s 45ms/step - loss: 0.6042 - accuracy: 0.1880 - precision_m: 0.4967 - recall_m: 0.1800 - f1_m: 0.2544 - val_loss: 0.5619 - val_accuracy: 0.2822 - val_precision_m: 0.5127 - val_recall_m: 0.3279 - val_f1_m: 0.3987\n","Epoch 8/50\n","131/131 [==============================] - 6s 45ms/step - loss: 0.6033 - accuracy: 0.2006 - precision_m: 0.4979 - recall_m: 0.2260 - f1_m: 0.3024 - val_loss: 0.5606 - val_accuracy: 0.2822 - val_precision_m: 0.5127 - val_recall_m: 0.3279 - val_f1_m: 0.3987\n","Epoch 9/50\n","131/131 [==============================] - 6s 46ms/step - loss: 0.6068 - accuracy: 0.1817 - precision_m: 0.5112 - recall_m: 0.2120 - f1_m: 0.2938 - val_loss: 0.5599 - val_accuracy: 0.2822 - val_precision_m: 0.5127 - val_recall_m: 0.3279 - val_f1_m: 0.3987\n","Epoch 10/50\n","131/131 [==============================] - 6s 45ms/step - loss: 0.6070 - accuracy: 0.1791 - precision_m: 0.4948 - recall_m: 0.1745 - f1_m: 0.2494 - val_loss: 0.5604 - val_accuracy: 0.2822 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00 - val_f1_m: 0.0000e+00\n","Epoch 11/50\n","131/131 [==============================] - 6s 46ms/step - loss: 0.6066 - accuracy: 0.1788 - precision_m: 0.4942 - recall_m: 0.1165 - f1_m: 0.1737 - val_loss: 0.5603 - val_accuracy: 0.2822 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00 - val_f1_m: 0.0000e+00\n","Epoch 00011: early stopping\n","Score for fold 3: loss of 0.5389556288719177; accuracy of 31.068703532218933% ;precision_m of 0.0 ;recall_m of 0.0 ;            f1_m of 0.0\n","Epoch 1/50\n","131/131 [==============================] - 9s 55ms/step - loss: 0.5764 - accuracy: 0.2720 - precision_m: 0.4549 - recall_m: 0.1861 - f1_m: 0.2488 - val_loss: 0.5026 - val_accuracy: 0.3273 - val_precision_m: 0.5824 - val_recall_m: 0.3934 - val_f1_m: 0.4681\n","Epoch 2/50\n","131/131 [==============================] - 6s 48ms/step - loss: 0.5466 - accuracy: 0.2756 - precision_m: 0.5323 - recall_m: 0.2561 - f1_m: 0.3380 - val_loss: 0.4989 - val_accuracy: 0.3273 - val_precision_m: 0.5824 - val_recall_m: 0.3934 - val_f1_m: 0.4681\n","Epoch 3/50\n","131/131 [==============================] - 6s 48ms/step - loss: 0.5518 - accuracy: 0.2652 - precision_m: 0.5111 - recall_m: 0.2226 - f1_m: 0.3071 - val_loss: 0.5042 - val_accuracy: 0.3273 - val_precision_m: 0.5824 - val_recall_m: 0.3934 - val_f1_m: 0.4681\n","Epoch 4/50\n","131/131 [==============================] - 6s 48ms/step - loss: 0.5525 - accuracy: 0.2571 - precision_m: 0.5011 - recall_m: 0.2142 - f1_m: 0.2895 - val_loss: 0.5028 - val_accuracy: 0.3273 - val_precision_m: 0.5824 - val_recall_m: 0.3934 - val_f1_m: 0.4681\n","Epoch 5/50\n","131/131 [==============================] - 6s 49ms/step - loss: 0.5505 - accuracy: 0.2645 - precision_m: 0.4922 - recall_m: 0.2146 - f1_m: 0.2911 - val_loss: 0.5050 - val_accuracy: 0.3273 - val_precision_m: 0.5824 - val_recall_m: 0.3934 - val_f1_m: 0.4681\n","Epoch 6/50\n","131/131 [==============================] - 6s 49ms/step - loss: 0.5398 - accuracy: 0.2805 - precision_m: 0.5337 - recall_m: 0.2708 - f1_m: 0.3543 - val_loss: 0.5032 - val_accuracy: 0.3273 - val_precision_m: 0.5824 - val_recall_m: 0.3934 - val_f1_m: 0.4681\n","Epoch 7/50\n","131/131 [==============================] - 6s 48ms/step - loss: 0.5497 - accuracy: 0.2624 - precision_m: 0.5393 - recall_m: 0.1743 - f1_m: 0.2545 - val_loss: 0.4991 - val_accuracy: 0.3273 - val_precision_m: 0.5824 - val_recall_m: 0.3934 - val_f1_m: 0.4681\n","Epoch 8/50\n","131/131 [==============================] - 6s 48ms/step - loss: 0.5430 - accuracy: 0.2811 - precision_m: 0.5305 - recall_m: 0.2882 - f1_m: 0.3684 - val_loss: 0.4986 - val_accuracy: 0.3273 - val_precision_m: 0.5824 - val_recall_m: 0.3934 - val_f1_m: 0.4681\n","Epoch 9/50\n","131/131 [==============================] - 6s 48ms/step - loss: 0.5498 - accuracy: 0.2618 - precision_m: 0.4991 - recall_m: 0.1853 - f1_m: 0.2651 - val_loss: 0.4986 - val_accuracy: 0.3273 - val_precision_m: 0.5824 - val_recall_m: 0.3934 - val_f1_m: 0.4681\n","Epoch 10/50\n","131/131 [==============================] - 6s 48ms/step - loss: 0.5428 - accuracy: 0.2674 - precision_m: 0.5196 - recall_m: 0.2301 - f1_m: 0.3128 - val_loss: 0.5039 - val_accuracy: 0.3273 - val_precision_m: 0.5824 - val_recall_m: 0.3934 - val_f1_m: 0.4681\n","Epoch 11/50\n","131/131 [==============================] - 6s 48ms/step - loss: 0.5463 - accuracy: 0.2701 - precision_m: 0.5248 - recall_m: 0.2134 - f1_m: 0.2962 - val_loss: 0.5003 - val_accuracy: 0.3273 - val_precision_m: 0.5824 - val_recall_m: 0.3934 - val_f1_m: 0.4681\n","Epoch 00011: early stopping\n","Score for fold 1: loss of 0.6476519703865051; accuracy of 15.566577017307281% ;precision_m of 0.5127865076065063 ;recall_m of 0.2593536674976349 ;            f1_m of 0.34322670102119446\n","Epoch 1/50\n","131/131 [==============================] - 10s 53ms/step - loss: 0.6211 - accuracy: 0.2055 - precision_m: 0.4967 - recall_m: 0.1592 - f1_m: 0.2235 - val_loss: 0.5234 - val_accuracy: 0.3279 - val_precision_m: 0.5827 - val_recall_m: 0.3938 - val_f1_m: 0.4685\n","Epoch 2/50\n","131/131 [==============================] - 6s 47ms/step - loss: 0.5937 - accuracy: 0.2115 - precision_m: 0.5071 - recall_m: 0.1814 - f1_m: 0.2623 - val_loss: 0.5241 - val_accuracy: 0.3279 - val_precision_m: 0.5827 - val_recall_m: 0.3938 - val_f1_m: 0.4685\n","Epoch 3/50\n","131/131 [==============================] - 6s 47ms/step - loss: 0.5902 - accuracy: 0.2119 - precision_m: 0.5424 - recall_m: 0.2170 - f1_m: 0.3006 - val_loss: 0.5263 - val_accuracy: 0.3279 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00 - val_f1_m: 0.0000e+00\n","Epoch 4/50\n","131/131 [==============================] - 6s 48ms/step - loss: 0.5908 - accuracy: 0.2202 - precision_m: 0.4901 - recall_m: 0.1645 - f1_m: 0.2292 - val_loss: 0.5283 - val_accuracy: 0.3279 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00 - val_f1_m: 0.0000e+00\n","Epoch 5/50\n","131/131 [==============================] - 6s 48ms/step - loss: 0.5919 - accuracy: 0.2127 - precision_m: 0.5209 - recall_m: 0.1838 - f1_m: 0.2636 - val_loss: 0.5128 - val_accuracy: 0.3279 - val_precision_m: 0.5827 - val_recall_m: 0.3938 - val_f1_m: 0.4685\n","Epoch 6/50\n","131/131 [==============================] - 6s 48ms/step - loss: 0.5915 - accuracy: 0.2193 - precision_m: 0.5208 - recall_m: 0.2172 - f1_m: 0.3031 - val_loss: 0.5201 - val_accuracy: 0.3279 - val_precision_m: 0.5827 - val_recall_m: 0.3938 - val_f1_m: 0.4685\n","Epoch 7/50\n","131/131 [==============================] - 6s 48ms/step - loss: 0.5911 - accuracy: 0.2097 - precision_m: 0.5219 - recall_m: 0.1973 - f1_m: 0.2825 - val_loss: 0.5188 - val_accuracy: 0.3279 - val_precision_m: 0.5827 - val_recall_m: 0.3938 - val_f1_m: 0.4685\n","Epoch 8/50\n","131/131 [==============================] - 6s 48ms/step - loss: 0.5941 - accuracy: 0.2063 - precision_m: 0.5115 - recall_m: 0.2117 - f1_m: 0.2926 - val_loss: 0.5184 - val_accuracy: 0.3279 - val_precision_m: 0.5827 - val_recall_m: 0.3938 - val_f1_m: 0.4685\n","Epoch 9/50\n","131/131 [==============================] - 6s 47ms/step - loss: 0.5879 - accuracy: 0.2134 - precision_m: 0.5392 - recall_m: 0.2592 - f1_m: 0.3447 - val_loss: 0.5193 - val_accuracy: 0.3279 - val_precision_m: 0.5827 - val_recall_m: 0.3938 - val_f1_m: 0.4685\n","Epoch 10/50\n","131/131 [==============================] - 6s 47ms/step - loss: 0.5936 - accuracy: 0.2059 - precision_m: 0.5265 - recall_m: 0.2212 - f1_m: 0.3069 - val_loss: 0.5202 - val_accuracy: 0.3279 - val_precision_m: 0.5827 - val_recall_m: 0.3938 - val_f1_m: 0.4685\n","Epoch 11/50\n","131/131 [==============================] - 6s 47ms/step - loss: 0.5924 - accuracy: 0.2004 - precision_m: 0.5126 - recall_m: 0.2370 - f1_m: 0.3224 - val_loss: 0.5187 - val_accuracy: 0.3279 - val_precision_m: 0.5827 - val_recall_m: 0.3938 - val_f1_m: 0.4685\n","Epoch 00011: early stopping\n","Score for fold 2: loss of 0.5674277544021606; accuracy of 25.076335668563843% ;precision_m of 0.5106163024902344 ;recall_m of 0.3112577795982361 ;            f1_m of 0.3850182890892029\n","Epoch 1/50\n","131/131 [==============================] - 9s 54ms/step - loss: 0.6342 - accuracy: 0.1957 - precision_m: 0.4770 - recall_m: 0.1704 - f1_m: 0.2389 - val_loss: 0.5639 - val_accuracy: 0.2822 - val_precision_m: 0.5127 - val_recall_m: 0.3279 - val_f1_m: 0.3987\n","Epoch 2/50\n","131/131 [==============================] - 6s 48ms/step - loss: 0.6046 - accuracy: 0.1863 - precision_m: 0.5149 - recall_m: 0.1686 - f1_m: 0.2482 - val_loss: 0.5669 - val_accuracy: 0.2822 - val_precision_m: 0.5127 - val_recall_m: 0.3279 - val_f1_m: 0.3987\n","Epoch 3/50\n","131/131 [==============================] - 6s 48ms/step - loss: 0.6065 - accuracy: 0.1917 - precision_m: 0.5065 - recall_m: 0.1456 - f1_m: 0.2130 - val_loss: 0.5552 - val_accuracy: 0.2822 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00 - val_f1_m: 0.0000e+00\n","Epoch 4/50\n","131/131 [==============================] - 6s 49ms/step - loss: 0.6064 - accuracy: 0.1886 - precision_m: 0.5125 - recall_m: 0.1254 - f1_m: 0.1925 - val_loss: 0.5696 - val_accuracy: 0.2822 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00 - val_f1_m: 0.0000e+00\n","Epoch 5/50\n","131/131 [==============================] - 6s 48ms/step - loss: 0.6027 - accuracy: 0.1927 - precision_m: 0.5264 - recall_m: 0.1695 - f1_m: 0.2379 - val_loss: 0.5577 - val_accuracy: 0.2822 - val_precision_m: 0.5127 - val_recall_m: 0.3279 - val_f1_m: 0.3987\n","Epoch 6/50\n","131/131 [==============================] - 6s 48ms/step - loss: 0.6094 - accuracy: 0.1767 - precision_m: 0.5147 - recall_m: 0.1349 - f1_m: 0.2083 - val_loss: 0.5573 - val_accuracy: 0.2822 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00 - val_f1_m: 0.0000e+00\n","Epoch 7/50\n","131/131 [==============================] - 6s 47ms/step - loss: 0.6048 - accuracy: 0.1857 - precision_m: 0.5060 - recall_m: 0.1567 - f1_m: 0.2269 - val_loss: 0.5549 - val_accuracy: 0.2822 - val_precision_m: 0.5127 - val_recall_m: 0.3279 - val_f1_m: 0.3987\n","Epoch 8/50\n","131/131 [==============================] - 6s 48ms/step - loss: 0.6035 - accuracy: 0.1845 - precision_m: 0.5225 - recall_m: 0.1898 - f1_m: 0.2694 - val_loss: 0.5653 - val_accuracy: 0.2822 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00 - val_f1_m: 0.0000e+00\n","Epoch 9/50\n","131/131 [==============================] - 6s 48ms/step - loss: 0.6053 - accuracy: 0.1869 - precision_m: 0.5187 - recall_m: 0.1712 - f1_m: 0.2419 - val_loss: 0.5550 - val_accuracy: 0.2822 - val_precision_m: 0.5127 - val_recall_m: 0.3279 - val_f1_m: 0.3987\n","Epoch 10/50\n","131/131 [==============================] - 6s 48ms/step - loss: 0.6616 - accuracy: 0.1848 - precision_m: 0.4983 - recall_m: 0.1856 - f1_m: 0.2462 - val_loss: 0.5616 - val_accuracy: 0.2822 - val_precision_m: 0.5127 - val_recall_m: 0.3279 - val_f1_m: 0.3987\n","Epoch 11/50\n","131/131 [==============================] - 6s 48ms/step - loss: 0.6082 - accuracy: 0.1838 - precision_m: 0.5080 - recall_m: 0.1797 - f1_m: 0.2584 - val_loss: 0.5559 - val_accuracy: 0.2822 - val_precision_m: 0.5127 - val_recall_m: 0.3279 - val_f1_m: 0.3987\n","Epoch 00011: early stopping\n","Score for fold 3: loss of 0.5318218469619751; accuracy of 31.068703532218933% ;precision_m of 0.5502504706382751 ;recall_m of 0.36772269010543823 ;            f1_m of 0.43958553671836853\n","Epoch 1/50\n","131/131 [==============================] - 9s 49ms/step - loss: 0.5914 - accuracy: 0.2531 - precision_m: 0.4159 - recall_m: 0.1639 - f1_m: 0.2178 - val_loss: 0.5077 - val_accuracy: 0.3273 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00 - val_f1_m: 0.0000e+00\n","Epoch 2/50\n","131/131 [==============================] - 6s 43ms/step - loss: 0.5482 - accuracy: 0.2740 - precision_m: 0.5163 - recall_m: 0.1955 - f1_m: 0.2716 - val_loss: 0.5073 - val_accuracy: 0.3273 - val_precision_m: 0.5824 - val_recall_m: 0.3934 - val_f1_m: 0.4681\n","Epoch 3/50\n","131/131 [==============================] - 6s 43ms/step - loss: 0.5473 - accuracy: 0.2668 - precision_m: 0.4810 - recall_m: 0.1661 - f1_m: 0.2340 - val_loss: 0.5060 - val_accuracy: 0.3273 - val_precision_m: 0.5824 - val_recall_m: 0.3934 - val_f1_m: 0.4681\n","Epoch 4/50\n","131/131 [==============================] - 6s 43ms/step - loss: 0.5462 - accuracy: 0.2752 - precision_m: 0.5229 - recall_m: 0.2249 - f1_m: 0.3077 - val_loss: 0.5029 - val_accuracy: 0.3273 - val_precision_m: 0.5824 - val_recall_m: 0.3934 - val_f1_m: 0.4681\n","Epoch 5/50\n","131/131 [==============================] - 6s 43ms/step - loss: 0.5475 - accuracy: 0.2643 - precision_m: 0.5288 - recall_m: 0.2213 - f1_m: 0.3004 - val_loss: 0.4992 - val_accuracy: 0.3273 - val_precision_m: 0.5824 - val_recall_m: 0.3934 - val_f1_m: 0.4681\n","Epoch 6/50\n","131/131 [==============================] - 6s 43ms/step - loss: 0.5452 - accuracy: 0.2682 - precision_m: 0.5114 - recall_m: 0.2264 - f1_m: 0.3082 - val_loss: 0.5078 - val_accuracy: 0.3273 - val_precision_m: 0.5824 - val_recall_m: 0.3934 - val_f1_m: 0.4681\n","Epoch 7/50\n","131/131 [==============================] - 6s 43ms/step - loss: 0.5468 - accuracy: 0.2671 - precision_m: 0.5172 - recall_m: 0.1819 - f1_m: 0.2593 - val_loss: 0.4997 - val_accuracy: 0.3273 - val_precision_m: 0.5824 - val_recall_m: 0.3934 - val_f1_m: 0.4681\n","Epoch 8/50\n","131/131 [==============================] - 6s 43ms/step - loss: 0.5459 - accuracy: 0.2703 - precision_m: 0.4617 - recall_m: 0.1938 - f1_m: 0.2606 - val_loss: 0.5061 - val_accuracy: 0.3273 - val_precision_m: 0.5824 - val_recall_m: 0.3934 - val_f1_m: 0.4681\n","Epoch 9/50\n","131/131 [==============================] - 6s 43ms/step - loss: 0.5482 - accuracy: 0.2661 - precision_m: 0.5076 - recall_m: 0.2200 - f1_m: 0.3009 - val_loss: 0.5015 - val_accuracy: 0.3273 - val_precision_m: 0.5824 - val_recall_m: 0.3934 - val_f1_m: 0.4681\n","Epoch 10/50\n","131/131 [==============================] - 6s 43ms/step - loss: 0.5467 - accuracy: 0.2655 - precision_m: 0.5247 - recall_m: 0.2872 - f1_m: 0.3683 - val_loss: 0.5014 - val_accuracy: 0.3273 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00 - val_f1_m: 0.0000e+00\n","Epoch 11/50\n","131/131 [==============================] - 6s 43ms/step - loss: 0.5485 - accuracy: 0.2679 - precision_m: 0.4793 - recall_m: 0.2208 - f1_m: 0.2908 - val_loss: 0.4971 - val_accuracy: 0.3273 - val_precision_m: 0.5824 - val_recall_m: 0.3934 - val_f1_m: 0.4681\n","Epoch 12/50\n","131/131 [==============================] - 6s 42ms/step - loss: 0.5495 - accuracy: 0.2594 - precision_m: 0.5128 - recall_m: 0.2591 - f1_m: 0.3411 - val_loss: 0.4987 - val_accuracy: 0.3273 - val_precision_m: 0.5824 - val_recall_m: 0.3934 - val_f1_m: 0.4681\n","Epoch 00012: early stopping\n","Score for fold 1: loss of 0.6539265513420105; accuracy of 15.566577017307281% ;precision_m of 0.5129217505455017 ;recall_m of 0.2593536674976349 ;            f1_m of 0.3432560861110687\n","Epoch 1/50\n","131/131 [==============================] - 9s 49ms/step - loss: 0.6169 - accuracy: 0.2267 - precision_m: 0.5008 - recall_m: 0.1970 - f1_m: 0.2738 - val_loss: 0.5301 - val_accuracy: 0.3279 - val_precision_m: 0.5827 - val_recall_m: 0.3938 - val_f1_m: 0.4685\n","Epoch 2/50\n","131/131 [==============================] - 6s 43ms/step - loss: 0.5918 - accuracy: 0.2224 - precision_m: 0.5121 - recall_m: 0.1770 - f1_m: 0.2552 - val_loss: 0.5223 - val_accuracy: 0.3279 - val_precision_m: 0.5827 - val_recall_m: 0.3938 - val_f1_m: 0.4685\n","Epoch 3/50\n","131/131 [==============================] - 6s 43ms/step - loss: 0.5889 - accuracy: 0.2136 - precision_m: 0.5294 - recall_m: 0.2273 - f1_m: 0.3046 - val_loss: 0.5251 - val_accuracy: 0.3279 - val_precision_m: 0.5827 - val_recall_m: 0.3938 - val_f1_m: 0.4685\n","Epoch 4/50\n","131/131 [==============================] - 6s 43ms/step - loss: 0.6148 - accuracy: 0.2096 - precision_m: 0.5252 - recall_m: 0.2102 - f1_m: 0.2880 - val_loss: 0.5275 - val_accuracy: 0.3279 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00 - val_f1_m: 0.0000e+00\n","Epoch 5/50\n","131/131 [==============================] - 6s 43ms/step - loss: 0.5960 - accuracy: 0.2072 - precision_m: 0.5212 - recall_m: 0.1670 - f1_m: 0.2408 - val_loss: 0.5248 - val_accuracy: 0.3279 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00 - val_f1_m: 0.0000e+00\n","Epoch 6/50\n","131/131 [==============================] - 6s 43ms/step - loss: 0.5923 - accuracy: 0.2070 - precision_m: 0.5132 - recall_m: 0.1385 - f1_m: 0.1993 - val_loss: 0.5163 - val_accuracy: 0.3279 - val_precision_m: 0.5827 - val_recall_m: 0.3938 - val_f1_m: 0.4685\n","Epoch 7/50\n","131/131 [==============================] - 6s 43ms/step - loss: 0.5903 - accuracy: 0.2056 - precision_m: 0.4915 - recall_m: 0.1635 - f1_m: 0.2380 - val_loss: 0.5237 - val_accuracy: 0.3279 - val_precision_m: 0.5827 - val_recall_m: 0.3938 - val_f1_m: 0.4685\n","Epoch 8/50\n","131/131 [==============================] - 6s 44ms/step - loss: 0.5937 - accuracy: 0.1988 - precision_m: 0.5139 - recall_m: 0.1957 - f1_m: 0.2781 - val_loss: 0.5195 - val_accuracy: 0.3279 - val_precision_m: 0.5827 - val_recall_m: 0.3938 - val_f1_m: 0.4685\n","Epoch 9/50\n","131/131 [==============================] - 6s 43ms/step - loss: 0.5899 - accuracy: 0.2074 - precision_m: 0.5194 - recall_m: 0.1867 - f1_m: 0.2670 - val_loss: 0.5167 - val_accuracy: 0.3279 - val_precision_m: 0.5827 - val_recall_m: 0.3938 - val_f1_m: 0.4685\n","Epoch 10/50\n","131/131 [==============================] - 6s 43ms/step - loss: 0.5910 - accuracy: 0.2063 - precision_m: 0.5230 - recall_m: 0.2143 - f1_m: 0.3006 - val_loss: 0.5143 - val_accuracy: 0.3279 - val_precision_m: 0.5827 - val_recall_m: 0.3938 - val_f1_m: 0.4685\n","Epoch 11/50\n","131/131 [==============================] - 6s 43ms/step - loss: 0.5909 - accuracy: 0.2022 - precision_m: 0.5091 - recall_m: 0.2239 - f1_m: 0.3073 - val_loss: 0.5170 - val_accuracy: 0.3279 - val_precision_m: 0.5827 - val_recall_m: 0.3938 - val_f1_m: 0.4685\n","Epoch 00011: early stopping\n","Score for fold 2: loss of 0.5679912567138672; accuracy of 25.076335668563843% ;precision_m of 0.5106163024902344 ;recall_m of 0.3112577795982361 ;            f1_m of 0.3850182890892029\n","Epoch 1/50\n","131/131 [==============================] - 9s 49ms/step - loss: 0.6327 - accuracy: 0.2004 - precision_m: 0.4292 - recall_m: 0.1635 - f1_m: 0.2148 - val_loss: 0.5606 - val_accuracy: 0.2822 - val_precision_m: 0.5127 - val_recall_m: 0.3279 - val_f1_m: 0.3987\n","Epoch 2/50\n","131/131 [==============================] - 6s 43ms/step - loss: 0.6089 - accuracy: 0.1842 - precision_m: 0.5143 - recall_m: 0.1622 - f1_m: 0.2325 - val_loss: 0.5684 - val_accuracy: 0.2822 - val_precision_m: 0.5127 - val_recall_m: 0.3279 - val_f1_m: 0.3987\n","Epoch 3/50\n","131/131 [==============================] - 6s 44ms/step - loss: 0.6075 - accuracy: 0.1907 - precision_m: 0.5092 - recall_m: 0.1803 - f1_m: 0.2598 - val_loss: 0.5682 - val_accuracy: 0.2822 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00 - val_f1_m: 0.0000e+00\n","Epoch 4/50\n","131/131 [==============================] - 6s 43ms/step - loss: 0.6061 - accuracy: 0.1897 - precision_m: 0.5124 - recall_m: 0.1905 - f1_m: 0.2706 - val_loss: 0.5640 - val_accuracy: 0.2822 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00 - val_f1_m: 0.0000e+00\n","Epoch 5/50\n","131/131 [==============================] - 6s 43ms/step - loss: 0.6093 - accuracy: 0.1762 - precision_m: 0.4621 - recall_m: 0.1075 - f1_m: 0.1557 - val_loss: 0.5635 - val_accuracy: 0.2822 - val_precision_m: 0.5127 - val_recall_m: 0.3279 - val_f1_m: 0.3987\n","Epoch 6/50\n","131/131 [==============================] - 6s 43ms/step - loss: 0.6046 - accuracy: 0.1874 - precision_m: 0.5010 - recall_m: 0.1673 - f1_m: 0.2476 - val_loss: 0.5614 - val_accuracy: 0.2822 - val_precision_m: 0.5127 - val_recall_m: 0.3279 - val_f1_m: 0.3987\n","Epoch 7/50\n","131/131 [==============================] - 6s 44ms/step - loss: 0.6066 - accuracy: 0.1863 - precision_m: 0.5119 - recall_m: 0.2211 - f1_m: 0.3039 - val_loss: 0.5570 - val_accuracy: 0.2822 - val_precision_m: 0.5127 - val_recall_m: 0.3279 - val_f1_m: 0.3987\n","Epoch 8/50\n","131/131 [==============================] - 6s 43ms/step - loss: 0.6104 - accuracy: 0.1725 - precision_m: 0.5020 - recall_m: 0.1995 - f1_m: 0.2787 - val_loss: 0.5490 - val_accuracy: 0.2822 - val_precision_m: 0.5127 - val_recall_m: 0.3279 - val_f1_m: 0.3987\n","Epoch 9/50\n","131/131 [==============================] - 6s 43ms/step - loss: 0.6074 - accuracy: 0.1890 - precision_m: 0.5141 - recall_m: 0.1897 - f1_m: 0.2649 - val_loss: 0.5592 - val_accuracy: 0.2822 - val_precision_m: 0.5127 - val_recall_m: 0.3279 - val_f1_m: 0.3987\n","Epoch 10/50\n","131/131 [==============================] - 6s 43ms/step - loss: 0.6065 - accuracy: 0.1922 - precision_m: 0.5052 - recall_m: 0.2040 - f1_m: 0.2840 - val_loss: 0.5564 - val_accuracy: 0.2822 - val_precision_m: 0.5127 - val_recall_m: 0.3279 - val_f1_m: 0.3987\n","Epoch 11/50\n","131/131 [==============================] - 6s 43ms/step - loss: 0.6126 - accuracy: 0.1656 - precision_m: 0.5125 - recall_m: 0.1635 - f1_m: 0.2328 - val_loss: 0.5528 - val_accuracy: 0.2822 - val_precision_m: 0.5127 - val_recall_m: 0.3279 - val_f1_m: 0.3987\n","Epoch 00011: early stopping\n","Score for fold 3: loss of 0.5253331065177917; accuracy of 31.068703532218933% ;precision_m of 0.5502504706382751 ;recall_m of 0.36772269010543823 ;            f1_m of 0.43958553671836853\n","Epoch 1/50\n","131/131 [==============================] - 9s 51ms/step - loss: 0.5861 - accuracy: 0.2577 - precision_m: 0.4758 - recall_m: 0.1858 - f1_m: 0.2485 - val_loss: 0.4986 - val_accuracy: 0.3273 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00 - val_f1_m: 0.0000e+00\n","Epoch 2/50\n","131/131 [==============================] - 6s 45ms/step - loss: 0.5514 - accuracy: 0.2675 - precision_m: 0.5419 - recall_m: 0.1769 - f1_m: 0.2474 - val_loss: 0.4996 - val_accuracy: 0.3273 - val_precision_m: 0.5824 - val_recall_m: 0.3934 - val_f1_m: 0.4681\n","Epoch 3/50\n","131/131 [==============================] - 6s 45ms/step - loss: 0.5496 - accuracy: 0.2672 - precision_m: 0.5092 - recall_m: 0.2085 - f1_m: 0.2890 - val_loss: 0.5023 - val_accuracy: 0.3273 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00 - val_f1_m: 0.0000e+00\n","Epoch 4/50\n","131/131 [==============================] - 6s 45ms/step - loss: 0.5490 - accuracy: 0.2741 - precision_m: 0.4789 - recall_m: 0.1853 - f1_m: 0.2560 - val_loss: 0.5019 - val_accuracy: 0.3273 - val_precision_m: 0.5824 - val_recall_m: 0.3934 - val_f1_m: 0.4681\n","Epoch 5/50\n","131/131 [==============================] - 6s 46ms/step - loss: 0.5428 - accuracy: 0.2780 - precision_m: 0.5234 - recall_m: 0.2188 - f1_m: 0.2999 - val_loss: 0.5019 - val_accuracy: 0.3273 - val_precision_m: 0.5824 - val_recall_m: 0.3934 - val_f1_m: 0.4681\n","Epoch 6/50\n","131/131 [==============================] - 6s 45ms/step - loss: 0.5509 - accuracy: 0.2620 - precision_m: 0.5182 - recall_m: 0.2499 - f1_m: 0.3343 - val_loss: 0.5047 - val_accuracy: 0.3273 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00 - val_f1_m: 0.0000e+00\n","Epoch 7/50\n","131/131 [==============================] - 6s 46ms/step - loss: 0.5460 - accuracy: 0.2693 - precision_m: 0.4547 - recall_m: 0.1747 - f1_m: 0.2436 - val_loss: 0.5028 - val_accuracy: 0.3273 - val_precision_m: 0.5824 - val_recall_m: 0.3934 - val_f1_m: 0.4681\n","Epoch 8/50\n","131/131 [==============================] - 6s 45ms/step - loss: 0.5437 - accuracy: 0.2738 - precision_m: 0.5364 - recall_m: 0.2524 - f1_m: 0.3349 - val_loss: 0.5035 - val_accuracy: 0.3273 - val_precision_m: 0.5824 - val_recall_m: 0.3934 - val_f1_m: 0.4681\n","Epoch 9/50\n","131/131 [==============================] - 6s 45ms/step - loss: 0.5457 - accuracy: 0.2776 - precision_m: 0.5239 - recall_m: 0.2416 - f1_m: 0.3212 - val_loss: 0.4973 - val_accuracy: 0.3273 - val_precision_m: 0.5824 - val_recall_m: 0.3934 - val_f1_m: 0.4681\n","Epoch 10/50\n","131/131 [==============================] - 6s 45ms/step - loss: 0.5430 - accuracy: 0.2735 - precision_m: 0.5046 - recall_m: 0.2432 - f1_m: 0.3232 - val_loss: 0.5035 - val_accuracy: 0.3273 - val_precision_m: 0.5824 - val_recall_m: 0.3934 - val_f1_m: 0.4681\n","Epoch 11/50\n","131/131 [==============================] - 6s 46ms/step - loss: 0.5481 - accuracy: 0.2735 - precision_m: 0.5020 - recall_m: 0.2296 - f1_m: 0.3127 - val_loss: 0.5013 - val_accuracy: 0.3273 - val_precision_m: 0.5824 - val_recall_m: 0.3934 - val_f1_m: 0.4681\n","Epoch 12/50\n","131/131 [==============================] - 6s 45ms/step - loss: 0.5460 - accuracy: 0.2660 - precision_m: 0.5197 - recall_m: 0.2682 - f1_m: 0.3508 - val_loss: 0.5004 - val_accuracy: 0.3273 - val_precision_m: 0.5824 - val_recall_m: 0.3934 - val_f1_m: 0.4681\n","Epoch 00012: early stopping\n","Score for fold 1: loss of 0.6543947458267212; accuracy of 15.566577017307281% ;precision_m of 0.5127865076065063 ;recall_m of 0.2593536674976349 ;            f1_m of 0.34322670102119446\n","Epoch 1/50\n","131/131 [==============================] - 10s 52ms/step - loss: 0.6166 - accuracy: 0.2186 - precision_m: 0.5305 - recall_m: 0.1885 - f1_m: 0.2676 - val_loss: 0.5224 - val_accuracy: 0.3279 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00 - val_f1_m: 0.0000e+00\n","Epoch 2/50\n","131/131 [==============================] - 6s 45ms/step - loss: 0.5885 - accuracy: 0.2222 - precision_m: 0.5383 - recall_m: 0.1799 - f1_m: 0.2597 - val_loss: 0.5244 - val_accuracy: 0.3279 - val_precision_m: 0.5827 - val_recall_m: 0.3938 - val_f1_m: 0.4685\n","Epoch 3/50\n","131/131 [==============================] - 6s 45ms/step - loss: 0.5970 - accuracy: 0.2027 - precision_m: 0.5173 - recall_m: 0.1958 - f1_m: 0.2815 - val_loss: 0.5228 - val_accuracy: 0.3279 - val_precision_m: 0.5827 - val_recall_m: 0.3938 - val_f1_m: 0.4685\n","Epoch 4/50\n","131/131 [==============================] - 6s 45ms/step - loss: 0.5914 - accuracy: 0.2150 - precision_m: 0.5119 - recall_m: 0.1867 - f1_m: 0.2689 - val_loss: 0.5279 - val_accuracy: 0.3279 - val_precision_m: 0.5827 - val_recall_m: 0.3938 - val_f1_m: 0.4685\n","Epoch 5/50\n","131/131 [==============================] - 6s 46ms/step - loss: 0.5913 - accuracy: 0.2095 - precision_m: 0.5330 - recall_m: 0.2128 - f1_m: 0.2942 - val_loss: 0.5199 - val_accuracy: 0.3279 - val_precision_m: 0.5827 - val_recall_m: 0.3938 - val_f1_m: 0.4685\n","Epoch 6/50\n","131/131 [==============================] - 6s 45ms/step - loss: 0.5914 - accuracy: 0.2112 - precision_m: 0.5100 - recall_m: 0.2000 - f1_m: 0.2851 - val_loss: 0.5227 - val_accuracy: 0.3279 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00 - val_f1_m: 0.0000e+00\n","Epoch 7/50\n","131/131 [==============================] - 6s 45ms/step - loss: 0.5971 - accuracy: 0.1982 - precision_m: 0.4945 - recall_m: 0.1423 - f1_m: 0.2106 - val_loss: 0.5153 - val_accuracy: 0.3279 - val_precision_m: 0.5827 - val_recall_m: 0.3938 - val_f1_m: 0.4685\n","Epoch 8/50\n","131/131 [==============================] - 6s 45ms/step - loss: 0.5867 - accuracy: 0.2129 - precision_m: 0.5276 - recall_m: 0.2275 - f1_m: 0.3093 - val_loss: 0.5216 - val_accuracy: 0.3279 - val_precision_m: 0.5827 - val_recall_m: 0.3938 - val_f1_m: 0.4685\n","Epoch 9/50\n","131/131 [==============================] - 6s 45ms/step - loss: 0.5909 - accuracy: 0.2223 - precision_m: 0.5193 - recall_m: 0.1595 - f1_m: 0.2345 - val_loss: 0.5269 - val_accuracy: 0.3279 - val_precision_m: 0.5827 - val_recall_m: 0.3938 - val_f1_m: 0.4685\n","Epoch 10/50\n","131/131 [==============================] - 6s 45ms/step - loss: 0.5901 - accuracy: 0.2091 - precision_m: 0.5231 - recall_m: 0.2143 - f1_m: 0.3014 - val_loss: 0.5217 - val_accuracy: 0.3279 - val_precision_m: 0.5827 - val_recall_m: 0.3938 - val_f1_m: 0.4685\n","Epoch 11/50\n","131/131 [==============================] - 6s 45ms/step - loss: 0.5959 - accuracy: 0.2042 - precision_m: 0.4940 - recall_m: 0.1737 - f1_m: 0.2470 - val_loss: 0.5138 - val_accuracy: 0.3279 - val_precision_m: 0.5827 - val_recall_m: 0.3938 - val_f1_m: 0.4685\n","Epoch 12/50\n","131/131 [==============================] - 6s 45ms/step - loss: 0.5927 - accuracy: 0.2011 - precision_m: 0.5194 - recall_m: 0.2585 - f1_m: 0.3438 - val_loss: 0.5162 - val_accuracy: 0.3279 - val_precision_m: 0.5827 - val_recall_m: 0.3938 - val_f1_m: 0.4685\n","Epoch 00012: early stopping\n","Score for fold 2: loss of 0.5641634464263916; accuracy of 25.076335668563843% ;precision_m of 0.5106163024902344 ;recall_m of 0.3112577795982361 ;            f1_m of 0.3850182890892029\n","Epoch 1/50\n","131/131 [==============================] - 9s 51ms/step - loss: 0.6432 - accuracy: 0.1922 - precision_m: 0.4648 - recall_m: 0.1394 - f1_m: 0.1930 - val_loss: 0.5605 - val_accuracy: 0.2822 - val_precision_m: 0.5127 - val_recall_m: 0.3279 - val_f1_m: 0.3987\n","Epoch 2/50\n","131/131 [==============================] - 6s 45ms/step - loss: 0.6127 - accuracy: 0.1758 - precision_m: 0.4946 - recall_m: 0.1527 - f1_m: 0.2251 - val_loss: 0.5639 - val_accuracy: 0.2822 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00 - val_f1_m: 0.0000e+00\n","Epoch 3/50\n","131/131 [==============================] - 6s 45ms/step - loss: 0.6059 - accuracy: 0.1848 - precision_m: 0.5124 - recall_m: 0.1601 - f1_m: 0.2374 - val_loss: 0.5538 - val_accuracy: 0.2822 - val_precision_m: 0.5127 - val_recall_m: 0.3279 - val_f1_m: 0.3987\n","Epoch 4/50\n","131/131 [==============================] - 6s 46ms/step - loss: 0.6063 - accuracy: 0.1936 - precision_m: 0.5125 - recall_m: 0.1833 - f1_m: 0.2644 - val_loss: 0.5670 - val_accuracy: 0.2822 - val_precision_m: 0.5127 - val_recall_m: 0.3279 - val_f1_m: 0.3987\n","Epoch 5/50\n","131/131 [==============================] - 6s 45ms/step - loss: 0.6095 - accuracy: 0.1748 - precision_m: 0.5192 - recall_m: 0.1499 - f1_m: 0.2165 - val_loss: 0.5607 - val_accuracy: 0.2822 - val_precision_m: 0.5127 - val_recall_m: 0.3279 - val_f1_m: 0.3987\n","Epoch 6/50\n","131/131 [==============================] - 6s 45ms/step - loss: 0.6046 - accuracy: 0.1918 - precision_m: 0.5079 - recall_m: 0.2033 - f1_m: 0.2824 - val_loss: 0.5647 - val_accuracy: 0.2822 - val_precision_m: 0.5127 - val_recall_m: 0.3279 - val_f1_m: 0.3987\n","Epoch 7/50\n","131/131 [==============================] - 6s 45ms/step - loss: 0.6045 - accuracy: 0.1813 - precision_m: 0.5424 - recall_m: 0.1966 - f1_m: 0.2823 - val_loss: 0.5538 - val_accuracy: 0.2822 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00 - val_f1_m: 0.0000e+00\n","Epoch 8/50\n","131/131 [==============================] - 6s 45ms/step - loss: 0.6105 - accuracy: 0.1843 - precision_m: 0.5000 - recall_m: 0.1447 - f1_m: 0.2105 - val_loss: 0.5543 - val_accuracy: 0.2822 - val_precision_m: 0.5127 - val_recall_m: 0.3279 - val_f1_m: 0.3987\n","Epoch 9/50\n","131/131 [==============================] - 6s 45ms/step - loss: 0.6124 - accuracy: 0.1710 - precision_m: 0.4785 - recall_m: 0.1307 - f1_m: 0.1949 - val_loss: 0.5531 - val_accuracy: 0.2822 - val_precision_m: 0.5127 - val_recall_m: 0.3279 - val_f1_m: 0.3987\n","Epoch 10/50\n","131/131 [==============================] - 6s 45ms/step - loss: 0.6072 - accuracy: 0.1745 - precision_m: 0.5138 - recall_m: 0.2219 - f1_m: 0.3069 - val_loss: 0.5633 - val_accuracy: 0.2822 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00 - val_f1_m: 0.0000e+00\n","Epoch 11/50\n","131/131 [==============================] - 6s 45ms/step - loss: 0.6082 - accuracy: 0.1803 - precision_m: 0.4923 - recall_m: 0.1544 - f1_m: 0.2288 - val_loss: 0.5555 - val_accuracy: 0.2822 - val_precision_m: 0.5127 - val_recall_m: 0.3279 - val_f1_m: 0.3987\n","Epoch 00011: early stopping\n","Score for fold 3: loss of 0.5335127711296082; accuracy of 31.068703532218933% ;precision_m of 0.5502504706382751 ;recall_m of 0.36772269010543823 ;            f1_m of 0.43958553671836853\n","Epoch 1/50\n","131/131 [==============================] - 9s 53ms/step - loss: 0.5777 - accuracy: 0.2628 - precision_m: 0.4884 - recall_m: 0.1868 - f1_m: 0.2478 - val_loss: 0.5170 - val_accuracy: 0.3273 - val_precision_m: 0.5824 - val_recall_m: 0.3934 - val_f1_m: 0.4681\n","Epoch 2/50\n","131/131 [==============================] - 6s 47ms/step - loss: 0.5473 - accuracy: 0.2725 - precision_m: 0.5199 - recall_m: 0.2061 - f1_m: 0.2871 - val_loss: 0.5049 - val_accuracy: 0.3273 - val_precision_m: 0.5824 - val_recall_m: 0.3934 - val_f1_m: 0.4681\n","Epoch 3/50\n","131/131 [==============================] - 6s 48ms/step - loss: 0.5441 - accuracy: 0.2796 - precision_m: 0.5263 - recall_m: 0.1856 - f1_m: 0.2617 - val_loss: 0.5012 - val_accuracy: 0.3273 - val_precision_m: 0.5824 - val_recall_m: 0.3934 - val_f1_m: 0.4681\n","Epoch 4/50\n","131/131 [==============================] - 6s 48ms/step - loss: 0.5469 - accuracy: 0.2680 - precision_m: 0.5273 - recall_m: 0.1829 - f1_m: 0.2565 - val_loss: 0.5011 - val_accuracy: 0.3273 - val_precision_m: 0.5824 - val_recall_m: 0.3934 - val_f1_m: 0.4681\n","Epoch 5/50\n","131/131 [==============================] - 6s 48ms/step - loss: 0.5474 - accuracy: 0.2636 - precision_m: 0.5285 - recall_m: 0.2660 - f1_m: 0.3510 - val_loss: 0.5025 - val_accuracy: 0.3273 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00 - val_f1_m: 0.0000e+00\n","Epoch 6/50\n","131/131 [==============================] - 6s 47ms/step - loss: 0.5511 - accuracy: 0.2564 - precision_m: 0.4974 - recall_m: 0.1881 - f1_m: 0.2677 - val_loss: 0.4999 - val_accuracy: 0.3273 - val_precision_m: 0.5824 - val_recall_m: 0.3934 - val_f1_m: 0.4681\n","Epoch 7/50\n","131/131 [==============================] - 6s 48ms/step - loss: 0.5519 - accuracy: 0.2590 - precision_m: 0.4991 - recall_m: 0.2173 - f1_m: 0.2949 - val_loss: 0.5028 - val_accuracy: 0.3273 - val_precision_m: 0.5824 - val_recall_m: 0.3934 - val_f1_m: 0.4681\n","Epoch 8/50\n","131/131 [==============================] - 6s 47ms/step - loss: 0.5438 - accuracy: 0.2739 - precision_m: 0.5241 - recall_m: 0.2523 - f1_m: 0.3369 - val_loss: 0.5035 - val_accuracy: 0.3273 - val_precision_m: 0.5824 - val_recall_m: 0.3934 - val_f1_m: 0.4681\n","Epoch 9/50\n","131/131 [==============================] - 6s 48ms/step - loss: 0.5460 - accuracy: 0.2738 - precision_m: 0.5146 - recall_m: 0.2492 - f1_m: 0.3238 - val_loss: 0.5063 - val_accuracy: 0.3273 - val_precision_m: 0.5824 - val_recall_m: 0.3934 - val_f1_m: 0.4681\n","Epoch 10/50\n","131/131 [==============================] - 6s 48ms/step - loss: 0.5469 - accuracy: 0.2623 - precision_m: 0.5176 - recall_m: 0.2735 - f1_m: 0.3545 - val_loss: 0.4992 - val_accuracy: 0.3273 - val_precision_m: 0.5824 - val_recall_m: 0.3934 - val_f1_m: 0.4681\n","Epoch 11/50\n","131/131 [==============================] - 6s 48ms/step - loss: 0.5498 - accuracy: 0.2636 - precision_m: 0.5114 - recall_m: 0.2438 - f1_m: 0.3232 - val_loss: 0.4996 - val_accuracy: 0.3273 - val_precision_m: 0.5824 - val_recall_m: 0.3934 - val_f1_m: 0.4681\n","Epoch 00011: early stopping\n","Score for fold 1: loss of 0.6501350402832031; accuracy of 15.566577017307281% ;precision_m of 0.5127865076065063 ;recall_m of 0.2593536674976349 ;            f1_m of 0.34322670102119446\n","Epoch 1/50\n","131/131 [==============================] - 10s 54ms/step - loss: 0.6215 - accuracy: 0.2166 - precision_m: 0.4312 - recall_m: 0.1756 - f1_m: 0.2363 - val_loss: 0.5075 - val_accuracy: 0.3279 - val_precision_m: 0.5827 - val_recall_m: 0.3938 - val_f1_m: 0.4685\n","Epoch 2/50\n","131/131 [==============================] - 6s 47ms/step - loss: 0.5938 - accuracy: 0.2075 - precision_m: 0.5240 - recall_m: 0.2209 - f1_m: 0.3072 - val_loss: 0.5171 - val_accuracy: 0.3279 - val_precision_m: 0.5827 - val_recall_m: 0.3938 - val_f1_m: 0.4685\n","Epoch 3/50\n","131/131 [==============================] - 6s 48ms/step - loss: 0.5886 - accuracy: 0.2115 - precision_m: 0.5118 - recall_m: 0.2188 - f1_m: 0.3015 - val_loss: 0.5331 - val_accuracy: 0.3279 - val_precision_m: 0.5827 - val_recall_m: 0.3938 - val_f1_m: 0.4685\n","Epoch 4/50\n","131/131 [==============================] - 6s 47ms/step - loss: 0.5904 - accuracy: 0.2193 - precision_m: 0.5372 - recall_m: 0.2318 - f1_m: 0.3192 - val_loss: 0.5251 - val_accuracy: 0.3279 - val_precision_m: 0.5827 - val_recall_m: 0.3938 - val_f1_m: 0.4685\n","Epoch 5/50\n","131/131 [==============================] - 6s 48ms/step - loss: 0.5938 - accuracy: 0.2094 - precision_m: 0.5164 - recall_m: 0.1804 - f1_m: 0.2571 - val_loss: 0.5211 - val_accuracy: 0.3279 - val_precision_m: 0.5827 - val_recall_m: 0.3938 - val_f1_m: 0.4685\n","Epoch 6/50\n","131/131 [==============================] - 6s 47ms/step - loss: 0.5920 - accuracy: 0.2112 - precision_m: 0.5076 - recall_m: 0.2139 - f1_m: 0.2990 - val_loss: 0.5173 - val_accuracy: 0.3279 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00 - val_f1_m: 0.0000e+00\n","Epoch 7/50\n","131/131 [==============================] - 6s 47ms/step - loss: 0.5875 - accuracy: 0.2150 - precision_m: 0.4897 - recall_m: 0.1426 - f1_m: 0.2023 - val_loss: 0.5302 - val_accuracy: 0.3279 - val_precision_m: 0.5827 - val_recall_m: 0.3938 - val_f1_m: 0.4685\n","Epoch 8/50\n","131/131 [==============================] - 6s 48ms/step - loss: 0.5959 - accuracy: 0.2164 - precision_m: 0.5138 - recall_m: 0.2285 - f1_m: 0.3126 - val_loss: 0.5216 - val_accuracy: 0.3279 - val_precision_m: 0.5827 - val_recall_m: 0.3938 - val_f1_m: 0.4685\n","Epoch 9/50\n","131/131 [==============================] - 6s 48ms/step - loss: 0.5906 - accuracy: 0.2142 - precision_m: 0.5155 - recall_m: 0.2006 - f1_m: 0.2752 - val_loss: 0.5273 - val_accuracy: 0.3279 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00 - val_f1_m: 0.0000e+00\n","Epoch 10/50\n","131/131 [==============================] - 6s 47ms/step - loss: 0.5878 - accuracy: 0.2157 - precision_m: 0.5129 - recall_m: 0.1821 - f1_m: 0.2567 - val_loss: 0.5259 - val_accuracy: 0.3279 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00 - val_f1_m: 0.0000e+00\n","Epoch 11/50\n","131/131 [==============================] - 6s 47ms/step - loss: 0.5917 - accuracy: 0.2085 - precision_m: 0.5077 - recall_m: 0.1508 - f1_m: 0.2257 - val_loss: 0.5151 - val_accuracy: 0.3279 - val_precision_m: 0.5827 - val_recall_m: 0.3938 - val_f1_m: 0.4685\n","Epoch 00011: early stopping\n","Score for fold 2: loss of 0.5634970664978027; accuracy of 25.076335668563843% ;precision_m of 0.5106163024902344 ;recall_m of 0.3112577795982361 ;            f1_m of 0.3850182890892029\n","Epoch 1/50\n","131/131 [==============================] - 9s 54ms/step - loss: 0.6338 - accuracy: 0.1928 - precision_m: 0.5104 - recall_m: 0.1485 - f1_m: 0.2135 - val_loss: 0.5478 - val_accuracy: 0.2822 - val_precision_m: 0.5127 - val_recall_m: 0.3279 - val_f1_m: 0.3987\n","Epoch 2/50\n","131/131 [==============================] - 6s 47ms/step - loss: 0.6086 - accuracy: 0.1811 - precision_m: 0.5112 - recall_m: 0.1758 - f1_m: 0.2540 - val_loss: 0.5611 - val_accuracy: 0.2822 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00 - val_f1_m: 0.0000e+00\n","Epoch 3/50\n","131/131 [==============================] - 6s 47ms/step - loss: 0.6042 - accuracy: 0.1845 - precision_m: 0.5267 - recall_m: 0.1588 - f1_m: 0.2370 - val_loss: 0.5647 - val_accuracy: 0.2822 - val_precision_m: 0.5127 - val_recall_m: 0.3279 - val_f1_m: 0.3987\n","Epoch 4/50\n","131/131 [==============================] - 6s 48ms/step - loss: 0.6315 - accuracy: 0.1827 - precision_m: 0.5089 - recall_m: 0.1977 - f1_m: 0.2727 - val_loss: 0.5516 - val_accuracy: 0.2822 - val_precision_m: 0.5127 - val_recall_m: 0.3279 - val_f1_m: 0.3987\n","Epoch 5/50\n","131/131 [==============================] - 6s 47ms/step - loss: 0.6077 - accuracy: 0.1781 - precision_m: 0.4965 - recall_m: 0.1702 - f1_m: 0.2450 - val_loss: 0.5564 - val_accuracy: 0.2822 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00 - val_f1_m: 0.0000e+00\n","Epoch 6/50\n","131/131 [==============================] - 6s 48ms/step - loss: 0.6047 - accuracy: 0.1863 - precision_m: 0.4925 - recall_m: 0.1394 - f1_m: 0.2114 - val_loss: 0.5587 - val_accuracy: 0.2822 - val_precision_m: 0.5127 - val_recall_m: 0.3279 - val_f1_m: 0.3987\n","Epoch 7/50\n","131/131 [==============================] - 6s 47ms/step - loss: 0.6120 - accuracy: 0.1784 - precision_m: 0.5060 - recall_m: 0.1916 - f1_m: 0.2686 - val_loss: 0.5633 - val_accuracy: 0.2822 - val_precision_m: 0.5127 - val_recall_m: 0.3279 - val_f1_m: 0.3987\n","Epoch 8/50\n","131/131 [==============================] - 6s 48ms/step - loss: 0.6109 - accuracy: 0.1693 - precision_m: 0.4983 - recall_m: 0.1474 - f1_m: 0.2208 - val_loss: 0.5559 - val_accuracy: 0.2822 - val_precision_m: 0.5127 - val_recall_m: 0.3279 - val_f1_m: 0.3987\n","Epoch 9/50\n","131/131 [==============================] - 6s 48ms/step - loss: 0.6122 - accuracy: 0.1834 - precision_m: 0.5086 - recall_m: 0.2137 - f1_m: 0.2990 - val_loss: 0.5587 - val_accuracy: 0.2822 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00 - val_f1_m: 0.0000e+00\n","Epoch 10/50\n","131/131 [==============================] - 6s 48ms/step - loss: 0.6037 - accuracy: 0.1853 - precision_m: 0.4981 - recall_m: 0.1831 - f1_m: 0.2646 - val_loss: 0.5575 - val_accuracy: 0.2822 - val_precision_m: 0.5127 - val_recall_m: 0.3279 - val_f1_m: 0.3987\n","Epoch 11/50\n","131/131 [==============================] - 6s 48ms/step - loss: 0.6062 - accuracy: 0.1845 - precision_m: 0.5069 - recall_m: 0.1404 - f1_m: 0.2131 - val_loss: 0.5591 - val_accuracy: 0.2822 - val_precision_m: 0.5127 - val_recall_m: 0.3279 - val_f1_m: 0.3987\n","Epoch 00011: early stopping\n","Score for fold 3: loss of 0.5338538885116577; accuracy of 31.068703532218933% ;precision_m of 0.5502504706382751 ;recall_m of 0.36772269010543823 ;            f1_m of 0.43958553671836853\n","Epoch 1/50\n","131/131 [==============================] - 9s 54ms/step - loss: 0.5996 - accuracy: 0.2427 - precision_m: 0.4449 - recall_m: 0.1697 - f1_m: 0.2383 - val_loss: 0.5019 - val_accuracy: 0.3273 - val_precision_m: 0.5824 - val_recall_m: 0.3934 - val_f1_m: 0.4681\n","Epoch 2/50\n","131/131 [==============================] - 6s 43ms/step - loss: 0.5492 - accuracy: 0.2678 - precision_m: 0.4855 - recall_m: 0.1655 - f1_m: 0.2410 - val_loss: 0.5025 - val_accuracy: 0.3273 - val_precision_m: 0.5824 - val_recall_m: 0.3934 - val_f1_m: 0.4681\n","Epoch 3/50\n","131/131 [==============================] - 6s 44ms/step - loss: 0.5508 - accuracy: 0.2569 - precision_m: 0.5272 - recall_m: 0.2066 - f1_m: 0.2893 - val_loss: 0.5004 - val_accuracy: 0.3273 - val_precision_m: 0.5824 - val_recall_m: 0.3934 - val_f1_m: 0.4681\n","Epoch 4/50\n","131/131 [==============================] - 6s 44ms/step - loss: 0.5491 - accuracy: 0.2695 - precision_m: 0.5169 - recall_m: 0.2448 - f1_m: 0.3281 - val_loss: 0.4985 - val_accuracy: 0.3273 - val_precision_m: 0.5824 - val_recall_m: 0.3934 - val_f1_m: 0.4681\n","Epoch 5/50\n","131/131 [==============================] - 6s 43ms/step - loss: 0.5526 - accuracy: 0.2622 - precision_m: 0.4997 - recall_m: 0.1513 - f1_m: 0.2167 - val_loss: 0.4971 - val_accuracy: 0.3273 - val_precision_m: 0.5824 - val_recall_m: 0.3934 - val_f1_m: 0.4681\n","Epoch 6/50\n","131/131 [==============================] - 6s 44ms/step - loss: 0.5474 - accuracy: 0.2706 - precision_m: 0.5140 - recall_m: 0.2264 - f1_m: 0.3068 - val_loss: 0.5015 - val_accuracy: 0.3273 - val_precision_m: 0.5824 - val_recall_m: 0.3934 - val_f1_m: 0.4681\n","Epoch 7/50\n","131/131 [==============================] - 6s 43ms/step - loss: 0.5501 - accuracy: 0.2650 - precision_m: 0.4791 - recall_m: 0.1985 - f1_m: 0.2719 - val_loss: 0.5005 - val_accuracy: 0.3273 - val_precision_m: 0.5824 - val_recall_m: 0.3934 - val_f1_m: 0.4681\n","Epoch 8/50\n","131/131 [==============================] - 6s 44ms/step - loss: 0.5482 - accuracy: 0.2601 - precision_m: 0.5219 - recall_m: 0.2638 - f1_m: 0.3392 - val_loss: 0.5066 - val_accuracy: 0.3273 - val_precision_m: 0.5824 - val_recall_m: 0.3934 - val_f1_m: 0.4681\n","Epoch 9/50\n","131/131 [==============================] - 6s 43ms/step - loss: 0.5492 - accuracy: 0.2691 - precision_m: 0.5325 - recall_m: 0.1777 - f1_m: 0.2470 - val_loss: 0.5012 - val_accuracy: 0.3273 - val_precision_m: 0.5824 - val_recall_m: 0.3934 - val_f1_m: 0.4681\n","Epoch 10/50\n","131/131 [==============================] - 6s 44ms/step - loss: 0.5450 - accuracy: 0.2708 - precision_m: 0.5171 - recall_m: 0.2665 - f1_m: 0.3451 - val_loss: 0.5052 - val_accuracy: 0.3273 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00 - val_f1_m: 0.0000e+00\n","Epoch 11/50\n","131/131 [==============================] - 6s 43ms/step - loss: 0.5471 - accuracy: 0.2701 - precision_m: 0.5164 - recall_m: 0.1643 - f1_m: 0.2331 - val_loss: 0.5007 - val_accuracy: 0.3273 - val_precision_m: 0.5824 - val_recall_m: 0.3934 - val_f1_m: 0.4681\n","Epoch 00011: early stopping\n","Score for fold 1: loss of 0.646206796169281; accuracy of 15.566577017307281% ;precision_m of 0.5127865076065063 ;recall_m of 0.2593536674976349 ;            f1_m of 0.34322670102119446\n","Epoch 1/50\n","131/131 [==============================] - 9s 50ms/step - loss: 0.6188 - accuracy: 0.2228 - precision_m: 0.4977 - recall_m: 0.1580 - f1_m: 0.2293 - val_loss: 0.5210 - val_accuracy: 0.3279 - val_precision_m: 0.5827 - val_recall_m: 0.3938 - val_f1_m: 0.4685\n","Epoch 2/50\n","131/131 [==============================] - 6s 43ms/step - loss: 0.5936 - accuracy: 0.2123 - precision_m: 0.5375 - recall_m: 0.2081 - f1_m: 0.2931 - val_loss: 0.5212 - val_accuracy: 0.3279 - val_precision_m: 0.5827 - val_recall_m: 0.3938 - val_f1_m: 0.4685\n","Epoch 3/50\n","131/131 [==============================] - 6s 44ms/step - loss: 0.5932 - accuracy: 0.2027 - precision_m: 0.5329 - recall_m: 0.1876 - f1_m: 0.2728 - val_loss: 0.5225 - val_accuracy: 0.3279 - val_precision_m: 0.5827 - val_recall_m: 0.3938 - val_f1_m: 0.4685\n","Epoch 4/50\n","131/131 [==============================] - 6s 43ms/step - loss: 0.5891 - accuracy: 0.2166 - precision_m: 0.5326 - recall_m: 0.2167 - f1_m: 0.3020 - val_loss: 0.5193 - val_accuracy: 0.3279 - val_precision_m: 0.5827 - val_recall_m: 0.3938 - val_f1_m: 0.4685\n","Epoch 5/50\n","131/131 [==============================] - 6s 44ms/step - loss: 0.5985 - accuracy: 0.2015 - precision_m: 0.5112 - recall_m: 0.1887 - f1_m: 0.2686 - val_loss: 0.5209 - val_accuracy: 0.3279 - val_precision_m: 0.5827 - val_recall_m: 0.3938 - val_f1_m: 0.4685\n","Epoch 6/50\n","131/131 [==============================] - 6s 43ms/step - loss: 0.5957 - accuracy: 0.1998 - precision_m: 0.5258 - recall_m: 0.1828 - f1_m: 0.2601 - val_loss: 0.5222 - val_accuracy: 0.3279 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00 - val_f1_m: 0.0000e+00\n","Epoch 7/50\n","131/131 [==============================] - 6s 44ms/step - loss: 0.5890 - accuracy: 0.2064 - precision_m: 0.5368 - recall_m: 0.1990 - f1_m: 0.2828 - val_loss: 0.5208 - val_accuracy: 0.3279 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00 - val_f1_m: 0.0000e+00\n","Epoch 8/50\n","131/131 [==============================] - 6s 43ms/step - loss: 0.8007 - accuracy: 0.1980 - precision_m: 0.4706 - recall_m: 0.2162 - f1_m: 0.2647 - val_loss: 0.5214 - val_accuracy: 0.3279 - val_precision_m: 0.5827 - val_recall_m: 0.3938 - val_f1_m: 0.4685\n","Epoch 9/50\n","131/131 [==============================] - 6s 44ms/step - loss: 0.5935 - accuracy: 0.2082 - precision_m: 0.5087 - recall_m: 0.1679 - f1_m: 0.2483 - val_loss: 0.5149 - val_accuracy: 0.3279 - val_precision_m: 0.5827 - val_recall_m: 0.3938 - val_f1_m: 0.4685\n","Epoch 10/50\n","131/131 [==============================] - 6s 44ms/step - loss: 0.5872 - accuracy: 0.2139 - precision_m: 0.5362 - recall_m: 0.1971 - f1_m: 0.2854 - val_loss: 0.4925 - val_accuracy: 0.3413 - val_precision_m: 0.6407 - val_recall_m: 0.3809 - val_f1_m: 0.4736\n","Epoch 11/50\n","131/131 [==============================] - 6s 43ms/step - loss: 0.5677 - accuracy: 0.2873 - precision_m: 0.6173 - recall_m: 0.1964 - f1_m: 0.2923 - val_loss: 0.5261 - val_accuracy: 0.3279 - val_precision_m: 0.6020 - val_recall_m: 0.0540 - val_f1_m: 0.0948\n","Epoch 12/50\n","131/131 [==============================] - 6s 44ms/step - loss: 0.5893 - accuracy: 0.2049 - precision_m: 0.5391 - recall_m: 0.1535 - f1_m: 0.2310 - val_loss: 0.4943 - val_accuracy: 0.3279 - val_precision_m: 0.7206 - val_recall_m: 0.2405 - val_f1_m: 0.3523\n","Epoch 13/50\n","131/131 [==============================] - 6s 44ms/step - loss: 0.5742 - accuracy: 0.2548 - precision_m: 0.6217 - recall_m: 0.1793 - f1_m: 0.2685 - val_loss: 0.4655 - val_accuracy: 0.3575 - val_precision_m: 0.6935 - val_recall_m: 0.3505 - val_f1_m: 0.4580\n","Epoch 14/50\n","131/131 [==============================] - 6s 43ms/step - loss: 0.5455 - accuracy: 0.3035 - precision_m: 0.6571 - recall_m: 0.2257 - f1_m: 0.3307 - val_loss: 0.4519 - val_accuracy: 0.4004 - val_precision_m: 0.6856 - val_recall_m: 0.3497 - val_f1_m: 0.4564\n","Epoch 15/50\n","131/131 [==============================] - 6s 44ms/step - loss: 0.5324 - accuracy: 0.2763 - precision_m: 0.6509 - recall_m: 0.2931 - f1_m: 0.3987 - val_loss: 0.4446 - val_accuracy: 0.3603 - val_precision_m: 0.6673 - val_recall_m: 0.4319 - val_f1_m: 0.5224\n","Epoch 16/50\n","131/131 [==============================] - 6s 43ms/step - loss: 0.5144 - accuracy: 0.2918 - precision_m: 0.6495 - recall_m: 0.3722 - f1_m: 0.4700 - val_loss: 0.4197 - val_accuracy: 0.3832 - val_precision_m: 0.6768 - val_recall_m: 0.4960 - val_f1_m: 0.5697\n","Epoch 17/50\n","131/131 [==============================] - 6s 44ms/step - loss: 0.4917 - accuracy: 0.3590 - precision_m: 0.6652 - recall_m: 0.4476 - f1_m: 0.5313 - val_loss: 0.3952 - val_accuracy: 0.5071 - val_precision_m: 0.6929 - val_recall_m: 0.5818 - val_f1_m: 0.6311\n","Epoch 18/50\n","131/131 [==============================] - 6s 43ms/step - loss: 0.4683 - accuracy: 0.4410 - precision_m: 0.6775 - recall_m: 0.5153 - f1_m: 0.5827 - val_loss: 0.3632 - val_accuracy: 0.5272 - val_precision_m: 0.7039 - val_recall_m: 0.6183 - val_f1_m: 0.6571\n","Epoch 19/50\n","131/131 [==============================] - 6s 44ms/step - loss: 0.4410 - accuracy: 0.4950 - precision_m: 0.6974 - recall_m: 0.5543 - f1_m: 0.6158 - val_loss: 0.3538 - val_accuracy: 0.5043 - val_precision_m: 0.7381 - val_recall_m: 0.5939 - val_f1_m: 0.6571\n","Epoch 20/50\n","131/131 [==============================] - 6s 43ms/step - loss: 0.4147 - accuracy: 0.5085 - precision_m: 0.7116 - recall_m: 0.6144 - f1_m: 0.6577 - val_loss: 0.3382 - val_accuracy: 0.5615 - val_precision_m: 0.7311 - val_recall_m: 0.6316 - val_f1_m: 0.6769\n","Epoch 21/50\n","131/131 [==============================] - 6s 44ms/step - loss: 0.4041 - accuracy: 0.5122 - precision_m: 0.7068 - recall_m: 0.6321 - f1_m: 0.6658 - val_loss: 0.3296 - val_accuracy: 0.5748 - val_precision_m: 0.7328 - val_recall_m: 0.6486 - val_f1_m: 0.6867\n","Epoch 22/50\n","131/131 [==============================] - 6s 43ms/step - loss: 0.3917 - accuracy: 0.5479 - precision_m: 0.7355 - recall_m: 0.6494 - f1_m: 0.6880 - val_loss: 0.3393 - val_accuracy: 0.5281 - val_precision_m: 0.7289 - val_recall_m: 0.6208 - val_f1_m: 0.6691\n","Epoch 23/50\n","131/131 [==============================] - 6s 44ms/step - loss: 0.3778 - accuracy: 0.5579 - precision_m: 0.7310 - recall_m: 0.6629 - f1_m: 0.6936 - val_loss: 0.3205 - val_accuracy: 0.5806 - val_precision_m: 0.7606 - val_recall_m: 0.6478 - val_f1_m: 0.6981\n","Epoch 24/50\n","131/131 [==============================] - 6s 43ms/step - loss: 0.3638 - accuracy: 0.5860 - precision_m: 0.7443 - recall_m: 0.6841 - f1_m: 0.7118 - val_loss: 0.3172 - val_accuracy: 0.5720 - val_precision_m: 0.7612 - val_recall_m: 0.6819 - val_f1_m: 0.7181\n","Epoch 25/50\n","131/131 [==============================] - 6s 44ms/step - loss: 0.3555 - accuracy: 0.6002 - precision_m: 0.7607 - recall_m: 0.7025 - f1_m: 0.7285 - val_loss: 0.3234 - val_accuracy: 0.5767 - val_precision_m: 0.7482 - val_recall_m: 0.6421 - val_f1_m: 0.6895\n","Epoch 26/50\n","131/131 [==============================] - 6s 43ms/step - loss: 0.3473 - accuracy: 0.5984 - precision_m: 0.7650 - recall_m: 0.7002 - f1_m: 0.7299 - val_loss: 0.3123 - val_accuracy: 0.5949 - val_precision_m: 0.7774 - val_recall_m: 0.6426 - val_f1_m: 0.7020\n","Epoch 27/50\n","131/131 [==============================] - 6s 44ms/step - loss: 0.3460 - accuracy: 0.5910 - precision_m: 0.7705 - recall_m: 0.7063 - f1_m: 0.7356 - val_loss: 0.3098 - val_accuracy: 0.6120 - val_precision_m: 0.7739 - val_recall_m: 0.6651 - val_f1_m: 0.7137\n","Epoch 28/50\n","131/131 [==============================] - 6s 44ms/step - loss: 0.3396 - accuracy: 0.5882 - precision_m: 0.7676 - recall_m: 0.7113 - f1_m: 0.7370 - val_loss: 0.2999 - val_accuracy: 0.6244 - val_precision_m: 0.7712 - val_recall_m: 0.6765 - val_f1_m: 0.7192\n","Epoch 29/50\n","131/131 [==============================] - 6s 44ms/step - loss: 0.3339 - accuracy: 0.5951 - precision_m: 0.7702 - recall_m: 0.7126 - f1_m: 0.7391 - val_loss: 0.2976 - val_accuracy: 0.6406 - val_precision_m: 0.7798 - val_recall_m: 0.7023 - val_f1_m: 0.7373\n","Epoch 30/50\n","131/131 [==============================] - 6s 44ms/step - loss: 0.3334 - accuracy: 0.5914 - precision_m: 0.7659 - recall_m: 0.7231 - f1_m: 0.7423 - val_loss: 0.3051 - val_accuracy: 0.6139 - val_precision_m: 0.7729 - val_recall_m: 0.6850 - val_f1_m: 0.7248\n","Epoch 31/50\n","131/131 [==============================] - 6s 44ms/step - loss: 0.3249 - accuracy: 0.6075 - precision_m: 0.7762 - recall_m: 0.7314 - f1_m: 0.7518 - val_loss: 0.3006 - val_accuracy: 0.6292 - val_precision_m: 0.7739 - val_recall_m: 0.7020 - val_f1_m: 0.7349\n","Epoch 32/50\n","131/131 [==============================] - 6s 44ms/step - loss: 0.3203 - accuracy: 0.6090 - precision_m: 0.7721 - recall_m: 0.7477 - f1_m: 0.7581 - val_loss: 0.2952 - val_accuracy: 0.6397 - val_precision_m: 0.7724 - val_recall_m: 0.7091 - val_f1_m: 0.7380\n","Epoch 33/50\n","131/131 [==============================] - 6s 44ms/step - loss: 0.3124 - accuracy: 0.6293 - precision_m: 0.7886 - recall_m: 0.7558 - f1_m: 0.7706 - val_loss: 0.2972 - val_accuracy: 0.6254 - val_precision_m: 0.7722 - val_recall_m: 0.7014 - val_f1_m: 0.7334\n","Epoch 34/50\n","131/131 [==============================] - 6s 44ms/step - loss: 0.3091 - accuracy: 0.6242 - precision_m: 0.7897 - recall_m: 0.7584 - f1_m: 0.7724 - val_loss: 0.2885 - val_accuracy: 0.6282 - val_precision_m: 0.7626 - val_recall_m: 0.7104 - val_f1_m: 0.7344\n","Epoch 35/50\n","131/131 [==============================] - 6s 44ms/step - loss: 0.2961 - accuracy: 0.6226 - precision_m: 0.7900 - recall_m: 0.7677 - f1_m: 0.7775 - val_loss: 0.2976 - val_accuracy: 0.6339 - val_precision_m: 0.7784 - val_recall_m: 0.7136 - val_f1_m: 0.7433\n","Epoch 36/50\n","131/131 [==============================] - 6s 44ms/step - loss: 0.2882 - accuracy: 0.6166 - precision_m: 0.8054 - recall_m: 0.7747 - f1_m: 0.7887 - val_loss: 0.2954 - val_accuracy: 0.6358 - val_precision_m: 0.7708 - val_recall_m: 0.7562 - val_f1_m: 0.7622\n","Epoch 37/50\n","131/131 [==============================] - 6s 44ms/step - loss: 0.2816 - accuracy: 0.6290 - precision_m: 0.8081 - recall_m: 0.7822 - f1_m: 0.7937 - val_loss: 0.2857 - val_accuracy: 0.6320 - val_precision_m: 0.7777 - val_recall_m: 0.7505 - val_f1_m: 0.7627\n","Epoch 38/50\n","131/131 [==============================] - 6s 44ms/step - loss: 0.2728 - accuracy: 0.6199 - precision_m: 0.8053 - recall_m: 0.7885 - f1_m: 0.7956 - val_loss: 0.2817 - val_accuracy: 0.6511 - val_precision_m: 0.7942 - val_recall_m: 0.7554 - val_f1_m: 0.7737\n","Epoch 39/50\n","131/131 [==============================] - 6s 44ms/step - loss: 0.2724 - accuracy: 0.6231 - precision_m: 0.8190 - recall_m: 0.7919 - f1_m: 0.8042 - val_loss: 0.2850 - val_accuracy: 0.6378 - val_precision_m: 0.8050 - val_recall_m: 0.7403 - val_f1_m: 0.7695\n","Epoch 40/50\n","131/131 [==============================] - 6s 44ms/step - loss: 0.2612 - accuracy: 0.6021 - precision_m: 0.8318 - recall_m: 0.8015 - f1_m: 0.8153 - val_loss: 0.2945 - val_accuracy: 0.6635 - val_precision_m: 0.7813 - val_recall_m: 0.7514 - val_f1_m: 0.7649\n","Epoch 41/50\n","131/131 [==============================] - 6s 44ms/step - loss: 0.2570 - accuracy: 0.6184 - precision_m: 0.8320 - recall_m: 0.8032 - f1_m: 0.8163 - val_loss: 0.2870 - val_accuracy: 0.6368 - val_precision_m: 0.8029 - val_recall_m: 0.7403 - val_f1_m: 0.7690\n","Epoch 42/50\n","131/131 [==============================] - 6s 44ms/step - loss: 0.2531 - accuracy: 0.6265 - precision_m: 0.8401 - recall_m: 0.8128 - f1_m: 0.8251 - val_loss: 0.2785 - val_accuracy: 0.6949 - val_precision_m: 0.7926 - val_recall_m: 0.7535 - val_f1_m: 0.7711\n","Epoch 43/50\n","131/131 [==============================] - 6s 44ms/step - loss: 0.2489 - accuracy: 0.6344 - precision_m: 0.8387 - recall_m: 0.8062 - f1_m: 0.8209 - val_loss: 0.2866 - val_accuracy: 0.6692 - val_precision_m: 0.8231 - val_recall_m: 0.7554 - val_f1_m: 0.7865\n","Epoch 44/50\n","131/131 [==============================] - 6s 43ms/step - loss: 0.2353 - accuracy: 0.6313 - precision_m: 0.8595 - recall_m: 0.8167 - f1_m: 0.8365 - val_loss: 0.2844 - val_accuracy: 0.6721 - val_precision_m: 0.8174 - val_recall_m: 0.7640 - val_f1_m: 0.7887\n","Epoch 45/50\n","131/131 [==============================] - 6s 44ms/step - loss: 0.2297 - accuracy: 0.6455 - precision_m: 0.8600 - recall_m: 0.8225 - f1_m: 0.8398 - val_loss: 0.2761 - val_accuracy: 0.6864 - val_precision_m: 0.8321 - val_recall_m: 0.7494 - val_f1_m: 0.7868\n","Epoch 46/50\n","131/131 [==============================] - 6s 44ms/step - loss: 0.2254 - accuracy: 0.6580 - precision_m: 0.8609 - recall_m: 0.8319 - f1_m: 0.8452 - val_loss: 0.2771 - val_accuracy: 0.6921 - val_precision_m: 0.8223 - val_recall_m: 0.7638 - val_f1_m: 0.7903\n","Epoch 47/50\n","131/131 [==============================] - 6s 44ms/step - loss: 0.2162 - accuracy: 0.6810 - precision_m: 0.8678 - recall_m: 0.8320 - f1_m: 0.8485 - val_loss: 0.2784 - val_accuracy: 0.6864 - val_precision_m: 0.8196 - val_recall_m: 0.7652 - val_f1_m: 0.7901\n","Epoch 48/50\n","131/131 [==============================] - 6s 43ms/step - loss: 0.2159 - accuracy: 0.6572 - precision_m: 0.8658 - recall_m: 0.8439 - f1_m: 0.8537 - val_loss: 0.2915 - val_accuracy: 0.6778 - val_precision_m: 0.8207 - val_recall_m: 0.7640 - val_f1_m: 0.7899\n","Epoch 49/50\n","131/131 [==============================] - 6s 44ms/step - loss: 0.2165 - accuracy: 0.6633 - precision_m: 0.8749 - recall_m: 0.8349 - f1_m: 0.8535 - val_loss: 0.2906 - val_accuracy: 0.6902 - val_precision_m: 0.8050 - val_recall_m: 0.7675 - val_f1_m: 0.7843\n","Epoch 50/50\n","131/131 [==============================] - 6s 44ms/step - loss: 0.2111 - accuracy: 0.6644 - precision_m: 0.8688 - recall_m: 0.8471 - f1_m: 0.8571 - val_loss: 0.2901 - val_accuracy: 0.6930 - val_precision_m: 0.8168 - val_recall_m: 0.7757 - val_f1_m: 0.7941\n","Score for fold 2: loss of 0.34269165992736816; accuracy of 64.0839695930481% ;precision_m of 0.7908105850219727 ;recall_m of 0.7720423340797424 ;            f1_m of 0.7797624468803406\n","Epoch 1/50\n","131/131 [==============================] - 9s 50ms/step - loss: 0.6251 - accuracy: 0.1962 - precision_m: 0.4958 - recall_m: 0.1480 - f1_m: 0.2071 - val_loss: 0.5541 - val_accuracy: 0.2822 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00 - val_f1_m: 0.0000e+00\n","Epoch 2/50\n","131/131 [==============================] - 6s 44ms/step - loss: 0.6088 - accuracy: 0.1833 - precision_m: 0.5022 - recall_m: 0.1481 - f1_m: 0.2237 - val_loss: 0.5650 - val_accuracy: 0.2822 - val_precision_m: 0.5127 - val_recall_m: 0.3279 - val_f1_m: 0.3987\n","Epoch 3/50\n","131/131 [==============================] - 6s 43ms/step - loss: 0.6138 - accuracy: 0.1834 - precision_m: 0.5013 - recall_m: 0.1521 - f1_m: 0.2244 - val_loss: 0.5777 - val_accuracy: 0.2822 - val_precision_m: 0.5431 - val_recall_m: 0.1983 - val_f1_m: 0.2863\n","Epoch 4/50\n","131/131 [==============================] - 6s 44ms/step - loss: 0.6145 - accuracy: 0.1912 - precision_m: 0.5033 - recall_m: 0.1535 - f1_m: 0.2310 - val_loss: 0.5575 - val_accuracy: 0.2822 - val_precision_m: 0.5127 - val_recall_m: 0.3279 - val_f1_m: 0.3987\n","Epoch 5/50\n","131/131 [==============================] - 6s 44ms/step - loss: 0.6095 - accuracy: 0.1855 - precision_m: 0.5180 - recall_m: 0.1939 - f1_m: 0.2776 - val_loss: 0.5604 - val_accuracy: 0.2822 - val_precision_m: 0.5078 - val_recall_m: 0.3070 - val_f1_m: 0.3807\n","Epoch 6/50\n","131/131 [==============================] - 6s 44ms/step - loss: 0.6074 - accuracy: 0.1857 - precision_m: 0.5061 - recall_m: 0.1852 - f1_m: 0.2673 - val_loss: 0.5573 - val_accuracy: 0.2822 - val_precision_m: 0.6056 - val_recall_m: 0.0518 - val_f1_m: 0.0942\n","Epoch 7/50\n","131/131 [==============================] - 6s 44ms/step - loss: 0.6072 - accuracy: 0.1852 - precision_m: 0.5029 - recall_m: 0.1575 - f1_m: 0.2339 - val_loss: 0.5561 - val_accuracy: 0.2822 - val_precision_m: 0.5127 - val_recall_m: 0.3279 - val_f1_m: 0.3987\n","Epoch 8/50\n","131/131 [==============================] - 6s 44ms/step - loss: 0.6021 - accuracy: 0.1886 - precision_m: 0.5272 - recall_m: 0.1800 - f1_m: 0.2656 - val_loss: 0.5606 - val_accuracy: 0.2822 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00 - val_f1_m: 0.0000e+00\n","Epoch 9/50\n","131/131 [==============================] - 6s 44ms/step - loss: 0.6110 - accuracy: 0.1689 - precision_m: 0.5201 - recall_m: 0.1575 - f1_m: 0.2388 - val_loss: 0.5602 - val_accuracy: 0.2822 - val_precision_m: 0.5127 - val_recall_m: 0.3279 - val_f1_m: 0.3987\n","Epoch 10/50\n","131/131 [==============================] - 6s 44ms/step - loss: 0.6085 - accuracy: 0.1776 - precision_m: 0.5138 - recall_m: 0.1789 - f1_m: 0.2617 - val_loss: 0.5543 - val_accuracy: 0.2822 - val_precision_m: 0.5127 - val_recall_m: 0.3279 - val_f1_m: 0.3987\n","Epoch 11/50\n","131/131 [==============================] - 6s 43ms/step - loss: 0.6050 - accuracy: 0.1857 - precision_m: 0.5194 - recall_m: 0.2094 - f1_m: 0.2924 - val_loss: 0.5543 - val_accuracy: 0.2822 - val_precision_m: 0.5127 - val_recall_m: 0.3279 - val_f1_m: 0.3987\n","Epoch 12/50\n","131/131 [==============================] - 6s 44ms/step - loss: 0.6060 - accuracy: 0.1880 - precision_m: 0.5323 - recall_m: 0.2003 - f1_m: 0.2890 - val_loss: 0.5564 - val_accuracy: 0.2822 - val_precision_m: 0.5127 - val_recall_m: 0.3279 - val_f1_m: 0.3987\n","Epoch 00012: early stopping\n","Score for fold 3: loss of 0.5353705286979675; accuracy of 31.068703532218933% ;precision_m of 0.5502504706382751 ;recall_m of 0.36772269010543823 ;            f1_m of 0.43958553671836853\n","Epoch 1/50\n","131/131 [==============================] - 10s 52ms/step - loss: 0.5911 - accuracy: 0.2576 - precision_m: 0.4714 - recall_m: 0.1969 - f1_m: 0.2671 - val_loss: 0.5105 - val_accuracy: 0.3273 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00 - val_f1_m: 0.0000e+00\n","Epoch 2/50\n","131/131 [==============================] - 6s 46ms/step - loss: 0.5498 - accuracy: 0.2680 - precision_m: 0.4971 - recall_m: 0.1596 - f1_m: 0.2263 - val_loss: 0.5070 - val_accuracy: 0.3273 - val_precision_m: 0.5824 - val_recall_m: 0.3934 - val_f1_m: 0.4681\n","Epoch 3/50\n","131/131 [==============================] - 6s 45ms/step - loss: 0.5492 - accuracy: 0.2753 - precision_m: 0.5071 - recall_m: 0.2139 - f1_m: 0.2920 - val_loss: 0.5024 - val_accuracy: 0.3273 - val_precision_m: 0.5824 - val_recall_m: 0.3934 - val_f1_m: 0.4681\n","Epoch 4/50\n","131/131 [==============================] - 6s 46ms/step - loss: 0.5486 - accuracy: 0.2655 - precision_m: 0.4760 - recall_m: 0.1855 - f1_m: 0.2580 - val_loss: 0.5026 - val_accuracy: 0.3273 - val_precision_m: 0.5824 - val_recall_m: 0.3934 - val_f1_m: 0.4681\n","Epoch 5/50\n","131/131 [==============================] - 6s 46ms/step - loss: 0.5452 - accuracy: 0.2680 - precision_m: 0.5162 - recall_m: 0.2309 - f1_m: 0.3114 - val_loss: 0.4981 - val_accuracy: 0.3273 - val_precision_m: 0.5824 - val_recall_m: 0.3934 - val_f1_m: 0.4681\n","Epoch 6/50\n","131/131 [==============================] - 6s 46ms/step - loss: 0.5496 - accuracy: 0.2546 - precision_m: 0.5116 - recall_m: 0.2105 - f1_m: 0.2916 - val_loss: 0.5007 - val_accuracy: 0.3273 - val_precision_m: 0.5824 - val_recall_m: 0.3934 - val_f1_m: 0.4681\n","Epoch 7/50\n","131/131 [==============================] - 6s 46ms/step - loss: 0.5513 - accuracy: 0.2628 - precision_m: 0.5045 - recall_m: 0.1933 - f1_m: 0.2689 - val_loss: 0.4974 - val_accuracy: 0.3273 - val_precision_m: 0.5824 - val_recall_m: 0.3934 - val_f1_m: 0.4681\n","Epoch 8/50\n","131/131 [==============================] - 6s 45ms/step - loss: 0.5461 - accuracy: 0.2704 - precision_m: 0.5342 - recall_m: 0.2800 - f1_m: 0.3645 - val_loss: 0.5036 - val_accuracy: 0.3273 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00 - val_f1_m: 0.0000e+00\n","Epoch 9/50\n","131/131 [==============================] - 6s 45ms/step - loss: 0.5433 - accuracy: 0.2747 - precision_m: 0.5339 - recall_m: 0.2202 - f1_m: 0.3017 - val_loss: 0.5046 - val_accuracy: 0.3273 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00 - val_f1_m: 0.0000e+00\n","Epoch 10/50\n","131/131 [==============================] - 6s 45ms/step - loss: 0.5478 - accuracy: 0.2616 - precision_m: 0.5359 - recall_m: 0.1963 - f1_m: 0.2780 - val_loss: 0.5012 - val_accuracy: 0.3273 - val_precision_m: 0.5824 - val_recall_m: 0.3934 - val_f1_m: 0.4681\n","Epoch 11/50\n","131/131 [==============================] - 6s 45ms/step - loss: 0.5453 - accuracy: 0.2699 - precision_m: 0.5036 - recall_m: 0.1796 - f1_m: 0.2484 - val_loss: 0.5049 - val_accuracy: 0.3273 - val_precision_m: 0.5824 - val_recall_m: 0.3934 - val_f1_m: 0.4681\n","Epoch 12/50\n","131/131 [==============================] - 6s 45ms/step - loss: 0.5449 - accuracy: 0.2765 - precision_m: 0.5174 - recall_m: 0.2206 - f1_m: 0.3030 - val_loss: 0.5039 - val_accuracy: 0.3273 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00 - val_f1_m: 0.0000e+00\n","Epoch 00012: early stopping\n","Score for fold 1: loss of 0.6453498601913452; accuracy of 15.566577017307281% ;precision_m of 0.0 ;recall_m of 0.0 ;            f1_m of 0.0\n","Epoch 1/50\n","131/131 [==============================] - 9s 52ms/step - loss: 0.6386 - accuracy: 0.2203 - precision_m: 0.5235 - recall_m: 0.2019 - f1_m: 0.2534 - val_loss: 0.5193 - val_accuracy: 0.3279 - val_precision_m: 0.5827 - val_recall_m: 0.3938 - val_f1_m: 0.4685\n","Epoch 2/50\n","131/131 [==============================] - 6s 45ms/step - loss: 0.5938 - accuracy: 0.2217 - precision_m: 0.5384 - recall_m: 0.1981 - f1_m: 0.2827 - val_loss: 0.5251 - val_accuracy: 0.3279 - val_precision_m: 0.5827 - val_recall_m: 0.3938 - val_f1_m: 0.4685\n","Epoch 3/50\n","131/131 [==============================] - 6s 46ms/step - loss: 0.5972 - accuracy: 0.2006 - precision_m: 0.5039 - recall_m: 0.1861 - f1_m: 0.2667 - val_loss: 0.5171 - val_accuracy: 0.3279 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00 - val_f1_m: 0.0000e+00\n","Epoch 4/50\n","131/131 [==============================] - 6s 46ms/step - loss: 0.5901 - accuracy: 0.2104 - precision_m: 0.5235 - recall_m: 0.2012 - f1_m: 0.2846 - val_loss: 0.5117 - val_accuracy: 0.3279 - val_precision_m: 0.5827 - val_recall_m: 0.3938 - val_f1_m: 0.4685\n","Epoch 5/50\n","131/131 [==============================] - 6s 46ms/step - loss: 0.5922 - accuracy: 0.2096 - precision_m: 0.5045 - recall_m: 0.1853 - f1_m: 0.2647 - val_loss: 0.5188 - val_accuracy: 0.3279 - val_precision_m: 0.5827 - val_recall_m: 0.3938 - val_f1_m: 0.4685\n","Epoch 6/50\n","131/131 [==============================] - 6s 46ms/step - loss: 0.5893 - accuracy: 0.2158 - precision_m: 0.5252 - recall_m: 0.2119 - f1_m: 0.2987 - val_loss: 0.5310 - val_accuracy: 0.3279 - val_precision_m: 0.5827 - val_recall_m: 0.3938 - val_f1_m: 0.4685\n","Epoch 7/50\n","131/131 [==============================] - 6s 46ms/step - loss: 0.5925 - accuracy: 0.2129 - precision_m: 0.5187 - recall_m: 0.2044 - f1_m: 0.2884 - val_loss: 0.5176 - val_accuracy: 0.3279 - val_precision_m: 0.5827 - val_recall_m: 0.3938 - val_f1_m: 0.4685\n","Epoch 8/50\n","131/131 [==============================] - 6s 46ms/step - loss: 0.5895 - accuracy: 0.2122 - precision_m: 0.5260 - recall_m: 0.2364 - f1_m: 0.3229 - val_loss: 0.5218 - val_accuracy: 0.3279 - val_precision_m: 0.5827 - val_recall_m: 0.3938 - val_f1_m: 0.4685\n","Epoch 9/50\n","131/131 [==============================] - 6s 46ms/step - loss: 0.5926 - accuracy: 0.2054 - precision_m: 0.5176 - recall_m: 0.2338 - f1_m: 0.3184 - val_loss: 0.5300 - val_accuracy: 0.3279 - val_precision_m: 0.5827 - val_recall_m: 0.3938 - val_f1_m: 0.4685\n","Epoch 10/50\n","131/131 [==============================] - 6s 45ms/step - loss: 0.5914 - accuracy: 0.2103 - precision_m: 0.5121 - recall_m: 0.1853 - f1_m: 0.2645 - val_loss: 0.5220 - val_accuracy: 0.3279 - val_precision_m: 0.5827 - val_recall_m: 0.3938 - val_f1_m: 0.4685\n","Epoch 11/50\n","131/131 [==============================] - 6s 46ms/step - loss: 0.5925 - accuracy: 0.2088 - precision_m: 0.5108 - recall_m: 0.2057 - f1_m: 0.2861 - val_loss: 0.5266 - val_accuracy: 0.3279 - val_precision_m: 0.5827 - val_recall_m: 0.3938 - val_f1_m: 0.4685\n","Epoch 00011: early stopping\n","Score for fold 2: loss of 0.567818284034729; accuracy of 25.076335668563843% ;precision_m of 0.5106163024902344 ;recall_m of 0.3112577795982361 ;            f1_m of 0.3850182890892029\n","Epoch 1/50\n","131/131 [==============================] - 9s 52ms/step - loss: 0.6894 - accuracy: 0.1768 - precision_m: 0.5020 - recall_m: 0.2093 - f1_m: 0.2676 - val_loss: 0.5665 - val_accuracy: 0.2822 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00 - val_f1_m: 0.0000e+00\n","Epoch 2/50\n","131/131 [==============================] - 6s 45ms/step - loss: 0.6082 - accuracy: 0.1881 - precision_m: 0.5214 - recall_m: 0.1708 - f1_m: 0.2490 - val_loss: 0.5593 - val_accuracy: 0.2822 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00 - val_f1_m: 0.0000e+00\n","Epoch 3/50\n","131/131 [==============================] - 6s 45ms/step - loss: 0.6082 - accuracy: 0.1810 - precision_m: 0.5080 - recall_m: 0.1753 - f1_m: 0.2553 - val_loss: 0.5628 - val_accuracy: 0.2822 - val_precision_m: 0.5127 - val_recall_m: 0.3279 - val_f1_m: 0.3987\n","Epoch 4/50\n","131/131 [==============================] - 6s 46ms/step - loss: 0.6099 - accuracy: 0.1759 - precision_m: 0.5031 - recall_m: 0.1577 - f1_m: 0.2277 - val_loss: 0.5635 - val_accuracy: 0.2822 - val_precision_m: 0.5127 - val_recall_m: 0.3279 - val_f1_m: 0.3987\n","Epoch 5/50\n","131/131 [==============================] - 6s 45ms/step - loss: 0.6075 - accuracy: 0.1827 - precision_m: 0.4854 - recall_m: 0.1715 - f1_m: 0.2475 - val_loss: 0.5656 - val_accuracy: 0.2822 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00 - val_f1_m: 0.0000e+00\n","Epoch 6/50\n","131/131 [==============================] - 6s 46ms/step - loss: 0.6064 - accuracy: 0.1970 - precision_m: 0.5171 - recall_m: 0.1457 - f1_m: 0.2201 - val_loss: 0.5670 - val_accuracy: 0.2822 - val_precision_m: 0.5127 - val_recall_m: 0.3279 - val_f1_m: 0.3987\n","Epoch 7/50\n","131/131 [==============================] - 6s 45ms/step - loss: 0.6144 - accuracy: 0.1756 - precision_m: 0.4841 - recall_m: 0.1318 - f1_m: 0.2018 - val_loss: 0.5608 - val_accuracy: 0.2822 - val_precision_m: 0.5127 - val_recall_m: 0.3279 - val_f1_m: 0.3987\n","Epoch 8/50\n","131/131 [==============================] - 6s 46ms/step - loss: 0.6093 - accuracy: 0.1742 - precision_m: 0.4986 - recall_m: 0.1818 - f1_m: 0.2552 - val_loss: 0.5589 - val_accuracy: 0.2822 - val_precision_m: 0.5127 - val_recall_m: 0.3279 - val_f1_m: 0.3987\n","Epoch 9/50\n","131/131 [==============================] - 6s 45ms/step - loss: 0.6057 - accuracy: 0.1802 - precision_m: 0.5087 - recall_m: 0.2125 - f1_m: 0.2970 - val_loss: 0.5642 - val_accuracy: 0.2822 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00 - val_f1_m: 0.0000e+00\n","Epoch 10/50\n","131/131 [==============================] - 6s 46ms/step - loss: 0.6061 - accuracy: 0.1907 - precision_m: 0.5178 - recall_m: 0.1761 - f1_m: 0.2515 - val_loss: 0.5636 - val_accuracy: 0.2822 - val_precision_m: 0.5127 - val_recall_m: 0.3279 - val_f1_m: 0.3987\n","Epoch 11/50\n","131/131 [==============================] - 6s 45ms/step - loss: 0.6058 - accuracy: 0.1897 - precision_m: 0.5134 - recall_m: 0.2181 - f1_m: 0.3017 - val_loss: 0.5637 - val_accuracy: 0.2822 - val_precision_m: 0.5127 - val_recall_m: 0.3279 - val_f1_m: 0.3987\n","Epoch 12/50\n","131/131 [==============================] - 6s 46ms/step - loss: 0.6045 - accuracy: 0.1870 - precision_m: 0.5449 - recall_m: 0.2220 - f1_m: 0.3030 - val_loss: 0.5620 - val_accuracy: 0.2822 - val_precision_m: 0.5127 - val_recall_m: 0.3279 - val_f1_m: 0.3987\n","Epoch 13/50\n","131/131 [==============================] - 6s 45ms/step - loss: 0.6004 - accuracy: 0.1872 - precision_m: 0.5158 - recall_m: 0.1833 - f1_m: 0.2631 - val_loss: 0.5639 - val_accuracy: 0.2822 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00 - val_f1_m: 0.0000e+00\n","Epoch 00013: early stopping\n","Score for fold 3: loss of 0.5449804067611694; accuracy of 31.068703532218933% ;precision_m of 0.0 ;recall_m of 0.0 ;            f1_m of 0.0\n","Epoch 1/50\n","131/131 [==============================] - 10s 54ms/step - loss: 0.5831 - accuracy: 0.2772 - precision_m: 0.5027 - recall_m: 0.2057 - f1_m: 0.2845 - val_loss: 0.4985 - val_accuracy: 0.3273 - val_precision_m: 0.5824 - val_recall_m: 0.3934 - val_f1_m: 0.4681\n","Epoch 2/50\n","131/131 [==============================] - 6s 48ms/step - loss: 0.5446 - accuracy: 0.2748 - precision_m: 0.5147 - recall_m: 0.2152 - f1_m: 0.2967 - val_loss: 0.5039 - val_accuracy: 0.3273 - val_precision_m: 0.5824 - val_recall_m: 0.3934 - val_f1_m: 0.4681\n","Epoch 3/50\n","131/131 [==============================] - 6s 48ms/step - loss: 0.5524 - accuracy: 0.2559 - precision_m: 0.4862 - recall_m: 0.1692 - f1_m: 0.2419 - val_loss: 0.5032 - val_accuracy: 0.3273 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00 - val_f1_m: 0.0000e+00\n","Epoch 4/50\n","131/131 [==============================] - 6s 48ms/step - loss: 0.5479 - accuracy: 0.2703 - precision_m: 0.5227 - recall_m: 0.1624 - f1_m: 0.2351 - val_loss: 0.5023 - val_accuracy: 0.3273 - val_precision_m: 0.5824 - val_recall_m: 0.3934 - val_f1_m: 0.4681\n","Epoch 5/50\n","131/131 [==============================] - 6s 48ms/step - loss: 0.5461 - accuracy: 0.2722 - precision_m: 0.5274 - recall_m: 0.2170 - f1_m: 0.2987 - val_loss: 0.5028 - val_accuracy: 0.3273 - val_precision_m: 0.5824 - val_recall_m: 0.3934 - val_f1_m: 0.4681\n","Epoch 6/50\n","131/131 [==============================] - 6s 48ms/step - loss: 0.5446 - accuracy: 0.2730 - precision_m: 0.4919 - recall_m: 0.2256 - f1_m: 0.2990 - val_loss: 0.5001 - val_accuracy: 0.3273 - val_precision_m: 0.5824 - val_recall_m: 0.3934 - val_f1_m: 0.4681\n","Epoch 7/50\n","131/131 [==============================] - 6s 48ms/step - loss: 0.5467 - accuracy: 0.2626 - precision_m: 0.5145 - recall_m: 0.1948 - f1_m: 0.2770 - val_loss: 0.4970 - val_accuracy: 0.3273 - val_precision_m: 0.5824 - val_recall_m: 0.3934 - val_f1_m: 0.4681\n","Epoch 8/50\n","131/131 [==============================] - 6s 48ms/step - loss: 0.5473 - accuracy: 0.2714 - precision_m: 0.5070 - recall_m: 0.2300 - f1_m: 0.3030 - val_loss: 0.4998 - val_accuracy: 0.3273 - val_precision_m: 0.5824 - val_recall_m: 0.3934 - val_f1_m: 0.4681\n","Epoch 9/50\n","131/131 [==============================] - 6s 48ms/step - loss: 0.5486 - accuracy: 0.2603 - precision_m: 0.5125 - recall_m: 0.2570 - f1_m: 0.3401 - val_loss: 0.5013 - val_accuracy: 0.3273 - val_precision_m: 0.5824 - val_recall_m: 0.3934 - val_f1_m: 0.4681\n","Epoch 10/50\n","131/131 [==============================] - 6s 48ms/step - loss: 0.5463 - accuracy: 0.2692 - precision_m: 0.5238 - recall_m: 0.2597 - f1_m: 0.3442 - val_loss: 0.5007 - val_accuracy: 0.3273 - val_precision_m: 0.5824 - val_recall_m: 0.3934 - val_f1_m: 0.4681\n","Epoch 11/50\n","131/131 [==============================] - 6s 48ms/step - loss: 0.5500 - accuracy: 0.2618 - precision_m: 0.5187 - recall_m: 0.1800 - f1_m: 0.2563 - val_loss: 0.4989 - val_accuracy: 0.3273 - val_precision_m: 0.5824 - val_recall_m: 0.3934 - val_f1_m: 0.4681\n","Epoch 00011: early stopping\n","Score for fold 1: loss of 0.6503585577011108; accuracy of 15.566577017307281% ;precision_m of 0.5127865076065063 ;recall_m of 0.2593536674976349 ;            f1_m of 0.34322670102119446\n","Epoch 1/50\n","131/131 [==============================] - 9s 55ms/step - loss: 0.6293 - accuracy: 0.2133 - precision_m: 0.4694 - recall_m: 0.2017 - f1_m: 0.2634 - val_loss: 0.5314 - val_accuracy: 0.3279 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00 - val_f1_m: 0.0000e+00\n","Epoch 2/50\n","131/131 [==============================] - 6s 47ms/step - loss: 0.5924 - accuracy: 0.2098 - precision_m: 0.5322 - recall_m: 0.1601 - f1_m: 0.2344 - val_loss: 0.5233 - val_accuracy: 0.3279 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00 - val_f1_m: 0.0000e+00\n","Epoch 3/50\n","131/131 [==============================] - 6s 48ms/step - loss: 0.5941 - accuracy: 0.2032 - precision_m: 0.5255 - recall_m: 0.1567 - f1_m: 0.2291 - val_loss: 0.5256 - val_accuracy: 0.3279 - val_precision_m: 0.5827 - val_recall_m: 0.3938 - val_f1_m: 0.4685\n","Epoch 4/50\n","131/131 [==============================] - 6s 48ms/step - loss: 0.5915 - accuracy: 0.2145 - precision_m: 0.5162 - recall_m: 0.1949 - f1_m: 0.2787 - val_loss: 0.5165 - val_accuracy: 0.3279 - val_precision_m: 0.5827 - val_recall_m: 0.3938 - val_f1_m: 0.4685\n","Epoch 5/50\n","131/131 [==============================] - 6s 49ms/step - loss: 0.5955 - accuracy: 0.2060 - precision_m: 0.5122 - recall_m: 0.2301 - f1_m: 0.3131 - val_loss: 0.5186 - val_accuracy: 0.3279 - val_precision_m: 0.5827 - val_recall_m: 0.3938 - val_f1_m: 0.4685\n","Epoch 6/50\n","131/131 [==============================] - 6s 48ms/step - loss: 0.5902 - accuracy: 0.2142 - precision_m: 0.5249 - recall_m: 0.2080 - f1_m: 0.2944 - val_loss: 0.5188 - val_accuracy: 0.3279 - val_precision_m: 0.5827 - val_recall_m: 0.3938 - val_f1_m: 0.4685\n","Epoch 7/50\n","131/131 [==============================] - 6s 48ms/step - loss: 0.5909 - accuracy: 0.2075 - precision_m: 0.5237 - recall_m: 0.2240 - f1_m: 0.3026 - val_loss: 0.5203 - val_accuracy: 0.3279 - val_precision_m: 0.5827 - val_recall_m: 0.3938 - val_f1_m: 0.4685\n","Epoch 8/50\n","131/131 [==============================] - 6s 48ms/step - loss: 0.5893 - accuracy: 0.2092 - precision_m: 0.5409 - recall_m: 0.1993 - f1_m: 0.2821 - val_loss: 0.5234 - val_accuracy: 0.3279 - val_precision_m: 0.5827 - val_recall_m: 0.3938 - val_f1_m: 0.4685\n","Epoch 9/50\n","131/131 [==============================] - 6s 48ms/step - loss: 0.5955 - accuracy: 0.2024 - precision_m: 0.4631 - recall_m: 0.1410 - f1_m: 0.2025 - val_loss: 0.5215 - val_accuracy: 0.3279 - val_precision_m: 0.5827 - val_recall_m: 0.3938 - val_f1_m: 0.4685\n","Epoch 10/50\n","131/131 [==============================] - 6s 48ms/step - loss: 0.5923 - accuracy: 0.2141 - precision_m: 0.5127 - recall_m: 0.2309 - f1_m: 0.3156 - val_loss: 0.5247 - val_accuracy: 0.3279 - val_precision_m: 0.5827 - val_recall_m: 0.3938 - val_f1_m: 0.4685\n","Epoch 11/50\n","131/131 [==============================] - 6s 48ms/step - loss: 0.5914 - accuracy: 0.2111 - precision_m: 0.5180 - recall_m: 0.2262 - f1_m: 0.3084 - val_loss: 0.5160 - val_accuracy: 0.3279 - val_precision_m: 0.5827 - val_recall_m: 0.3938 - val_f1_m: 0.4685\n","Epoch 12/50\n","131/131 [==============================] - 6s 48ms/step - loss: 0.5916 - accuracy: 0.2107 - precision_m: 0.5169 - recall_m: 0.2489 - f1_m: 0.3320 - val_loss: 0.5287 - val_accuracy: 0.3279 - val_precision_m: 0.5827 - val_recall_m: 0.3938 - val_f1_m: 0.4685\n","Epoch 13/50\n","131/131 [==============================] - 6s 48ms/step - loss: 0.5906 - accuracy: 0.2129 - precision_m: 0.4849 - recall_m: 0.1641 - f1_m: 0.2393 - val_loss: 0.5190 - val_accuracy: 0.3279 - val_precision_m: 0.5827 - val_recall_m: 0.3938 - val_f1_m: 0.4685\n","Epoch 00013: early stopping\n","Score for fold 2: loss of 0.5656804442405701; accuracy of 25.076335668563843% ;precision_m of 0.5106163024902344 ;recall_m of 0.3112577795982361 ;            f1_m of 0.3850182890892029\n","Epoch 1/50\n","131/131 [==============================] - 10s 58ms/step - loss: 0.6388 - accuracy: 0.1900 - precision_m: 0.4499 - recall_m: 0.1542 - f1_m: 0.2099 - val_loss: 0.5582 - val_accuracy: 0.2822 - val_precision_m: 0.5127 - val_recall_m: 0.3279 - val_f1_m: 0.3987\n","Epoch 2/50\n","131/131 [==============================] - 6s 47ms/step - loss: 0.6088 - accuracy: 0.1759 - precision_m: 0.4806 - recall_m: 0.1397 - f1_m: 0.2062 - val_loss: 0.5618 - val_accuracy: 0.2822 - val_precision_m: 0.5127 - val_recall_m: 0.3279 - val_f1_m: 0.3987\n","Epoch 3/50\n","131/131 [==============================] - 6s 48ms/step - loss: 0.6059 - accuracy: 0.1892 - precision_m: 0.5183 - recall_m: 0.1680 - f1_m: 0.2442 - val_loss: 0.5580 - val_accuracy: 0.2822 - val_precision_m: 0.5127 - val_recall_m: 0.3279 - val_f1_m: 0.3987\n","Epoch 4/50\n","131/131 [==============================] - 6s 48ms/step - loss: 0.6042 - accuracy: 0.1906 - precision_m: 0.4935 - recall_m: 0.1978 - f1_m: 0.2722 - val_loss: 0.5619 - val_accuracy: 0.2822 - val_precision_m: 0.5127 - val_recall_m: 0.3279 - val_f1_m: 0.3987\n","Epoch 5/50\n","131/131 [==============================] - 6s 49ms/step - loss: 0.6083 - accuracy: 0.1802 - precision_m: 0.5059 - recall_m: 0.1574 - f1_m: 0.2314 - val_loss: 0.5625 - val_accuracy: 0.2822 - val_precision_m: 0.5127 - val_recall_m: 0.3279 - val_f1_m: 0.3987\n","Epoch 6/50\n","131/131 [==============================] - 6s 48ms/step - loss: 0.6089 - accuracy: 0.1746 - precision_m: 0.5109 - recall_m: 0.1682 - f1_m: 0.2418 - val_loss: 0.5627 - val_accuracy: 0.2822 - val_precision_m: 0.5127 - val_recall_m: 0.3279 - val_f1_m: 0.3987\n","Epoch 7/50\n","131/131 [==============================] - 6s 48ms/step - loss: 0.6049 - accuracy: 0.1829 - precision_m: 0.5236 - recall_m: 0.1496 - f1_m: 0.2253 - val_loss: 0.5578 - val_accuracy: 0.2822 - val_precision_m: 0.5127 - val_recall_m: 0.3279 - val_f1_m: 0.3987\n","Epoch 8/50\n","131/131 [==============================] - 6s 48ms/step - loss: 0.6042 - accuracy: 0.1842 - precision_m: 0.5340 - recall_m: 0.2150 - f1_m: 0.3010 - val_loss: 0.5598 - val_accuracy: 0.2822 - val_precision_m: 0.5127 - val_recall_m: 0.3279 - val_f1_m: 0.3987\n","Epoch 9/50\n","131/131 [==============================] - 6s 49ms/step - loss: 0.6036 - accuracy: 0.1915 - precision_m: 0.5182 - recall_m: 0.1972 - f1_m: 0.2796 - val_loss: 0.5467 - val_accuracy: 0.2822 - val_precision_m: 0.5074 - val_recall_m: 0.3131 - val_f1_m: 0.3857\n","Epoch 10/50\n","131/131 [==============================] - 6s 48ms/step - loss: 0.6563 - accuracy: 0.1810 - precision_m: 0.4539 - recall_m: 0.1863 - f1_m: 0.2476 - val_loss: 0.5605 - val_accuracy: 0.2822 - val_precision_m: 0.5539 - val_recall_m: 0.1880 - val_f1_m: 0.2754\n","Epoch 11/50\n","131/131 [==============================] - 6s 49ms/step - loss: 0.6141 - accuracy: 0.1883 - precision_m: 0.5075 - recall_m: 0.1295 - f1_m: 0.2002 - val_loss: 0.5504 - val_accuracy: 0.2822 - val_precision_m: 0.5127 - val_recall_m: 0.3279 - val_f1_m: 0.3987\n","Epoch 00011: early stopping\n","Score for fold 3: loss of 0.5271559953689575; accuracy of 31.068703532218933% ;precision_m of 0.5502504706382751 ;recall_m of 0.36772269010543823 ;            f1_m of 0.43958553671836853\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Model</th>\n","      <th>Word_Embedding</th>\n","      <th>Embedding_Size</th>\n","      <th>Accuracy</th>\n","      <th>Precision</th>\n","      <th>Recall</th>\n","      <th>F1</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>cnn</td>\n","      <td>cbow</td>\n","      <td>100</td>\n","      <td>62.957480</td>\n","      <td>0.833926</td>\n","      <td>0.736736</td>\n","      <td>0.778749</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>cnn</td>\n","      <td>cbow</td>\n","      <td>200</td>\n","      <td>63.402772</td>\n","      <td>0.832834</td>\n","      <td>0.730047</td>\n","      <td>0.774932</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>cnn</td>\n","      <td>cbow</td>\n","      <td>300</td>\n","      <td>62.079748</td>\n","      <td>0.818064</td>\n","      <td>0.743853</td>\n","      <td>0.776108</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>cnn</td>\n","      <td>skip</td>\n","      <td>100</td>\n","      <td>59.077770</td>\n","      <td>0.811288</td>\n","      <td>0.712502</td>\n","      <td>0.755424</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>cnn</td>\n","      <td>skip</td>\n","      <td>200</td>\n","      <td>60.336792</td>\n","      <td>0.817531</td>\n","      <td>0.712763</td>\n","      <td>0.758004</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>cnn</td>\n","      <td>skip</td>\n","      <td>300</td>\n","      <td>59.459124</td>\n","      <td>0.815232</td>\n","      <td>0.701116</td>\n","      <td>0.749841</td>\n","    </tr>\n","    <tr>\n","      <th>6</th>\n","      <td>cnn</td>\n","      <td>ft</td>\n","      <td>100</td>\n","      <td>60.299019</td>\n","      <td>0.813158</td>\n","      <td>0.692569</td>\n","      <td>0.742150</td>\n","    </tr>\n","    <tr>\n","      <th>7</th>\n","      <td>cnn</td>\n","      <td>ft</td>\n","      <td>200</td>\n","      <td>60.490183</td>\n","      <td>0.806549</td>\n","      <td>0.687904</td>\n","      <td>0.736034</td>\n","    </tr>\n","    <tr>\n","      <th>8</th>\n","      <td>cnn</td>\n","      <td>ft</td>\n","      <td>300</td>\n","      <td>60.019218</td>\n","      <td>0.806570</td>\n","      <td>0.694513</td>\n","      <td>0.737770</td>\n","    </tr>\n","    <tr>\n","      <th>9</th>\n","      <td>bi_lstm</td>\n","      <td>cbow</td>\n","      <td>100</td>\n","      <td>23.903872</td>\n","      <td>0.524596</td>\n","      <td>0.312778</td>\n","      <td>0.389287</td>\n","    </tr>\n","    <tr>\n","      <th>10</th>\n","      <td>bi_lstm</td>\n","      <td>cbow</td>\n","      <td>200</td>\n","      <td>23.903872</td>\n","      <td>0.353622</td>\n","      <td>0.226327</td>\n","      <td>0.274868</td>\n","    </tr>\n","    <tr>\n","      <th>11</th>\n","      <td>bi_lstm</td>\n","      <td>cbow</td>\n","      <td>300</td>\n","      <td>23.903872</td>\n","      <td>0.524551</td>\n","      <td>0.312778</td>\n","      <td>0.389277</td>\n","    </tr>\n","    <tr>\n","      <th>12</th>\n","      <td>bi_lstm</td>\n","      <td>skip</td>\n","      <td>100</td>\n","      <td>32.822447</td>\n","      <td>0.576500</td>\n","      <td>0.394046</td>\n","      <td>0.460701</td>\n","    </tr>\n","    <tr>\n","      <th>13</th>\n","      <td>bi_lstm</td>\n","      <td>skip</td>\n","      <td>200</td>\n","      <td>23.903872</td>\n","      <td>0.524551</td>\n","      <td>0.312778</td>\n","      <td>0.389277</td>\n","    </tr>\n","    <tr>\n","      <th>14</th>\n","      <td>bi_lstm</td>\n","      <td>skip</td>\n","      <td>300</td>\n","      <td>23.903872</td>\n","      <td>0.353622</td>\n","      <td>0.226327</td>\n","      <td>0.274868</td>\n","    </tr>\n","    <tr>\n","      <th>15</th>\n","      <td>bi_lstm</td>\n","      <td>ft</td>\n","      <td>100</td>\n","      <td>23.903872</td>\n","      <td>0.183417</td>\n","      <td>0.122574</td>\n","      <td>0.146529</td>\n","    </tr>\n","    <tr>\n","      <th>16</th>\n","      <td>bi_lstm</td>\n","      <td>ft</td>\n","      <td>200</td>\n","      <td>23.903872</td>\n","      <td>0.524551</td>\n","      <td>0.312778</td>\n","      <td>0.389277</td>\n","    </tr>\n","    <tr>\n","      <th>17</th>\n","      <td>bi_lstm</td>\n","      <td>ft</td>\n","      <td>300</td>\n","      <td>23.903872</td>\n","      <td>0.170974</td>\n","      <td>0.086451</td>\n","      <td>0.114419</td>\n","    </tr>\n","    <tr>\n","      <th>18</th>\n","      <td>rnn_lstm</td>\n","      <td>cbow</td>\n","      <td>100</td>\n","      <td>23.903872</td>\n","      <td>0.524551</td>\n","      <td>0.312778</td>\n","      <td>0.389277</td>\n","    </tr>\n","    <tr>\n","      <th>19</th>\n","      <td>rnn_lstm</td>\n","      <td>cbow</td>\n","      <td>200</td>\n","      <td>23.903872</td>\n","      <td>0.524551</td>\n","      <td>0.312778</td>\n","      <td>0.389277</td>\n","    </tr>\n","    <tr>\n","      <th>20</th>\n","      <td>rnn_lstm</td>\n","      <td>cbow</td>\n","      <td>300</td>\n","      <td>23.903872</td>\n","      <td>0.524551</td>\n","      <td>0.312778</td>\n","      <td>0.389277</td>\n","    </tr>\n","    <tr>\n","      <th>21</th>\n","      <td>rnn_lstm</td>\n","      <td>skip</td>\n","      <td>100</td>\n","      <td>23.916590</td>\n","      <td>0.524596</td>\n","      <td>0.312778</td>\n","      <td>0.389287</td>\n","    </tr>\n","    <tr>\n","      <th>22</th>\n","      <td>rnn_lstm</td>\n","      <td>skip</td>\n","      <td>200</td>\n","      <td>23.903872</td>\n","      <td>0.524551</td>\n","      <td>0.312778</td>\n","      <td>0.389277</td>\n","    </tr>\n","    <tr>\n","      <th>23</th>\n","      <td>rnn_lstm</td>\n","      <td>skip</td>\n","      <td>300</td>\n","      <td>23.903872</td>\n","      <td>0.524596</td>\n","      <td>0.312778</td>\n","      <td>0.389287</td>\n","    </tr>\n","    <tr>\n","      <th>24</th>\n","      <td>rnn_lstm</td>\n","      <td>ft</td>\n","      <td>100</td>\n","      <td>23.903872</td>\n","      <td>0.524551</td>\n","      <td>0.312778</td>\n","      <td>0.389277</td>\n","    </tr>\n","    <tr>\n","      <th>25</th>\n","      <td>rnn_lstm</td>\n","      <td>ft</td>\n","      <td>200</td>\n","      <td>23.903872</td>\n","      <td>0.524551</td>\n","      <td>0.312778</td>\n","      <td>0.389277</td>\n","    </tr>\n","    <tr>\n","      <th>26</th>\n","      <td>rnn_lstm</td>\n","      <td>ft</td>\n","      <td>300</td>\n","      <td>23.903872</td>\n","      <td>0.524551</td>\n","      <td>0.312778</td>\n","      <td>0.389277</td>\n","    </tr>\n","    <tr>\n","      <th>27</th>\n","      <td>cnn_gru</td>\n","      <td>cbow</td>\n","      <td>100</td>\n","      <td>23.903872</td>\n","      <td>0.524551</td>\n","      <td>0.312778</td>\n","      <td>0.389277</td>\n","    </tr>\n","    <tr>\n","      <th>28</th>\n","      <td>cnn_gru</td>\n","      <td>cbow</td>\n","      <td>200</td>\n","      <td>23.903872</td>\n","      <td>0.524551</td>\n","      <td>0.312778</td>\n","      <td>0.389277</td>\n","    </tr>\n","    <tr>\n","      <th>29</th>\n","      <td>cnn_gru</td>\n","      <td>cbow</td>\n","      <td>300</td>\n","      <td>23.903872</td>\n","      <td>0.524551</td>\n","      <td>0.312778</td>\n","      <td>0.389277</td>\n","    </tr>\n","    <tr>\n","      <th>30</th>\n","      <td>cnn_gru</td>\n","      <td>skip</td>\n","      <td>100</td>\n","      <td>23.903872</td>\n","      <td>0.524551</td>\n","      <td>0.312778</td>\n","      <td>0.389277</td>\n","    </tr>\n","    <tr>\n","      <th>31</th>\n","      <td>cnn_gru</td>\n","      <td>skip</td>\n","      <td>200</td>\n","      <td>23.903872</td>\n","      <td>0.524551</td>\n","      <td>0.312778</td>\n","      <td>0.389277</td>\n","    </tr>\n","    <tr>\n","      <th>32</th>\n","      <td>cnn_gru</td>\n","      <td>skip</td>\n","      <td>300</td>\n","      <td>23.903872</td>\n","      <td>0.353622</td>\n","      <td>0.226327</td>\n","      <td>0.274868</td>\n","    </tr>\n","    <tr>\n","      <th>33</th>\n","      <td>cnn_gru</td>\n","      <td>ft</td>\n","      <td>100</td>\n","      <td>23.903872</td>\n","      <td>0.341134</td>\n","      <td>0.190204</td>\n","      <td>0.242748</td>\n","    </tr>\n","    <tr>\n","      <th>34</th>\n","      <td>cnn_gru</td>\n","      <td>ft</td>\n","      <td>200</td>\n","      <td>23.903872</td>\n","      <td>0.524551</td>\n","      <td>0.312778</td>\n","      <td>0.389277</td>\n","    </tr>\n","    <tr>\n","      <th>35</th>\n","      <td>cnn_gru</td>\n","      <td>ft</td>\n","      <td>300</td>\n","      <td>23.903872</td>\n","      <td>0.341134</td>\n","      <td>0.190204</td>\n","      <td>0.242748</td>\n","    </tr>\n","    <tr>\n","      <th>36</th>\n","      <td>cnn_lstm</td>\n","      <td>cbow</td>\n","      <td>100</td>\n","      <td>23.903872</td>\n","      <td>0.524551</td>\n","      <td>0.312778</td>\n","      <td>0.389277</td>\n","    </tr>\n","    <tr>\n","      <th>37</th>\n","      <td>cnn_lstm</td>\n","      <td>cbow</td>\n","      <td>200</td>\n","      <td>23.903872</td>\n","      <td>0.170205</td>\n","      <td>0.103753</td>\n","      <td>0.128339</td>\n","    </tr>\n","    <tr>\n","      <th>38</th>\n","      <td>cnn_lstm</td>\n","      <td>cbow</td>\n","      <td>300</td>\n","      <td>23.903872</td>\n","      <td>0.524551</td>\n","      <td>0.312778</td>\n","      <td>0.389277</td>\n","    </tr>\n","    <tr>\n","      <th>39</th>\n","      <td>cnn_lstm</td>\n","      <td>skip</td>\n","      <td>100</td>\n","      <td>23.903872</td>\n","      <td>0.524596</td>\n","      <td>0.312778</td>\n","      <td>0.389287</td>\n","    </tr>\n","    <tr>\n","      <th>40</th>\n","      <td>cnn_lstm</td>\n","      <td>skip</td>\n","      <td>200</td>\n","      <td>23.903872</td>\n","      <td>0.524551</td>\n","      <td>0.312778</td>\n","      <td>0.389277</td>\n","    </tr>\n","    <tr>\n","      <th>41</th>\n","      <td>cnn_lstm</td>\n","      <td>skip</td>\n","      <td>300</td>\n","      <td>23.903872</td>\n","      <td>0.524551</td>\n","      <td>0.312778</td>\n","      <td>0.389277</td>\n","    </tr>\n","    <tr>\n","      <th>42</th>\n","      <td>cnn_lstm</td>\n","      <td>ft</td>\n","      <td>100</td>\n","      <td>36.906417</td>\n","      <td>0.617949</td>\n","      <td>0.466373</td>\n","      <td>0.520858</td>\n","    </tr>\n","    <tr>\n","      <th>43</th>\n","      <td>cnn_lstm</td>\n","      <td>ft</td>\n","      <td>200</td>\n","      <td>23.903872</td>\n","      <td>0.170205</td>\n","      <td>0.103753</td>\n","      <td>0.128339</td>\n","    </tr>\n","    <tr>\n","      <th>44</th>\n","      <td>cnn_lstm</td>\n","      <td>ft</td>\n","      <td>300</td>\n","      <td>23.903872</td>\n","      <td>0.524551</td>\n","      <td>0.312778</td>\n","      <td>0.389277</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["       Model Word_Embedding  Embedding_Size  ...  Precision    Recall        F1\n","0        cnn           cbow             100  ...   0.833926  0.736736  0.778749\n","1        cnn           cbow             200  ...   0.832834  0.730047  0.774932\n","2        cnn           cbow             300  ...   0.818064  0.743853  0.776108\n","3        cnn           skip             100  ...   0.811288  0.712502  0.755424\n","4        cnn           skip             200  ...   0.817531  0.712763  0.758004\n","5        cnn           skip             300  ...   0.815232  0.701116  0.749841\n","6        cnn             ft             100  ...   0.813158  0.692569  0.742150\n","7        cnn             ft             200  ...   0.806549  0.687904  0.736034\n","8        cnn             ft             300  ...   0.806570  0.694513  0.737770\n","9    bi_lstm           cbow             100  ...   0.524596  0.312778  0.389287\n","10   bi_lstm           cbow             200  ...   0.353622  0.226327  0.274868\n","11   bi_lstm           cbow             300  ...   0.524551  0.312778  0.389277\n","12   bi_lstm           skip             100  ...   0.576500  0.394046  0.460701\n","13   bi_lstm           skip             200  ...   0.524551  0.312778  0.389277\n","14   bi_lstm           skip             300  ...   0.353622  0.226327  0.274868\n","15   bi_lstm             ft             100  ...   0.183417  0.122574  0.146529\n","16   bi_lstm             ft             200  ...   0.524551  0.312778  0.389277\n","17   bi_lstm             ft             300  ...   0.170974  0.086451  0.114419\n","18  rnn_lstm           cbow             100  ...   0.524551  0.312778  0.389277\n","19  rnn_lstm           cbow             200  ...   0.524551  0.312778  0.389277\n","20  rnn_lstm           cbow             300  ...   0.524551  0.312778  0.389277\n","21  rnn_lstm           skip             100  ...   0.524596  0.312778  0.389287\n","22  rnn_lstm           skip             200  ...   0.524551  0.312778  0.389277\n","23  rnn_lstm           skip             300  ...   0.524596  0.312778  0.389287\n","24  rnn_lstm             ft             100  ...   0.524551  0.312778  0.389277\n","25  rnn_lstm             ft             200  ...   0.524551  0.312778  0.389277\n","26  rnn_lstm             ft             300  ...   0.524551  0.312778  0.389277\n","27   cnn_gru           cbow             100  ...   0.524551  0.312778  0.389277\n","28   cnn_gru           cbow             200  ...   0.524551  0.312778  0.389277\n","29   cnn_gru           cbow             300  ...   0.524551  0.312778  0.389277\n","30   cnn_gru           skip             100  ...   0.524551  0.312778  0.389277\n","31   cnn_gru           skip             200  ...   0.524551  0.312778  0.389277\n","32   cnn_gru           skip             300  ...   0.353622  0.226327  0.274868\n","33   cnn_gru             ft             100  ...   0.341134  0.190204  0.242748\n","34   cnn_gru             ft             200  ...   0.524551  0.312778  0.389277\n","35   cnn_gru             ft             300  ...   0.341134  0.190204  0.242748\n","36  cnn_lstm           cbow             100  ...   0.524551  0.312778  0.389277\n","37  cnn_lstm           cbow             200  ...   0.170205  0.103753  0.128339\n","38  cnn_lstm           cbow             300  ...   0.524551  0.312778  0.389277\n","39  cnn_lstm           skip             100  ...   0.524596  0.312778  0.389287\n","40  cnn_lstm           skip             200  ...   0.524551  0.312778  0.389277\n","41  cnn_lstm           skip             300  ...   0.524551  0.312778  0.389277\n","42  cnn_lstm             ft             100  ...   0.617949  0.466373  0.520858\n","43  cnn_lstm             ft             200  ...   0.170205  0.103753  0.128339\n","44  cnn_lstm             ft             300  ...   0.524551  0.312778  0.389277\n","\n","[45 rows x 7 columns]"]},"metadata":{"tags":[]},"execution_count":26}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":173},"id":"tPfJy-MUXstK","executionInfo":{"elapsed":1291,"status":"ok","timestamp":1614159114974,"user":{"displayName":"Shanaka Chathuranga","photoUrl":"","userId":"01381725564551416324"},"user_tz":-330},"outputId":"0fe7bdb9-9b29-422b-9d3b-fa568966fa9b"},"source":["accdf=pd.DataFrame({'Model':modelname,'Word_Embedding':wename, 'Embedding_Size':wesize,'Accuracy':acclist,'Precision':prelist,'Recall':reclist, 'F1':f1list})\r\n","accdf"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Model</th>\n","      <th>Word_Embedding</th>\n","      <th>Embedding_Size</th>\n","      <th>Accuracy</th>\n","      <th>Precision</th>\n","      <th>Recall</th>\n","      <th>F1</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>cnn</td>\n","      <td>cbow</td>\n","      <td>100</td>\n","      <td>56.711825</td>\n","      <td>0.800674</td>\n","      <td>0.649048</td>\n","      <td>0.708220</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>cnn</td>\n","      <td>skip</td>\n","      <td>300</td>\n","      <td>56.953214</td>\n","      <td>0.795895</td>\n","      <td>0.662368</td>\n","      <td>0.716923</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>rnn_gru</td>\n","      <td>cbow</td>\n","      <td>100</td>\n","      <td>23.903872</td>\n","      <td>0.524596</td>\n","      <td>0.312778</td>\n","      <td>0.389287</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>rnn_gru</td>\n","      <td>skip</td>\n","      <td>300</td>\n","      <td>23.916590</td>\n","      <td>0.354383</td>\n","      <td>0.209089</td>\n","      <td>0.261001</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["     Model Word_Embedding  Embedding_Size  ...  Precision    Recall        F1\n","0      cnn           cbow             100  ...   0.800674  0.649048  0.708220\n","1      cnn           skip             300  ...   0.795895  0.662368  0.716923\n","2  rnn_gru           cbow             100  ...   0.524596  0.312778  0.389287\n","3  rnn_gru           skip             300  ...   0.354383  0.209089  0.261001\n","\n","[4 rows x 7 columns]"]},"metadata":{"tags":[]},"execution_count":64}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":35},"id":"TxuYt5K88u8O","executionInfo":{"elapsed":1078,"status":"ok","timestamp":1614152133576,"user":{"displayName":"Shanaka Chathuranga","photoUrl":"","userId":"01381725564551416324"},"user_tz":-330},"outputId":"193de938-c178-433d-b1c1-545967ae6a50"},"source":["txt='cbow_100'\r\n","we_type=txt.split('_')[0]\r\n","path=mainloc+'wordembeddings/w2v_'+we_type+'_'+str(EMBEDDING_SIZE)\r\n","path"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["'/content/drive/My Drive/Research/ABSA_Project/wordembeddings/w2v_cbow_300'"]},"metadata":{"tags":[]},"execution_count":28}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"c8P1Hil9vL3W","executionInfo":{"elapsed":279925,"status":"ok","timestamp":1614150431497,"user":{"displayName":"Shanaka Chathuranga","photoUrl":"","userId":"01381725564551416324"},"user_tz":-330},"outputId":"bb2828e3-184f-4dc4-8486-1ffcc9248229"},"source":["N_FOLDS=3 \r\n","EPOCHS=1000\r\n","VALIDATION_SPLIT=0.2\r\n","BATCH_SIZE=32\r\n","PATIENCE=50\r\n","MONITOR='val_f1_m'\r\n","MONITOR_MODE='max'\r\n","shuffle=True\r\n","DROPOUT_VALUE_2=0.5\r\n","NUM_CLASSES=6\r\n","EMBEDDING_SIZE=300\r\n","EMP_PATH=mainloc+'word_embeddings/w2v_cbow_300.txt'\r\n","\r\n","vocab_length,padded_sentences,length_long_sentence,embedding_matrix=loadembedding_matrix(x,mainloc+'word_embeddings/w2v_cbow_300.txt',300)\r\n","crossval('cnn')"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Epoch 1/1000\n","131/131 [==============================] - 2s 11ms/step - loss: 0.5080 - accuracy: 0.3973 - precision_m: 0.6346 - recall_m: 0.3909 - f1_m: 0.4592 - val_loss: 0.3081 - val_accuracy: 0.6116 - val_precision_m: 0.8252 - val_recall_m: 0.6695 - val_f1_m: 0.7369\n","Epoch 2/1000\n","131/131 [==============================] - 1s 9ms/step - loss: 0.3472 - accuracy: 0.5699 - precision_m: 0.7802 - recall_m: 0.6437 - f1_m: 0.7042 - val_loss: 0.2768 - val_accuracy: 0.6355 - val_precision_m: 0.8180 - val_recall_m: 0.7352 - val_f1_m: 0.7727\n","Epoch 3/1000\n","131/131 [==============================] - 1s 9ms/step - loss: 0.2989 - accuracy: 0.6272 - precision_m: 0.8207 - recall_m: 0.7039 - f1_m: 0.7563 - val_loss: 0.2578 - val_accuracy: 0.6403 - val_precision_m: 0.8128 - val_recall_m: 0.7621 - val_f1_m: 0.7849\n","Epoch 4/1000\n","131/131 [==============================] - 1s 9ms/step - loss: 0.2916 - accuracy: 0.6019 - precision_m: 0.8168 - recall_m: 0.7175 - f1_m: 0.7625 - val_loss: 0.2582 - val_accuracy: 0.6708 - val_precision_m: 0.8190 - val_recall_m: 0.7844 - val_f1_m: 0.8000\n","Epoch 5/1000\n","131/131 [==============================] - 1s 9ms/step - loss: 0.2702 - accuracy: 0.6288 - precision_m: 0.8335 - recall_m: 0.7474 - f1_m: 0.7868 - val_loss: 0.2606 - val_accuracy: 0.6994 - val_precision_m: 0.8432 - val_recall_m: 0.7237 - val_f1_m: 0.7773\n","Epoch 6/1000\n","131/131 [==============================] - 1s 9ms/step - loss: 0.2740 - accuracy: 0.6441 - precision_m: 0.8278 - recall_m: 0.7412 - f1_m: 0.7809 - val_loss: 0.2420 - val_accuracy: 0.6794 - val_precision_m: 0.8377 - val_recall_m: 0.7713 - val_f1_m: 0.8018\n","Epoch 7/1000\n","131/131 [==============================] - 1s 9ms/step - loss: 0.2601 - accuracy: 0.6497 - precision_m: 0.8525 - recall_m: 0.7621 - f1_m: 0.8034 - val_loss: 0.2415 - val_accuracy: 0.6689 - val_precision_m: 0.8485 - val_recall_m: 0.7592 - val_f1_m: 0.7996\n","Epoch 8/1000\n","131/131 [==============================] - 1s 9ms/step - loss: 0.2589 - accuracy: 0.6544 - precision_m: 0.8382 - recall_m: 0.7568 - f1_m: 0.7941 - val_loss: 0.2534 - val_accuracy: 0.6937 - val_precision_m: 0.8205 - val_recall_m: 0.7776 - val_f1_m: 0.7972\n","Epoch 9/1000\n","131/131 [==============================] - 1s 9ms/step - loss: 0.2444 - accuracy: 0.6557 - precision_m: 0.8534 - recall_m: 0.7819 - f1_m: 0.8151 - val_loss: 0.2436 - val_accuracy: 0.6927 - val_precision_m: 0.8306 - val_recall_m: 0.7775 - val_f1_m: 0.8018\n","Epoch 10/1000\n","131/131 [==============================] - 1s 9ms/step - loss: 0.2455 - accuracy: 0.6426 - precision_m: 0.8479 - recall_m: 0.7809 - f1_m: 0.8115 - val_loss: 0.2411 - val_accuracy: 0.6708 - val_precision_m: 0.8386 - val_recall_m: 0.7581 - val_f1_m: 0.7950\n","Epoch 11/1000\n","131/131 [==============================] - 1s 9ms/step - loss: 0.2378 - accuracy: 0.6502 - precision_m: 0.8643 - recall_m: 0.7773 - f1_m: 0.8169 - val_loss: 0.2408 - val_accuracy: 0.6985 - val_precision_m: 0.8341 - val_recall_m: 0.7770 - val_f1_m: 0.8034\n","Epoch 12/1000\n","131/131 [==============================] - 1s 9ms/step - loss: 0.2322 - accuracy: 0.6645 - precision_m: 0.8699 - recall_m: 0.7900 - f1_m: 0.8266 - val_loss: 0.2438 - val_accuracy: 0.6603 - val_precision_m: 0.8374 - val_recall_m: 0.7700 - val_f1_m: 0.8012\n","Epoch 13/1000\n","131/131 [==============================] - 1s 9ms/step - loss: 0.2321 - accuracy: 0.6782 - precision_m: 0.8591 - recall_m: 0.7902 - f1_m: 0.8219 - val_loss: 0.2366 - val_accuracy: 0.6832 - val_precision_m: 0.8325 - val_recall_m: 0.7799 - val_f1_m: 0.8041\n","Epoch 14/1000\n","131/131 [==============================] - 1s 9ms/step - loss: 0.2173 - accuracy: 0.6741 - precision_m: 0.8772 - recall_m: 0.8050 - f1_m: 0.8382 - val_loss: 0.2444 - val_accuracy: 0.6889 - val_precision_m: 0.8167 - val_recall_m: 0.7895 - val_f1_m: 0.8018\n","Epoch 15/1000\n","131/131 [==============================] - 1s 9ms/step - loss: 0.2175 - accuracy: 0.6655 - precision_m: 0.8702 - recall_m: 0.8051 - f1_m: 0.8355 - val_loss: 0.2479 - val_accuracy: 0.7071 - val_precision_m: 0.8291 - val_recall_m: 0.7780 - val_f1_m: 0.8016\n","Epoch 16/1000\n","131/131 [==============================] - 1s 9ms/step - loss: 0.2101 - accuracy: 0.6686 - precision_m: 0.8795 - recall_m: 0.8132 - f1_m: 0.8441 - val_loss: 0.2388 - val_accuracy: 0.6794 - val_precision_m: 0.8236 - val_recall_m: 0.7967 - val_f1_m: 0.8089\n","Epoch 17/1000\n","131/131 [==============================] - 1s 9ms/step - loss: 0.2082 - accuracy: 0.6849 - precision_m: 0.8731 - recall_m: 0.8154 - f1_m: 0.8420 - val_loss: 0.2434 - val_accuracy: 0.7090 - val_precision_m: 0.8239 - val_recall_m: 0.7856 - val_f1_m: 0.8033\n","Epoch 18/1000\n","131/131 [==============================] - 1s 9ms/step - loss: 0.2027 - accuracy: 0.6865 - precision_m: 0.8803 - recall_m: 0.8151 - f1_m: 0.8451 - val_loss: 0.2460 - val_accuracy: 0.6756 - val_precision_m: 0.8250 - val_recall_m: 0.7988 - val_f1_m: 0.8107\n","Epoch 19/1000\n","131/131 [==============================] - 1s 9ms/step - loss: 0.1981 - accuracy: 0.6855 - precision_m: 0.8848 - recall_m: 0.8294 - f1_m: 0.8553 - val_loss: 0.2421 - val_accuracy: 0.6546 - val_precision_m: 0.8249 - val_recall_m: 0.7948 - val_f1_m: 0.8087\n","Epoch 20/1000\n","131/131 [==============================] - 1s 9ms/step - loss: 0.1982 - accuracy: 0.6680 - precision_m: 0.8793 - recall_m: 0.8226 - f1_m: 0.8487 - val_loss: 0.2484 - val_accuracy: 0.6899 - val_precision_m: 0.8048 - val_recall_m: 0.8067 - val_f1_m: 0.8044\n","Epoch 21/1000\n","131/131 [==============================] - 1s 9ms/step - loss: 0.1948 - accuracy: 0.6919 - precision_m: 0.8845 - recall_m: 0.8337 - f1_m: 0.8571 - val_loss: 0.2432 - val_accuracy: 0.6899 - val_precision_m: 0.8259 - val_recall_m: 0.7950 - val_f1_m: 0.8092\n","Epoch 22/1000\n","131/131 [==============================] - 1s 9ms/step - loss: 0.1870 - accuracy: 0.6995 - precision_m: 0.8927 - recall_m: 0.8342 - f1_m: 0.8615 - val_loss: 0.2454 - val_accuracy: 0.6870 - val_precision_m: 0.8234 - val_recall_m: 0.7860 - val_f1_m: 0.8032\n","Epoch 23/1000\n","131/131 [==============================] - 1s 9ms/step - loss: 0.1846 - accuracy: 0.6810 - precision_m: 0.8905 - recall_m: 0.8361 - f1_m: 0.8615 - val_loss: 0.2454 - val_accuracy: 0.6889 - val_precision_m: 0.8431 - val_recall_m: 0.7607 - val_f1_m: 0.7988\n","Epoch 24/1000\n","131/131 [==============================] - 1s 9ms/step - loss: 0.1862 - accuracy: 0.6935 - precision_m: 0.8974 - recall_m: 0.8399 - f1_m: 0.8663 - val_loss: 0.2482 - val_accuracy: 0.6851 - val_precision_m: 0.8141 - val_recall_m: 0.7886 - val_f1_m: 0.8002\n","Epoch 25/1000\n","131/131 [==============================] - 1s 9ms/step - loss: 0.1736 - accuracy: 0.7086 - precision_m: 0.8977 - recall_m: 0.8479 - f1_m: 0.8711 - val_loss: 0.2493 - val_accuracy: 0.6632 - val_precision_m: 0.8152 - val_recall_m: 0.7943 - val_f1_m: 0.8035\n","Epoch 26/1000\n","131/131 [==============================] - 1s 9ms/step - loss: 0.1706 - accuracy: 0.6939 - precision_m: 0.8996 - recall_m: 0.8571 - f1_m: 0.8769 - val_loss: 0.2468 - val_accuracy: 0.6794 - val_precision_m: 0.8222 - val_recall_m: 0.7944 - val_f1_m: 0.8069\n","Epoch 27/1000\n","131/131 [==============================] - 1s 9ms/step - loss: 0.1724 - accuracy: 0.6961 - precision_m: 0.9042 - recall_m: 0.8488 - f1_m: 0.8745 - val_loss: 0.2435 - val_accuracy: 0.6746 - val_precision_m: 0.8314 - val_recall_m: 0.7950 - val_f1_m: 0.8119\n","Epoch 28/1000\n","131/131 [==============================] - 1s 9ms/step - loss: 0.1655 - accuracy: 0.6856 - precision_m: 0.9028 - recall_m: 0.8486 - f1_m: 0.8741 - val_loss: 0.2468 - val_accuracy: 0.6813 - val_precision_m: 0.8371 - val_recall_m: 0.7766 - val_f1_m: 0.8047\n","Epoch 29/1000\n","131/131 [==============================] - 1s 9ms/step - loss: 0.1606 - accuracy: 0.6969 - precision_m: 0.9119 - recall_m: 0.8593 - f1_m: 0.8837 - val_loss: 0.2471 - val_accuracy: 0.6899 - val_precision_m: 0.8289 - val_recall_m: 0.7753 - val_f1_m: 0.8000\n","Epoch 30/1000\n","131/131 [==============================] - 1s 9ms/step - loss: 0.1633 - accuracy: 0.6914 - precision_m: 0.9072 - recall_m: 0.8556 - f1_m: 0.8795 - val_loss: 0.2478 - val_accuracy: 0.6708 - val_precision_m: 0.8411 - val_recall_m: 0.7846 - val_f1_m: 0.8108\n","Epoch 31/1000\n","131/131 [==============================] - 1s 9ms/step - loss: 0.1610 - accuracy: 0.6842 - precision_m: 0.9099 - recall_m: 0.8599 - f1_m: 0.8833 - val_loss: 0.2502 - val_accuracy: 0.6756 - val_precision_m: 0.8188 - val_recall_m: 0.7966 - val_f1_m: 0.8066\n","Epoch 32/1000\n","131/131 [==============================] - 1s 9ms/step - loss: 0.1516 - accuracy: 0.6999 - precision_m: 0.9135 - recall_m: 0.8716 - f1_m: 0.8914 - val_loss: 0.2519 - val_accuracy: 0.6908 - val_precision_m: 0.8211 - val_recall_m: 0.7940 - val_f1_m: 0.8063\n","Epoch 33/1000\n","131/131 [==============================] - 1s 9ms/step - loss: 0.1546 - accuracy: 0.7032 - precision_m: 0.9123 - recall_m: 0.8615 - f1_m: 0.8855 - val_loss: 0.2583 - val_accuracy: 0.6937 - val_precision_m: 0.8101 - val_recall_m: 0.8006 - val_f1_m: 0.8043\n","Epoch 34/1000\n","131/131 [==============================] - 1s 9ms/step - loss: 0.1515 - accuracy: 0.6954 - precision_m: 0.9129 - recall_m: 0.8714 - f1_m: 0.8905 - val_loss: 0.2538 - val_accuracy: 0.6823 - val_precision_m: 0.8280 - val_recall_m: 0.7837 - val_f1_m: 0.8043\n","Epoch 35/1000\n","131/131 [==============================] - 1s 9ms/step - loss: 0.1465 - accuracy: 0.7019 - precision_m: 0.9194 - recall_m: 0.8697 - f1_m: 0.8930 - val_loss: 0.2649 - val_accuracy: 0.7013 - val_precision_m: 0.8065 - val_recall_m: 0.7816 - val_f1_m: 0.7925\n","Epoch 36/1000\n","131/131 [==============================] - 1s 9ms/step - loss: 0.1449 - accuracy: 0.7198 - precision_m: 0.9182 - recall_m: 0.8761 - f1_m: 0.8961 - val_loss: 0.2569 - val_accuracy: 0.6832 - val_precision_m: 0.8237 - val_recall_m: 0.7986 - val_f1_m: 0.8100\n","Epoch 37/1000\n","131/131 [==============================] - 1s 9ms/step - loss: 0.1422 - accuracy: 0.7101 - precision_m: 0.9206 - recall_m: 0.8776 - f1_m: 0.8977 - val_loss: 0.2620 - val_accuracy: 0.6842 - val_precision_m: 0.8093 - val_recall_m: 0.8108 - val_f1_m: 0.8088\n","Epoch 38/1000\n","131/131 [==============================] - 1s 9ms/step - loss: 0.1436 - accuracy: 0.6992 - precision_m: 0.9174 - recall_m: 0.8806 - f1_m: 0.8978 - val_loss: 0.2590 - val_accuracy: 0.6918 - val_precision_m: 0.8275 - val_recall_m: 0.7857 - val_f1_m: 0.8050\n","Epoch 39/1000\n","131/131 [==============================] - 1s 9ms/step - loss: 0.1420 - accuracy: 0.7138 - precision_m: 0.9177 - recall_m: 0.8800 - f1_m: 0.8973 - val_loss: 0.2614 - val_accuracy: 0.6956 - val_precision_m: 0.8113 - val_recall_m: 0.8030 - val_f1_m: 0.8059\n","Epoch 40/1000\n","131/131 [==============================] - 1s 9ms/step - loss: 0.1405 - accuracy: 0.6852 - precision_m: 0.9211 - recall_m: 0.8868 - f1_m: 0.9029 - val_loss: 0.2592 - val_accuracy: 0.6803 - val_precision_m: 0.8336 - val_recall_m: 0.7770 - val_f1_m: 0.8032\n","Epoch 41/1000\n","131/131 [==============================] - 1s 9ms/step - loss: 0.1307 - accuracy: 0.7231 - precision_m: 0.9280 - recall_m: 0.8861 - f1_m: 0.9059 - val_loss: 0.2694 - val_accuracy: 0.6966 - val_precision_m: 0.8065 - val_recall_m: 0.7877 - val_f1_m: 0.7956\n","Epoch 42/1000\n","131/131 [==============================] - 1s 9ms/step - loss: 0.1359 - accuracy: 0.7111 - precision_m: 0.9227 - recall_m: 0.8872 - f1_m: 0.9038 - val_loss: 0.2630 - val_accuracy: 0.6756 - val_precision_m: 0.8209 - val_recall_m: 0.7890 - val_f1_m: 0.8038\n","Epoch 43/1000\n","131/131 [==============================] - 1s 9ms/step - loss: 0.1347 - accuracy: 0.7228 - precision_m: 0.9232 - recall_m: 0.8817 - f1_m: 0.9013 - val_loss: 0.2622 - val_accuracy: 0.6794 - val_precision_m: 0.8327 - val_recall_m: 0.7760 - val_f1_m: 0.8023\n","Epoch 44/1000\n","131/131 [==============================] - 1s 9ms/step - loss: 0.1303 - accuracy: 0.7139 - precision_m: 0.9275 - recall_m: 0.8880 - f1_m: 0.9065 - val_loss: 0.2696 - val_accuracy: 0.6718 - val_precision_m: 0.8179 - val_recall_m: 0.7960 - val_f1_m: 0.8060\n","Epoch 45/1000\n","131/131 [==============================] - 1s 9ms/step - loss: 0.1309 - accuracy: 0.6989 - precision_m: 0.9276 - recall_m: 0.8867 - f1_m: 0.9056 - val_loss: 0.2627 - val_accuracy: 0.6660 - val_precision_m: 0.8239 - val_recall_m: 0.7915 - val_f1_m: 0.8063\n","Epoch 46/1000\n","131/131 [==============================] - 1s 9ms/step - loss: 0.1303 - accuracy: 0.7167 - precision_m: 0.9295 - recall_m: 0.8905 - f1_m: 0.9088 - val_loss: 0.2676 - val_accuracy: 0.6660 - val_precision_m: 0.8240 - val_recall_m: 0.7980 - val_f1_m: 0.8100\n","Epoch 47/1000\n","131/131 [==============================] - 1s 9ms/step - loss: 0.1242 - accuracy: 0.7086 - precision_m: 0.9280 - recall_m: 0.8974 - f1_m: 0.9118 - val_loss: 0.2656 - val_accuracy: 0.6708 - val_precision_m: 0.8219 - val_recall_m: 0.7941 - val_f1_m: 0.8065\n","Epoch 48/1000\n","131/131 [==============================] - 1s 9ms/step - loss: 0.1237 - accuracy: 0.7237 - precision_m: 0.9316 - recall_m: 0.9019 - f1_m: 0.9157 - val_loss: 0.2753 - val_accuracy: 0.6908 - val_precision_m: 0.8179 - val_recall_m: 0.7842 - val_f1_m: 0.7995\n","Epoch 49/1000\n","131/131 [==============================] - 1s 9ms/step - loss: 0.1204 - accuracy: 0.7206 - precision_m: 0.9315 - recall_m: 0.9008 - f1_m: 0.9155 - val_loss: 0.2712 - val_accuracy: 0.6594 - val_precision_m: 0.8271 - val_recall_m: 0.7904 - val_f1_m: 0.8075\n","Epoch 50/1000\n","131/131 [==============================] - 1s 9ms/step - loss: 0.1244 - accuracy: 0.7133 - precision_m: 0.9301 - recall_m: 0.8947 - f1_m: 0.9115 - val_loss: 0.2715 - val_accuracy: 0.6698 - val_precision_m: 0.8356 - val_recall_m: 0.7740 - val_f1_m: 0.8028\n","Epoch 51/1000\n","131/131 [==============================] - 1s 9ms/step - loss: 0.1187 - accuracy: 0.7212 - precision_m: 0.9322 - recall_m: 0.9001 - f1_m: 0.9154 - val_loss: 0.2741 - val_accuracy: 0.6794 - val_precision_m: 0.8064 - val_recall_m: 0.8079 - val_f1_m: 0.8062\n","Epoch 52/1000\n","131/131 [==============================] - 1s 9ms/step - loss: 0.1226 - accuracy: 0.6998 - precision_m: 0.9338 - recall_m: 0.8969 - f1_m: 0.9142 - val_loss: 0.2738 - val_accuracy: 0.6918 - val_precision_m: 0.8278 - val_recall_m: 0.7875 - val_f1_m: 0.8061\n","Epoch 53/1000\n","131/131 [==============================] - 1s 9ms/step - loss: 0.1157 - accuracy: 0.7239 - precision_m: 0.9353 - recall_m: 0.9052 - f1_m: 0.9195 - val_loss: 0.2745 - val_accuracy: 0.6727 - val_precision_m: 0.8225 - val_recall_m: 0.7968 - val_f1_m: 0.8084\n","Epoch 54/1000\n","131/131 [==============================] - 1s 9ms/step - loss: 0.1162 - accuracy: 0.7240 - precision_m: 0.9283 - recall_m: 0.9044 - f1_m: 0.9154 - val_loss: 0.2789 - val_accuracy: 0.6756 - val_precision_m: 0.8343 - val_recall_m: 0.7740 - val_f1_m: 0.8021\n","Epoch 55/1000\n","131/131 [==============================] - 1s 9ms/step - loss: 0.1121 - accuracy: 0.7258 - precision_m: 0.9349 - recall_m: 0.9095 - f1_m: 0.9215 - val_loss: 0.2772 - val_accuracy: 0.6794 - val_precision_m: 0.8210 - val_recall_m: 0.7828 - val_f1_m: 0.8001\n","Epoch 56/1000\n","131/131 [==============================] - 1s 9ms/step - loss: 0.1120 - accuracy: 0.7007 - precision_m: 0.9355 - recall_m: 0.9113 - f1_m: 0.9227 - val_loss: 0.2800 - val_accuracy: 0.6698 - val_precision_m: 0.8313 - val_recall_m: 0.7746 - val_f1_m: 0.8011\n","Epoch 57/1000\n","131/131 [==============================] - 1s 9ms/step - loss: 0.1117 - accuracy: 0.7249 - precision_m: 0.9336 - recall_m: 0.8994 - f1_m: 0.9153 - val_loss: 0.2774 - val_accuracy: 0.6927 - val_precision_m: 0.8167 - val_recall_m: 0.7750 - val_f1_m: 0.7938\n","Epoch 58/1000\n","131/131 [==============================] - 1s 9ms/step - loss: 0.1142 - accuracy: 0.7256 - precision_m: 0.9348 - recall_m: 0.9086 - f1_m: 0.9208 - val_loss: 0.2785 - val_accuracy: 0.6641 - val_precision_m: 0.8199 - val_recall_m: 0.8034 - val_f1_m: 0.8104\n","Epoch 59/1000\n","131/131 [==============================] - 1s 9ms/step - loss: 0.1064 - accuracy: 0.7145 - precision_m: 0.9307 - recall_m: 0.9164 - f1_m: 0.9229 - val_loss: 0.2805 - val_accuracy: 0.6746 - val_precision_m: 0.8096 - val_recall_m: 0.7981 - val_f1_m: 0.8028\n","Epoch 60/1000\n","131/131 [==============================] - 1s 9ms/step - loss: 0.1058 - accuracy: 0.7088 - precision_m: 0.9427 - recall_m: 0.9150 - f1_m: 0.9281 - val_loss: 0.2835 - val_accuracy: 0.6918 - val_precision_m: 0.8067 - val_recall_m: 0.7959 - val_f1_m: 0.8003\n","Epoch 61/1000\n","131/131 [==============================] - 1s 9ms/step - loss: 0.1023 - accuracy: 0.7206 - precision_m: 0.9415 - recall_m: 0.9147 - f1_m: 0.9271 - val_loss: 0.2770 - val_accuracy: 0.6765 - val_precision_m: 0.8228 - val_recall_m: 0.7979 - val_f1_m: 0.8092\n","Epoch 62/1000\n","131/131 [==============================] - 1s 10ms/step - loss: 0.1005 - accuracy: 0.7279 - precision_m: 0.9428 - recall_m: 0.9239 - f1_m: 0.9328 - val_loss: 0.2791 - val_accuracy: 0.6765 - val_precision_m: 0.8221 - val_recall_m: 0.8004 - val_f1_m: 0.8098\n","Epoch 63/1000\n","131/131 [==============================] - 1s 9ms/step - loss: 0.1055 - accuracy: 0.7186 - precision_m: 0.9406 - recall_m: 0.9165 - f1_m: 0.9278 - val_loss: 0.2880 - val_accuracy: 0.6622 - val_precision_m: 0.8349 - val_recall_m: 0.7626 - val_f1_m: 0.7964\n","Epoch 64/1000\n","131/131 [==============================] - 1s 9ms/step - loss: 0.0992 - accuracy: 0.7165 - precision_m: 0.9453 - recall_m: 0.9201 - f1_m: 0.9320 - val_loss: 0.2931 - val_accuracy: 0.6727 - val_precision_m: 0.8258 - val_recall_m: 0.7847 - val_f1_m: 0.8033\n","Epoch 65/1000\n","131/131 [==============================] - 1s 10ms/step - loss: 0.1037 - accuracy: 0.7174 - precision_m: 0.9392 - recall_m: 0.9169 - f1_m: 0.9273 - val_loss: 0.2837 - val_accuracy: 0.6918 - val_precision_m: 0.8244 - val_recall_m: 0.7746 - val_f1_m: 0.7975\n","Epoch 66/1000\n","131/131 [==============================] - 1s 9ms/step - loss: 0.1008 - accuracy: 0.7166 - precision_m: 0.9463 - recall_m: 0.9180 - f1_m: 0.9312 - val_loss: 0.2838 - val_accuracy: 0.6784 - val_precision_m: 0.8244 - val_recall_m: 0.7708 - val_f1_m: 0.7958\n","Epoch 67/1000\n","131/131 [==============================] - 1s 9ms/step - loss: 0.0933 - accuracy: 0.7173 - precision_m: 0.9491 - recall_m: 0.9253 - f1_m: 0.9364 - val_loss: 0.2922 - val_accuracy: 0.6708 - val_precision_m: 0.8312 - val_recall_m: 0.7593 - val_f1_m: 0.7925\n","Epoch 68/1000\n","131/131 [==============================] - 1s 9ms/step - loss: 0.0996 - accuracy: 0.7266 - precision_m: 0.9454 - recall_m: 0.9153 - f1_m: 0.9295 - val_loss: 0.2843 - val_accuracy: 0.6823 - val_precision_m: 0.8311 - val_recall_m: 0.7835 - val_f1_m: 0.8051\n","Epoch 69/1000\n","131/131 [==============================] - 1s 9ms/step - loss: 0.0938 - accuracy: 0.7098 - precision_m: 0.9478 - recall_m: 0.9226 - f1_m: 0.9344 - val_loss: 0.2959 - val_accuracy: 0.6651 - val_precision_m: 0.8248 - val_recall_m: 0.7958 - val_f1_m: 0.8090\n","Epoch 70/1000\n","131/131 [==============================] - 1s 9ms/step - loss: 0.0977 - accuracy: 0.7314 - precision_m: 0.9391 - recall_m: 0.9207 - f1_m: 0.9294 - val_loss: 0.2946 - val_accuracy: 0.6908 - val_precision_m: 0.8282 - val_recall_m: 0.7706 - val_f1_m: 0.7972\n","Epoch 71/1000\n","131/131 [==============================] - 1s 9ms/step - loss: 0.0934 - accuracy: 0.7190 - precision_m: 0.9466 - recall_m: 0.9218 - f1_m: 0.9336 - val_loss: 0.2922 - val_accuracy: 0.6823 - val_precision_m: 0.8278 - val_recall_m: 0.7839 - val_f1_m: 0.8041\n","Epoch 72/1000\n","131/131 [==============================] - 1s 9ms/step - loss: 0.0906 - accuracy: 0.7234 - precision_m: 0.9473 - recall_m: 0.9334 - f1_m: 0.9397 - val_loss: 0.2914 - val_accuracy: 0.6813 - val_precision_m: 0.8292 - val_recall_m: 0.7909 - val_f1_m: 0.8082\n","Epoch 73/1000\n","131/131 [==============================] - 1s 9ms/step - loss: 0.0903 - accuracy: 0.7373 - precision_m: 0.9535 - recall_m: 0.9292 - f1_m: 0.9405 - val_loss: 0.2972 - val_accuracy: 0.6784 - val_precision_m: 0.8233 - val_recall_m: 0.7733 - val_f1_m: 0.7967\n","Epoch 74/1000\n","131/131 [==============================] - 1s 9ms/step - loss: 0.0880 - accuracy: 0.7249 - precision_m: 0.9500 - recall_m: 0.9303 - f1_m: 0.9395 - val_loss: 0.2989 - val_accuracy: 0.6889 - val_precision_m: 0.8215 - val_recall_m: 0.7668 - val_f1_m: 0.7922\n","Epoch 75/1000\n","131/131 [==============================] - 1s 9ms/step - loss: 0.0930 - accuracy: 0.7139 - precision_m: 0.9426 - recall_m: 0.9266 - f1_m: 0.9340 - val_loss: 0.3063 - val_accuracy: 0.6737 - val_precision_m: 0.8304 - val_recall_m: 0.7725 - val_f1_m: 0.7991\n","Epoch 76/1000\n","131/131 [==============================] - 1s 9ms/step - loss: 0.0974 - accuracy: 0.7158 - precision_m: 0.9445 - recall_m: 0.9166 - f1_m: 0.9299 - val_loss: 0.2951 - val_accuracy: 0.6861 - val_precision_m: 0.8144 - val_recall_m: 0.7928 - val_f1_m: 0.8022\n","Epoch 77/1000\n","131/131 [==============================] - 1s 10ms/step - loss: 0.0933 - accuracy: 0.7232 - precision_m: 0.9475 - recall_m: 0.9197 - f1_m: 0.9328 - val_loss: 0.2961 - val_accuracy: 0.6756 - val_precision_m: 0.8228 - val_recall_m: 0.7923 - val_f1_m: 0.8062\n","Epoch 00077: early stopping\n","Score for fold 1: loss of 0.5939943790435791; accuracy of 51.39259696006775% ;precision_m of 0.844610333442688 ;recall_m of 0.6961743831634521 ;            f1_m of 0.76019287109375\n","Epoch 1/1000\n","131/131 [==============================] - 1s 10ms/step - loss: 0.3663 - accuracy: 0.6152 - precision_m: 0.8292 - recall_m: 0.7684 - f1_m: 0.7963 - val_loss: 0.2689 - val_accuracy: 0.7131 - val_precision_m: 0.8520 - val_recall_m: 0.7448 - val_f1_m: 0.7934\n","Epoch 2/1000\n","131/131 [==============================] - 1s 9ms/step - loss: 0.3124 - accuracy: 0.6202 - precision_m: 0.8516 - recall_m: 0.7651 - f1_m: 0.8049 - val_loss: 0.2587 - val_accuracy: 0.7064 - val_precision_m: 0.8461 - val_recall_m: 0.7882 - val_f1_m: 0.8148\n","Epoch 3/1000\n","131/131 [==============================] - 1s 9ms/step - loss: 0.2925 - accuracy: 0.6209 - precision_m: 0.8546 - recall_m: 0.7822 - f1_m: 0.8159 - val_loss: 0.2562 - val_accuracy: 0.7121 - val_precision_m: 0.8538 - val_recall_m: 0.7853 - val_f1_m: 0.8171\n","Epoch 4/1000\n","131/131 [==============================] - 1s 10ms/step - loss: 0.2819 - accuracy: 0.6322 - precision_m: 0.8652 - recall_m: 0.7912 - f1_m: 0.8255 - val_loss: 0.2588 - val_accuracy: 0.7131 - val_precision_m: 0.8510 - val_recall_m: 0.7879 - val_f1_m: 0.8171\n","Epoch 5/1000\n","131/131 [==============================] - 1s 9ms/step - loss: 0.2679 - accuracy: 0.6322 - precision_m: 0.8657 - recall_m: 0.7985 - f1_m: 0.8297 - val_loss: 0.2502 - val_accuracy: 0.7121 - val_precision_m: 0.8694 - val_recall_m: 0.7654 - val_f1_m: 0.8127\n","Epoch 6/1000\n","131/131 [==============================] - 1s 9ms/step - loss: 0.2557 - accuracy: 0.6441 - precision_m: 0.8745 - recall_m: 0.8043 - f1_m: 0.8368 - val_loss: 0.2492 - val_accuracy: 0.7026 - val_precision_m: 0.8681 - val_recall_m: 0.7696 - val_f1_m: 0.8144\n","Epoch 7/1000\n","131/131 [==============================] - 1s 9ms/step - loss: 0.2482 - accuracy: 0.6410 - precision_m: 0.8791 - recall_m: 0.8118 - f1_m: 0.8433 - val_loss: 0.2489 - val_accuracy: 0.7245 - val_precision_m: 0.8663 - val_recall_m: 0.7630 - val_f1_m: 0.8103\n","Epoch 8/1000\n","131/131 [==============================] - 1s 9ms/step - loss: 0.2435 - accuracy: 0.6472 - precision_m: 0.8808 - recall_m: 0.8135 - f1_m: 0.8450 - val_loss: 0.2479 - val_accuracy: 0.7026 - val_precision_m: 0.8606 - val_recall_m: 0.7700 - val_f1_m: 0.8115\n","Epoch 9/1000\n","131/131 [==============================] - 1s 10ms/step - loss: 0.2359 - accuracy: 0.6436 - precision_m: 0.8847 - recall_m: 0.8209 - f1_m: 0.8506 - val_loss: 0.2498 - val_accuracy: 0.7016 - val_precision_m: 0.8405 - val_recall_m: 0.7748 - val_f1_m: 0.8052\n","Epoch 10/1000\n","131/131 [==============================] - 1s 9ms/step - loss: 0.2342 - accuracy: 0.6469 - precision_m: 0.8885 - recall_m: 0.8177 - f1_m: 0.8508 - val_loss: 0.2477 - val_accuracy: 0.7207 - val_precision_m: 0.8569 - val_recall_m: 0.7733 - val_f1_m: 0.8118\n","Epoch 11/1000\n","131/131 [==============================] - 1s 9ms/step - loss: 0.2185 - accuracy: 0.6596 - precision_m: 0.8917 - recall_m: 0.8284 - f1_m: 0.8579 - val_loss: 0.2491 - val_accuracy: 0.7112 - val_precision_m: 0.8511 - val_recall_m: 0.7869 - val_f1_m: 0.8167\n","Epoch 12/1000\n","131/131 [==============================] - 1s 9ms/step - loss: 0.2186 - accuracy: 0.6505 - precision_m: 0.8947 - recall_m: 0.8335 - f1_m: 0.8621 - val_loss: 0.2507 - val_accuracy: 0.7112 - val_precision_m: 0.8408 - val_recall_m: 0.7949 - val_f1_m: 0.8160\n","Epoch 13/1000\n","131/131 [==============================] - 1s 10ms/step - loss: 0.2103 - accuracy: 0.6558 - precision_m: 0.8943 - recall_m: 0.8398 - f1_m: 0.8652 - val_loss: 0.2500 - val_accuracy: 0.6902 - val_precision_m: 0.8481 - val_recall_m: 0.7688 - val_f1_m: 0.8048\n","Epoch 14/1000\n","131/131 [==============================] - 1s 9ms/step - loss: 0.2057 - accuracy: 0.6522 - precision_m: 0.9012 - recall_m: 0.8404 - f1_m: 0.8688 - val_loss: 0.2470 - val_accuracy: 0.7140 - val_precision_m: 0.8427 - val_recall_m: 0.7873 - val_f1_m: 0.8127\n","Epoch 15/1000\n","131/131 [==============================] - 1s 10ms/step - loss: 0.2066 - accuracy: 0.6517 - precision_m: 0.8964 - recall_m: 0.8417 - f1_m: 0.8672 - val_loss: 0.2532 - val_accuracy: 0.7131 - val_precision_m: 0.8464 - val_recall_m: 0.7633 - val_f1_m: 0.8011\n","Epoch 16/1000\n","131/131 [==============================] - 1s 9ms/step - loss: 0.2030 - accuracy: 0.6489 - precision_m: 0.9006 - recall_m: 0.8446 - f1_m: 0.8710 - val_loss: 0.2504 - val_accuracy: 0.7092 - val_precision_m: 0.8551 - val_recall_m: 0.7596 - val_f1_m: 0.8029\n","Epoch 17/1000\n","131/131 [==============================] - 1s 9ms/step - loss: 0.1945 - accuracy: 0.6458 - precision_m: 0.9020 - recall_m: 0.8482 - f1_m: 0.8734 - val_loss: 0.2437 - val_accuracy: 0.7073 - val_precision_m: 0.8464 - val_recall_m: 0.7843 - val_f1_m: 0.8127\n","Epoch 18/1000\n","131/131 [==============================] - 1s 9ms/step - loss: 0.1926 - accuracy: 0.6562 - precision_m: 0.9062 - recall_m: 0.8523 - f1_m: 0.8776 - val_loss: 0.2466 - val_accuracy: 0.7178 - val_precision_m: 0.8489 - val_recall_m: 0.7964 - val_f1_m: 0.8204\n","Epoch 19/1000\n","131/131 [==============================] - 1s 9ms/step - loss: 0.1905 - accuracy: 0.6625 - precision_m: 0.9049 - recall_m: 0.8565 - f1_m: 0.8792 - val_loss: 0.2477 - val_accuracy: 0.7007 - val_precision_m: 0.8586 - val_recall_m: 0.7718 - val_f1_m: 0.8115\n","Epoch 20/1000\n","131/131 [==============================] - 1s 9ms/step - loss: 0.1868 - accuracy: 0.6596 - precision_m: 0.9081 - recall_m: 0.8570 - f1_m: 0.8809 - val_loss: 0.2457 - val_accuracy: 0.7073 - val_precision_m: 0.8565 - val_recall_m: 0.7756 - val_f1_m: 0.8129\n","Epoch 21/1000\n","131/131 [==============================] - 1s 9ms/step - loss: 0.1809 - accuracy: 0.6703 - precision_m: 0.9123 - recall_m: 0.8599 - f1_m: 0.8845 - val_loss: 0.2459 - val_accuracy: 0.7016 - val_precision_m: 0.8557 - val_recall_m: 0.7700 - val_f1_m: 0.8089\n","Epoch 22/1000\n","131/131 [==============================] - 1s 9ms/step - loss: 0.1840 - accuracy: 0.6586 - precision_m: 0.9115 - recall_m: 0.8580 - f1_m: 0.8829 - val_loss: 0.2582 - val_accuracy: 0.7121 - val_precision_m: 0.8436 - val_recall_m: 0.7711 - val_f1_m: 0.8045\n","Epoch 23/1000\n","131/131 [==============================] - 1s 10ms/step - loss: 0.1753 - accuracy: 0.6679 - precision_m: 0.9124 - recall_m: 0.8709 - f1_m: 0.8903 - val_loss: 0.2530 - val_accuracy: 0.6902 - val_precision_m: 0.8500 - val_recall_m: 0.7671 - val_f1_m: 0.8050\n","Epoch 24/1000\n","131/131 [==============================] - 1s 10ms/step - loss: 0.1737 - accuracy: 0.6644 - precision_m: 0.9178 - recall_m: 0.8704 - f1_m: 0.8927 - val_loss: 0.2535 - val_accuracy: 0.7102 - val_precision_m: 0.8436 - val_recall_m: 0.7835 - val_f1_m: 0.8113\n","Epoch 25/1000\n","131/131 [==============================] - 1s 9ms/step - loss: 0.1687 - accuracy: 0.6598 - precision_m: 0.9197 - recall_m: 0.8749 - f1_m: 0.8959 - val_loss: 0.2523 - val_accuracy: 0.6940 - val_precision_m: 0.8453 - val_recall_m: 0.7764 - val_f1_m: 0.8078\n","Epoch 26/1000\n","131/131 [==============================] - 1s 10ms/step - loss: 0.1718 - accuracy: 0.6613 - precision_m: 0.9176 - recall_m: 0.8677 - f1_m: 0.8912 - val_loss: 0.2547 - val_accuracy: 0.7226 - val_precision_m: 0.8382 - val_recall_m: 0.7705 - val_f1_m: 0.8014\n","Epoch 27/1000\n","131/131 [==============================] - 1s 9ms/step - loss: 0.1693 - accuracy: 0.6646 - precision_m: 0.9187 - recall_m: 0.8705 - f1_m: 0.8930 - val_loss: 0.2550 - val_accuracy: 0.7045 - val_precision_m: 0.8441 - val_recall_m: 0.7793 - val_f1_m: 0.8089\n","Epoch 28/1000\n","131/131 [==============================] - 1s 9ms/step - loss: 0.1637 - accuracy: 0.6703 - precision_m: 0.9178 - recall_m: 0.8731 - f1_m: 0.8942 - val_loss: 0.2506 - val_accuracy: 0.7121 - val_precision_m: 0.8467 - val_recall_m: 0.7744 - val_f1_m: 0.8075\n","Epoch 29/1000\n","131/131 [==============================] - 1s 9ms/step - loss: 0.1626 - accuracy: 0.6718 - precision_m: 0.9159 - recall_m: 0.8755 - f1_m: 0.8945 - val_loss: 0.2538 - val_accuracy: 0.7083 - val_precision_m: 0.8448 - val_recall_m: 0.7706 - val_f1_m: 0.8044\n","Epoch 30/1000\n","131/131 [==============================] - 1s 9ms/step - loss: 0.1637 - accuracy: 0.6715 - precision_m: 0.9186 - recall_m: 0.8776 - f1_m: 0.8969 - val_loss: 0.2516 - val_accuracy: 0.7131 - val_precision_m: 0.8536 - val_recall_m: 0.7679 - val_f1_m: 0.8070\n","Epoch 31/1000\n","131/131 [==============================] - 1s 10ms/step - loss: 0.1551 - accuracy: 0.6634 - precision_m: 0.9260 - recall_m: 0.8822 - f1_m: 0.9029 - val_loss: 0.2552 - val_accuracy: 0.7092 - val_precision_m: 0.8384 - val_recall_m: 0.7839 - val_f1_m: 0.8084\n","Epoch 32/1000\n","131/131 [==============================] - 1s 9ms/step - loss: 0.1575 - accuracy: 0.6706 - precision_m: 0.9250 - recall_m: 0.8786 - f1_m: 0.9005 - val_loss: 0.2545 - val_accuracy: 0.6978 - val_precision_m: 0.8450 - val_recall_m: 0.7990 - val_f1_m: 0.8198\n","Epoch 33/1000\n","131/131 [==============================] - 1s 9ms/step - loss: 0.1543 - accuracy: 0.6734 - precision_m: 0.9267 - recall_m: 0.8837 - f1_m: 0.9040 - val_loss: 0.2540 - val_accuracy: 0.7054 - val_precision_m: 0.8536 - val_recall_m: 0.7794 - val_f1_m: 0.8132\n","Epoch 34/1000\n","131/131 [==============================] - 1s 9ms/step - loss: 0.1579 - accuracy: 0.6586 - precision_m: 0.9242 - recall_m: 0.8812 - f1_m: 0.9012 - val_loss: 0.2536 - val_accuracy: 0.7112 - val_precision_m: 0.8487 - val_recall_m: 0.7611 - val_f1_m: 0.8008\n","Epoch 35/1000\n","131/131 [==============================] - 1s 9ms/step - loss: 0.1554 - accuracy: 0.6710 - precision_m: 0.9250 - recall_m: 0.8809 - f1_m: 0.9016 - val_loss: 0.2584 - val_accuracy: 0.7159 - val_precision_m: 0.8499 - val_recall_m: 0.7663 - val_f1_m: 0.8037\n","Epoch 36/1000\n","131/131 [==============================] - 1s 9ms/step - loss: 0.1501 - accuracy: 0.6665 - precision_m: 0.9288 - recall_m: 0.8867 - f1_m: 0.9067 - val_loss: 0.2609 - val_accuracy: 0.7131 - val_precision_m: 0.8372 - val_recall_m: 0.7709 - val_f1_m: 0.8008\n","Epoch 37/1000\n","131/131 [==============================] - 1s 9ms/step - loss: 0.1495 - accuracy: 0.6789 - precision_m: 0.9275 - recall_m: 0.8870 - f1_m: 0.9061 - val_loss: 0.2656 - val_accuracy: 0.6797 - val_precision_m: 0.8463 - val_recall_m: 0.7571 - val_f1_m: 0.7977\n","Epoch 38/1000\n","131/131 [==============================] - 1s 9ms/step - loss: 0.1472 - accuracy: 0.6758 - precision_m: 0.9300 - recall_m: 0.8905 - f1_m: 0.9091 - val_loss: 0.2605 - val_accuracy: 0.7216 - val_precision_m: 0.8502 - val_recall_m: 0.7672 - val_f1_m: 0.8050\n","Epoch 39/1000\n","131/131 [==============================] - 1s 10ms/step - loss: 0.1446 - accuracy: 0.6665 - precision_m: 0.9348 - recall_m: 0.8916 - f1_m: 0.9119 - val_loss: 0.2611 - val_accuracy: 0.7092 - val_precision_m: 0.8383 - val_recall_m: 0.7685 - val_f1_m: 0.8007\n","Epoch 40/1000\n","131/131 [==============================] - 1s 9ms/step - loss: 0.1402 - accuracy: 0.6732 - precision_m: 0.9340 - recall_m: 0.8942 - f1_m: 0.9130 - val_loss: 0.2651 - val_accuracy: 0.6949 - val_precision_m: 0.8496 - val_recall_m: 0.7685 - val_f1_m: 0.8057\n","Epoch 41/1000\n","131/131 [==============================] - 1s 9ms/step - loss: 0.1422 - accuracy: 0.6775 - precision_m: 0.9316 - recall_m: 0.8912 - f1_m: 0.9103 - val_loss: 0.2636 - val_accuracy: 0.7102 - val_precision_m: 0.8396 - val_recall_m: 0.7696 - val_f1_m: 0.8013\n","Epoch 42/1000\n","131/131 [==============================] - 1s 9ms/step - loss: 0.1413 - accuracy: 0.6718 - precision_m: 0.9310 - recall_m: 0.8944 - f1_m: 0.9117 - val_loss: 0.2632 - val_accuracy: 0.7054 - val_precision_m: 0.8459 - val_recall_m: 0.7673 - val_f1_m: 0.8032\n","Epoch 43/1000\n","131/131 [==============================] - 1s 9ms/step - loss: 0.1433 - accuracy: 0.6720 - precision_m: 0.9301 - recall_m: 0.8909 - f1_m: 0.9095 - val_loss: 0.2622 - val_accuracy: 0.6959 - val_precision_m: 0.8481 - val_recall_m: 0.7662 - val_f1_m: 0.8036\n","Epoch 44/1000\n","131/131 [==============================] - 1s 9ms/step - loss: 0.1349 - accuracy: 0.6679 - precision_m: 0.9355 - recall_m: 0.8966 - f1_m: 0.9150 - val_loss: 0.2630 - val_accuracy: 0.7150 - val_precision_m: 0.8474 - val_recall_m: 0.7672 - val_f1_m: 0.8039\n","Epoch 45/1000\n","131/131 [==============================] - 1s 10ms/step - loss: 0.1356 - accuracy: 0.6682 - precision_m: 0.9327 - recall_m: 0.8986 - f1_m: 0.9148 - val_loss: 0.2658 - val_accuracy: 0.7092 - val_precision_m: 0.8308 - val_recall_m: 0.7790 - val_f1_m: 0.8024\n","Epoch 46/1000\n","131/131 [==============================] - 1s 10ms/step - loss: 0.1329 - accuracy: 0.6741 - precision_m: 0.9351 - recall_m: 0.8997 - f1_m: 0.9165 - val_loss: 0.2666 - val_accuracy: 0.7073 - val_precision_m: 0.8266 - val_recall_m: 0.7870 - val_f1_m: 0.8046\n","Epoch 47/1000\n","131/131 [==============================] - 1s 10ms/step - loss: 0.1331 - accuracy: 0.6760 - precision_m: 0.9356 - recall_m: 0.8974 - f1_m: 0.9155 - val_loss: 0.2633 - val_accuracy: 0.7007 - val_precision_m: 0.8380 - val_recall_m: 0.7733 - val_f1_m: 0.8027\n","Epoch 48/1000\n","131/131 [==============================] - 1s 9ms/step - loss: 0.1298 - accuracy: 0.6713 - precision_m: 0.9382 - recall_m: 0.9030 - f1_m: 0.9196 - val_loss: 0.2657 - val_accuracy: 0.7112 - val_precision_m: 0.8391 - val_recall_m: 0.7757 - val_f1_m: 0.8044\n","Epoch 49/1000\n","131/131 [==============================] - 1s 10ms/step - loss: 0.1296 - accuracy: 0.6698 - precision_m: 0.9394 - recall_m: 0.9017 - f1_m: 0.9195 - val_loss: 0.2645 - val_accuracy: 0.7035 - val_precision_m: 0.8376 - val_recall_m: 0.7777 - val_f1_m: 0.8051\n","Epoch 50/1000\n","131/131 [==============================] - 1s 9ms/step - loss: 0.1333 - accuracy: 0.6722 - precision_m: 0.9360 - recall_m: 0.8999 - f1_m: 0.9170 - val_loss: 0.2667 - val_accuracy: 0.7092 - val_precision_m: 0.8363 - val_recall_m: 0.7745 - val_f1_m: 0.8027\n","Epoch 51/1000\n","131/131 [==============================] - 1s 10ms/step - loss: 0.1266 - accuracy: 0.6737 - precision_m: 0.9396 - recall_m: 0.9074 - f1_m: 0.9227 - val_loss: 0.2675 - val_accuracy: 0.7083 - val_precision_m: 0.8245 - val_recall_m: 0.7881 - val_f1_m: 0.8045\n","Epoch 52/1000\n","131/131 [==============================] - 1s 9ms/step - loss: 0.1270 - accuracy: 0.6729 - precision_m: 0.9396 - recall_m: 0.9057 - f1_m: 0.9218 - val_loss: 0.2655 - val_accuracy: 0.7150 - val_precision_m: 0.8360 - val_recall_m: 0.7723 - val_f1_m: 0.8014\n","Epoch 53/1000\n","131/131 [==============================] - 1s 10ms/step - loss: 0.1270 - accuracy: 0.6694 - precision_m: 0.9392 - recall_m: 0.9063 - f1_m: 0.9219 - val_loss: 0.2672 - val_accuracy: 0.6988 - val_precision_m: 0.8474 - val_recall_m: 0.7850 - val_f1_m: 0.8134\n","Epoch 54/1000\n","131/131 [==============================] - 1s 9ms/step - loss: 0.1234 - accuracy: 0.6801 - precision_m: 0.9425 - recall_m: 0.9095 - f1_m: 0.9250 - val_loss: 0.2658 - val_accuracy: 0.7178 - val_precision_m: 0.8276 - val_recall_m: 0.7932 - val_f1_m: 0.8087\n","Epoch 55/1000\n","131/131 [==============================] - 1s 9ms/step - loss: 0.1185 - accuracy: 0.6799 - precision_m: 0.9492 - recall_m: 0.9126 - f1_m: 0.9300 - val_loss: 0.2645 - val_accuracy: 0.7112 - val_precision_m: 0.8476 - val_recall_m: 0.7705 - val_f1_m: 0.8057\n","Epoch 56/1000\n","131/131 [==============================] - 1s 10ms/step - loss: 0.1264 - accuracy: 0.6842 - precision_m: 0.9380 - recall_m: 0.9092 - f1_m: 0.9228 - val_loss: 0.2692 - val_accuracy: 0.6959 - val_precision_m: 0.8412 - val_recall_m: 0.7613 - val_f1_m: 0.7970\n","Epoch 57/1000\n","131/131 [==============================] - 1s 9ms/step - loss: 0.1241 - accuracy: 0.6715 - precision_m: 0.9424 - recall_m: 0.9062 - f1_m: 0.9234 - val_loss: 0.2659 - val_accuracy: 0.7064 - val_precision_m: 0.8480 - val_recall_m: 0.7699 - val_f1_m: 0.8054\n","Epoch 58/1000\n","131/131 [==============================] - 1s 10ms/step - loss: 0.1196 - accuracy: 0.6780 - precision_m: 0.9460 - recall_m: 0.9118 - f1_m: 0.9280 - val_loss: 0.2694 - val_accuracy: 0.7102 - val_precision_m: 0.8463 - val_recall_m: 0.7488 - val_f1_m: 0.7928\n","Epoch 59/1000\n","131/131 [==============================] - 1s 10ms/step - loss: 0.1175 - accuracy: 0.6777 - precision_m: 0.9441 - recall_m: 0.9141 - f1_m: 0.9284 - val_loss: 0.2742 - val_accuracy: 0.6988 - val_precision_m: 0.8318 - val_recall_m: 0.7847 - val_f1_m: 0.8058\n","Epoch 60/1000\n","131/131 [==============================] - 1s 10ms/step - loss: 0.1212 - accuracy: 0.6772 - precision_m: 0.9449 - recall_m: 0.9111 - f1_m: 0.9271 - val_loss: 0.2736 - val_accuracy: 0.7035 - val_precision_m: 0.8332 - val_recall_m: 0.7749 - val_f1_m: 0.8008\n","Epoch 61/1000\n","131/131 [==============================] - 1s 10ms/step - loss: 0.1172 - accuracy: 0.6837 - precision_m: 0.9471 - recall_m: 0.9146 - f1_m: 0.9300 - val_loss: 0.2742 - val_accuracy: 0.7064 - val_precision_m: 0.8325 - val_recall_m: 0.7764 - val_f1_m: 0.8018\n","Epoch 62/1000\n","131/131 [==============================] - 1s 10ms/step - loss: 0.1156 - accuracy: 0.6825 - precision_m: 0.9456 - recall_m: 0.9142 - f1_m: 0.9291 - val_loss: 0.2726 - val_accuracy: 0.7083 - val_precision_m: 0.8284 - val_recall_m: 0.7747 - val_f1_m: 0.7986\n","Epoch 63/1000\n","131/131 [==============================] - 1s 9ms/step - loss: 0.1146 - accuracy: 0.6737 - precision_m: 0.9465 - recall_m: 0.9150 - f1_m: 0.9299 - val_loss: 0.2722 - val_accuracy: 0.7045 - val_precision_m: 0.8353 - val_recall_m: 0.7733 - val_f1_m: 0.8017\n","Epoch 64/1000\n","131/131 [==============================] - 1s 10ms/step - loss: 0.1130 - accuracy: 0.6756 - precision_m: 0.9462 - recall_m: 0.9182 - f1_m: 0.9314 - val_loss: 0.2768 - val_accuracy: 0.7092 - val_precision_m: 0.8268 - val_recall_m: 0.7850 - val_f1_m: 0.8036\n","Epoch 65/1000\n","131/131 [==============================] - 1s 9ms/step - loss: 0.1141 - accuracy: 0.6813 - precision_m: 0.9505 - recall_m: 0.9134 - f1_m: 0.9310 - val_loss: 0.2734 - val_accuracy: 0.6969 - val_precision_m: 0.8388 - val_recall_m: 0.7854 - val_f1_m: 0.8097\n","Epoch 66/1000\n","131/131 [==============================] - 1s 9ms/step - loss: 0.1146 - accuracy: 0.6746 - precision_m: 0.9453 - recall_m: 0.9131 - f1_m: 0.9284 - val_loss: 0.2776 - val_accuracy: 0.7188 - val_precision_m: 0.8417 - val_recall_m: 0.7783 - val_f1_m: 0.8074\n","Epoch 67/1000\n","131/131 [==============================] - 1s 10ms/step - loss: 0.1100 - accuracy: 0.6927 - precision_m: 0.9469 - recall_m: 0.9168 - f1_m: 0.9311 - val_loss: 0.2762 - val_accuracy: 0.7073 - val_precision_m: 0.8348 - val_recall_m: 0.7903 - val_f1_m: 0.8103\n","Epoch 68/1000\n","131/131 [==============================] - 1s 9ms/step - loss: 0.1093 - accuracy: 0.6775 - precision_m: 0.9502 - recall_m: 0.9167 - f1_m: 0.9326 - val_loss: 0.2777 - val_accuracy: 0.7045 - val_precision_m: 0.8325 - val_recall_m: 0.7922 - val_f1_m: 0.8107\n","Epoch 00068: early stopping\n","Score for fold 2: loss of 0.2465963512659073; accuracy of 69.7328269481659% ;precision_m of 0.8589565753936768 ;recall_m of 0.8325409293174744 ;            f1_m of 0.8441144227981567\n","Epoch 1/1000\n","131/131 [==============================] - 1s 10ms/step - loss: 0.1969 - accuracy: 0.6348 - precision_m: 0.9038 - recall_m: 0.8612 - f1_m: 0.8812 - val_loss: 0.2210 - val_accuracy: 0.7417 - val_precision_m: 0.8917 - val_recall_m: 0.7962 - val_f1_m: 0.8399\n","Epoch 2/1000\n","131/131 [==============================] - 1s 10ms/step - loss: 0.1837 - accuracy: 0.6293 - precision_m: 0.9129 - recall_m: 0.8683 - f1_m: 0.8893 - val_loss: 0.2130 - val_accuracy: 0.7216 - val_precision_m: 0.8890 - val_recall_m: 0.7982 - val_f1_m: 0.8396\n","Epoch 3/1000\n","131/131 [==============================] - 1s 10ms/step - loss: 0.1799 - accuracy: 0.6271 - precision_m: 0.9133 - recall_m: 0.8711 - f1_m: 0.8909 - val_loss: 0.2122 - val_accuracy: 0.7369 - val_precision_m: 0.8896 - val_recall_m: 0.7990 - val_f1_m: 0.8406\n","Epoch 4/1000\n","131/131 [==============================] - 1s 10ms/step - loss: 0.1696 - accuracy: 0.6331 - precision_m: 0.9153 - recall_m: 0.8774 - f1_m: 0.8953 - val_loss: 0.2116 - val_accuracy: 0.7388 - val_precision_m: 0.8949 - val_recall_m: 0.7923 - val_f1_m: 0.8391\n","Epoch 5/1000\n","131/131 [==============================] - 1s 10ms/step - loss: 0.1625 - accuracy: 0.6388 - precision_m: 0.9250 - recall_m: 0.8831 - f1_m: 0.9028 - val_loss: 0.2178 - val_accuracy: 0.7359 - val_precision_m: 0.8990 - val_recall_m: 0.7853 - val_f1_m: 0.8370\n","Epoch 6/1000\n","131/131 [==============================] - 1s 9ms/step - loss: 0.1595 - accuracy: 0.6281 - precision_m: 0.9210 - recall_m: 0.8838 - f1_m: 0.9012 - val_loss: 0.2137 - val_accuracy: 0.7359 - val_precision_m: 0.8832 - val_recall_m: 0.8130 - val_f1_m: 0.8451\n","Epoch 7/1000\n","131/131 [==============================] - 1s 9ms/step - loss: 0.1532 - accuracy: 0.6419 - precision_m: 0.9284 - recall_m: 0.8890 - f1_m: 0.9077 - val_loss: 0.2230 - val_accuracy: 0.7350 - val_precision_m: 0.8805 - val_recall_m: 0.7969 - val_f1_m: 0.8351\n","Epoch 8/1000\n","131/131 [==============================] - 1s 10ms/step - loss: 0.1472 - accuracy: 0.6446 - precision_m: 0.9297 - recall_m: 0.8914 - f1_m: 0.9095 - val_loss: 0.2129 - val_accuracy: 0.7321 - val_precision_m: 0.8846 - val_recall_m: 0.8034 - val_f1_m: 0.8404\n","Epoch 9/1000\n","131/131 [==============================] - 1s 9ms/step - loss: 0.1452 - accuracy: 0.6336 - precision_m: 0.9308 - recall_m: 0.8938 - f1_m: 0.9113 - val_loss: 0.2086 - val_accuracy: 0.7169 - val_precision_m: 0.8925 - val_recall_m: 0.8024 - val_f1_m: 0.8434\n","Epoch 10/1000\n","131/131 [==============================] - 1s 10ms/step - loss: 0.1470 - accuracy: 0.6333 - precision_m: 0.9281 - recall_m: 0.8892 - f1_m: 0.9076 - val_loss: 0.2187 - val_accuracy: 0.7436 - val_precision_m: 0.8871 - val_recall_m: 0.8057 - val_f1_m: 0.8428\n","Epoch 11/1000\n","131/131 [==============================] - 1s 10ms/step - loss: 0.1479 - accuracy: 0.6448 - precision_m: 0.9303 - recall_m: 0.8912 - f1_m: 0.9097 - val_loss: 0.2149 - val_accuracy: 0.7197 - val_precision_m: 0.8836 - val_recall_m: 0.8056 - val_f1_m: 0.8411\n","Epoch 12/1000\n","131/131 [==============================] - 1s 10ms/step - loss: 0.1415 - accuracy: 0.6427 - precision_m: 0.9321 - recall_m: 0.8973 - f1_m: 0.9137 - val_loss: 0.2163 - val_accuracy: 0.7226 - val_precision_m: 0.8758 - val_recall_m: 0.8139 - val_f1_m: 0.8423\n","Epoch 13/1000\n","131/131 [==============================] - 1s 10ms/step - loss: 0.1397 - accuracy: 0.6438 - precision_m: 0.9336 - recall_m: 0.8953 - f1_m: 0.9135 - val_loss: 0.2212 - val_accuracy: 0.7407 - val_precision_m: 0.8864 - val_recall_m: 0.7945 - val_f1_m: 0.8363\n","Epoch 14/1000\n","131/131 [==============================] - 1s 10ms/step - loss: 0.1391 - accuracy: 0.6493 - precision_m: 0.9378 - recall_m: 0.8975 - f1_m: 0.9165 - val_loss: 0.2206 - val_accuracy: 0.7312 - val_precision_m: 0.8789 - val_recall_m: 0.8014 - val_f1_m: 0.8366\n","Epoch 15/1000\n","131/131 [==============================] - 1s 10ms/step - loss: 0.1374 - accuracy: 0.6403 - precision_m: 0.9327 - recall_m: 0.9012 - f1_m: 0.9162 - val_loss: 0.2156 - val_accuracy: 0.7483 - val_precision_m: 0.8857 - val_recall_m: 0.8047 - val_f1_m: 0.8419\n","Epoch 16/1000\n","131/131 [==============================] - 1s 9ms/step - loss: 0.1300 - accuracy: 0.6558 - precision_m: 0.9384 - recall_m: 0.9027 - f1_m: 0.9195 - val_loss: 0.2230 - val_accuracy: 0.7369 - val_precision_m: 0.8644 - val_recall_m: 0.8165 - val_f1_m: 0.8382\n","Epoch 17/1000\n","131/131 [==============================] - 1s 10ms/step - loss: 0.1353 - accuracy: 0.6481 - precision_m: 0.9355 - recall_m: 0.9014 - f1_m: 0.9174 - val_loss: 0.2154 - val_accuracy: 0.7264 - val_precision_m: 0.8794 - val_recall_m: 0.8090 - val_f1_m: 0.8414\n","Epoch 18/1000\n","131/131 [==============================] - 1s 10ms/step - loss: 0.1298 - accuracy: 0.6417 - precision_m: 0.9425 - recall_m: 0.9048 - f1_m: 0.9227 - val_loss: 0.2162 - val_accuracy: 0.7274 - val_precision_m: 0.8854 - val_recall_m: 0.8014 - val_f1_m: 0.8397\n","Epoch 19/1000\n","131/131 [==============================] - 1s 10ms/step - loss: 0.1269 - accuracy: 0.6388 - precision_m: 0.9388 - recall_m: 0.9057 - f1_m: 0.9214 - val_loss: 0.2138 - val_accuracy: 0.7340 - val_precision_m: 0.8837 - val_recall_m: 0.8147 - val_f1_m: 0.8462\n","Epoch 20/1000\n","131/131 [==============================] - 1s 10ms/step - loss: 0.1294 - accuracy: 0.6331 - precision_m: 0.9391 - recall_m: 0.9059 - f1_m: 0.9216 - val_loss: 0.2150 - val_accuracy: 0.7255 - val_precision_m: 0.8862 - val_recall_m: 0.7939 - val_f1_m: 0.8361\n","Epoch 21/1000\n","131/131 [==============================] - 1s 10ms/step - loss: 0.1290 - accuracy: 0.6465 - precision_m: 0.9403 - recall_m: 0.9059 - f1_m: 0.9221 - val_loss: 0.2213 - val_accuracy: 0.7512 - val_precision_m: 0.8821 - val_recall_m: 0.7976 - val_f1_m: 0.8362\n","Epoch 22/1000\n","131/131 [==============================] - 1s 10ms/step - loss: 0.1252 - accuracy: 0.6424 - precision_m: 0.9397 - recall_m: 0.9094 - f1_m: 0.9238 - val_loss: 0.2268 - val_accuracy: 0.7378 - val_precision_m: 0.8673 - val_recall_m: 0.8061 - val_f1_m: 0.8341\n","Epoch 23/1000\n","131/131 [==============================] - 1s 10ms/step - loss: 0.1212 - accuracy: 0.6486 - precision_m: 0.9421 - recall_m: 0.9132 - f1_m: 0.9270 - val_loss: 0.2266 - val_accuracy: 0.7388 - val_precision_m: 0.8826 - val_recall_m: 0.7869 - val_f1_m: 0.8302\n","Epoch 24/1000\n","131/131 [==============================] - 1s 10ms/step - loss: 0.1218 - accuracy: 0.6462 - precision_m: 0.9428 - recall_m: 0.9119 - f1_m: 0.9265 - val_loss: 0.2203 - val_accuracy: 0.7378 - val_precision_m: 0.8874 - val_recall_m: 0.7885 - val_f1_m: 0.8334\n","Epoch 25/1000\n","131/131 [==============================] - 1s 10ms/step - loss: 0.1240 - accuracy: 0.6586 - precision_m: 0.9419 - recall_m: 0.9084 - f1_m: 0.9241 - val_loss: 0.2179 - val_accuracy: 0.7245 - val_precision_m: 0.8827 - val_recall_m: 0.8081 - val_f1_m: 0.8422\n","Epoch 26/1000\n","131/131 [==============================] - 1s 10ms/step - loss: 0.1237 - accuracy: 0.6453 - precision_m: 0.9426 - recall_m: 0.9084 - f1_m: 0.9247 - val_loss: 0.2218 - val_accuracy: 0.7340 - val_precision_m: 0.8712 - val_recall_m: 0.8191 - val_f1_m: 0.8427\n","Epoch 27/1000\n","131/131 [==============================] - 1s 10ms/step - loss: 0.1251 - accuracy: 0.6465 - precision_m: 0.9416 - recall_m: 0.9104 - f1_m: 0.9251 - val_loss: 0.2265 - val_accuracy: 0.7312 - val_precision_m: 0.8707 - val_recall_m: 0.8095 - val_f1_m: 0.8371\n","Epoch 28/1000\n","131/131 [==============================] - 1s 10ms/step - loss: 0.1230 - accuracy: 0.6567 - precision_m: 0.9445 - recall_m: 0.9094 - f1_m: 0.9260 - val_loss: 0.2215 - val_accuracy: 0.7312 - val_precision_m: 0.8784 - val_recall_m: 0.8058 - val_f1_m: 0.8388\n","Epoch 29/1000\n","131/131 [==============================] - 1s 10ms/step - loss: 0.1181 - accuracy: 0.6417 - precision_m: 0.9450 - recall_m: 0.9131 - f1_m: 0.9283 - val_loss: 0.2237 - val_accuracy: 0.7331 - val_precision_m: 0.8753 - val_recall_m: 0.8085 - val_f1_m: 0.8391\n","Epoch 30/1000\n","131/131 [==============================] - 1s 10ms/step - loss: 0.1183 - accuracy: 0.6462 - precision_m: 0.9439 - recall_m: 0.9144 - f1_m: 0.9283 - val_loss: 0.2228 - val_accuracy: 0.7283 - val_precision_m: 0.8771 - val_recall_m: 0.8017 - val_f1_m: 0.8360\n","Epoch 31/1000\n","131/131 [==============================] - 1s 10ms/step - loss: 0.1165 - accuracy: 0.6489 - precision_m: 0.9440 - recall_m: 0.9157 - f1_m: 0.9293 - val_loss: 0.2292 - val_accuracy: 0.7226 - val_precision_m: 0.8634 - val_recall_m: 0.8153 - val_f1_m: 0.8372\n","Epoch 32/1000\n","131/131 [==============================] - 1s 10ms/step - loss: 0.1158 - accuracy: 0.6479 - precision_m: 0.9459 - recall_m: 0.9153 - f1_m: 0.9298 - val_loss: 0.2279 - val_accuracy: 0.7378 - val_precision_m: 0.8841 - val_recall_m: 0.7920 - val_f1_m: 0.8340\n","Epoch 33/1000\n","131/131 [==============================] - 1s 10ms/step - loss: 0.1126 - accuracy: 0.6574 - precision_m: 0.9478 - recall_m: 0.9174 - f1_m: 0.9318 - val_loss: 0.2310 - val_accuracy: 0.7112 - val_precision_m: 0.8755 - val_recall_m: 0.7994 - val_f1_m: 0.8340\n","Epoch 34/1000\n","131/131 [==============================] - 1s 10ms/step - loss: 0.1127 - accuracy: 0.6515 - precision_m: 0.9487 - recall_m: 0.9172 - f1_m: 0.9323 - val_loss: 0.2301 - val_accuracy: 0.7426 - val_precision_m: 0.8789 - val_recall_m: 0.8042 - val_f1_m: 0.8382\n","Epoch 35/1000\n","131/131 [==============================] - 1s 10ms/step - loss: 0.1114 - accuracy: 0.6594 - precision_m: 0.9476 - recall_m: 0.9231 - f1_m: 0.9346 - val_loss: 0.2257 - val_accuracy: 0.7235 - val_precision_m: 0.8714 - val_recall_m: 0.8127 - val_f1_m: 0.8396\n","Epoch 36/1000\n","131/131 [==============================] - 1s 10ms/step - loss: 0.1118 - accuracy: 0.6491 - precision_m: 0.9471 - recall_m: 0.9220 - f1_m: 0.9339 - val_loss: 0.2254 - val_accuracy: 0.7178 - val_precision_m: 0.8781 - val_recall_m: 0.8094 - val_f1_m: 0.8410\n","Epoch 37/1000\n","131/131 [==============================] - 1s 10ms/step - loss: 0.1119 - accuracy: 0.6419 - precision_m: 0.9485 - recall_m: 0.9191 - f1_m: 0.9330 - val_loss: 0.2255 - val_accuracy: 0.7226 - val_precision_m: 0.8670 - val_recall_m: 0.8153 - val_f1_m: 0.8386\n","Epoch 38/1000\n","131/131 [==============================] - 1s 10ms/step - loss: 0.1092 - accuracy: 0.6489 - precision_m: 0.9511 - recall_m: 0.9215 - f1_m: 0.9356 - val_loss: 0.2311 - val_accuracy: 0.7207 - val_precision_m: 0.8737 - val_recall_m: 0.8023 - val_f1_m: 0.8351\n","Epoch 39/1000\n","131/131 [==============================] - 1s 10ms/step - loss: 0.1130 - accuracy: 0.6586 - precision_m: 0.9501 - recall_m: 0.9147 - f1_m: 0.9315 - val_loss: 0.2370 - val_accuracy: 0.7350 - val_precision_m: 0.8617 - val_recall_m: 0.8046 - val_f1_m: 0.8303\n","Epoch 40/1000\n","131/131 [==============================] - 1s 9ms/step - loss: 0.1059 - accuracy: 0.6524 - precision_m: 0.9515 - recall_m: 0.9250 - f1_m: 0.9375 - val_loss: 0.2351 - val_accuracy: 0.7255 - val_precision_m: 0.8795 - val_recall_m: 0.7969 - val_f1_m: 0.8346\n","Epoch 41/1000\n","131/131 [==============================] - 1s 10ms/step - loss: 0.1147 - accuracy: 0.6474 - precision_m: 0.9473 - recall_m: 0.9167 - f1_m: 0.9312 - val_loss: 0.2303 - val_accuracy: 0.7398 - val_precision_m: 0.8802 - val_recall_m: 0.8054 - val_f1_m: 0.8397\n","Epoch 42/1000\n","131/131 [==============================] - 1s 10ms/step - loss: 0.1111 - accuracy: 0.6536 - precision_m: 0.9477 - recall_m: 0.9190 - f1_m: 0.9326 - val_loss: 0.2331 - val_accuracy: 0.7483 - val_precision_m: 0.8642 - val_recall_m: 0.8086 - val_f1_m: 0.8338\n","Epoch 43/1000\n","131/131 [==============================] - 1s 10ms/step - loss: 0.1057 - accuracy: 0.6462 - precision_m: 0.9515 - recall_m: 0.9224 - f1_m: 0.9363 - val_loss: 0.2316 - val_accuracy: 0.7226 - val_precision_m: 0.8758 - val_recall_m: 0.7956 - val_f1_m: 0.8322\n","Epoch 44/1000\n","131/131 [==============================] - 1s 10ms/step - loss: 0.1039 - accuracy: 0.6522 - precision_m: 0.9548 - recall_m: 0.9254 - f1_m: 0.9394 - val_loss: 0.2370 - val_accuracy: 0.7293 - val_precision_m: 0.8727 - val_recall_m: 0.8029 - val_f1_m: 0.8347\n","Epoch 45/1000\n","131/131 [==============================] - 1s 9ms/step - loss: 0.1030 - accuracy: 0.6574 - precision_m: 0.9539 - recall_m: 0.9246 - f1_m: 0.9386 - val_loss: 0.2338 - val_accuracy: 0.7245 - val_precision_m: 0.8796 - val_recall_m: 0.7904 - val_f1_m: 0.8307\n","Epoch 46/1000\n","131/131 [==============================] - 1s 10ms/step - loss: 0.1088 - accuracy: 0.6558 - precision_m: 0.9511 - recall_m: 0.9199 - f1_m: 0.9349 - val_loss: 0.2332 - val_accuracy: 0.7417 - val_precision_m: 0.8778 - val_recall_m: 0.7946 - val_f1_m: 0.8329\n","Epoch 47/1000\n","131/131 [==============================] - 1s 10ms/step - loss: 0.1067 - accuracy: 0.6675 - precision_m: 0.9513 - recall_m: 0.9218 - f1_m: 0.9358 - val_loss: 0.2360 - val_accuracy: 0.7216 - val_precision_m: 0.8746 - val_recall_m: 0.7927 - val_f1_m: 0.8302\n","Epoch 48/1000\n","131/131 [==============================] - 1s 10ms/step - loss: 0.1024 - accuracy: 0.6710 - precision_m: 0.9548 - recall_m: 0.9280 - f1_m: 0.9407 - val_loss: 0.2327 - val_accuracy: 0.7207 - val_precision_m: 0.8702 - val_recall_m: 0.8032 - val_f1_m: 0.8338\n","Epoch 49/1000\n","131/131 [==============================] - 1s 10ms/step - loss: 0.1015 - accuracy: 0.6520 - precision_m: 0.9538 - recall_m: 0.9258 - f1_m: 0.9392 - val_loss: 0.2367 - val_accuracy: 0.7331 - val_precision_m: 0.8716 - val_recall_m: 0.8087 - val_f1_m: 0.8373\n","Epoch 50/1000\n","131/131 [==============================] - 1s 10ms/step - loss: 0.1060 - accuracy: 0.6601 - precision_m: 0.9479 - recall_m: 0.9251 - f1_m: 0.9359 - val_loss: 0.2351 - val_accuracy: 0.7369 - val_precision_m: 0.8749 - val_recall_m: 0.7945 - val_f1_m: 0.8310\n","Epoch 51/1000\n","131/131 [==============================] - 1s 10ms/step - loss: 0.1014 - accuracy: 0.6551 - precision_m: 0.9503 - recall_m: 0.9304 - f1_m: 0.9398 - val_loss: 0.2338 - val_accuracy: 0.7302 - val_precision_m: 0.8752 - val_recall_m: 0.7862 - val_f1_m: 0.8264\n","Epoch 52/1000\n","131/131 [==============================] - 1s 10ms/step - loss: 0.1018 - accuracy: 0.6551 - precision_m: 0.9547 - recall_m: 0.9266 - f1_m: 0.9400 - val_loss: 0.2410 - val_accuracy: 0.7302 - val_precision_m: 0.8617 - val_recall_m: 0.7980 - val_f1_m: 0.8266\n","Epoch 53/1000\n","131/131 [==============================] - 1s 10ms/step - loss: 0.0980 - accuracy: 0.6656 - precision_m: 0.9535 - recall_m: 0.9274 - f1_m: 0.9398 - val_loss: 0.2422 - val_accuracy: 0.7417 - val_precision_m: 0.8696 - val_recall_m: 0.7878 - val_f1_m: 0.8251\n","Epoch 54/1000\n","131/131 [==============================] - 1s 10ms/step - loss: 0.0997 - accuracy: 0.6484 - precision_m: 0.9516 - recall_m: 0.9278 - f1_m: 0.9392 - val_loss: 0.2391 - val_accuracy: 0.7359 - val_precision_m: 0.8678 - val_recall_m: 0.8044 - val_f1_m: 0.8334\n","Epoch 55/1000\n","131/131 [==============================] - 1s 10ms/step - loss: 0.0985 - accuracy: 0.6574 - precision_m: 0.9518 - recall_m: 0.9276 - f1_m: 0.9391 - val_loss: 0.2447 - val_accuracy: 0.7331 - val_precision_m: 0.8653 - val_recall_m: 0.7917 - val_f1_m: 0.8251\n","Epoch 56/1000\n","131/131 [==============================] - 1s 10ms/step - loss: 0.1013 - accuracy: 0.6627 - precision_m: 0.9575 - recall_m: 0.9267 - f1_m: 0.9413 - val_loss: 0.2463 - val_accuracy: 0.7426 - val_precision_m: 0.8725 - val_recall_m: 0.7917 - val_f1_m: 0.8285\n","Epoch 57/1000\n","131/131 [==============================] - 1s 10ms/step - loss: 0.0960 - accuracy: 0.6672 - precision_m: 0.9542 - recall_m: 0.9317 - f1_m: 0.9424 - val_loss: 0.2390 - val_accuracy: 0.7264 - val_precision_m: 0.8692 - val_recall_m: 0.8065 - val_f1_m: 0.8350\n","Epoch 58/1000\n","131/131 [==============================] - 1s 10ms/step - loss: 0.0984 - accuracy: 0.6598 - precision_m: 0.9550 - recall_m: 0.9272 - f1_m: 0.9405 - val_loss: 0.2449 - val_accuracy: 0.7398 - val_precision_m: 0.8726 - val_recall_m: 0.8051 - val_f1_m: 0.8359\n","Epoch 59/1000\n","131/131 [==============================] - 1s 10ms/step - loss: 0.0965 - accuracy: 0.6546 - precision_m: 0.9557 - recall_m: 0.9317 - f1_m: 0.9431 - val_loss: 0.2465 - val_accuracy: 0.7407 - val_precision_m: 0.8709 - val_recall_m: 0.8037 - val_f1_m: 0.8340\n","Epoch 60/1000\n","131/131 [==============================] - 1s 10ms/step - loss: 0.0955 - accuracy: 0.6601 - precision_m: 0.9585 - recall_m: 0.9308 - f1_m: 0.9441 - val_loss: 0.2453 - val_accuracy: 0.7312 - val_precision_m: 0.8633 - val_recall_m: 0.8072 - val_f1_m: 0.8321\n","Epoch 61/1000\n","131/131 [==============================] - 1s 10ms/step - loss: 0.0977 - accuracy: 0.6603 - precision_m: 0.9553 - recall_m: 0.9308 - f1_m: 0.9424 - val_loss: 0.2431 - val_accuracy: 0.7140 - val_precision_m: 0.8694 - val_recall_m: 0.8030 - val_f1_m: 0.8334\n","Epoch 62/1000\n","131/131 [==============================] - 1s 10ms/step - loss: 0.0971 - accuracy: 0.6560 - precision_m: 0.9545 - recall_m: 0.9315 - f1_m: 0.9425 - val_loss: 0.2421 - val_accuracy: 0.7264 - val_precision_m: 0.8784 - val_recall_m: 0.7926 - val_f1_m: 0.8316\n","Epoch 63/1000\n","131/131 [==============================] - 1s 10ms/step - loss: 0.0958 - accuracy: 0.6577 - precision_m: 0.9545 - recall_m: 0.9334 - f1_m: 0.9434 - val_loss: 0.2463 - val_accuracy: 0.7131 - val_precision_m: 0.8678 - val_recall_m: 0.7939 - val_f1_m: 0.8277\n","Epoch 64/1000\n","131/131 [==============================] - 1s 10ms/step - loss: 0.0924 - accuracy: 0.6625 - precision_m: 0.9573 - recall_m: 0.9343 - f1_m: 0.9452 - val_loss: 0.2385 - val_accuracy: 0.7350 - val_precision_m: 0.8702 - val_recall_m: 0.8089 - val_f1_m: 0.8369\n","Epoch 65/1000\n","131/131 [==============================] - 1s 10ms/step - loss: 0.0943 - accuracy: 0.6515 - precision_m: 0.9576 - recall_m: 0.9333 - f1_m: 0.9449 - val_loss: 0.2468 - val_accuracy: 0.7350 - val_precision_m: 0.8706 - val_recall_m: 0.7970 - val_f1_m: 0.8308\n","Epoch 66/1000\n","131/131 [==============================] - 1s 10ms/step - loss: 0.0958 - accuracy: 0.6574 - precision_m: 0.9577 - recall_m: 0.9337 - f1_m: 0.9451 - val_loss: 0.2480 - val_accuracy: 0.7235 - val_precision_m: 0.8737 - val_recall_m: 0.7851 - val_f1_m: 0.8256\n","Epoch 67/1000\n","131/131 [==============================] - 1s 10ms/step - loss: 0.0956 - accuracy: 0.6441 - precision_m: 0.9576 - recall_m: 0.9325 - f1_m: 0.9445 - val_loss: 0.2448 - val_accuracy: 0.7293 - val_precision_m: 0.8706 - val_recall_m: 0.8000 - val_f1_m: 0.8323\n","Epoch 68/1000\n","131/131 [==============================] - 1s 10ms/step - loss: 0.0957 - accuracy: 0.6570 - precision_m: 0.9545 - recall_m: 0.9336 - f1_m: 0.9436 - val_loss: 0.2471 - val_accuracy: 0.7264 - val_precision_m: 0.8710 - val_recall_m: 0.8043 - val_f1_m: 0.8344\n","Epoch 69/1000\n","131/131 [==============================] - 1s 10ms/step - loss: 0.0893 - accuracy: 0.6572 - precision_m: 0.9624 - recall_m: 0.9380 - f1_m: 0.9496 - val_loss: 0.2469 - val_accuracy: 0.7264 - val_precision_m: 0.8754 - val_recall_m: 0.7977 - val_f1_m: 0.8331\n","Epoch 00069: early stopping\n","Score for fold 3: loss of 0.20610575377941132; accuracy of 71.67938947677612% ;precision_m of 0.8995307087898254 ;recall_m of 0.8009628653526306 ;            f1_m of 0.8459016680717468\n","------------------------------------------------------------------------\n","Score per fold\n","------------------------------------------------------------------------\n","> Fold 1 - Loss: 0.5939943790435791 - Accuracy: 51.39259696006775% - Precision: 0.844610333442688 - Recall: 0.6961743831634521 - F1: 0.76019287109375\n","------------------------------------------------------------------------\n","> Fold 2 - Loss: 0.2465963512659073 - Accuracy: 69.7328269481659% - Precision: 0.8589565753936768 - Recall: 0.8325409293174744 - F1: 0.8441144227981567\n","------------------------------------------------------------------------\n","> Fold 3 - Loss: 0.20610575377941132 - Accuracy: 71.67938947677612% - Precision: 0.8995307087898254 - Recall: 0.8009628653526306 - F1: 0.8459016680717468\n","------------------------------------------------------------------------\n","Average scores for all folds:\n","> Accuracy: 64.2682711283366 (+- 9.139092419747032)\n","> Precision: 0.8676992058753967\n","> Recall: 0.7765593926111857\n","> F1: 0.8167363206545512\n","> Loss: 0.34889882802963257\n","------------------------------------------------------------------------\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"Uh4Hxe4u67r2"},"source":["# CNN with Cross Validation \r\n","CBOW with size 300\r\n"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"5ou0Ml-57m4_","executionInfo":{"elapsed":255042,"status":"ok","timestamp":1614101269646,"user":{"displayName":"Shanaka Chathuranga","photoUrl":"","userId":"01381725564551416324"},"user_tz":-330},"outputId":"e5241604-5cae-486a-faa9-99629884bc8b"},"source":["N_FOLDS=3 \r\n","EPOCHS=1000\r\n","VALIDATION_SPLIT=0.2\r\n","BATCH_SIZE=32\r\n","PATIENCE=50\r\n","MONITOR='val_f1_m'\r\n","MONITOR_MODE='max'\r\n","shuffle=True\r\n","DROPOUT_VALUE_2=0.5\r\n","EMBEDDING_SIZE=300\r\n","\r\n","def create_model():\r\n","    model = Sequential()\r\n","    embedding_layer = Embedding(vocab_length, 300,weights=[embedding_matrix],input_length=length_long_sentence, trainable=False)\r\n","    model.add(embedding_layer)\r\n","    model.add(Conv1D(256,3, activation='relu'))\r\n","    model.add(GlobalMaxPooling1D())\r\n","    model.add(Dropout(DROPOUT_VALUE_2))\r\n","    model.add(Flatten())\r\n","    model.add(Dense(6, activation='sigmoid'))\r\n","    model.compile(loss='binary_crossentropy', optimizer='adam',metrics=[\"accuracy\",precision_m,recall_m,f1_m])\r\n","    return model \r\n","\r\n","# Define per-fold score containers <-- these are new\r\n","acc_per_fold = []\r\n","loss_per_fold = []\r\n","f1_per_fold = []\r\n","precision_per_fold =[]\r\n","recall_per_fold=[]\r\n","\r\n","#Define dependencied for model loading\r\n","dependencies = {\r\n","    'recall_m': recall_m,\r\n","    'f1_m':f1_m,\r\n","    'precision_m':precision_m    \r\n","}\r\n","\r\n","vocab_length,padded_sentences,length_long_sentence,embedding_matrix=loadembedding_matrix(x,mainloc+'word_embeddings/w2v_cbow_300.txt',300)\r\n","\r\n","kf = KFold(n_splits=N_FOLDS)\r\n","fold_no = 1\r\n","for train_index, test_index in kf.split(padded_sentences, y):\r\n","    model=create_model()\r\n","    es = EarlyStopping(monitor=MONITOR, mode=MONITOR_MODE, verbose=1,patience= PATIENCE )\r\n","    history = model.fit(padded_sentences[train_index],y.values[train_index],epochs=EPOCHS,callbacks=[es],batch_size=BATCH_SIZE,shuffle=True,validation_split=VALIDATION_SPLIT)\r\n","    \r\n","    # Generate generalization metrics\r\n","    scores = model.evaluate(padded_sentences[test_index], y.values[test_index], verbose=0)\r\n","    print(f'Score for fold {fold_no}: {model.metrics_names[0]} of {scores[0]}; {model.metrics_names[1]} of {scores[1]*100}% ;{model.metrics_names[2]} of {scores[2]} ;{model.metrics_names[3]} of {scores[3]} ; \\\r\n","           {model.metrics_names[4]} of {scores[4]}')\r\n","    loss_per_fold.append(scores[0])\r\n","    acc_per_fold.append(scores[1] * 100)\r\n","    precision_per_fold.append(scores[2])\r\n","    recall_per_fold.append(scores[3])\r\n","    f1_per_fold.append(scores[4])\r\n","\r\n","    # Increase fold number\r\n","    fold_no = fold_no + 1\r\n","    \r\n","accuracy_crossval(acc_per_fold,loss_per_fold,f1_per_fold,precision_per_fold,recall_per_fold)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Epoch 1/1000\n","131/131 [==============================] - 2s 11ms/step - loss: 0.5054 - accuracy: 0.3807 - precision_m: 0.6205 - recall_m: 0.3581 - f1_m: 0.4402 - val_loss: 0.3035 - val_accuracy: 0.6336 - val_precision_m: 0.7783 - val_recall_m: 0.7386 - val_f1_m: 0.7562\n","Epoch 2/1000\n","131/131 [==============================] - 1s 8ms/step - loss: 0.3352 - accuracy: 0.5917 - precision_m: 0.7821 - recall_m: 0.6625 - f1_m: 0.7150 - val_loss: 0.2695 - val_accuracy: 0.6374 - val_precision_m: 0.8284 - val_recall_m: 0.7223 - val_f1_m: 0.7700\n","Epoch 3/1000\n","131/131 [==============================] - 1s 8ms/step - loss: 0.3070 - accuracy: 0.5967 - precision_m: 0.8091 - recall_m: 0.6983 - f1_m: 0.7477 - val_loss: 0.2640 - val_accuracy: 0.6622 - val_precision_m: 0.8265 - val_recall_m: 0.7483 - val_f1_m: 0.7836\n","Epoch 4/1000\n","131/131 [==============================] - 1s 8ms/step - loss: 0.2863 - accuracy: 0.6358 - precision_m: 0.8236 - recall_m: 0.7348 - f1_m: 0.7754 - val_loss: 0.2455 - val_accuracy: 0.6555 - val_precision_m: 0.8481 - val_recall_m: 0.7523 - val_f1_m: 0.7962\n","Epoch 5/1000\n","131/131 [==============================] - 1s 8ms/step - loss: 0.2762 - accuracy: 0.6392 - precision_m: 0.8241 - recall_m: 0.7399 - f1_m: 0.7784 - val_loss: 0.2495 - val_accuracy: 0.6765 - val_precision_m: 0.8445 - val_recall_m: 0.7422 - val_f1_m: 0.7882\n","Epoch 6/1000\n","131/131 [==============================] - 1s 8ms/step - loss: 0.2636 - accuracy: 0.6411 - precision_m: 0.8396 - recall_m: 0.7490 - f1_m: 0.7901 - val_loss: 0.2426 - val_accuracy: 0.6613 - val_precision_m: 0.8358 - val_recall_m: 0.7669 - val_f1_m: 0.7987\n","Epoch 7/1000\n","131/131 [==============================] - 1s 8ms/step - loss: 0.2590 - accuracy: 0.6530 - precision_m: 0.8421 - recall_m: 0.7528 - f1_m: 0.7936 - val_loss: 0.2370 - val_accuracy: 0.6603 - val_precision_m: 0.8281 - val_recall_m: 0.7904 - val_f1_m: 0.8081\n","Epoch 8/1000\n","131/131 [==============================] - 1s 8ms/step - loss: 0.2597 - accuracy: 0.6394 - precision_m: 0.8425 - recall_m: 0.7600 - f1_m: 0.7977 - val_loss: 0.2432 - val_accuracy: 0.6746 - val_precision_m: 0.8413 - val_recall_m: 0.7789 - val_f1_m: 0.8074\n","Epoch 9/1000\n","131/131 [==============================] - 1s 8ms/step - loss: 0.2507 - accuracy: 0.6476 - precision_m: 0.8442 - recall_m: 0.7771 - f1_m: 0.8082 - val_loss: 0.2355 - val_accuracy: 0.6546 - val_precision_m: 0.8307 - val_recall_m: 0.7948 - val_f1_m: 0.8116\n","Epoch 10/1000\n","131/131 [==============================] - 1s 8ms/step - loss: 0.2381 - accuracy: 0.6573 - precision_m: 0.8587 - recall_m: 0.7807 - f1_m: 0.8170 - val_loss: 0.2352 - val_accuracy: 0.6660 - val_precision_m: 0.8300 - val_recall_m: 0.7945 - val_f1_m: 0.8111\n","Epoch 11/1000\n","131/131 [==============================] - 1s 8ms/step - loss: 0.2364 - accuracy: 0.6542 - precision_m: 0.8519 - recall_m: 0.7786 - f1_m: 0.8124 - val_loss: 0.2361 - val_accuracy: 0.6641 - val_precision_m: 0.8419 - val_recall_m: 0.7737 - val_f1_m: 0.8054\n","Epoch 12/1000\n","131/131 [==============================] - 1s 8ms/step - loss: 0.2274 - accuracy: 0.6608 - precision_m: 0.8676 - recall_m: 0.7929 - f1_m: 0.8272 - val_loss: 0.2423 - val_accuracy: 0.6985 - val_precision_m: 0.8428 - val_recall_m: 0.7732 - val_f1_m: 0.8056\n","Epoch 13/1000\n","131/131 [==============================] - 1s 8ms/step - loss: 0.2278 - accuracy: 0.6689 - precision_m: 0.8586 - recall_m: 0.7869 - f1_m: 0.8196 - val_loss: 0.2435 - val_accuracy: 0.6737 - val_precision_m: 0.8201 - val_recall_m: 0.8025 - val_f1_m: 0.8098\n","Epoch 14/1000\n","131/131 [==============================] - 1s 8ms/step - loss: 0.2132 - accuracy: 0.6809 - precision_m: 0.8755 - recall_m: 0.8154 - f1_m: 0.8434 - val_loss: 0.2428 - val_accuracy: 0.6918 - val_precision_m: 0.8334 - val_recall_m: 0.7845 - val_f1_m: 0.8071\n","Epoch 15/1000\n","131/131 [==============================] - 1s 8ms/step - loss: 0.2144 - accuracy: 0.6716 - precision_m: 0.8701 - recall_m: 0.8095 - f1_m: 0.8378 - val_loss: 0.2379 - val_accuracy: 0.6899 - val_precision_m: 0.8361 - val_recall_m: 0.7678 - val_f1_m: 0.7995\n","Epoch 16/1000\n","131/131 [==============================] - 1s 8ms/step - loss: 0.2092 - accuracy: 0.6818 - precision_m: 0.8761 - recall_m: 0.8131 - f1_m: 0.8423 - val_loss: 0.2391 - val_accuracy: 0.6698 - val_precision_m: 0.8394 - val_recall_m: 0.7742 - val_f1_m: 0.8047\n","Epoch 17/1000\n","131/131 [==============================] - 1s 8ms/step - loss: 0.2041 - accuracy: 0.6784 - precision_m: 0.8803 - recall_m: 0.8144 - f1_m: 0.8450 - val_loss: 0.2362 - val_accuracy: 0.6708 - val_precision_m: 0.8304 - val_recall_m: 0.7871 - val_f1_m: 0.8071\n","Epoch 18/1000\n","131/131 [==============================] - 1s 8ms/step - loss: 0.2003 - accuracy: 0.6723 - precision_m: 0.8805 - recall_m: 0.8189 - f1_m: 0.8473 - val_loss: 0.2409 - val_accuracy: 0.6546 - val_precision_m: 0.8313 - val_recall_m: 0.7765 - val_f1_m: 0.8017\n","Epoch 19/1000\n","131/131 [==============================] - 1s 9ms/step - loss: 0.1940 - accuracy: 0.6827 - precision_m: 0.8871 - recall_m: 0.8276 - f1_m: 0.8550 - val_loss: 0.2378 - val_accuracy: 0.6784 - val_precision_m: 0.8369 - val_recall_m: 0.7947 - val_f1_m: 0.8140\n","Epoch 20/1000\n","131/131 [==============================] - 1s 8ms/step - loss: 0.1915 - accuracy: 0.6778 - precision_m: 0.8893 - recall_m: 0.8372 - f1_m: 0.8614 - val_loss: 0.2438 - val_accuracy: 0.6651 - val_precision_m: 0.8218 - val_recall_m: 0.8010 - val_f1_m: 0.8102\n","Epoch 21/1000\n","131/131 [==============================] - 1s 8ms/step - loss: 0.1898 - accuracy: 0.6944 - precision_m: 0.8861 - recall_m: 0.8345 - f1_m: 0.8583 - val_loss: 0.2417 - val_accuracy: 0.6775 - val_precision_m: 0.8390 - val_recall_m: 0.7796 - val_f1_m: 0.8069\n","Epoch 22/1000\n","131/131 [==============================] - 1s 8ms/step - loss: 0.1927 - accuracy: 0.6809 - precision_m: 0.8918 - recall_m: 0.8355 - f1_m: 0.8620 - val_loss: 0.2405 - val_accuracy: 0.6727 - val_precision_m: 0.8286 - val_recall_m: 0.7840 - val_f1_m: 0.8046\n","Epoch 23/1000\n","131/131 [==============================] - 1s 8ms/step - loss: 0.1815 - accuracy: 0.6963 - precision_m: 0.8935 - recall_m: 0.8418 - f1_m: 0.8659 - val_loss: 0.2382 - val_accuracy: 0.6832 - val_precision_m: 0.8346 - val_recall_m: 0.7955 - val_f1_m: 0.8132\n","Epoch 24/1000\n","131/131 [==============================] - 1s 8ms/step - loss: 0.1733 - accuracy: 0.6929 - precision_m: 0.8988 - recall_m: 0.8475 - f1_m: 0.8710 - val_loss: 0.2473 - val_accuracy: 0.6966 - val_precision_m: 0.8220 - val_recall_m: 0.8103 - val_f1_m: 0.8148\n","Epoch 25/1000\n","131/131 [==============================] - 1s 8ms/step - loss: 0.1780 - accuracy: 0.6866 - precision_m: 0.8949 - recall_m: 0.8453 - f1_m: 0.8684 - val_loss: 0.2467 - val_accuracy: 0.6842 - val_precision_m: 0.8278 - val_recall_m: 0.8022 - val_f1_m: 0.8134\n","Epoch 26/1000\n","131/131 [==============================] - 1s 8ms/step - loss: 0.1683 - accuracy: 0.6964 - precision_m: 0.8959 - recall_m: 0.8519 - f1_m: 0.8723 - val_loss: 0.2405 - val_accuracy: 0.6794 - val_precision_m: 0.8435 - val_recall_m: 0.7879 - val_f1_m: 0.8135\n","Epoch 27/1000\n","131/131 [==============================] - 1s 9ms/step - loss: 0.1602 - accuracy: 0.7079 - precision_m: 0.9098 - recall_m: 0.8618 - f1_m: 0.8841 - val_loss: 0.2433 - val_accuracy: 0.6679 - val_precision_m: 0.8259 - val_recall_m: 0.7944 - val_f1_m: 0.8085\n","Epoch 28/1000\n","131/131 [==============================] - 1s 8ms/step - loss: 0.1690 - accuracy: 0.6969 - precision_m: 0.8951 - recall_m: 0.8491 - f1_m: 0.8706 - val_loss: 0.2443 - val_accuracy: 0.6870 - val_precision_m: 0.8251 - val_recall_m: 0.7968 - val_f1_m: 0.8094\n","Epoch 29/1000\n","131/131 [==============================] - 1s 8ms/step - loss: 0.1605 - accuracy: 0.7138 - precision_m: 0.9024 - recall_m: 0.8586 - f1_m: 0.8789 - val_loss: 0.2543 - val_accuracy: 0.6660 - val_precision_m: 0.8281 - val_recall_m: 0.7773 - val_f1_m: 0.8005\n","Epoch 30/1000\n","131/131 [==============================] - 1s 8ms/step - loss: 0.1546 - accuracy: 0.7044 - precision_m: 0.9126 - recall_m: 0.8644 - f1_m: 0.8873 - val_loss: 0.2516 - val_accuracy: 0.6746 - val_precision_m: 0.8361 - val_recall_m: 0.7722 - val_f1_m: 0.8017\n","Epoch 31/1000\n","131/131 [==============================] - 1s 8ms/step - loss: 0.1644 - accuracy: 0.6982 - precision_m: 0.9048 - recall_m: 0.8559 - f1_m: 0.8788 - val_loss: 0.2477 - val_accuracy: 0.6794 - val_precision_m: 0.8265 - val_recall_m: 0.7910 - val_f1_m: 0.8070\n","Epoch 32/1000\n","131/131 [==============================] - 1s 8ms/step - loss: 0.1508 - accuracy: 0.7017 - precision_m: 0.9178 - recall_m: 0.8744 - f1_m: 0.8947 - val_loss: 0.2513 - val_accuracy: 0.6784 - val_precision_m: 0.8229 - val_recall_m: 0.7997 - val_f1_m: 0.8098\n","Epoch 33/1000\n","131/131 [==============================] - 1s 8ms/step - loss: 0.1462 - accuracy: 0.7084 - precision_m: 0.9177 - recall_m: 0.8726 - f1_m: 0.8934 - val_loss: 0.2551 - val_accuracy: 0.6594 - val_precision_m: 0.8165 - val_recall_m: 0.7993 - val_f1_m: 0.8065\n","Epoch 34/1000\n","131/131 [==============================] - 1s 8ms/step - loss: 0.1517 - accuracy: 0.6982 - precision_m: 0.9137 - recall_m: 0.8727 - f1_m: 0.8920 - val_loss: 0.2528 - val_accuracy: 0.6842 - val_precision_m: 0.8381 - val_recall_m: 0.7816 - val_f1_m: 0.8076\n","Epoch 35/1000\n","131/131 [==============================] - 1s 8ms/step - loss: 0.1542 - accuracy: 0.7053 - precision_m: 0.9116 - recall_m: 0.8662 - f1_m: 0.8878 - val_loss: 0.2511 - val_accuracy: 0.6813 - val_precision_m: 0.8371 - val_recall_m: 0.7835 - val_f1_m: 0.8078\n","Epoch 36/1000\n","131/131 [==============================] - 1s 8ms/step - loss: 0.1356 - accuracy: 0.7095 - precision_m: 0.9230 - recall_m: 0.8859 - f1_m: 0.9033 - val_loss: 0.2504 - val_accuracy: 0.6918 - val_precision_m: 0.8305 - val_recall_m: 0.7885 - val_f1_m: 0.8077\n","Epoch 37/1000\n","131/131 [==============================] - 1s 8ms/step - loss: 0.1368 - accuracy: 0.7229 - precision_m: 0.9211 - recall_m: 0.8877 - f1_m: 0.9034 - val_loss: 0.2573 - val_accuracy: 0.6851 - val_precision_m: 0.8224 - val_recall_m: 0.7924 - val_f1_m: 0.8058\n","Epoch 38/1000\n","131/131 [==============================] - 1s 8ms/step - loss: 0.1356 - accuracy: 0.7200 - precision_m: 0.9234 - recall_m: 0.8899 - f1_m: 0.9053 - val_loss: 0.2509 - val_accuracy: 0.6784 - val_precision_m: 0.8398 - val_recall_m: 0.7729 - val_f1_m: 0.8036\n","Epoch 39/1000\n","131/131 [==============================] - 1s 8ms/step - loss: 0.1387 - accuracy: 0.7056 - precision_m: 0.9201 - recall_m: 0.8832 - f1_m: 0.9005 - val_loss: 0.2532 - val_accuracy: 0.6737 - val_precision_m: 0.8286 - val_recall_m: 0.7917 - val_f1_m: 0.8087\n","Epoch 40/1000\n","131/131 [==============================] - 1s 8ms/step - loss: 0.1321 - accuracy: 0.7282 - precision_m: 0.9194 - recall_m: 0.8917 - f1_m: 0.9044 - val_loss: 0.2591 - val_accuracy: 0.6689 - val_precision_m: 0.8246 - val_recall_m: 0.7857 - val_f1_m: 0.8034\n","Epoch 41/1000\n","131/131 [==============================] - 1s 8ms/step - loss: 0.1265 - accuracy: 0.7123 - precision_m: 0.9367 - recall_m: 0.8976 - f1_m: 0.9159 - val_loss: 0.2602 - val_accuracy: 0.6832 - val_precision_m: 0.8226 - val_recall_m: 0.8003 - val_f1_m: 0.8098\n","Epoch 42/1000\n","131/131 [==============================] - 1s 8ms/step - loss: 0.1325 - accuracy: 0.7130 - precision_m: 0.9232 - recall_m: 0.8931 - f1_m: 0.9072 - val_loss: 0.2578 - val_accuracy: 0.6880 - val_precision_m: 0.8168 - val_recall_m: 0.8038 - val_f1_m: 0.8089\n","Epoch 43/1000\n","131/131 [==============================] - 1s 8ms/step - loss: 0.1300 - accuracy: 0.7179 - precision_m: 0.9297 - recall_m: 0.8930 - f1_m: 0.9102 - val_loss: 0.2607 - val_accuracy: 0.6718 - val_precision_m: 0.8450 - val_recall_m: 0.7664 - val_f1_m: 0.8023\n","Epoch 44/1000\n","131/131 [==============================] - 1s 8ms/step - loss: 0.1336 - accuracy: 0.7177 - precision_m: 0.9298 - recall_m: 0.8831 - f1_m: 0.9050 - val_loss: 0.2646 - val_accuracy: 0.6842 - val_precision_m: 0.8205 - val_recall_m: 0.8007 - val_f1_m: 0.8091\n","Epoch 45/1000\n","131/131 [==============================] - 1s 8ms/step - loss: 0.1210 - accuracy: 0.7233 - precision_m: 0.9346 - recall_m: 0.9032 - f1_m: 0.9178 - val_loss: 0.2697 - val_accuracy: 0.6698 - val_precision_m: 0.8302 - val_recall_m: 0.7670 - val_f1_m: 0.7961\n","Epoch 46/1000\n","131/131 [==============================] - 1s 8ms/step - loss: 0.1222 - accuracy: 0.7207 - precision_m: 0.9324 - recall_m: 0.8973 - f1_m: 0.9138 - val_loss: 0.2686 - val_accuracy: 0.6765 - val_precision_m: 0.8281 - val_recall_m: 0.7737 - val_f1_m: 0.7985\n","Epoch 47/1000\n","131/131 [==============================] - 1s 9ms/step - loss: 0.1194 - accuracy: 0.7216 - precision_m: 0.9325 - recall_m: 0.9026 - f1_m: 0.9167 - val_loss: 0.2713 - val_accuracy: 0.6756 - val_precision_m: 0.8228 - val_recall_m: 0.7792 - val_f1_m: 0.7990\n","Epoch 48/1000\n","131/131 [==============================] - 1s 8ms/step - loss: 0.1155 - accuracy: 0.7203 - precision_m: 0.9369 - recall_m: 0.9047 - f1_m: 0.9200 - val_loss: 0.2728 - val_accuracy: 0.6689 - val_precision_m: 0.8191 - val_recall_m: 0.7978 - val_f1_m: 0.8071\n","Epoch 49/1000\n","131/131 [==============================] - 1s 8ms/step - loss: 0.1240 - accuracy: 0.7201 - precision_m: 0.9335 - recall_m: 0.8958 - f1_m: 0.9136 - val_loss: 0.2685 - val_accuracy: 0.6775 - val_precision_m: 0.8293 - val_recall_m: 0.7874 - val_f1_m: 0.8063\n","Epoch 50/1000\n","131/131 [==============================] - 1s 8ms/step - loss: 0.1188 - accuracy: 0.7211 - precision_m: 0.9329 - recall_m: 0.8959 - f1_m: 0.9133 - val_loss: 0.2704 - val_accuracy: 0.6679 - val_precision_m: 0.8226 - val_recall_m: 0.7860 - val_f1_m: 0.8028\n","Epoch 51/1000\n","131/131 [==============================] - 1s 8ms/step - loss: 0.1154 - accuracy: 0.7214 - precision_m: 0.9353 - recall_m: 0.9052 - f1_m: 0.9194 - val_loss: 0.2744 - val_accuracy: 0.6679 - val_precision_m: 0.8195 - val_recall_m: 0.7876 - val_f1_m: 0.8020\n","Epoch 52/1000\n","131/131 [==============================] - 1s 8ms/step - loss: 0.1098 - accuracy: 0.7247 - precision_m: 0.9371 - recall_m: 0.9058 - f1_m: 0.9205 - val_loss: 0.2732 - val_accuracy: 0.6794 - val_precision_m: 0.8272 - val_recall_m: 0.7831 - val_f1_m: 0.8027\n","Epoch 53/1000\n","131/131 [==============================] - 1s 8ms/step - loss: 0.1202 - accuracy: 0.7194 - precision_m: 0.9350 - recall_m: 0.8935 - f1_m: 0.9131 - val_loss: 0.2837 - val_accuracy: 0.6784 - val_precision_m: 0.8071 - val_recall_m: 0.8130 - val_f1_m: 0.8087\n","Epoch 54/1000\n","131/131 [==============================] - 1s 8ms/step - loss: 0.1164 - accuracy: 0.7091 - precision_m: 0.9341 - recall_m: 0.9083 - f1_m: 0.9202 - val_loss: 0.2766 - val_accuracy: 0.6622 - val_precision_m: 0.8102 - val_recall_m: 0.8050 - val_f1_m: 0.8063\n","Epoch 55/1000\n","131/131 [==============================] - 1s 8ms/step - loss: 0.1087 - accuracy: 0.7189 - precision_m: 0.9386 - recall_m: 0.9150 - f1_m: 0.9259 - val_loss: 0.2792 - val_accuracy: 0.6479 - val_precision_m: 0.8177 - val_recall_m: 0.7825 - val_f1_m: 0.7985\n","Epoch 56/1000\n","131/131 [==============================] - 1s 8ms/step - loss: 0.1075 - accuracy: 0.7151 - precision_m: 0.9345 - recall_m: 0.9124 - f1_m: 0.9225 - val_loss: 0.2739 - val_accuracy: 0.6889 - val_precision_m: 0.8231 - val_recall_m: 0.7933 - val_f1_m: 0.8066\n","Epoch 57/1000\n","131/131 [==============================] - 1s 8ms/step - loss: 0.1047 - accuracy: 0.7388 - precision_m: 0.9458 - recall_m: 0.9184 - f1_m: 0.9313 - val_loss: 0.2713 - val_accuracy: 0.6823 - val_precision_m: 0.8266 - val_recall_m: 0.7921 - val_f1_m: 0.8073\n","Epoch 58/1000\n","131/131 [==============================] - 1s 8ms/step - loss: 0.1057 - accuracy: 0.7107 - precision_m: 0.9403 - recall_m: 0.9172 - f1_m: 0.9280 - val_loss: 0.2850 - val_accuracy: 0.6784 - val_precision_m: 0.8201 - val_recall_m: 0.7845 - val_f1_m: 0.8003\n","Epoch 59/1000\n","131/131 [==============================] - 1s 8ms/step - loss: 0.1049 - accuracy: 0.7195 - precision_m: 0.9418 - recall_m: 0.9093 - f1_m: 0.9247 - val_loss: 0.2862 - val_accuracy: 0.6803 - val_precision_m: 0.8142 - val_recall_m: 0.7818 - val_f1_m: 0.7964\n","Epoch 60/1000\n","131/131 [==============================] - 1s 8ms/step - loss: 0.1016 - accuracy: 0.7217 - precision_m: 0.9436 - recall_m: 0.9192 - f1_m: 0.9307 - val_loss: 0.2857 - val_accuracy: 0.6632 - val_precision_m: 0.8182 - val_recall_m: 0.7876 - val_f1_m: 0.8012\n","Epoch 61/1000\n","131/131 [==============================] - 1s 8ms/step - loss: 0.1033 - accuracy: 0.7173 - precision_m: 0.9443 - recall_m: 0.9151 - f1_m: 0.9290 - val_loss: 0.2841 - val_accuracy: 0.6794 - val_precision_m: 0.8161 - val_recall_m: 0.7803 - val_f1_m: 0.7963\n","Epoch 62/1000\n","131/131 [==============================] - 1s 8ms/step - loss: 0.1025 - accuracy: 0.7242 - precision_m: 0.9428 - recall_m: 0.9175 - f1_m: 0.9293 - val_loss: 0.2808 - val_accuracy: 0.6870 - val_precision_m: 0.8202 - val_recall_m: 0.7881 - val_f1_m: 0.8026\n","Epoch 63/1000\n","131/131 [==============================] - 1s 8ms/step - loss: 0.0964 - accuracy: 0.7323 - precision_m: 0.9434 - recall_m: 0.9243 - f1_m: 0.9331 - val_loss: 0.2865 - val_accuracy: 0.6851 - val_precision_m: 0.8110 - val_recall_m: 0.7902 - val_f1_m: 0.7990\n","Epoch 64/1000\n","131/131 [==============================] - 1s 8ms/step - loss: 0.0965 - accuracy: 0.7382 - precision_m: 0.9431 - recall_m: 0.9177 - f1_m: 0.9295 - val_loss: 0.2856 - val_accuracy: 0.6975 - val_precision_m: 0.8189 - val_recall_m: 0.7707 - val_f1_m: 0.7927\n","Epoch 65/1000\n","131/131 [==============================] - 1s 8ms/step - loss: 0.0990 - accuracy: 0.7250 - precision_m: 0.9487 - recall_m: 0.9226 - f1_m: 0.9350 - val_loss: 0.2879 - val_accuracy: 0.6670 - val_precision_m: 0.8181 - val_recall_m: 0.7914 - val_f1_m: 0.8029\n","Epoch 66/1000\n","131/131 [==============================] - 1s 8ms/step - loss: 0.0978 - accuracy: 0.7379 - precision_m: 0.9445 - recall_m: 0.9170 - f1_m: 0.9299 - val_loss: 0.2885 - val_accuracy: 0.6832 - val_precision_m: 0.8156 - val_recall_m: 0.7828 - val_f1_m: 0.7974\n","Epoch 67/1000\n","131/131 [==============================] - 1s 8ms/step - loss: 0.0976 - accuracy: 0.7347 - precision_m: 0.9443 - recall_m: 0.9195 - f1_m: 0.9313 - val_loss: 0.2931 - val_accuracy: 0.6784 - val_precision_m: 0.8258 - val_recall_m: 0.7850 - val_f1_m: 0.8032\n","Epoch 68/1000\n","131/131 [==============================] - 1s 8ms/step - loss: 0.1023 - accuracy: 0.7139 - precision_m: 0.9426 - recall_m: 0.9195 - f1_m: 0.9304 - val_loss: 0.2925 - val_accuracy: 0.6727 - val_precision_m: 0.8132 - val_recall_m: 0.7805 - val_f1_m: 0.7951\n","Epoch 69/1000\n","131/131 [==============================] - 1s 8ms/step - loss: 0.0894 - accuracy: 0.7318 - precision_m: 0.9539 - recall_m: 0.9276 - f1_m: 0.9401 - val_loss: 0.2967 - val_accuracy: 0.6765 - val_precision_m: 0.8213 - val_recall_m: 0.7820 - val_f1_m: 0.7992\n","Epoch 70/1000\n","131/131 [==============================] - 1s 8ms/step - loss: 0.0976 - accuracy: 0.7187 - precision_m: 0.9441 - recall_m: 0.9240 - f1_m: 0.9333 - val_loss: 0.2926 - val_accuracy: 0.6775 - val_precision_m: 0.8216 - val_recall_m: 0.7777 - val_f1_m: 0.7976\n","Epoch 71/1000\n","131/131 [==============================] - 1s 9ms/step - loss: 0.0969 - accuracy: 0.7287 - precision_m: 0.9454 - recall_m: 0.9181 - f1_m: 0.9310 - val_loss: 0.2940 - val_accuracy: 0.6851 - val_precision_m: 0.8148 - val_recall_m: 0.7862 - val_f1_m: 0.7988\n","Epoch 72/1000\n","131/131 [==============================] - 1s 9ms/step - loss: 0.0924 - accuracy: 0.7218 - precision_m: 0.9433 - recall_m: 0.9270 - f1_m: 0.9345 - val_loss: 0.2978 - val_accuracy: 0.6660 - val_precision_m: 0.8218 - val_recall_m: 0.7843 - val_f1_m: 0.8013\n","Epoch 73/1000\n","131/131 [==============================] - 1s 8ms/step - loss: 0.0900 - accuracy: 0.7195 - precision_m: 0.9461 - recall_m: 0.9248 - f1_m: 0.9348 - val_loss: 0.2966 - val_accuracy: 0.6660 - val_precision_m: 0.8207 - val_recall_m: 0.7888 - val_f1_m: 0.8030\n","Epoch 74/1000\n","131/131 [==============================] - 1s 8ms/step - loss: 0.0917 - accuracy: 0.7325 - precision_m: 0.9431 - recall_m: 0.9270 - f1_m: 0.9343 - val_loss: 0.2959 - val_accuracy: 0.6975 - val_precision_m: 0.8195 - val_recall_m: 0.7787 - val_f1_m: 0.7970\n","Epoch 00074: early stopping\n","Score for fold 1: loss of 0.5834028720855713; accuracy of 55.01716732978821% ;precision_m of 0.8505698442459106 ;recall_m of 0.6880421042442322 ;            f1_m of 0.7575557231903076\n","Epoch 1/1000\n","131/131 [==============================] - 2s 10ms/step - loss: 0.5465 - accuracy: 0.3890 - precision_m: 0.6258 - recall_m: 0.3802 - f1_m: 0.4617 - val_loss: 0.3092 - val_accuracy: 0.6416 - val_precision_m: 0.8009 - val_recall_m: 0.7101 - val_f1_m: 0.7507\n","Epoch 2/1000\n","131/131 [==============================] - 1s 8ms/step - loss: 0.3561 - accuracy: 0.5670 - precision_m: 0.7967 - recall_m: 0.6863 - f1_m: 0.7361 - val_loss: 0.2759 - val_accuracy: 0.6520 - val_precision_m: 0.8066 - val_recall_m: 0.7533 - val_f1_m: 0.7774\n","Epoch 3/1000\n","131/131 [==============================] - 1s 8ms/step - loss: 0.3261 - accuracy: 0.5734 - precision_m: 0.8138 - recall_m: 0.7312 - f1_m: 0.7692 - val_loss: 0.2596 - val_accuracy: 0.6768 - val_precision_m: 0.8383 - val_recall_m: 0.7575 - val_f1_m: 0.7943\n","Epoch 4/1000\n","131/131 [==============================] - 1s 8ms/step - loss: 0.2986 - accuracy: 0.5909 - precision_m: 0.8287 - recall_m: 0.7533 - f1_m: 0.7879 - val_loss: 0.2556 - val_accuracy: 0.6854 - val_precision_m: 0.8403 - val_recall_m: 0.7636 - val_f1_m: 0.7986\n","Epoch 5/1000\n","131/131 [==============================] - 1s 8ms/step - loss: 0.2897 - accuracy: 0.5948 - precision_m: 0.8328 - recall_m: 0.7689 - f1_m: 0.7983 - val_loss: 0.2427 - val_accuracy: 0.6864 - val_precision_m: 0.8287 - val_recall_m: 0.7889 - val_f1_m: 0.8071\n","Epoch 6/1000\n","131/131 [==============================] - 1s 8ms/step - loss: 0.2802 - accuracy: 0.6019 - precision_m: 0.8429 - recall_m: 0.7753 - f1_m: 0.8066 - val_loss: 0.2490 - val_accuracy: 0.7121 - val_precision_m: 0.8269 - val_recall_m: 0.7781 - val_f1_m: 0.8005\n","Epoch 7/1000\n","131/131 [==============================] - 1s 8ms/step - loss: 0.2758 - accuracy: 0.6187 - precision_m: 0.8449 - recall_m: 0.7867 - f1_m: 0.8137 - val_loss: 0.2450 - val_accuracy: 0.6826 - val_precision_m: 0.8409 - val_recall_m: 0.7699 - val_f1_m: 0.8022\n","Epoch 8/1000\n","131/131 [==============================] - 1s 8ms/step - loss: 0.2692 - accuracy: 0.6178 - precision_m: 0.8476 - recall_m: 0.7774 - f1_m: 0.8098 - val_loss: 0.2410 - val_accuracy: 0.6940 - val_precision_m: 0.8474 - val_recall_m: 0.7712 - val_f1_m: 0.8059\n","Epoch 9/1000\n","131/131 [==============================] - 1s 8ms/step - loss: 0.2619 - accuracy: 0.6102 - precision_m: 0.8612 - recall_m: 0.7849 - f1_m: 0.8202 - val_loss: 0.2388 - val_accuracy: 0.6892 - val_precision_m: 0.8510 - val_recall_m: 0.7734 - val_f1_m: 0.8091\n","Epoch 10/1000\n","131/131 [==============================] - 1s 9ms/step - loss: 0.2499 - accuracy: 0.6441 - precision_m: 0.8663 - recall_m: 0.7939 - f1_m: 0.8275 - val_loss: 0.2403 - val_accuracy: 0.6921 - val_precision_m: 0.8528 - val_recall_m: 0.7710 - val_f1_m: 0.8086\n","Epoch 11/1000\n","131/131 [==============================] - 1s 9ms/step - loss: 0.2558 - accuracy: 0.6148 - precision_m: 0.8676 - recall_m: 0.7988 - f1_m: 0.8307 - val_loss: 0.2444 - val_accuracy: 0.7073 - val_precision_m: 0.8320 - val_recall_m: 0.8039 - val_f1_m: 0.8168\n","Epoch 12/1000\n","131/131 [==============================] - 1s 9ms/step - loss: 0.2424 - accuracy: 0.6435 - precision_m: 0.8689 - recall_m: 0.8014 - f1_m: 0.8331 - val_loss: 0.2402 - val_accuracy: 0.7007 - val_precision_m: 0.8431 - val_recall_m: 0.7835 - val_f1_m: 0.8111\n","Epoch 13/1000\n","131/131 [==============================] - 1s 8ms/step - loss: 0.2474 - accuracy: 0.6138 - precision_m: 0.8678 - recall_m: 0.8108 - f1_m: 0.8373 - val_loss: 0.2379 - val_accuracy: 0.6902 - val_precision_m: 0.8362 - val_recall_m: 0.7955 - val_f1_m: 0.8141\n","Epoch 14/1000\n","131/131 [==============================] - 1s 9ms/step - loss: 0.2333 - accuracy: 0.6421 - precision_m: 0.8757 - recall_m: 0.8118 - f1_m: 0.8415 - val_loss: 0.2386 - val_accuracy: 0.7007 - val_precision_m: 0.8375 - val_recall_m: 0.8035 - val_f1_m: 0.8188\n","Epoch 15/1000\n","131/131 [==============================] - 1s 8ms/step - loss: 0.2294 - accuracy: 0.6275 - precision_m: 0.8723 - recall_m: 0.8181 - f1_m: 0.8430 - val_loss: 0.2479 - val_accuracy: 0.7121 - val_precision_m: 0.8331 - val_recall_m: 0.7801 - val_f1_m: 0.8045\n","Epoch 16/1000\n","131/131 [==============================] - 1s 8ms/step - loss: 0.2304 - accuracy: 0.6590 - precision_m: 0.8699 - recall_m: 0.8173 - f1_m: 0.8417 - val_loss: 0.2434 - val_accuracy: 0.7102 - val_precision_m: 0.8415 - val_recall_m: 0.7835 - val_f1_m: 0.8105\n","Epoch 17/1000\n","131/131 [==============================] - 1s 8ms/step - loss: 0.2278 - accuracy: 0.6447 - precision_m: 0.8811 - recall_m: 0.8203 - f1_m: 0.8486 - val_loss: 0.2405 - val_accuracy: 0.7026 - val_precision_m: 0.8366 - val_recall_m: 0.8045 - val_f1_m: 0.8189\n","Epoch 18/1000\n","131/131 [==============================] - 1s 8ms/step - loss: 0.2203 - accuracy: 0.6360 - precision_m: 0.8810 - recall_m: 0.8341 - f1_m: 0.8558 - val_loss: 0.2394 - val_accuracy: 0.7169 - val_precision_m: 0.8470 - val_recall_m: 0.7870 - val_f1_m: 0.8148\n","Epoch 19/1000\n","131/131 [==============================] - 1s 8ms/step - loss: 0.2151 - accuracy: 0.6355 - precision_m: 0.8850 - recall_m: 0.8359 - f1_m: 0.8590 - val_loss: 0.2392 - val_accuracy: 0.7131 - val_precision_m: 0.8480 - val_recall_m: 0.7882 - val_f1_m: 0.8158\n","Epoch 20/1000\n","131/131 [==============================] - 1s 9ms/step - loss: 0.2143 - accuracy: 0.6540 - precision_m: 0.8819 - recall_m: 0.8332 - f1_m: 0.8559 - val_loss: 0.2386 - val_accuracy: 0.6997 - val_precision_m: 0.8376 - val_recall_m: 0.8045 - val_f1_m: 0.8194\n","Epoch 21/1000\n","131/131 [==============================] - 1s 8ms/step - loss: 0.2081 - accuracy: 0.6305 - precision_m: 0.8888 - recall_m: 0.8470 - f1_m: 0.8664 - val_loss: 0.2416 - val_accuracy: 0.6997 - val_precision_m: 0.8463 - val_recall_m: 0.7750 - val_f1_m: 0.8077\n","Epoch 22/1000\n","131/131 [==============================] - 1s 8ms/step - loss: 0.2053 - accuracy: 0.6636 - precision_m: 0.8903 - recall_m: 0.8369 - f1_m: 0.8620 - val_loss: 0.2398 - val_accuracy: 0.7026 - val_precision_m: 0.8407 - val_recall_m: 0.7807 - val_f1_m: 0.8085\n","Epoch 23/1000\n","131/131 [==============================] - 1s 8ms/step - loss: 0.2029 - accuracy: 0.6423 - precision_m: 0.8958 - recall_m: 0.8461 - f1_m: 0.8689 - val_loss: 0.2404 - val_accuracy: 0.7112 - val_precision_m: 0.8500 - val_recall_m: 0.7698 - val_f1_m: 0.8069\n","Epoch 24/1000\n","131/131 [==============================] - 1s 8ms/step - loss: 0.1976 - accuracy: 0.6517 - precision_m: 0.9077 - recall_m: 0.8394 - f1_m: 0.8714 - val_loss: 0.2390 - val_accuracy: 0.6969 - val_precision_m: 0.8399 - val_recall_m: 0.7912 - val_f1_m: 0.8135\n","Epoch 25/1000\n","131/131 [==============================] - 1s 8ms/step - loss: 0.1932 - accuracy: 0.6619 - precision_m: 0.9010 - recall_m: 0.8520 - f1_m: 0.8749 - val_loss: 0.2386 - val_accuracy: 0.6921 - val_precision_m: 0.8406 - val_recall_m: 0.8010 - val_f1_m: 0.8190\n","Epoch 26/1000\n","131/131 [==============================] - 1s 8ms/step - loss: 0.1859 - accuracy: 0.6608 - precision_m: 0.9033 - recall_m: 0.8587 - f1_m: 0.8795 - val_loss: 0.2446 - val_accuracy: 0.7207 - val_precision_m: 0.8453 - val_recall_m: 0.7838 - val_f1_m: 0.8119\n","Epoch 27/1000\n","131/131 [==============================] - 1s 8ms/step - loss: 0.1975 - accuracy: 0.6715 - precision_m: 0.8943 - recall_m: 0.8526 - f1_m: 0.8721 - val_loss: 0.2384 - val_accuracy: 0.6997 - val_precision_m: 0.8417 - val_recall_m: 0.8012 - val_f1_m: 0.8195\n","Epoch 28/1000\n","131/131 [==============================] - 1s 9ms/step - loss: 0.1829 - accuracy: 0.6559 - precision_m: 0.9024 - recall_m: 0.8665 - f1_m: 0.8832 - val_loss: 0.2402 - val_accuracy: 0.6930 - val_precision_m: 0.8498 - val_recall_m: 0.7830 - val_f1_m: 0.8136\n","Epoch 29/1000\n","131/131 [==============================] - 1s 8ms/step - loss: 0.1885 - accuracy: 0.6442 - precision_m: 0.8975 - recall_m: 0.8535 - f1_m: 0.8743 - val_loss: 0.2452 - val_accuracy: 0.7054 - val_precision_m: 0.8385 - val_recall_m: 0.7866 - val_f1_m: 0.8104\n","Epoch 30/1000\n","131/131 [==============================] - 1s 9ms/step - loss: 0.1806 - accuracy: 0.6521 - precision_m: 0.9064 - recall_m: 0.8632 - f1_m: 0.8836 - val_loss: 0.2413 - val_accuracy: 0.6949 - val_precision_m: 0.8475 - val_recall_m: 0.7696 - val_f1_m: 0.8053\n","Epoch 31/1000\n","131/131 [==============================] - 1s 8ms/step - loss: 0.1824 - accuracy: 0.6495 - precision_m: 0.9061 - recall_m: 0.8605 - f1_m: 0.8819 - val_loss: 0.2418 - val_accuracy: 0.6978 - val_precision_m: 0.8424 - val_recall_m: 0.7998 - val_f1_m: 0.8192\n","Epoch 32/1000\n","131/131 [==============================] - 1s 9ms/step - loss: 0.1719 - accuracy: 0.6602 - precision_m: 0.9118 - recall_m: 0.8724 - f1_m: 0.8909 - val_loss: 0.2531 - val_accuracy: 0.7121 - val_precision_m: 0.8372 - val_recall_m: 0.7906 - val_f1_m: 0.8118\n","Epoch 33/1000\n","131/131 [==============================] - 1s 8ms/step - loss: 0.1724 - accuracy: 0.6738 - precision_m: 0.9102 - recall_m: 0.8650 - f1_m: 0.8859 - val_loss: 0.2524 - val_accuracy: 0.7140 - val_precision_m: 0.8293 - val_recall_m: 0.8068 - val_f1_m: 0.8168\n","Epoch 34/1000\n","131/131 [==============================] - 1s 8ms/step - loss: 0.1693 - accuracy: 0.6606 - precision_m: 0.9127 - recall_m: 0.8677 - f1_m: 0.8888 - val_loss: 0.2457 - val_accuracy: 0.7007 - val_precision_m: 0.8433 - val_recall_m: 0.7956 - val_f1_m: 0.8174\n","Epoch 35/1000\n","131/131 [==============================] - 1s 8ms/step - loss: 0.1716 - accuracy: 0.6721 - precision_m: 0.9134 - recall_m: 0.8681 - f1_m: 0.8893 - val_loss: 0.2489 - val_accuracy: 0.6988 - val_precision_m: 0.8395 - val_recall_m: 0.7828 - val_f1_m: 0.8088\n","Epoch 36/1000\n","131/131 [==============================] - 1s 9ms/step - loss: 0.1605 - accuracy: 0.6727 - precision_m: 0.9211 - recall_m: 0.8834 - f1_m: 0.9009 - val_loss: 0.2465 - val_accuracy: 0.7054 - val_precision_m: 0.8534 - val_recall_m: 0.7809 - val_f1_m: 0.8141\n","Epoch 37/1000\n","131/131 [==============================] - 1s 8ms/step - loss: 0.1642 - accuracy: 0.6674 - precision_m: 0.9162 - recall_m: 0.8734 - f1_m: 0.8934 - val_loss: 0.2472 - val_accuracy: 0.6969 - val_precision_m: 0.8576 - val_recall_m: 0.7816 - val_f1_m: 0.8166\n","Epoch 38/1000\n","131/131 [==============================] - 1s 8ms/step - loss: 0.1624 - accuracy: 0.6580 - precision_m: 0.9156 - recall_m: 0.8822 - f1_m: 0.8979 - val_loss: 0.2516 - val_accuracy: 0.6902 - val_precision_m: 0.8460 - val_recall_m: 0.7758 - val_f1_m: 0.8079\n","Epoch 39/1000\n","131/131 [==============================] - 1s 8ms/step - loss: 0.1580 - accuracy: 0.6580 - precision_m: 0.9218 - recall_m: 0.8831 - f1_m: 0.9013 - val_loss: 0.2518 - val_accuracy: 0.6911 - val_precision_m: 0.8380 - val_recall_m: 0.7808 - val_f1_m: 0.8069\n","Epoch 40/1000\n","131/131 [==============================] - 1s 9ms/step - loss: 0.1576 - accuracy: 0.6604 - precision_m: 0.9237 - recall_m: 0.8752 - f1_m: 0.8981 - val_loss: 0.2542 - val_accuracy: 0.7140 - val_precision_m: 0.8279 - val_recall_m: 0.7932 - val_f1_m: 0.8089\n","Epoch 41/1000\n","131/131 [==============================] - 1s 8ms/step - loss: 0.1549 - accuracy: 0.6604 - precision_m: 0.9296 - recall_m: 0.8843 - f1_m: 0.9056 - val_loss: 0.2556 - val_accuracy: 0.7188 - val_precision_m: 0.8307 - val_recall_m: 0.7871 - val_f1_m: 0.8070\n","Epoch 42/1000\n","131/131 [==============================] - 1s 8ms/step - loss: 0.1536 - accuracy: 0.6603 - precision_m: 0.9247 - recall_m: 0.8809 - f1_m: 0.9016 - val_loss: 0.2564 - val_accuracy: 0.7121 - val_precision_m: 0.8504 - val_recall_m: 0.7633 - val_f1_m: 0.8032\n","Epoch 43/1000\n","131/131 [==============================] - 1s 8ms/step - loss: 0.1530 - accuracy: 0.6665 - precision_m: 0.9295 - recall_m: 0.8813 - f1_m: 0.9040 - val_loss: 0.2519 - val_accuracy: 0.6988 - val_precision_m: 0.8440 - val_recall_m: 0.7918 - val_f1_m: 0.8161\n","Epoch 44/1000\n","131/131 [==============================] - 1s 8ms/step - loss: 0.1432 - accuracy: 0.6826 - precision_m: 0.9291 - recall_m: 0.8920 - f1_m: 0.9095 - val_loss: 0.2561 - val_accuracy: 0.7026 - val_precision_m: 0.8425 - val_recall_m: 0.7809 - val_f1_m: 0.8094\n","Epoch 45/1000\n","131/131 [==============================] - 1s 8ms/step - loss: 0.1448 - accuracy: 0.6617 - precision_m: 0.9275 - recall_m: 0.8857 - f1_m: 0.9054 - val_loss: 0.2557 - val_accuracy: 0.6988 - val_precision_m: 0.8352 - val_recall_m: 0.7956 - val_f1_m: 0.8134\n","Epoch 46/1000\n","131/131 [==============================] - 1s 8ms/step - loss: 0.1422 - accuracy: 0.6636 - precision_m: 0.9278 - recall_m: 0.8930 - f1_m: 0.9094 - val_loss: 0.2535 - val_accuracy: 0.6949 - val_precision_m: 0.8392 - val_recall_m: 0.7910 - val_f1_m: 0.8133\n","Epoch 47/1000\n","131/131 [==============================] - 1s 8ms/step - loss: 0.1425 - accuracy: 0.6541 - precision_m: 0.9320 - recall_m: 0.8945 - f1_m: 0.9121 - val_loss: 0.2570 - val_accuracy: 0.7159 - val_precision_m: 0.8442 - val_recall_m: 0.7868 - val_f1_m: 0.8135\n","Epoch 48/1000\n","131/131 [==============================] - 1s 8ms/step - loss: 0.1421 - accuracy: 0.6711 - precision_m: 0.9330 - recall_m: 0.8936 - f1_m: 0.9122 - val_loss: 0.2548 - val_accuracy: 0.6892 - val_precision_m: 0.8515 - val_recall_m: 0.7747 - val_f1_m: 0.8095\n","Epoch 49/1000\n","131/131 [==============================] - 1s 9ms/step - loss: 0.1519 - accuracy: 0.6683 - precision_m: 0.9197 - recall_m: 0.8852 - f1_m: 0.9015 - val_loss: 0.2628 - val_accuracy: 0.7073 - val_precision_m: 0.8344 - val_recall_m: 0.7801 - val_f1_m: 0.8050\n","Epoch 50/1000\n","131/131 [==============================] - 1s 9ms/step - loss: 0.1375 - accuracy: 0.6621 - precision_m: 0.9323 - recall_m: 0.8974 - f1_m: 0.9139 - val_loss: 0.2584 - val_accuracy: 0.7016 - val_precision_m: 0.8340 - val_recall_m: 0.7965 - val_f1_m: 0.8135\n","Epoch 51/1000\n","131/131 [==============================] - 1s 8ms/step - loss: 0.1391 - accuracy: 0.6734 - precision_m: 0.9259 - recall_m: 0.8978 - f1_m: 0.9110 - val_loss: 0.2578 - val_accuracy: 0.7102 - val_precision_m: 0.8315 - val_recall_m: 0.7930 - val_f1_m: 0.8104\n","Epoch 52/1000\n","131/131 [==============================] - 1s 8ms/step - loss: 0.1414 - accuracy: 0.6633 - precision_m: 0.9277 - recall_m: 0.9010 - f1_m: 0.9136 - val_loss: 0.2553 - val_accuracy: 0.7026 - val_precision_m: 0.8628 - val_recall_m: 0.7807 - val_f1_m: 0.8182\n","Epoch 53/1000\n","131/131 [==============================] - 1s 8ms/step - loss: 0.1318 - accuracy: 0.6640 - precision_m: 0.9374 - recall_m: 0.9007 - f1_m: 0.9182 - val_loss: 0.2605 - val_accuracy: 0.7169 - val_precision_m: 0.8340 - val_recall_m: 0.7985 - val_f1_m: 0.8145\n","Epoch 54/1000\n","131/131 [==============================] - 1s 8ms/step - loss: 0.1330 - accuracy: 0.6846 - precision_m: 0.9324 - recall_m: 0.9041 - f1_m: 0.9174 - val_loss: 0.2600 - val_accuracy: 0.7045 - val_precision_m: 0.8493 - val_recall_m: 0.7743 - val_f1_m: 0.8087\n","Epoch 55/1000\n","131/131 [==============================] - 1s 8ms/step - loss: 0.1245 - accuracy: 0.6873 - precision_m: 0.9402 - recall_m: 0.9086 - f1_m: 0.9234 - val_loss: 0.2639 - val_accuracy: 0.7197 - val_precision_m: 0.8409 - val_recall_m: 0.7866 - val_f1_m: 0.8117\n","Epoch 56/1000\n","131/131 [==============================] - 1s 9ms/step - loss: 0.1329 - accuracy: 0.6806 - precision_m: 0.9382 - recall_m: 0.9000 - f1_m: 0.9180 - val_loss: 0.2621 - val_accuracy: 0.7054 - val_precision_m: 0.8505 - val_recall_m: 0.7694 - val_f1_m: 0.8066\n","Epoch 57/1000\n","131/131 [==============================] - 1s 8ms/step - loss: 0.1307 - accuracy: 0.6707 - precision_m: 0.9317 - recall_m: 0.9011 - f1_m: 0.9156 - val_loss: 0.2613 - val_accuracy: 0.7016 - val_precision_m: 0.8396 - val_recall_m: 0.7814 - val_f1_m: 0.8079\n","Epoch 58/1000\n","131/131 [==============================] - 1s 8ms/step - loss: 0.1249 - accuracy: 0.6873 - precision_m: 0.9406 - recall_m: 0.9097 - f1_m: 0.9243 - val_loss: 0.2604 - val_accuracy: 0.7026 - val_precision_m: 0.8489 - val_recall_m: 0.7787 - val_f1_m: 0.8110\n","Epoch 59/1000\n","131/131 [==============================] - 1s 8ms/step - loss: 0.1283 - accuracy: 0.6735 - precision_m: 0.9351 - recall_m: 0.9046 - f1_m: 0.9189 - val_loss: 0.2655 - val_accuracy: 0.7169 - val_precision_m: 0.8374 - val_recall_m: 0.7996 - val_f1_m: 0.8172\n","Epoch 60/1000\n","131/131 [==============================] - 1s 8ms/step - loss: 0.1270 - accuracy: 0.6771 - precision_m: 0.9337 - recall_m: 0.9083 - f1_m: 0.9203 - val_loss: 0.2715 - val_accuracy: 0.7064 - val_precision_m: 0.8270 - val_recall_m: 0.7890 - val_f1_m: 0.8065\n","Epoch 61/1000\n","131/131 [==============================] - 1s 8ms/step - loss: 0.1257 - accuracy: 0.6759 - precision_m: 0.9379 - recall_m: 0.9068 - f1_m: 0.9216 - val_loss: 0.2667 - val_accuracy: 0.6978 - val_precision_m: 0.8430 - val_recall_m: 0.7824 - val_f1_m: 0.8104\n","Epoch 62/1000\n","131/131 [==============================] - 1s 8ms/step - loss: 0.1254 - accuracy: 0.6635 - precision_m: 0.9403 - recall_m: 0.9114 - f1_m: 0.9252 - val_loss: 0.2716 - val_accuracy: 0.7197 - val_precision_m: 0.8473 - val_recall_m: 0.7595 - val_f1_m: 0.7997\n","Epoch 63/1000\n","131/131 [==============================] - 1s 8ms/step - loss: 0.1226 - accuracy: 0.6764 - precision_m: 0.9451 - recall_m: 0.9042 - f1_m: 0.9236 - val_loss: 0.2679 - val_accuracy: 0.6969 - val_precision_m: 0.8411 - val_recall_m: 0.7766 - val_f1_m: 0.8061\n","Epoch 64/1000\n","131/131 [==============================] - 1s 9ms/step - loss: 0.1207 - accuracy: 0.6693 - precision_m: 0.9399 - recall_m: 0.9119 - f1_m: 0.9251 - val_loss: 0.2703 - val_accuracy: 0.6940 - val_precision_m: 0.8359 - val_recall_m: 0.7770 - val_f1_m: 0.8044\n","Epoch 65/1000\n","131/131 [==============================] - 1s 8ms/step - loss: 0.1205 - accuracy: 0.6769 - precision_m: 0.9428 - recall_m: 0.9066 - f1_m: 0.9236 - val_loss: 0.2718 - val_accuracy: 0.6911 - val_precision_m: 0.8352 - val_recall_m: 0.7888 - val_f1_m: 0.8097\n","Epoch 66/1000\n","131/131 [==============================] - 1s 8ms/step - loss: 0.1249 - accuracy: 0.6633 - precision_m: 0.9393 - recall_m: 0.9083 - f1_m: 0.9231 - val_loss: 0.2701 - val_accuracy: 0.6921 - val_precision_m: 0.8540 - val_recall_m: 0.7532 - val_f1_m: 0.7985\n","Epoch 67/1000\n","131/131 [==============================] - 1s 9ms/step - loss: 0.1149 - accuracy: 0.6859 - precision_m: 0.9459 - recall_m: 0.9132 - f1_m: 0.9286 - val_loss: 0.2747 - val_accuracy: 0.7073 - val_precision_m: 0.8443 - val_recall_m: 0.7594 - val_f1_m: 0.7983\n","Epoch 68/1000\n","131/131 [==============================] - 1s 9ms/step - loss: 0.1178 - accuracy: 0.6779 - precision_m: 0.9389 - recall_m: 0.9171 - f1_m: 0.9274 - val_loss: 0.2748 - val_accuracy: 0.6911 - val_precision_m: 0.8238 - val_recall_m: 0.7990 - val_f1_m: 0.8100\n","Epoch 69/1000\n","131/131 [==============================] - 1s 8ms/step - loss: 0.1186 - accuracy: 0.6884 - precision_m: 0.9403 - recall_m: 0.9142 - f1_m: 0.9266 - val_loss: 0.2718 - val_accuracy: 0.7092 - val_precision_m: 0.8412 - val_recall_m: 0.7729 - val_f1_m: 0.8042\n","Epoch 70/1000\n","131/131 [==============================] - 1s 8ms/step - loss: 0.1144 - accuracy: 0.6658 - precision_m: 0.9459 - recall_m: 0.9110 - f1_m: 0.9275 - val_loss: 0.2784 - val_accuracy: 0.7064 - val_precision_m: 0.8237 - val_recall_m: 0.7891 - val_f1_m: 0.8050\n","Epoch 71/1000\n","131/131 [==============================] - 1s 8ms/step - loss: 0.1173 - accuracy: 0.6767 - precision_m: 0.9436 - recall_m: 0.9216 - f1_m: 0.9321 - val_loss: 0.2705 - val_accuracy: 0.6940 - val_precision_m: 0.8469 - val_recall_m: 0.7812 - val_f1_m: 0.8113\n","Epoch 72/1000\n","131/131 [==============================] - 1s 9ms/step - loss: 0.1124 - accuracy: 0.6740 - precision_m: 0.9490 - recall_m: 0.9221 - f1_m: 0.9348 - val_loss: 0.2745 - val_accuracy: 0.6969 - val_precision_m: 0.8440 - val_recall_m: 0.7693 - val_f1_m: 0.8035\n","Epoch 73/1000\n","131/131 [==============================] - 1s 8ms/step - loss: 0.1117 - accuracy: 0.6818 - precision_m: 0.9449 - recall_m: 0.9163 - f1_m: 0.9299 - val_loss: 0.2772 - val_accuracy: 0.7121 - val_precision_m: 0.8298 - val_recall_m: 0.7852 - val_f1_m: 0.8058\n","Epoch 74/1000\n","131/131 [==============================] - 1s 9ms/step - loss: 0.1092 - accuracy: 0.6874 - precision_m: 0.9471 - recall_m: 0.9221 - f1_m: 0.9339 - val_loss: 0.2769 - val_accuracy: 0.6978 - val_precision_m: 0.8429 - val_recall_m: 0.7895 - val_f1_m: 0.8142\n","Epoch 75/1000\n","131/131 [==============================] - 1s 8ms/step - loss: 0.1082 - accuracy: 0.6982 - precision_m: 0.9454 - recall_m: 0.9217 - f1_m: 0.9329 - val_loss: 0.2748 - val_accuracy: 0.6949 - val_precision_m: 0.8401 - val_recall_m: 0.7803 - val_f1_m: 0.8076\n","Epoch 76/1000\n","131/131 [==============================] - 1s 9ms/step - loss: 0.1028 - accuracy: 0.7042 - precision_m: 0.9513 - recall_m: 0.9266 - f1_m: 0.9383 - val_loss: 0.2786 - val_accuracy: 0.7016 - val_precision_m: 0.8426 - val_recall_m: 0.7791 - val_f1_m: 0.8083\n","Epoch 77/1000\n","131/131 [==============================] - 1s 8ms/step - loss: 0.1073 - accuracy: 0.6910 - precision_m: 0.9442 - recall_m: 0.9181 - f1_m: 0.9306 - val_loss: 0.2786 - val_accuracy: 0.6835 - val_precision_m: 0.8320 - val_recall_m: 0.7847 - val_f1_m: 0.8065\n","Epoch 00077: early stopping\n","Score for fold 2: loss of 0.3694007098674774; accuracy of 65.95419645309448% ;precision_m of 0.8045609593391418 ;recall_m of 0.7779812216758728 ;            f1_m of 0.7893940210342407\n","Epoch 1/1000\n","131/131 [==============================] - 2s 10ms/step - loss: 0.5529 - accuracy: 0.3685 - precision_m: 0.6128 - recall_m: 0.3726 - f1_m: 0.4439 - val_loss: 0.3463 - val_accuracy: 0.6797 - val_precision_m: 0.7892 - val_recall_m: 0.6808 - val_f1_m: 0.7290\n","Epoch 2/1000\n","131/131 [==============================] - 1s 9ms/step - loss: 0.3727 - accuracy: 0.5606 - precision_m: 0.7828 - recall_m: 0.6776 - f1_m: 0.7245 - val_loss: 0.3208 - val_accuracy: 0.6568 - val_precision_m: 0.7823 - val_recall_m: 0.7277 - val_f1_m: 0.7523\n","Epoch 3/1000\n","131/131 [==============================] - 1s 8ms/step - loss: 0.3372 - accuracy: 0.5703 - precision_m: 0.8181 - recall_m: 0.7275 - f1_m: 0.7688 - val_loss: 0.3091 - val_accuracy: 0.6978 - val_precision_m: 0.8059 - val_recall_m: 0.7239 - val_f1_m: 0.7610\n","Epoch 4/1000\n","131/131 [==============================] - 1s 9ms/step - loss: 0.3160 - accuracy: 0.5788 - precision_m: 0.8311 - recall_m: 0.7521 - f1_m: 0.7880 - val_loss: 0.2851 - val_accuracy: 0.6749 - val_precision_m: 0.8180 - val_recall_m: 0.7429 - val_f1_m: 0.7768\n","Epoch 5/1000\n","131/131 [==============================] - 1s 8ms/step - loss: 0.3107 - accuracy: 0.5982 - precision_m: 0.8298 - recall_m: 0.7509 - f1_m: 0.7869 - val_loss: 0.2938 - val_accuracy: 0.6816 - val_precision_m: 0.8366 - val_recall_m: 0.6944 - val_f1_m: 0.7566\n","Epoch 6/1000\n","131/131 [==============================] - 1s 9ms/step - loss: 0.2990 - accuracy: 0.5971 - precision_m: 0.8381 - recall_m: 0.7627 - f1_m: 0.7973 - val_loss: 0.2818 - val_accuracy: 0.6673 - val_precision_m: 0.8071 - val_recall_m: 0.7542 - val_f1_m: 0.7781\n","Epoch 7/1000\n","131/131 [==============================] - 1s 8ms/step - loss: 0.2817 - accuracy: 0.6175 - precision_m: 0.8449 - recall_m: 0.7829 - f1_m: 0.8109 - val_loss: 0.2810 - val_accuracy: 0.6930 - val_precision_m: 0.8215 - val_recall_m: 0.7556 - val_f1_m: 0.7851\n","Epoch 8/1000\n","131/131 [==============================] - 1s 9ms/step - loss: 0.2845 - accuracy: 0.5984 - precision_m: 0.8488 - recall_m: 0.7826 - f1_m: 0.8136 - val_loss: 0.2761 - val_accuracy: 0.6759 - val_precision_m: 0.8343 - val_recall_m: 0.7322 - val_f1_m: 0.7779\n","Epoch 9/1000\n","131/131 [==============================] - 1s 8ms/step - loss: 0.2722 - accuracy: 0.5873 - precision_m: 0.8519 - recall_m: 0.7839 - f1_m: 0.8155 - val_loss: 0.2881 - val_accuracy: 0.7007 - val_precision_m: 0.8297 - val_recall_m: 0.7359 - val_f1_m: 0.7780\n","Epoch 10/1000\n","131/131 [==============================] - 1s 9ms/step - loss: 0.2584 - accuracy: 0.6189 - precision_m: 0.8597 - recall_m: 0.8002 - f1_m: 0.8276 - val_loss: 0.2885 - val_accuracy: 0.6969 - val_precision_m: 0.8175 - val_recall_m: 0.7511 - val_f1_m: 0.7811\n","Epoch 11/1000\n","131/131 [==============================] - 1s 8ms/step - loss: 0.2585 - accuracy: 0.6143 - precision_m: 0.8594 - recall_m: 0.8033 - f1_m: 0.8292 - val_loss: 0.2868 - val_accuracy: 0.6988 - val_precision_m: 0.8284 - val_recall_m: 0.7478 - val_f1_m: 0.7841\n","Epoch 12/1000\n","131/131 [==============================] - 1s 9ms/step - loss: 0.2513 - accuracy: 0.6358 - precision_m: 0.8706 - recall_m: 0.8109 - f1_m: 0.8387 - val_loss: 0.2794 - val_accuracy: 0.6749 - val_precision_m: 0.8335 - val_recall_m: 0.7428 - val_f1_m: 0.7832\n","Epoch 13/1000\n","131/131 [==============================] - 1s 8ms/step - loss: 0.2537 - accuracy: 0.6249 - precision_m: 0.8626 - recall_m: 0.8033 - f1_m: 0.8309 - val_loss: 0.2828 - val_accuracy: 0.6911 - val_precision_m: 0.8115 - val_recall_m: 0.7722 - val_f1_m: 0.7897\n","Epoch 14/1000\n","131/131 [==============================] - 1s 9ms/step - loss: 0.2441 - accuracy: 0.6103 - precision_m: 0.8709 - recall_m: 0.8245 - f1_m: 0.8461 - val_loss: 0.2894 - val_accuracy: 0.6978 - val_precision_m: 0.8208 - val_recall_m: 0.7615 - val_f1_m: 0.7879\n","Epoch 15/1000\n","131/131 [==============================] - 1s 10ms/step - loss: 0.2357 - accuracy: 0.6211 - precision_m: 0.8808 - recall_m: 0.8233 - f1_m: 0.8502 - val_loss: 0.2904 - val_accuracy: 0.7064 - val_precision_m: 0.8154 - val_recall_m: 0.7609 - val_f1_m: 0.7858\n","Epoch 16/1000\n","131/131 [==============================] - 1s 9ms/step - loss: 0.2335 - accuracy: 0.6207 - precision_m: 0.8784 - recall_m: 0.8194 - f1_m: 0.8468 - val_loss: 0.2868 - val_accuracy: 0.7054 - val_precision_m: 0.8232 - val_recall_m: 0.7611 - val_f1_m: 0.7893\n","Epoch 17/1000\n","131/131 [==============================] - 1s 9ms/step - loss: 0.2329 - accuracy: 0.5912 - precision_m: 0.8862 - recall_m: 0.8254 - f1_m: 0.8541 - val_loss: 0.2862 - val_accuracy: 0.7035 - val_precision_m: 0.8293 - val_recall_m: 0.7623 - val_f1_m: 0.7926\n","Epoch 18/1000\n","131/131 [==============================] - 1s 9ms/step - loss: 0.2205 - accuracy: 0.6478 - precision_m: 0.8905 - recall_m: 0.8396 - f1_m: 0.8635 - val_loss: 0.2862 - val_accuracy: 0.7150 - val_precision_m: 0.8252 - val_recall_m: 0.7718 - val_f1_m: 0.7959\n","Epoch 19/1000\n","131/131 [==============================] - 1s 8ms/step - loss: 0.2220 - accuracy: 0.6276 - precision_m: 0.8916 - recall_m: 0.8412 - f1_m: 0.8649 - val_loss: 0.2843 - val_accuracy: 0.6845 - val_precision_m: 0.8142 - val_recall_m: 0.7627 - val_f1_m: 0.7859\n","Epoch 20/1000\n","131/131 [==============================] - 1s 9ms/step - loss: 0.2175 - accuracy: 0.6297 - precision_m: 0.8883 - recall_m: 0.8337 - f1_m: 0.8593 - val_loss: 0.2812 - val_accuracy: 0.6921 - val_precision_m: 0.8356 - val_recall_m: 0.7406 - val_f1_m: 0.7833\n","Epoch 21/1000\n","131/131 [==============================] - 1s 8ms/step - loss: 0.2125 - accuracy: 0.6384 - precision_m: 0.8907 - recall_m: 0.8385 - f1_m: 0.8631 - val_loss: 0.2802 - val_accuracy: 0.6969 - val_precision_m: 0.8319 - val_recall_m: 0.7620 - val_f1_m: 0.7935\n","Epoch 22/1000\n","131/131 [==============================] - 1s 8ms/step - loss: 0.2155 - accuracy: 0.6349 - precision_m: 0.8874 - recall_m: 0.8418 - f1_m: 0.8629 - val_loss: 0.2991 - val_accuracy: 0.6930 - val_precision_m: 0.8076 - val_recall_m: 0.7429 - val_f1_m: 0.7716\n","Epoch 23/1000\n","131/131 [==============================] - 1s 9ms/step - loss: 0.2140 - accuracy: 0.6499 - precision_m: 0.8915 - recall_m: 0.8471 - f1_m: 0.8676 - val_loss: 0.2918 - val_accuracy: 0.6988 - val_precision_m: 0.8354 - val_recall_m: 0.7497 - val_f1_m: 0.7884\n","Epoch 24/1000\n","131/131 [==============================] - 1s 9ms/step - loss: 0.2019 - accuracy: 0.6436 - precision_m: 0.9024 - recall_m: 0.8537 - f1_m: 0.8766 - val_loss: 0.2879 - val_accuracy: 0.6969 - val_precision_m: 0.8276 - val_recall_m: 0.7605 - val_f1_m: 0.7907\n","Epoch 25/1000\n","131/131 [==============================] - 1s 9ms/step - loss: 0.2006 - accuracy: 0.6413 - precision_m: 0.9031 - recall_m: 0.8522 - f1_m: 0.8763 - val_loss: 0.3034 - val_accuracy: 0.6940 - val_precision_m: 0.8143 - val_recall_m: 0.7596 - val_f1_m: 0.7841\n","Epoch 26/1000\n","131/131 [==============================] - 1s 9ms/step - loss: 0.1944 - accuracy: 0.6330 - precision_m: 0.9005 - recall_m: 0.8531 - f1_m: 0.8753 - val_loss: 0.2888 - val_accuracy: 0.7073 - val_precision_m: 0.8356 - val_recall_m: 0.7581 - val_f1_m: 0.7932\n","Epoch 27/1000\n","131/131 [==============================] - 1s 8ms/step - loss: 0.1937 - accuracy: 0.6495 - precision_m: 0.8993 - recall_m: 0.8518 - f1_m: 0.8737 - val_loss: 0.2929 - val_accuracy: 0.6911 - val_precision_m: 0.8362 - val_recall_m: 0.7424 - val_f1_m: 0.7846\n","Epoch 28/1000\n","131/131 [==============================] - 1s 9ms/step - loss: 0.1949 - accuracy: 0.6364 - precision_m: 0.9033 - recall_m: 0.8473 - f1_m: 0.8734 - val_loss: 0.2971 - val_accuracy: 0.7026 - val_precision_m: 0.8142 - val_recall_m: 0.7653 - val_f1_m: 0.7873\n","Epoch 29/1000\n","131/131 [==============================] - 1s 9ms/step - loss: 0.1901 - accuracy: 0.6350 - precision_m: 0.9053 - recall_m: 0.8595 - f1_m: 0.8809 - val_loss: 0.2883 - val_accuracy: 0.6730 - val_precision_m: 0.8226 - val_recall_m: 0.7565 - val_f1_m: 0.7860\n","Epoch 30/1000\n","131/131 [==============================] - 1s 9ms/step - loss: 0.1845 - accuracy: 0.6367 - precision_m: 0.9117 - recall_m: 0.8741 - f1_m: 0.8918 - val_loss: 0.3000 - val_accuracy: 0.6911 - val_precision_m: 0.8188 - val_recall_m: 0.7522 - val_f1_m: 0.7823\n","Epoch 31/1000\n","131/131 [==============================] - 1s 9ms/step - loss: 0.1795 - accuracy: 0.6522 - precision_m: 0.9107 - recall_m: 0.8689 - f1_m: 0.8885 - val_loss: 0.2944 - val_accuracy: 0.6902 - val_precision_m: 0.8153 - val_recall_m: 0.7741 - val_f1_m: 0.7922\n","Epoch 32/1000\n","131/131 [==============================] - 1s 9ms/step - loss: 0.1765 - accuracy: 0.6301 - precision_m: 0.9158 - recall_m: 0.8760 - f1_m: 0.8945 - val_loss: 0.3068 - val_accuracy: 0.7007 - val_precision_m: 0.8158 - val_recall_m: 0.7416 - val_f1_m: 0.7750\n","Epoch 33/1000\n","131/131 [==============================] - 1s 9ms/step - loss: 0.1703 - accuracy: 0.6540 - precision_m: 0.9156 - recall_m: 0.8801 - f1_m: 0.8967 - val_loss: 0.3087 - val_accuracy: 0.6864 - val_precision_m: 0.8005 - val_recall_m: 0.7482 - val_f1_m: 0.7719\n","Epoch 34/1000\n","131/131 [==============================] - 1s 9ms/step - loss: 0.1685 - accuracy: 0.6477 - precision_m: 0.9169 - recall_m: 0.8737 - f1_m: 0.8941 - val_loss: 0.3030 - val_accuracy: 0.6988 - val_precision_m: 0.8074 - val_recall_m: 0.7807 - val_f1_m: 0.7920\n","Epoch 35/1000\n","131/131 [==============================] - 1s 9ms/step - loss: 0.1702 - accuracy: 0.6356 - precision_m: 0.9151 - recall_m: 0.8761 - f1_m: 0.8944 - val_loss: 0.3102 - val_accuracy: 0.6864 - val_precision_m: 0.8082 - val_recall_m: 0.7489 - val_f1_m: 0.7759\n","Epoch 36/1000\n","131/131 [==============================] - 1s 9ms/step - loss: 0.1654 - accuracy: 0.6646 - precision_m: 0.9191 - recall_m: 0.8753 - f1_m: 0.8959 - val_loss: 0.2948 - val_accuracy: 0.6911 - val_precision_m: 0.8203 - val_recall_m: 0.7711 - val_f1_m: 0.7929\n","Epoch 37/1000\n","131/131 [==============================] - 1s 9ms/step - loss: 0.1648 - accuracy: 0.6581 - precision_m: 0.9222 - recall_m: 0.8810 - f1_m: 0.9003 - val_loss: 0.2932 - val_accuracy: 0.6883 - val_precision_m: 0.8216 - val_recall_m: 0.7616 - val_f1_m: 0.7886\n","Epoch 38/1000\n","131/131 [==============================] - 1s 9ms/step - loss: 0.1708 - accuracy: 0.6471 - precision_m: 0.9153 - recall_m: 0.8689 - f1_m: 0.8906 - val_loss: 0.2940 - val_accuracy: 0.6864 - val_precision_m: 0.8220 - val_recall_m: 0.7555 - val_f1_m: 0.7852\n","Epoch 39/1000\n","131/131 [==============================] - 1s 8ms/step - loss: 0.1599 - accuracy: 0.6545 - precision_m: 0.9183 - recall_m: 0.8835 - f1_m: 0.8999 - val_loss: 0.3048 - val_accuracy: 0.7007 - val_precision_m: 0.8198 - val_recall_m: 0.7457 - val_f1_m: 0.7790\n","Epoch 40/1000\n","131/131 [==============================] - 1s 9ms/step - loss: 0.1619 - accuracy: 0.6387 - precision_m: 0.9189 - recall_m: 0.8808 - f1_m: 0.8987 - val_loss: 0.3114 - val_accuracy: 0.7073 - val_precision_m: 0.8136 - val_recall_m: 0.7623 - val_f1_m: 0.7852\n","Epoch 41/1000\n","131/131 [==============================] - 1s 8ms/step - loss: 0.1521 - accuracy: 0.6585 - precision_m: 0.9319 - recall_m: 0.8862 - f1_m: 0.9078 - val_loss: 0.3092 - val_accuracy: 0.6997 - val_precision_m: 0.8202 - val_recall_m: 0.7460 - val_f1_m: 0.7796\n","Epoch 42/1000\n","131/131 [==============================] - 1s 8ms/step - loss: 0.1591 - accuracy: 0.6375 - precision_m: 0.9312 - recall_m: 0.8829 - f1_m: 0.9056 - val_loss: 0.3114 - val_accuracy: 0.6978 - val_precision_m: 0.8026 - val_recall_m: 0.7739 - val_f1_m: 0.7859\n","Epoch 43/1000\n","131/131 [==============================] - 1s 9ms/step - loss: 0.1484 - accuracy: 0.6544 - precision_m: 0.9287 - recall_m: 0.8955 - f1_m: 0.9112 - val_loss: 0.3014 - val_accuracy: 0.7073 - val_precision_m: 0.8270 - val_recall_m: 0.7584 - val_f1_m: 0.7897\n","Epoch 44/1000\n","131/131 [==============================] - 1s 8ms/step - loss: 0.1452 - accuracy: 0.6545 - precision_m: 0.9273 - recall_m: 0.8946 - f1_m: 0.9101 - val_loss: 0.3080 - val_accuracy: 0.6930 - val_precision_m: 0.8189 - val_recall_m: 0.7545 - val_f1_m: 0.7830\n","Epoch 45/1000\n","131/131 [==============================] - 1s 9ms/step - loss: 0.1501 - accuracy: 0.6323 - precision_m: 0.9259 - recall_m: 0.8905 - f1_m: 0.9071 - val_loss: 0.3039 - val_accuracy: 0.6930 - val_precision_m: 0.8215 - val_recall_m: 0.7670 - val_f1_m: 0.7908\n","Epoch 46/1000\n","131/131 [==============================] - 1s 8ms/step - loss: 0.1453 - accuracy: 0.6493 - precision_m: 0.9291 - recall_m: 0.8956 - f1_m: 0.9112 - val_loss: 0.3117 - val_accuracy: 0.6902 - val_precision_m: 0.8139 - val_recall_m: 0.7690 - val_f1_m: 0.7885\n","Epoch 47/1000\n","131/131 [==============================] - 1s 8ms/step - loss: 0.1530 - accuracy: 0.6669 - precision_m: 0.9258 - recall_m: 0.8858 - f1_m: 0.9045 - val_loss: 0.3198 - val_accuracy: 0.7121 - val_precision_m: 0.8100 - val_recall_m: 0.7600 - val_f1_m: 0.7824\n","Epoch 48/1000\n","131/131 [==============================] - 1s 9ms/step - loss: 0.1459 - accuracy: 0.6392 - precision_m: 0.9297 - recall_m: 0.8945 - f1_m: 0.9111 - val_loss: 0.3147 - val_accuracy: 0.7140 - val_precision_m: 0.8191 - val_recall_m: 0.7529 - val_f1_m: 0.7827\n","Epoch 49/1000\n","131/131 [==============================] - 1s 9ms/step - loss: 0.1462 - accuracy: 0.6591 - precision_m: 0.9323 - recall_m: 0.9009 - f1_m: 0.9157 - val_loss: 0.3170 - val_accuracy: 0.6978 - val_precision_m: 0.8034 - val_recall_m: 0.7606 - val_f1_m: 0.7791\n","Epoch 50/1000\n","131/131 [==============================] - 1s 9ms/step - loss: 0.1502 - accuracy: 0.6476 - precision_m: 0.9213 - recall_m: 0.8934 - f1_m: 0.9065 - val_loss: 0.3227 - val_accuracy: 0.6940 - val_precision_m: 0.8115 - val_recall_m: 0.7494 - val_f1_m: 0.7771\n","Epoch 51/1000\n","131/131 [==============================] - 1s 9ms/step - loss: 0.1424 - accuracy: 0.6554 - precision_m: 0.9336 - recall_m: 0.8955 - f1_m: 0.9135 - val_loss: 0.3165 - val_accuracy: 0.7016 - val_precision_m: 0.7988 - val_recall_m: 0.7784 - val_f1_m: 0.7864\n","Epoch 52/1000\n","131/131 [==============================] - 1s 9ms/step - loss: 0.1357 - accuracy: 0.6472 - precision_m: 0.9342 - recall_m: 0.9043 - f1_m: 0.9185 - val_loss: 0.3107 - val_accuracy: 0.6988 - val_precision_m: 0.8122 - val_recall_m: 0.7715 - val_f1_m: 0.7898\n","Epoch 53/1000\n","131/131 [==============================] - 1s 9ms/step - loss: 0.1317 - accuracy: 0.6639 - precision_m: 0.9354 - recall_m: 0.9099 - f1_m: 0.9219 - val_loss: 0.3267 - val_accuracy: 0.7112 - val_precision_m: 0.7949 - val_recall_m: 0.7683 - val_f1_m: 0.7799\n","Epoch 54/1000\n","131/131 [==============================] - 1s 9ms/step - loss: 0.1288 - accuracy: 0.6619 - precision_m: 0.9369 - recall_m: 0.9101 - f1_m: 0.9227 - val_loss: 0.3211 - val_accuracy: 0.6949 - val_precision_m: 0.8157 - val_recall_m: 0.7525 - val_f1_m: 0.7811\n","Epoch 55/1000\n","131/131 [==============================] - 1s 9ms/step - loss: 0.1338 - accuracy: 0.6583 - precision_m: 0.9348 - recall_m: 0.8992 - f1_m: 0.9162 - val_loss: 0.3281 - val_accuracy: 0.7054 - val_precision_m: 0.8117 - val_recall_m: 0.7609 - val_f1_m: 0.7835\n","Epoch 56/1000\n","131/131 [==============================] - 1s 9ms/step - loss: 0.1303 - accuracy: 0.6713 - precision_m: 0.9361 - recall_m: 0.9065 - f1_m: 0.9204 - val_loss: 0.3170 - val_accuracy: 0.6921 - val_precision_m: 0.8264 - val_recall_m: 0.7458 - val_f1_m: 0.7820\n","Epoch 57/1000\n","131/131 [==============================] - 1s 9ms/step - loss: 0.1312 - accuracy: 0.6312 - precision_m: 0.9424 - recall_m: 0.9014 - f1_m: 0.9207 - val_loss: 0.3194 - val_accuracy: 0.6997 - val_precision_m: 0.8052 - val_recall_m: 0.7767 - val_f1_m: 0.7885\n","Epoch 58/1000\n","131/131 [==============================] - 1s 9ms/step - loss: 0.1229 - accuracy: 0.6539 - precision_m: 0.9406 - recall_m: 0.9128 - f1_m: 0.9259 - val_loss: 0.3219 - val_accuracy: 0.6816 - val_precision_m: 0.7992 - val_recall_m: 0.7733 - val_f1_m: 0.7837\n","Epoch 59/1000\n","131/131 [==============================] - 1s 9ms/step - loss: 0.1313 - accuracy: 0.6653 - precision_m: 0.9357 - recall_m: 0.9083 - f1_m: 0.9211 - val_loss: 0.3312 - val_accuracy: 0.6921 - val_precision_m: 0.8104 - val_recall_m: 0.7629 - val_f1_m: 0.7836\n","Epoch 60/1000\n","131/131 [==============================] - 1s 9ms/step - loss: 0.1232 - accuracy: 0.6629 - precision_m: 0.9385 - recall_m: 0.9095 - f1_m: 0.9230 - val_loss: 0.3313 - val_accuracy: 0.6988 - val_precision_m: 0.7983 - val_recall_m: 0.7618 - val_f1_m: 0.7772\n","Epoch 61/1000\n","131/131 [==============================] - 1s 8ms/step - loss: 0.1232 - accuracy: 0.6647 - precision_m: 0.9394 - recall_m: 0.9167 - f1_m: 0.9273 - val_loss: 0.3257 - val_accuracy: 0.6873 - val_precision_m: 0.8009 - val_recall_m: 0.7545 - val_f1_m: 0.7747\n","Epoch 62/1000\n","131/131 [==============================] - 1s 9ms/step - loss: 0.1267 - accuracy: 0.6668 - precision_m: 0.9330 - recall_m: 0.9117 - f1_m: 0.9216 - val_loss: 0.3290 - val_accuracy: 0.7007 - val_precision_m: 0.8123 - val_recall_m: 0.7432 - val_f1_m: 0.7745\n","Epoch 63/1000\n","131/131 [==============================] - 1s 9ms/step - loss: 0.1142 - accuracy: 0.6666 - precision_m: 0.9474 - recall_m: 0.9172 - f1_m: 0.9313 - val_loss: 0.3315 - val_accuracy: 0.6940 - val_precision_m: 0.8049 - val_recall_m: 0.7684 - val_f1_m: 0.7841\n","Epoch 64/1000\n","131/131 [==============================] - 1s 9ms/step - loss: 0.1152 - accuracy: 0.6588 - precision_m: 0.9471 - recall_m: 0.9165 - f1_m: 0.9309 - val_loss: 0.3358 - val_accuracy: 0.6959 - val_precision_m: 0.8017 - val_recall_m: 0.7714 - val_f1_m: 0.7846\n","Epoch 65/1000\n","131/131 [==============================] - 1s 9ms/step - loss: 0.1236 - accuracy: 0.6615 - precision_m: 0.9433 - recall_m: 0.9178 - f1_m: 0.9299 - val_loss: 0.3297 - val_accuracy: 0.6959 - val_precision_m: 0.8061 - val_recall_m: 0.7726 - val_f1_m: 0.7868\n","Epoch 66/1000\n","131/131 [==============================] - 1s 9ms/step - loss: 0.1197 - accuracy: 0.6483 - precision_m: 0.9436 - recall_m: 0.9195 - f1_m: 0.9307 - val_loss: 0.3242 - val_accuracy: 0.6873 - val_precision_m: 0.8031 - val_recall_m: 0.7667 - val_f1_m: 0.7821\n","Epoch 67/1000\n","131/131 [==============================] - 1s 9ms/step - loss: 0.1172 - accuracy: 0.6543 - precision_m: 0.9424 - recall_m: 0.9231 - f1_m: 0.9323 - val_loss: 0.3443 - val_accuracy: 0.7007 - val_precision_m: 0.8084 - val_recall_m: 0.7322 - val_f1_m: 0.7662\n","Epoch 68/1000\n","131/131 [==============================] - 1s 9ms/step - loss: 0.1178 - accuracy: 0.6606 - precision_m: 0.9457 - recall_m: 0.9145 - f1_m: 0.9294 - val_loss: 0.3340 - val_accuracy: 0.6978 - val_precision_m: 0.8138 - val_recall_m: 0.7592 - val_f1_m: 0.7838\n","Epoch 00068: early stopping\n","Score for fold 3: loss of 0.3028845489025116; accuracy of 67.44275093078613% ;precision_m of 0.8153212070465088 ;recall_m of 0.7394250631332397 ;            f1_m of 0.7740825414657593\n","------------------------------------------------------------------------\n","Score per fold\n","------------------------------------------------------------------------\n","> Fold 1 - Loss: 0.5834028720855713 - Accuracy: 55.01716732978821% - Precision: 0.8505698442459106 - Recall: 0.6880421042442322 - F1: 0.7575557231903076\n","------------------------------------------------------------------------\n","> Fold 2 - Loss: 0.3694007098674774 - Accuracy: 65.95419645309448% - Precision: 0.8045609593391418 - Recall: 0.7779812216758728 - F1: 0.7893940210342407\n","------------------------------------------------------------------------\n","> Fold 3 - Loss: 0.3028845489025116 - Accuracy: 67.44275093078613% - Precision: 0.8153212070465088 - Recall: 0.7394250631332397 - F1: 0.7740825414657593\n","------------------------------------------------------------------------\n","Average scores for all folds:\n","> Accuracy: 62.804704904556274 (+- 5.540051426781905)\n","> Precision: 0.8234840035438538\n","> Recall: 0.7351494630177816\n","> F1: 0.7736774285634359\n","> Loss: 0.41856271028518677\n","------------------------------------------------------------------------\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"SILsik9v8yDS"},"source":["# CNN with Cross Validation \r\n","CBOW with size 200\r\n","\r\n"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"DVoa64sO8sr8","executionInfo":{"elapsed":214190,"status":"ok","timestamp":1614101891049,"user":{"displayName":"Shanaka Chathuranga","photoUrl":"","userId":"01381725564551416324"},"user_tz":-330},"outputId":"8396e19d-06ca-47f6-d525-a25312230901"},"source":["N_FOLDS=3 \r\n","EPOCHS=1000\r\n","VALIDATION_SPLIT=0.2\r\n","BATCH_SIZE=32\r\n","PATIENCE=50\r\n","MONITOR='val_f1_m'\r\n","MONITOR_MODE='max'\r\n","shuffle=True\r\n","DROPOUT_VALUE_2=0.5\r\n","\r\n","def create_model():\r\n","    model = Sequential()\r\n","    embedding_layer = Embedding(vocab_length, 200,weights=[embedding_matrix],input_length=length_long_sentence, trainable=False)\r\n","    model.add(embedding_layer)\r\n","    model.add(Conv1D(256,3, activation='relu'))\r\n","    model.add(GlobalMaxPooling1D())\r\n","    model.add(Dropout(DROPOUT_VALUE_2))\r\n","    model.add(Flatten())\r\n","    model.add(Dense(6, activation='sigmoid'))\r\n","    model.compile(loss='binary_crossentropy', optimizer='adam',metrics=[\"accuracy\",precision_m,recall_m,f1_m])\r\n","    return model \r\n","\r\n","# Define per-fold score containers <-- these are new\r\n","acc_per_fold = []\r\n","loss_per_fold = []\r\n","f1_per_fold = []\r\n","precision_per_fold =[]\r\n","recall_per_fold=[]\r\n","\r\n","#Define dependencied for model loading\r\n","dependencies = {\r\n","    'recall_m': recall_m,\r\n","    'f1_m':f1_m,\r\n","    'precision_m':precision_m    \r\n","}\r\n","\r\n","vocab_length,padded_sentences,length_long_sentence,embedding_matrix=loadembedding_matrix(x,mainloc+'word_embeddings/w2v_cbow_200.txt',200)\r\n","\r\n","kf = KFold(n_splits=N_FOLDS)\r\n","fold_no = 1\r\n","for train_index, test_index in kf.split(padded_sentences, y):\r\n","    model=create_model()\r\n","    es = EarlyStopping(monitor=MONITOR, mode=MONITOR_MODE, verbose=1,patience= PATIENCE )\r\n","    history = model.fit(padded_sentences[train_index],y.values[train_index],epochs=EPOCHS,callbacks=[es],batch_size=BATCH_SIZE,shuffle=True,validation_split=VALIDATION_SPLIT)\r\n","    \r\n","    # Generate generalization metrics\r\n","    scores = model.evaluate(padded_sentences[test_index], y.values[test_index], verbose=0)\r\n","    print(f'Score for fold {fold_no}: {model.metrics_names[0]} of {scores[0]}; {model.metrics_names[1]} of {scores[1]*100}% ;{model.metrics_names[2]} of {scores[2]} ;{model.metrics_names[3]} of {scores[3]} ; \\\r\n","           {model.metrics_names[4]} of {scores[4]}')\r\n","    loss_per_fold.append(scores[0])\r\n","    acc_per_fold.append(scores[1] * 100)\r\n","    precision_per_fold.append(scores[2])\r\n","    recall_per_fold.append(scores[3])\r\n","    f1_per_fold.append(scores[4])\r\n","\r\n","    # Increase fold number\r\n","    fold_no = fold_no + 1\r\n","    \r\n","accuracy_crossval(acc_per_fold,loss_per_fold,f1_per_fold,precision_per_fold,recall_per_fold)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Epoch 1/1000\n","131/131 [==============================] - 2s 9ms/step - loss: 0.5160 - accuracy: 0.3857 - precision_m: 0.6231 - recall_m: 0.3569 - f1_m: 0.4398 - val_loss: 0.3020 - val_accuracy: 0.6174 - val_precision_m: 0.8144 - val_recall_m: 0.6987 - val_f1_m: 0.7500\n","Epoch 2/1000\n","131/131 [==============================] - 1s 7ms/step - loss: 0.3461 - accuracy: 0.5694 - precision_m: 0.7896 - recall_m: 0.6407 - f1_m: 0.7053 - val_loss: 0.2683 - val_accuracy: 0.6374 - val_precision_m: 0.8231 - val_recall_m: 0.7365 - val_f1_m: 0.7754\n","Epoch 3/1000\n","131/131 [==============================] - 1s 6ms/step - loss: 0.3081 - accuracy: 0.5948 - precision_m: 0.8039 - recall_m: 0.7069 - f1_m: 0.7507 - val_loss: 0.2591 - val_accuracy: 0.6422 - val_precision_m: 0.8253 - val_recall_m: 0.7495 - val_f1_m: 0.7840\n","Epoch 4/1000\n","131/131 [==============================] - 1s 7ms/step - loss: 0.2873 - accuracy: 0.6291 - precision_m: 0.8301 - recall_m: 0.7256 - f1_m: 0.7728 - val_loss: 0.2499 - val_accuracy: 0.6670 - val_precision_m: 0.8344 - val_recall_m: 0.7634 - val_f1_m: 0.7959\n","Epoch 5/1000\n","131/131 [==============================] - 1s 7ms/step - loss: 0.2803 - accuracy: 0.6377 - precision_m: 0.8219 - recall_m: 0.7358 - f1_m: 0.7752 - val_loss: 0.2455 - val_accuracy: 0.6651 - val_precision_m: 0.8348 - val_recall_m: 0.7651 - val_f1_m: 0.7969\n","Epoch 6/1000\n","131/131 [==============================] - 1s 6ms/step - loss: 0.2741 - accuracy: 0.6418 - precision_m: 0.8321 - recall_m: 0.7445 - f1_m: 0.7844 - val_loss: 0.2365 - val_accuracy: 0.6479 - val_precision_m: 0.8292 - val_recall_m: 0.7661 - val_f1_m: 0.7954\n","Epoch 7/1000\n","131/131 [==============================] - 1s 7ms/step - loss: 0.2689 - accuracy: 0.6323 - precision_m: 0.8345 - recall_m: 0.7472 - f1_m: 0.7871 - val_loss: 0.2374 - val_accuracy: 0.6737 - val_precision_m: 0.8381 - val_recall_m: 0.7773 - val_f1_m: 0.8054\n","Epoch 8/1000\n","131/131 [==============================] - 1s 6ms/step - loss: 0.2498 - accuracy: 0.6505 - precision_m: 0.8435 - recall_m: 0.7673 - f1_m: 0.8023 - val_loss: 0.2409 - val_accuracy: 0.6775 - val_precision_m: 0.8388 - val_recall_m: 0.7630 - val_f1_m: 0.7977\n","Epoch 9/1000\n","131/131 [==============================] - 1s 7ms/step - loss: 0.2450 - accuracy: 0.6457 - precision_m: 0.8472 - recall_m: 0.7732 - f1_m: 0.8075 - val_loss: 0.2362 - val_accuracy: 0.6708 - val_precision_m: 0.8304 - val_recall_m: 0.7838 - val_f1_m: 0.8054\n","Epoch 10/1000\n","131/131 [==============================] - 1s 7ms/step - loss: 0.2411 - accuracy: 0.6432 - precision_m: 0.8542 - recall_m: 0.7850 - f1_m: 0.8167 - val_loss: 0.2375 - val_accuracy: 0.6708 - val_precision_m: 0.8451 - val_recall_m: 0.7462 - val_f1_m: 0.7913\n","Epoch 11/1000\n","131/131 [==============================] - 1s 7ms/step - loss: 0.2287 - accuracy: 0.6581 - precision_m: 0.8608 - recall_m: 0.7826 - f1_m: 0.8188 - val_loss: 0.2364 - val_accuracy: 0.6803 - val_precision_m: 0.8322 - val_recall_m: 0.7835 - val_f1_m: 0.8061\n","Epoch 12/1000\n","131/131 [==============================] - 1s 7ms/step - loss: 0.2362 - accuracy: 0.6488 - precision_m: 0.8562 - recall_m: 0.7840 - f1_m: 0.8176 - val_loss: 0.2465 - val_accuracy: 0.6994 - val_precision_m: 0.8327 - val_recall_m: 0.7817 - val_f1_m: 0.8051\n","Epoch 13/1000\n","131/131 [==============================] - 1s 7ms/step - loss: 0.2236 - accuracy: 0.6684 - precision_m: 0.8663 - recall_m: 0.7937 - f1_m: 0.8274 - val_loss: 0.2406 - val_accuracy: 0.6765 - val_precision_m: 0.8308 - val_recall_m: 0.7913 - val_f1_m: 0.8094\n","Epoch 14/1000\n","131/131 [==============================] - 1s 7ms/step - loss: 0.2118 - accuracy: 0.6843 - precision_m: 0.8710 - recall_m: 0.8101 - f1_m: 0.8383 - val_loss: 0.2438 - val_accuracy: 0.6775 - val_precision_m: 0.8363 - val_recall_m: 0.7761 - val_f1_m: 0.8038\n","Epoch 15/1000\n","131/131 [==============================] - 1s 8ms/step - loss: 0.2148 - accuracy: 0.6684 - precision_m: 0.8675 - recall_m: 0.8100 - f1_m: 0.8366 - val_loss: 0.2355 - val_accuracy: 0.6622 - val_precision_m: 0.8347 - val_recall_m: 0.7761 - val_f1_m: 0.8031\n","Epoch 16/1000\n","131/131 [==============================] - 1s 7ms/step - loss: 0.2045 - accuracy: 0.6758 - precision_m: 0.8760 - recall_m: 0.8224 - f1_m: 0.8473 - val_loss: 0.2352 - val_accuracy: 0.6803 - val_precision_m: 0.8192 - val_recall_m: 0.7949 - val_f1_m: 0.8058\n","Epoch 17/1000\n","131/131 [==============================] - 1s 7ms/step - loss: 0.1996 - accuracy: 0.6807 - precision_m: 0.8814 - recall_m: 0.8278 - f1_m: 0.8525 - val_loss: 0.2377 - val_accuracy: 0.6851 - val_precision_m: 0.8427 - val_recall_m: 0.7567 - val_f1_m: 0.7959\n","Epoch 18/1000\n","131/131 [==============================] - 1s 7ms/step - loss: 0.2011 - accuracy: 0.6826 - precision_m: 0.8868 - recall_m: 0.8179 - f1_m: 0.8497 - val_loss: 0.2415 - val_accuracy: 0.6947 - val_precision_m: 0.8321 - val_recall_m: 0.7759 - val_f1_m: 0.8015\n","Epoch 19/1000\n","131/131 [==============================] - 1s 7ms/step - loss: 0.1876 - accuracy: 0.6773 - precision_m: 0.8859 - recall_m: 0.8339 - f1_m: 0.8582 - val_loss: 0.2361 - val_accuracy: 0.6823 - val_precision_m: 0.8272 - val_recall_m: 0.7768 - val_f1_m: 0.8000\n","Epoch 20/1000\n","131/131 [==============================] - 1s 7ms/step - loss: 0.1905 - accuracy: 0.6940 - precision_m: 0.8839 - recall_m: 0.8340 - f1_m: 0.8569 - val_loss: 0.2401 - val_accuracy: 0.6899 - val_precision_m: 0.8379 - val_recall_m: 0.7781 - val_f1_m: 0.8057\n","Epoch 21/1000\n","131/131 [==============================] - 1s 7ms/step - loss: 0.1920 - accuracy: 0.6906 - precision_m: 0.8857 - recall_m: 0.8367 - f1_m: 0.8592 - val_loss: 0.2385 - val_accuracy: 0.6784 - val_precision_m: 0.8152 - val_recall_m: 0.7996 - val_f1_m: 0.8061\n","Epoch 22/1000\n","131/131 [==============================] - 1s 6ms/step - loss: 0.1798 - accuracy: 0.6920 - precision_m: 0.8958 - recall_m: 0.8505 - f1_m: 0.8717 - val_loss: 0.2404 - val_accuracy: 0.7023 - val_precision_m: 0.8331 - val_recall_m: 0.7783 - val_f1_m: 0.8033\n","Epoch 23/1000\n","131/131 [==============================] - 1s 6ms/step - loss: 0.1848 - accuracy: 0.6771 - precision_m: 0.8932 - recall_m: 0.8344 - f1_m: 0.8618 - val_loss: 0.2389 - val_accuracy: 0.6775 - val_precision_m: 0.8236 - val_recall_m: 0.7795 - val_f1_m: 0.7998\n","Epoch 24/1000\n","131/131 [==============================] - 1s 7ms/step - loss: 0.1794 - accuracy: 0.6892 - precision_m: 0.8963 - recall_m: 0.8464 - f1_m: 0.8698 - val_loss: 0.2389 - val_accuracy: 0.6698 - val_precision_m: 0.8401 - val_recall_m: 0.7712 - val_f1_m: 0.8030\n","Epoch 25/1000\n","131/131 [==============================] - 1s 7ms/step - loss: 0.1676 - accuracy: 0.7008 - precision_m: 0.9080 - recall_m: 0.8507 - f1_m: 0.8777 - val_loss: 0.2476 - val_accuracy: 0.6956 - val_precision_m: 0.8201 - val_recall_m: 0.7896 - val_f1_m: 0.8032\n","Epoch 26/1000\n","131/131 [==============================] - 1s 6ms/step - loss: 0.1676 - accuracy: 0.7048 - precision_m: 0.9078 - recall_m: 0.8601 - f1_m: 0.8822 - val_loss: 0.2429 - val_accuracy: 0.6927 - val_precision_m: 0.8365 - val_recall_m: 0.7540 - val_f1_m: 0.7918\n","Epoch 27/1000\n","131/131 [==============================] - 1s 7ms/step - loss: 0.1619 - accuracy: 0.6868 - precision_m: 0.9131 - recall_m: 0.8550 - f1_m: 0.8821 - val_loss: 0.2454 - val_accuracy: 0.6698 - val_precision_m: 0.8190 - val_recall_m: 0.7890 - val_f1_m: 0.8026\n","Epoch 28/1000\n","131/131 [==============================] - 1s 6ms/step - loss: 0.1548 - accuracy: 0.6986 - precision_m: 0.9107 - recall_m: 0.8658 - f1_m: 0.8863 - val_loss: 0.2456 - val_accuracy: 0.6632 - val_precision_m: 0.8320 - val_recall_m: 0.7741 - val_f1_m: 0.8008\n","Epoch 29/1000\n","131/131 [==============================] - 1s 6ms/step - loss: 0.1618 - accuracy: 0.7021 - precision_m: 0.9114 - recall_m: 0.8572 - f1_m: 0.8826 - val_loss: 0.2445 - val_accuracy: 0.6651 - val_precision_m: 0.8300 - val_recall_m: 0.7684 - val_f1_m: 0.7965\n","Epoch 30/1000\n","131/131 [==============================] - 1s 7ms/step - loss: 0.1585 - accuracy: 0.7042 - precision_m: 0.9037 - recall_m: 0.8583 - f1_m: 0.8794 - val_loss: 0.2445 - val_accuracy: 0.6823 - val_precision_m: 0.8395 - val_recall_m: 0.7666 - val_f1_m: 0.7999\n","Epoch 31/1000\n","131/131 [==============================] - 1s 7ms/step - loss: 0.1555 - accuracy: 0.6945 - precision_m: 0.9140 - recall_m: 0.8614 - f1_m: 0.8860 - val_loss: 0.2435 - val_accuracy: 0.6708 - val_precision_m: 0.8333 - val_recall_m: 0.7614 - val_f1_m: 0.7946\n","Epoch 32/1000\n","131/131 [==============================] - 1s 7ms/step - loss: 0.1475 - accuracy: 0.7131 - precision_m: 0.9200 - recall_m: 0.8746 - f1_m: 0.8960 - val_loss: 0.2444 - val_accuracy: 0.6670 - val_precision_m: 0.8231 - val_recall_m: 0.7873 - val_f1_m: 0.8035\n","Epoch 33/1000\n","131/131 [==============================] - 1s 7ms/step - loss: 0.1445 - accuracy: 0.6983 - precision_m: 0.9130 - recall_m: 0.8702 - f1_m: 0.8901 - val_loss: 0.2452 - val_accuracy: 0.6851 - val_precision_m: 0.8280 - val_recall_m: 0.7675 - val_f1_m: 0.7956\n","Epoch 34/1000\n","131/131 [==============================] - 1s 7ms/step - loss: 0.1415 - accuracy: 0.7082 - precision_m: 0.9245 - recall_m: 0.8797 - f1_m: 0.9008 - val_loss: 0.2504 - val_accuracy: 0.6813 - val_precision_m: 0.8163 - val_recall_m: 0.7862 - val_f1_m: 0.7996\n","Epoch 35/1000\n","131/131 [==============================] - 1s 7ms/step - loss: 0.1436 - accuracy: 0.7029 - precision_m: 0.9224 - recall_m: 0.8768 - f1_m: 0.8982 - val_loss: 0.2509 - val_accuracy: 0.6737 - val_precision_m: 0.8136 - val_recall_m: 0.8000 - val_f1_m: 0.8056\n","Epoch 36/1000\n","131/131 [==============================] - 1s 7ms/step - loss: 0.1458 - accuracy: 0.6964 - precision_m: 0.9132 - recall_m: 0.8784 - f1_m: 0.8944 - val_loss: 0.2503 - val_accuracy: 0.6651 - val_precision_m: 0.8292 - val_recall_m: 0.7632 - val_f1_m: 0.7936\n","Epoch 37/1000\n","131/131 [==============================] - 1s 7ms/step - loss: 0.1392 - accuracy: 0.7045 - precision_m: 0.9202 - recall_m: 0.8837 - f1_m: 0.9008 - val_loss: 0.2507 - val_accuracy: 0.6765 - val_precision_m: 0.8215 - val_recall_m: 0.7834 - val_f1_m: 0.8009\n","Epoch 38/1000\n","131/131 [==============================] - 1s 7ms/step - loss: 0.1342 - accuracy: 0.7064 - precision_m: 0.9259 - recall_m: 0.8828 - f1_m: 0.9029 - val_loss: 0.2585 - val_accuracy: 0.6670 - val_precision_m: 0.8168 - val_recall_m: 0.7899 - val_f1_m: 0.8020\n","Epoch 39/1000\n","131/131 [==============================] - 1s 7ms/step - loss: 0.1324 - accuracy: 0.7174 - precision_m: 0.9227 - recall_m: 0.8884 - f1_m: 0.9043 - val_loss: 0.2533 - val_accuracy: 0.6708 - val_precision_m: 0.8244 - val_recall_m: 0.7808 - val_f1_m: 0.8010\n","Epoch 40/1000\n","131/131 [==============================] - 1s 7ms/step - loss: 0.1330 - accuracy: 0.7192 - precision_m: 0.9257 - recall_m: 0.8856 - f1_m: 0.9044 - val_loss: 0.2567 - val_accuracy: 0.6746 - val_precision_m: 0.8264 - val_recall_m: 0.7765 - val_f1_m: 0.7992\n","Epoch 41/1000\n","131/131 [==============================] - 1s 7ms/step - loss: 0.1316 - accuracy: 0.7120 - precision_m: 0.9303 - recall_m: 0.8922 - f1_m: 0.9103 - val_loss: 0.2522 - val_accuracy: 0.6813 - val_precision_m: 0.8302 - val_recall_m: 0.7759 - val_f1_m: 0.8009\n","Epoch 42/1000\n","131/131 [==============================] - 1s 7ms/step - loss: 0.1320 - accuracy: 0.7144 - precision_m: 0.9250 - recall_m: 0.8850 - f1_m: 0.9039 - val_loss: 0.2523 - val_accuracy: 0.6775 - val_precision_m: 0.8226 - val_recall_m: 0.7962 - val_f1_m: 0.8081\n","Epoch 43/1000\n","131/131 [==============================] - 1s 7ms/step - loss: 0.1246 - accuracy: 0.7147 - precision_m: 0.9277 - recall_m: 0.8988 - f1_m: 0.9124 - val_loss: 0.2606 - val_accuracy: 0.6756 - val_precision_m: 0.8193 - val_recall_m: 0.7899 - val_f1_m: 0.8031\n","Epoch 44/1000\n","131/131 [==============================] - 1s 8ms/step - loss: 0.1255 - accuracy: 0.7125 - precision_m: 0.9254 - recall_m: 0.8934 - f1_m: 0.9085 - val_loss: 0.2587 - val_accuracy: 0.6746 - val_precision_m: 0.8199 - val_recall_m: 0.7893 - val_f1_m: 0.8031\n","Epoch 45/1000\n","131/131 [==============================] - 1s 6ms/step - loss: 0.1201 - accuracy: 0.7142 - precision_m: 0.9275 - recall_m: 0.8978 - f1_m: 0.9120 - val_loss: 0.2598 - val_accuracy: 0.6727 - val_precision_m: 0.8211 - val_recall_m: 0.7823 - val_f1_m: 0.8000\n","Epoch 46/1000\n","131/131 [==============================] - 1s 7ms/step - loss: 0.1172 - accuracy: 0.7189 - precision_m: 0.9337 - recall_m: 0.9079 - f1_m: 0.9200 - val_loss: 0.2674 - val_accuracy: 0.6937 - val_precision_m: 0.8026 - val_recall_m: 0.8159 - val_f1_m: 0.8079\n","Epoch 47/1000\n","131/131 [==============================] - 1s 7ms/step - loss: 0.1121 - accuracy: 0.7085 - precision_m: 0.9291 - recall_m: 0.9159 - f1_m: 0.9217 - val_loss: 0.2626 - val_accuracy: 0.6718 - val_precision_m: 0.8189 - val_recall_m: 0.7773 - val_f1_m: 0.7964\n","Epoch 48/1000\n","131/131 [==============================] - 1s 7ms/step - loss: 0.1158 - accuracy: 0.7150 - precision_m: 0.9286 - recall_m: 0.9027 - f1_m: 0.9144 - val_loss: 0.2586 - val_accuracy: 0.6784 - val_precision_m: 0.8251 - val_recall_m: 0.7782 - val_f1_m: 0.7996\n","Epoch 49/1000\n","131/131 [==============================] - 1s 7ms/step - loss: 0.1153 - accuracy: 0.7077 - precision_m: 0.9319 - recall_m: 0.9052 - f1_m: 0.9177 - val_loss: 0.2632 - val_accuracy: 0.6908 - val_precision_m: 0.8188 - val_recall_m: 0.7829 - val_f1_m: 0.7996\n","Epoch 50/1000\n","131/131 [==============================] - 1s 7ms/step - loss: 0.1070 - accuracy: 0.7112 - precision_m: 0.9397 - recall_m: 0.9148 - f1_m: 0.9264 - val_loss: 0.2635 - val_accuracy: 0.6727 - val_precision_m: 0.8287 - val_recall_m: 0.7811 - val_f1_m: 0.8028\n","Epoch 51/1000\n","131/131 [==============================] - 1s 7ms/step - loss: 0.1103 - accuracy: 0.7222 - precision_m: 0.9392 - recall_m: 0.9040 - f1_m: 0.9207 - val_loss: 0.2642 - val_accuracy: 0.6908 - val_precision_m: 0.8123 - val_recall_m: 0.7968 - val_f1_m: 0.8033\n","Epoch 52/1000\n","131/131 [==============================] - 1s 7ms/step - loss: 0.1107 - accuracy: 0.7198 - precision_m: 0.9371 - recall_m: 0.9061 - f1_m: 0.9206 - val_loss: 0.2720 - val_accuracy: 0.6613 - val_precision_m: 0.8279 - val_recall_m: 0.7647 - val_f1_m: 0.7939\n","Epoch 53/1000\n","131/131 [==============================] - 1s 7ms/step - loss: 0.1063 - accuracy: 0.7061 - precision_m: 0.9434 - recall_m: 0.9122 - f1_m: 0.9270 - val_loss: 0.2699 - val_accuracy: 0.6851 - val_precision_m: 0.8191 - val_recall_m: 0.7726 - val_f1_m: 0.7939\n","Epoch 54/1000\n","131/131 [==============================] - 1s 7ms/step - loss: 0.1058 - accuracy: 0.7282 - precision_m: 0.9415 - recall_m: 0.9237 - f1_m: 0.9319 - val_loss: 0.2695 - val_accuracy: 0.6765 - val_precision_m: 0.8216 - val_recall_m: 0.7891 - val_f1_m: 0.8038\n","Epoch 55/1000\n","131/131 [==============================] - 1s 6ms/step - loss: 0.1042 - accuracy: 0.7310 - precision_m: 0.9419 - recall_m: 0.9197 - f1_m: 0.9302 - val_loss: 0.2674 - val_accuracy: 0.6813 - val_precision_m: 0.8334 - val_recall_m: 0.7721 - val_f1_m: 0.8003\n","Epoch 56/1000\n","131/131 [==============================] - 1s 7ms/step - loss: 0.1065 - accuracy: 0.7285 - precision_m: 0.9392 - recall_m: 0.9144 - f1_m: 0.9261 - val_loss: 0.2721 - val_accuracy: 0.6832 - val_precision_m: 0.8190 - val_recall_m: 0.7865 - val_f1_m: 0.8014\n","Epoch 57/1000\n","131/131 [==============================] - 1s 7ms/step - loss: 0.1035 - accuracy: 0.7235 - precision_m: 0.9415 - recall_m: 0.9159 - f1_m: 0.9280 - val_loss: 0.2727 - val_accuracy: 0.6880 - val_precision_m: 0.8258 - val_recall_m: 0.7716 - val_f1_m: 0.7968\n","Epoch 58/1000\n","131/131 [==============================] - 1s 7ms/step - loss: 0.1016 - accuracy: 0.7173 - precision_m: 0.9463 - recall_m: 0.9176 - f1_m: 0.9309 - val_loss: 0.2750 - val_accuracy: 0.6708 - val_precision_m: 0.8188 - val_recall_m: 0.7826 - val_f1_m: 0.7990\n","Epoch 59/1000\n","131/131 [==============================] - 1s 7ms/step - loss: 0.0997 - accuracy: 0.7315 - precision_m: 0.9449 - recall_m: 0.9211 - f1_m: 0.9324 - val_loss: 0.2777 - val_accuracy: 0.6832 - val_precision_m: 0.8183 - val_recall_m: 0.7780 - val_f1_m: 0.7966\n","Epoch 60/1000\n","131/131 [==============================] - 1s 7ms/step - loss: 0.0987 - accuracy: 0.7136 - precision_m: 0.9444 - recall_m: 0.9273 - f1_m: 0.9352 - val_loss: 0.2853 - val_accuracy: 0.6851 - val_precision_m: 0.8270 - val_recall_m: 0.7598 - val_f1_m: 0.7907\n","Epoch 61/1000\n","131/131 [==============================] - 1s 7ms/step - loss: 0.0983 - accuracy: 0.7407 - precision_m: 0.9466 - recall_m: 0.9164 - f1_m: 0.9307 - val_loss: 0.2847 - val_accuracy: 0.6832 - val_precision_m: 0.8190 - val_recall_m: 0.7760 - val_f1_m: 0.7955\n","Epoch 62/1000\n","131/131 [==============================] - 1s 7ms/step - loss: 0.0999 - accuracy: 0.7259 - precision_m: 0.9393 - recall_m: 0.9225 - f1_m: 0.9302 - val_loss: 0.2761 - val_accuracy: 0.6660 - val_precision_m: 0.8294 - val_recall_m: 0.7679 - val_f1_m: 0.7965\n","Epoch 63/1000\n","131/131 [==============================] - 1s 7ms/step - loss: 0.0958 - accuracy: 0.7359 - precision_m: 0.9436 - recall_m: 0.9228 - f1_m: 0.9327 - val_loss: 0.2850 - val_accuracy: 0.6727 - val_precision_m: 0.8125 - val_recall_m: 0.7929 - val_f1_m: 0.8012\n","Epoch 00063: early stopping\n","Score for fold 1: loss of 0.5433487892150879; accuracy of 50.66768527030945% ;precision_m of 0.8339507579803467 ;recall_m of 0.7151877880096436 ;            f1_m of 0.7678025960922241\n","Epoch 1/1000\n","131/131 [==============================] - 2s 8ms/step - loss: 0.5572 - accuracy: 0.3573 - precision_m: 0.6053 - recall_m: 0.3624 - f1_m: 0.4450 - val_loss: 0.3299 - val_accuracy: 0.6549 - val_precision_m: 0.7985 - val_recall_m: 0.6876 - val_f1_m: 0.7364\n","Epoch 2/1000\n","131/131 [==============================] - 1s 7ms/step - loss: 0.3761 - accuracy: 0.5462 - precision_m: 0.7695 - recall_m: 0.6552 - f1_m: 0.7060 - val_loss: 0.2795 - val_accuracy: 0.6692 - val_precision_m: 0.8340 - val_recall_m: 0.6999 - val_f1_m: 0.7589\n","Epoch 3/1000\n","131/131 [==============================] - 1s 7ms/step - loss: 0.3312 - accuracy: 0.5878 - precision_m: 0.8102 - recall_m: 0.7212 - f1_m: 0.7614 - val_loss: 0.2686 - val_accuracy: 0.6273 - val_precision_m: 0.8030 - val_recall_m: 0.7421 - val_f1_m: 0.7694\n","Epoch 4/1000\n","131/131 [==============================] - 1s 8ms/step - loss: 0.3097 - accuracy: 0.5753 - precision_m: 0.8184 - recall_m: 0.7503 - f1_m: 0.7813 - val_loss: 0.2641 - val_accuracy: 0.6873 - val_precision_m: 0.8160 - val_recall_m: 0.7661 - val_f1_m: 0.7886\n","Epoch 5/1000\n","131/131 [==============================] - 1s 7ms/step - loss: 0.2941 - accuracy: 0.5891 - precision_m: 0.8338 - recall_m: 0.7553 - f1_m: 0.7913 - val_loss: 0.2578 - val_accuracy: 0.6864 - val_precision_m: 0.8275 - val_recall_m: 0.7662 - val_f1_m: 0.7938\n","Epoch 6/1000\n","131/131 [==============================] - 1s 7ms/step - loss: 0.2863 - accuracy: 0.6125 - precision_m: 0.8400 - recall_m: 0.7692 - f1_m: 0.8022 - val_loss: 0.2507 - val_accuracy: 0.6949 - val_precision_m: 0.8389 - val_recall_m: 0.7690 - val_f1_m: 0.8007\n","Epoch 7/1000\n","131/131 [==============================] - 1s 7ms/step - loss: 0.2784 - accuracy: 0.6105 - precision_m: 0.8403 - recall_m: 0.7723 - f1_m: 0.8034 - val_loss: 0.2429 - val_accuracy: 0.6978 - val_precision_m: 0.8327 - val_recall_m: 0.7760 - val_f1_m: 0.8019\n","Epoch 8/1000\n","131/131 [==============================] - 1s 7ms/step - loss: 0.2696 - accuracy: 0.6037 - precision_m: 0.8476 - recall_m: 0.7820 - f1_m: 0.8124 - val_loss: 0.2467 - val_accuracy: 0.6997 - val_precision_m: 0.8131 - val_recall_m: 0.8008 - val_f1_m: 0.8056\n","Epoch 9/1000\n","131/131 [==============================] - 1s 7ms/step - loss: 0.2620 - accuracy: 0.6106 - precision_m: 0.8500 - recall_m: 0.7954 - f1_m: 0.8204 - val_loss: 0.2409 - val_accuracy: 0.6892 - val_precision_m: 0.8271 - val_recall_m: 0.7912 - val_f1_m: 0.8072\n","Epoch 10/1000\n","131/131 [==============================] - 1s 7ms/step - loss: 0.2530 - accuracy: 0.6309 - precision_m: 0.8566 - recall_m: 0.7985 - f1_m: 0.8255 - val_loss: 0.2471 - val_accuracy: 0.7064 - val_precision_m: 0.8385 - val_recall_m: 0.7593 - val_f1_m: 0.7948\n","Epoch 11/1000\n","131/131 [==============================] - 1s 7ms/step - loss: 0.2490 - accuracy: 0.6245 - precision_m: 0.8603 - recall_m: 0.8046 - f1_m: 0.8304 - val_loss: 0.2417 - val_accuracy: 0.6940 - val_precision_m: 0.8516 - val_recall_m: 0.7635 - val_f1_m: 0.8038\n","Epoch 12/1000\n","131/131 [==============================] - 1s 7ms/step - loss: 0.2425 - accuracy: 0.6247 - precision_m: 0.8704 - recall_m: 0.8043 - f1_m: 0.8346 - val_loss: 0.2378 - val_accuracy: 0.6988 - val_precision_m: 0.8288 - val_recall_m: 0.7927 - val_f1_m: 0.8092\n","Epoch 13/1000\n","131/131 [==============================] - 1s 7ms/step - loss: 0.2355 - accuracy: 0.6182 - precision_m: 0.8701 - recall_m: 0.8141 - f1_m: 0.8401 - val_loss: 0.2423 - val_accuracy: 0.6921 - val_precision_m: 0.8316 - val_recall_m: 0.7992 - val_f1_m: 0.8134\n","Epoch 14/1000\n","131/131 [==============================] - 1s 7ms/step - loss: 0.2287 - accuracy: 0.6454 - precision_m: 0.8723 - recall_m: 0.8260 - f1_m: 0.8470 - val_loss: 0.2399 - val_accuracy: 0.6883 - val_precision_m: 0.8385 - val_recall_m: 0.7690 - val_f1_m: 0.8005\n","Epoch 15/1000\n","131/131 [==============================] - 1s 7ms/step - loss: 0.2309 - accuracy: 0.6263 - precision_m: 0.8750 - recall_m: 0.8120 - f1_m: 0.8413 - val_loss: 0.2403 - val_accuracy: 0.6778 - val_precision_m: 0.8282 - val_recall_m: 0.7934 - val_f1_m: 0.8089\n","Epoch 16/1000\n","131/131 [==============================] - 1s 7ms/step - loss: 0.2162 - accuracy: 0.6290 - precision_m: 0.8823 - recall_m: 0.8303 - f1_m: 0.8547 - val_loss: 0.2384 - val_accuracy: 0.6873 - val_precision_m: 0.8364 - val_recall_m: 0.7907 - val_f1_m: 0.8115\n","Epoch 17/1000\n","131/131 [==============================] - 1s 7ms/step - loss: 0.2149 - accuracy: 0.6505 - precision_m: 0.8846 - recall_m: 0.8222 - f1_m: 0.8511 - val_loss: 0.2361 - val_accuracy: 0.6835 - val_precision_m: 0.8345 - val_recall_m: 0.7948 - val_f1_m: 0.8130\n","Epoch 18/1000\n","131/131 [==============================] - 1s 7ms/step - loss: 0.2158 - accuracy: 0.6438 - precision_m: 0.8782 - recall_m: 0.8342 - f1_m: 0.8547 - val_loss: 0.2452 - val_accuracy: 0.7178 - val_precision_m: 0.8381 - val_recall_m: 0.7734 - val_f1_m: 0.8033\n","Epoch 19/1000\n","131/131 [==============================] - 1s 7ms/step - loss: 0.2052 - accuracy: 0.6519 - precision_m: 0.8884 - recall_m: 0.8354 - f1_m: 0.8602 - val_loss: 0.2391 - val_accuracy: 0.6902 - val_precision_m: 0.8450 - val_recall_m: 0.7743 - val_f1_m: 0.8067\n","Epoch 20/1000\n","131/131 [==============================] - 1s 7ms/step - loss: 0.2063 - accuracy: 0.6566 - precision_m: 0.8916 - recall_m: 0.8327 - f1_m: 0.8601 - val_loss: 0.2386 - val_accuracy: 0.6949 - val_precision_m: 0.8278 - val_recall_m: 0.7922 - val_f1_m: 0.8086\n","Epoch 21/1000\n","131/131 [==============================] - 1s 7ms/step - loss: 0.2039 - accuracy: 0.6417 - precision_m: 0.8966 - recall_m: 0.8462 - f1_m: 0.8697 - val_loss: 0.2411 - val_accuracy: 0.6949 - val_precision_m: 0.8289 - val_recall_m: 0.7899 - val_f1_m: 0.8076\n","Epoch 22/1000\n","131/131 [==============================] - 1s 7ms/step - loss: 0.2002 - accuracy: 0.6446 - precision_m: 0.8907 - recall_m: 0.8489 - f1_m: 0.8683 - val_loss: 0.2390 - val_accuracy: 0.7121 - val_precision_m: 0.8526 - val_recall_m: 0.7681 - val_f1_m: 0.8067\n","Epoch 23/1000\n","131/131 [==============================] - 1s 7ms/step - loss: 0.1893 - accuracy: 0.6621 - precision_m: 0.9042 - recall_m: 0.8482 - f1_m: 0.8744 - val_loss: 0.2435 - val_accuracy: 0.7131 - val_precision_m: 0.8406 - val_recall_m: 0.7769 - val_f1_m: 0.8061\n","Epoch 24/1000\n","131/131 [==============================] - 1s 7ms/step - loss: 0.1907 - accuracy: 0.6564 - precision_m: 0.9008 - recall_m: 0.8601 - f1_m: 0.8790 - val_loss: 0.2393 - val_accuracy: 0.7007 - val_precision_m: 0.8522 - val_recall_m: 0.7704 - val_f1_m: 0.8080\n","Epoch 25/1000\n","131/131 [==============================] - 1s 7ms/step - loss: 0.1924 - accuracy: 0.6479 - precision_m: 0.9023 - recall_m: 0.8436 - f1_m: 0.8709 - val_loss: 0.2433 - val_accuracy: 0.7112 - val_precision_m: 0.8314 - val_recall_m: 0.7862 - val_f1_m: 0.8068\n","Epoch 26/1000\n","131/131 [==============================] - 1s 7ms/step - loss: 0.1809 - accuracy: 0.6625 - precision_m: 0.8998 - recall_m: 0.8632 - f1_m: 0.8804 - val_loss: 0.2409 - val_accuracy: 0.6959 - val_precision_m: 0.8325 - val_recall_m: 0.7820 - val_f1_m: 0.8053\n","Epoch 27/1000\n","131/131 [==============================] - 1s 7ms/step - loss: 0.1824 - accuracy: 0.6661 - precision_m: 0.9033 - recall_m: 0.8586 - f1_m: 0.8795 - val_loss: 0.2445 - val_accuracy: 0.6969 - val_precision_m: 0.8385 - val_recall_m: 0.7700 - val_f1_m: 0.8015\n","Epoch 28/1000\n","131/131 [==============================] - 1s 8ms/step - loss: 0.1788 - accuracy: 0.6521 - precision_m: 0.9107 - recall_m: 0.8574 - f1_m: 0.8822 - val_loss: 0.2394 - val_accuracy: 0.6911 - val_precision_m: 0.8514 - val_recall_m: 0.7710 - val_f1_m: 0.8079\n","Epoch 29/1000\n","131/131 [==============================] - 1s 7ms/step - loss: 0.1790 - accuracy: 0.6666 - precision_m: 0.9042 - recall_m: 0.8629 - f1_m: 0.8822 - val_loss: 0.2447 - val_accuracy: 0.7073 - val_precision_m: 0.8302 - val_recall_m: 0.7952 - val_f1_m: 0.8113\n","Epoch 30/1000\n","131/131 [==============================] - 1s 7ms/step - loss: 0.1767 - accuracy: 0.6561 - precision_m: 0.9069 - recall_m: 0.8690 - f1_m: 0.8869 - val_loss: 0.2433 - val_accuracy: 0.6921 - val_precision_m: 0.8371 - val_recall_m: 0.7829 - val_f1_m: 0.8080\n","Epoch 31/1000\n","131/131 [==============================] - 1s 7ms/step - loss: 0.1756 - accuracy: 0.6522 - precision_m: 0.9090 - recall_m: 0.8659 - f1_m: 0.8863 - val_loss: 0.2433 - val_accuracy: 0.6949 - val_precision_m: 0.8416 - val_recall_m: 0.7729 - val_f1_m: 0.8043\n","Epoch 32/1000\n","131/131 [==============================] - 1s 7ms/step - loss: 0.1626 - accuracy: 0.6729 - precision_m: 0.9167 - recall_m: 0.8770 - f1_m: 0.8957 - val_loss: 0.2464 - val_accuracy: 0.7054 - val_precision_m: 0.8392 - val_recall_m: 0.7916 - val_f1_m: 0.8137\n","Epoch 33/1000\n","131/131 [==============================] - 1s 7ms/step - loss: 0.1627 - accuracy: 0.6671 - precision_m: 0.9165 - recall_m: 0.8784 - f1_m: 0.8962 - val_loss: 0.2459 - val_accuracy: 0.7102 - val_precision_m: 0.8305 - val_recall_m: 0.7895 - val_f1_m: 0.8082\n","Epoch 34/1000\n","131/131 [==============================] - 1s 7ms/step - loss: 0.1614 - accuracy: 0.6754 - precision_m: 0.9170 - recall_m: 0.8794 - f1_m: 0.8968 - val_loss: 0.2455 - val_accuracy: 0.6969 - val_precision_m: 0.8454 - val_recall_m: 0.7774 - val_f1_m: 0.8086\n","Epoch 35/1000\n","131/131 [==============================] - 1s 7ms/step - loss: 0.1605 - accuracy: 0.6651 - precision_m: 0.9225 - recall_m: 0.8790 - f1_m: 0.8996 - val_loss: 0.2464 - val_accuracy: 0.6930 - val_precision_m: 0.8392 - val_recall_m: 0.7711 - val_f1_m: 0.8028\n","Epoch 36/1000\n","131/131 [==============================] - 1s 7ms/step - loss: 0.1536 - accuracy: 0.6534 - precision_m: 0.9224 - recall_m: 0.8837 - f1_m: 0.9019 - val_loss: 0.2477 - val_accuracy: 0.6978 - val_precision_m: 0.8286 - val_recall_m: 0.7878 - val_f1_m: 0.8067\n","Epoch 37/1000\n","131/131 [==============================] - 1s 7ms/step - loss: 0.1552 - accuracy: 0.6571 - precision_m: 0.9149 - recall_m: 0.8791 - f1_m: 0.8959 - val_loss: 0.2468 - val_accuracy: 0.7064 - val_precision_m: 0.8297 - val_recall_m: 0.7923 - val_f1_m: 0.8093\n","Epoch 38/1000\n","131/131 [==============================] - 1s 7ms/step - loss: 0.1495 - accuracy: 0.6625 - precision_m: 0.9220 - recall_m: 0.8912 - f1_m: 0.9055 - val_loss: 0.2499 - val_accuracy: 0.7073 - val_precision_m: 0.8374 - val_recall_m: 0.7808 - val_f1_m: 0.8071\n","Epoch 39/1000\n","131/131 [==============================] - 1s 7ms/step - loss: 0.1524 - accuracy: 0.6681 - precision_m: 0.9208 - recall_m: 0.8890 - f1_m: 0.9037 - val_loss: 0.2558 - val_accuracy: 0.6854 - val_precision_m: 0.8184 - val_recall_m: 0.7858 - val_f1_m: 0.8003\n","Epoch 40/1000\n","131/131 [==============================] - 1s 7ms/step - loss: 0.1547 - accuracy: 0.6480 - precision_m: 0.9152 - recall_m: 0.8827 - f1_m: 0.8978 - val_loss: 0.2504 - val_accuracy: 0.7121 - val_precision_m: 0.8262 - val_recall_m: 0.7911 - val_f1_m: 0.8069\n","Epoch 41/1000\n","131/131 [==============================] - 1s 7ms/step - loss: 0.1453 - accuracy: 0.6694 - precision_m: 0.9193 - recall_m: 0.8941 - f1_m: 0.9060 - val_loss: 0.2508 - val_accuracy: 0.7121 - val_precision_m: 0.8312 - val_recall_m: 0.7852 - val_f1_m: 0.8061\n","Epoch 42/1000\n","131/131 [==============================] - 1s 7ms/step - loss: 0.1414 - accuracy: 0.6508 - precision_m: 0.9348 - recall_m: 0.8961 - f1_m: 0.9144 - val_loss: 0.2483 - val_accuracy: 0.7064 - val_precision_m: 0.8386 - val_recall_m: 0.7784 - val_f1_m: 0.8061\n","Epoch 43/1000\n","131/131 [==============================] - 1s 7ms/step - loss: 0.1459 - accuracy: 0.6584 - precision_m: 0.9264 - recall_m: 0.8950 - f1_m: 0.9098 - val_loss: 0.2504 - val_accuracy: 0.7064 - val_precision_m: 0.8508 - val_recall_m: 0.7563 - val_f1_m: 0.7989\n","Epoch 44/1000\n","131/131 [==============================] - 1s 7ms/step - loss: 0.1443 - accuracy: 0.6610 - precision_m: 0.9308 - recall_m: 0.8876 - f1_m: 0.9078 - val_loss: 0.2541 - val_accuracy: 0.7169 - val_precision_m: 0.8306 - val_recall_m: 0.7882 - val_f1_m: 0.8080\n","Epoch 45/1000\n","131/131 [==============================] - 1s 7ms/step - loss: 0.1388 - accuracy: 0.6614 - precision_m: 0.9314 - recall_m: 0.8957 - f1_m: 0.9126 - val_loss: 0.2522 - val_accuracy: 0.7121 - val_precision_m: 0.8278 - val_recall_m: 0.7939 - val_f1_m: 0.8091\n","Epoch 46/1000\n","131/131 [==============================] - 1s 7ms/step - loss: 0.1320 - accuracy: 0.6715 - precision_m: 0.9311 - recall_m: 0.9064 - f1_m: 0.9179 - val_loss: 0.2543 - val_accuracy: 0.6978 - val_precision_m: 0.8388 - val_recall_m: 0.7669 - val_f1_m: 0.8000\n","Epoch 47/1000\n","131/131 [==============================] - 1s 7ms/step - loss: 0.1335 - accuracy: 0.6645 - precision_m: 0.9317 - recall_m: 0.8967 - f1_m: 0.9133 - val_loss: 0.2565 - val_accuracy: 0.7159 - val_precision_m: 0.8255 - val_recall_m: 0.7892 - val_f1_m: 0.8060\n","Epoch 48/1000\n","131/131 [==============================] - 1s 7ms/step - loss: 0.1339 - accuracy: 0.6660 - precision_m: 0.9303 - recall_m: 0.9001 - f1_m: 0.9143 - val_loss: 0.2594 - val_accuracy: 0.7207 - val_precision_m: 0.8282 - val_recall_m: 0.7796 - val_f1_m: 0.8018\n","Epoch 49/1000\n","131/131 [==============================] - 1s 7ms/step - loss: 0.1408 - accuracy: 0.6769 - precision_m: 0.9292 - recall_m: 0.8962 - f1_m: 0.9117 - val_loss: 0.2606 - val_accuracy: 0.7112 - val_precision_m: 0.8275 - val_recall_m: 0.7827 - val_f1_m: 0.8032\n","Epoch 50/1000\n","131/131 [==============================] - 1s 7ms/step - loss: 0.1271 - accuracy: 0.6671 - precision_m: 0.9372 - recall_m: 0.9099 - f1_m: 0.9228 - val_loss: 0.2593 - val_accuracy: 0.7045 - val_precision_m: 0.8217 - val_recall_m: 0.8022 - val_f1_m: 0.8108\n","Epoch 51/1000\n","131/131 [==============================] - 1s 7ms/step - loss: 0.1276 - accuracy: 0.6758 - precision_m: 0.9337 - recall_m: 0.9123 - f1_m: 0.9221 - val_loss: 0.2615 - val_accuracy: 0.7140 - val_precision_m: 0.8285 - val_recall_m: 0.7936 - val_f1_m: 0.8094\n","Epoch 52/1000\n","131/131 [==============================] - 1s 8ms/step - loss: 0.1313 - accuracy: 0.6625 - precision_m: 0.9262 - recall_m: 0.9024 - f1_m: 0.9135 - val_loss: 0.2607 - val_accuracy: 0.7083 - val_precision_m: 0.8346 - val_recall_m: 0.7855 - val_f1_m: 0.8076\n","Epoch 53/1000\n","131/131 [==============================] - 1s 7ms/step - loss: 0.1260 - accuracy: 0.6757 - precision_m: 0.9368 - recall_m: 0.9088 - f1_m: 0.9222 - val_loss: 0.2617 - val_accuracy: 0.7197 - val_precision_m: 0.8310 - val_recall_m: 0.7849 - val_f1_m: 0.8059\n","Epoch 54/1000\n","131/131 [==============================] - 1s 7ms/step - loss: 0.1245 - accuracy: 0.6757 - precision_m: 0.9374 - recall_m: 0.9084 - f1_m: 0.9222 - val_loss: 0.2640 - val_accuracy: 0.6940 - val_precision_m: 0.8367 - val_recall_m: 0.7756 - val_f1_m: 0.8036\n","Epoch 55/1000\n","131/131 [==============================] - 1s 7ms/step - loss: 0.1207 - accuracy: 0.6811 - precision_m: 0.9430 - recall_m: 0.9109 - f1_m: 0.9263 - val_loss: 0.2635 - val_accuracy: 0.7026 - val_precision_m: 0.8265 - val_recall_m: 0.7864 - val_f1_m: 0.8046\n","Epoch 56/1000\n","131/131 [==============================] - 1s 7ms/step - loss: 0.1292 - accuracy: 0.6670 - precision_m: 0.9344 - recall_m: 0.9022 - f1_m: 0.9173 - val_loss: 0.2684 - val_accuracy: 0.7245 - val_precision_m: 0.8255 - val_recall_m: 0.7831 - val_f1_m: 0.8025\n","Epoch 57/1000\n","131/131 [==============================] - 1s 7ms/step - loss: 0.1175 - accuracy: 0.6798 - precision_m: 0.9427 - recall_m: 0.9185 - f1_m: 0.9299 - val_loss: 0.2618 - val_accuracy: 0.7035 - val_precision_m: 0.8361 - val_recall_m: 0.7794 - val_f1_m: 0.8052\n","Epoch 58/1000\n","131/131 [==============================] - 1s 7ms/step - loss: 0.1173 - accuracy: 0.6734 - precision_m: 0.9389 - recall_m: 0.9135 - f1_m: 0.9256 - val_loss: 0.2657 - val_accuracy: 0.6921 - val_precision_m: 0.8294 - val_recall_m: 0.7798 - val_f1_m: 0.8021\n","Epoch 59/1000\n","131/131 [==============================] - 1s 7ms/step - loss: 0.1157 - accuracy: 0.6775 - precision_m: 0.9428 - recall_m: 0.9142 - f1_m: 0.9278 - val_loss: 0.2657 - val_accuracy: 0.6911 - val_precision_m: 0.8350 - val_recall_m: 0.7729 - val_f1_m: 0.8009\n","Epoch 60/1000\n","131/131 [==============================] - 1s 7ms/step - loss: 0.1132 - accuracy: 0.6666 - precision_m: 0.9503 - recall_m: 0.9236 - f1_m: 0.9362 - val_loss: 0.2679 - val_accuracy: 0.6969 - val_precision_m: 0.8343 - val_recall_m: 0.7773 - val_f1_m: 0.8033\n","Epoch 61/1000\n","131/131 [==============================] - 1s 7ms/step - loss: 0.1175 - accuracy: 0.6730 - precision_m: 0.9398 - recall_m: 0.9160 - f1_m: 0.9273 - val_loss: 0.2669 - val_accuracy: 0.7159 - val_precision_m: 0.8267 - val_recall_m: 0.7894 - val_f1_m: 0.8064\n","Epoch 62/1000\n","131/131 [==============================] - 1s 7ms/step - loss: 0.1135 - accuracy: 0.6725 - precision_m: 0.9425 - recall_m: 0.9199 - f1_m: 0.9304 - val_loss: 0.2684 - val_accuracy: 0.7150 - val_precision_m: 0.8188 - val_recall_m: 0.7968 - val_f1_m: 0.8061\n","Epoch 63/1000\n","131/131 [==============================] - 1s 7ms/step - loss: 0.1159 - accuracy: 0.6847 - precision_m: 0.9423 - recall_m: 0.9158 - f1_m: 0.9283 - val_loss: 0.2694 - val_accuracy: 0.7112 - val_precision_m: 0.8188 - val_recall_m: 0.7943 - val_f1_m: 0.8050\n","Epoch 64/1000\n","131/131 [==============================] - 1s 7ms/step - loss: 0.1168 - accuracy: 0.6698 - precision_m: 0.9418 - recall_m: 0.9181 - f1_m: 0.9290 - val_loss: 0.2732 - val_accuracy: 0.7016 - val_precision_m: 0.8121 - val_recall_m: 0.7899 - val_f1_m: 0.7995\n","Epoch 65/1000\n","131/131 [==============================] - 1s 7ms/step - loss: 0.1076 - accuracy: 0.6647 - precision_m: 0.9453 - recall_m: 0.9245 - f1_m: 0.9343 - val_loss: 0.2657 - val_accuracy: 0.7016 - val_precision_m: 0.8375 - val_recall_m: 0.7752 - val_f1_m: 0.8034\n","Epoch 66/1000\n","131/131 [==============================] - 1s 7ms/step - loss: 0.1034 - accuracy: 0.6847 - precision_m: 0.9464 - recall_m: 0.9272 - f1_m: 0.9361 - val_loss: 0.2755 - val_accuracy: 0.6978 - val_precision_m: 0.8291 - val_recall_m: 0.7886 - val_f1_m: 0.8068\n","Epoch 67/1000\n","131/131 [==============================] - 1s 7ms/step - loss: 0.1108 - accuracy: 0.6765 - precision_m: 0.9419 - recall_m: 0.9205 - f1_m: 0.9306 - val_loss: 0.2660 - val_accuracy: 0.7159 - val_precision_m: 0.8477 - val_recall_m: 0.7653 - val_f1_m: 0.8031\n","Epoch 68/1000\n","131/131 [==============================] - 1s 7ms/step - loss: 0.1125 - accuracy: 0.6826 - precision_m: 0.9417 - recall_m: 0.9201 - f1_m: 0.9303 - val_loss: 0.2783 - val_accuracy: 0.7216 - val_precision_m: 0.8159 - val_recall_m: 0.7933 - val_f1_m: 0.8028\n","Epoch 69/1000\n","131/131 [==============================] - 1s 7ms/step - loss: 0.1059 - accuracy: 0.6790 - precision_m: 0.9476 - recall_m: 0.9285 - f1_m: 0.9375 - val_loss: 0.2684 - val_accuracy: 0.7150 - val_precision_m: 0.8506 - val_recall_m: 0.7750 - val_f1_m: 0.8093\n","Epoch 70/1000\n","131/131 [==============================] - 1s 7ms/step - loss: 0.1076 - accuracy: 0.6739 - precision_m: 0.9468 - recall_m: 0.9250 - f1_m: 0.9353 - val_loss: 0.2719 - val_accuracy: 0.7016 - val_precision_m: 0.8398 - val_recall_m: 0.7787 - val_f1_m: 0.8064\n","Epoch 71/1000\n","131/131 [==============================] - 1s 7ms/step - loss: 0.1056 - accuracy: 0.6725 - precision_m: 0.9485 - recall_m: 0.9218 - f1_m: 0.9345 - val_loss: 0.2746 - val_accuracy: 0.6940 - val_precision_m: 0.8270 - val_recall_m: 0.7816 - val_f1_m: 0.8021\n","Epoch 72/1000\n","131/131 [==============================] - 1s 7ms/step - loss: 0.1009 - accuracy: 0.6809 - precision_m: 0.9478 - recall_m: 0.9343 - f1_m: 0.9404 - val_loss: 0.2718 - val_accuracy: 0.7131 - val_precision_m: 0.8347 - val_recall_m: 0.7831 - val_f1_m: 0.8066\n","Epoch 73/1000\n","131/131 [==============================] - 1s 7ms/step - loss: 0.1025 - accuracy: 0.6914 - precision_m: 0.9532 - recall_m: 0.9243 - f1_m: 0.9379 - val_loss: 0.2699 - val_accuracy: 0.7073 - val_precision_m: 0.8428 - val_recall_m: 0.7763 - val_f1_m: 0.8067\n","Epoch 74/1000\n","131/131 [==============================] - 1s 7ms/step - loss: 0.1012 - accuracy: 0.6780 - precision_m: 0.9501 - recall_m: 0.9279 - f1_m: 0.9383 - val_loss: 0.2723 - val_accuracy: 0.7197 - val_precision_m: 0.8279 - val_recall_m: 0.7928 - val_f1_m: 0.8082\n","Epoch 75/1000\n","131/131 [==============================] - 1s 7ms/step - loss: 0.0983 - accuracy: 0.6778 - precision_m: 0.9492 - recall_m: 0.9299 - f1_m: 0.9390 - val_loss: 0.2802 - val_accuracy: 0.6940 - val_precision_m: 0.8247 - val_recall_m: 0.7803 - val_f1_m: 0.8001\n","Epoch 76/1000\n","131/131 [==============================] - 1s 8ms/step - loss: 0.0956 - accuracy: 0.6852 - precision_m: 0.9563 - recall_m: 0.9329 - f1_m: 0.9440 - val_loss: 0.2766 - val_accuracy: 0.7197 - val_precision_m: 0.8310 - val_recall_m: 0.7753 - val_f1_m: 0.8009\n","Epoch 77/1000\n","131/131 [==============================] - 1s 7ms/step - loss: 0.1017 - accuracy: 0.6866 - precision_m: 0.9482 - recall_m: 0.9269 - f1_m: 0.9370 - val_loss: 0.2796 - val_accuracy: 0.7016 - val_precision_m: 0.8301 - val_recall_m: 0.7793 - val_f1_m: 0.8021\n","Epoch 78/1000\n","131/131 [==============================] - 1s 7ms/step - loss: 0.1012 - accuracy: 0.6865 - precision_m: 0.9527 - recall_m: 0.9256 - f1_m: 0.9384 - val_loss: 0.2803 - val_accuracy: 0.7150 - val_precision_m: 0.8100 - val_recall_m: 0.7938 - val_f1_m: 0.8001\n","Epoch 79/1000\n","131/131 [==============================] - 1s 7ms/step - loss: 0.0961 - accuracy: 0.6755 - precision_m: 0.9519 - recall_m: 0.9342 - f1_m: 0.9425 - val_loss: 0.2748 - val_accuracy: 0.7102 - val_precision_m: 0.8294 - val_recall_m: 0.7858 - val_f1_m: 0.8054\n","Epoch 80/1000\n","131/131 [==============================] - 1s 7ms/step - loss: 0.1010 - accuracy: 0.6850 - precision_m: 0.9509 - recall_m: 0.9320 - f1_m: 0.9409 - val_loss: 0.2824 - val_accuracy: 0.7121 - val_precision_m: 0.8315 - val_recall_m: 0.7784 - val_f1_m: 0.8025\n","Epoch 81/1000\n","131/131 [==============================] - 1s 7ms/step - loss: 0.0967 - accuracy: 0.6922 - precision_m: 0.9499 - recall_m: 0.9371 - f1_m: 0.9429 - val_loss: 0.2808 - val_accuracy: 0.7131 - val_precision_m: 0.8285 - val_recall_m: 0.7828 - val_f1_m: 0.8034\n","Epoch 82/1000\n","131/131 [==============================] - 1s 7ms/step - loss: 0.0941 - accuracy: 0.7033 - precision_m: 0.9542 - recall_m: 0.9335 - f1_m: 0.9432 - val_loss: 0.2790 - val_accuracy: 0.6969 - val_precision_m: 0.8244 - val_recall_m: 0.7952 - val_f1_m: 0.8084\n","Epoch 00082: early stopping\n","Score for fold 2: loss of 0.38222962617874146; accuracy of 66.03053212165833% ;precision_m of 0.7956562638282776 ;recall_m of 0.7809962630271912 ;            f1_m of 0.786693274974823\n","Epoch 1/1000\n","131/131 [==============================] - 2s 8ms/step - loss: 0.5600 - accuracy: 0.3366 - precision_m: 0.6024 - recall_m: 0.3520 - f1_m: 0.4316 - val_loss: 0.3530 - val_accuracy: 0.6444 - val_precision_m: 0.7618 - val_recall_m: 0.7224 - val_f1_m: 0.7399\n","Epoch 2/1000\n","131/131 [==============================] - 1s 7ms/step - loss: 0.3830 - accuracy: 0.5528 - precision_m: 0.7713 - recall_m: 0.6695 - f1_m: 0.7152 - val_loss: 0.3127 - val_accuracy: 0.6597 - val_precision_m: 0.7956 - val_recall_m: 0.7327 - val_f1_m: 0.7612\n","Epoch 3/1000\n","131/131 [==============================] - 1s 7ms/step - loss: 0.3458 - accuracy: 0.5576 - precision_m: 0.8064 - recall_m: 0.7154 - f1_m: 0.7569 - val_loss: 0.3016 - val_accuracy: 0.6616 - val_precision_m: 0.8030 - val_recall_m: 0.7538 - val_f1_m: 0.7759\n","Epoch 4/1000\n","131/131 [==============================] - 1s 7ms/step - loss: 0.3232 - accuracy: 0.5758 - precision_m: 0.8190 - recall_m: 0.7429 - f1_m: 0.7782 - val_loss: 0.2878 - val_accuracy: 0.6568 - val_precision_m: 0.8103 - val_recall_m: 0.7442 - val_f1_m: 0.7743\n","Epoch 5/1000\n","131/131 [==============================] - 1s 7ms/step - loss: 0.3060 - accuracy: 0.5830 - precision_m: 0.8332 - recall_m: 0.7559 - f1_m: 0.7916 - val_loss: 0.2977 - val_accuracy: 0.6988 - val_precision_m: 0.8150 - val_recall_m: 0.7441 - val_f1_m: 0.7760\n","Epoch 6/1000\n","131/131 [==============================] - 1s 7ms/step - loss: 0.2921 - accuracy: 0.5936 - precision_m: 0.8442 - recall_m: 0.7763 - f1_m: 0.8079 - val_loss: 0.2787 - val_accuracy: 0.6635 - val_precision_m: 0.8387 - val_recall_m: 0.7299 - val_f1_m: 0.7787\n","Epoch 7/1000\n","131/131 [==============================] - 1s 7ms/step - loss: 0.2802 - accuracy: 0.6045 - precision_m: 0.8565 - recall_m: 0.7738 - f1_m: 0.8115 - val_loss: 0.2879 - val_accuracy: 0.6835 - val_precision_m: 0.8189 - val_recall_m: 0.7491 - val_f1_m: 0.7809\n","Epoch 8/1000\n","131/131 [==============================] - 1s 7ms/step - loss: 0.2685 - accuracy: 0.6030 - precision_m: 0.8538 - recall_m: 0.7886 - f1_m: 0.8187 - val_loss: 0.2855 - val_accuracy: 0.6949 - val_precision_m: 0.8236 - val_recall_m: 0.7515 - val_f1_m: 0.7843\n","Epoch 9/1000\n","131/131 [==============================] - 1s 7ms/step - loss: 0.2739 - accuracy: 0.6058 - precision_m: 0.8505 - recall_m: 0.7833 - f1_m: 0.8143 - val_loss: 0.2822 - val_accuracy: 0.6730 - val_precision_m: 0.8018 - val_recall_m: 0.7795 - val_f1_m: 0.7889\n","Epoch 10/1000\n","131/131 [==============================] - 1s 7ms/step - loss: 0.2617 - accuracy: 0.6187 - precision_m: 0.8563 - recall_m: 0.8015 - f1_m: 0.8268 - val_loss: 0.2907 - val_accuracy: 0.6997 - val_precision_m: 0.8126 - val_recall_m: 0.7522 - val_f1_m: 0.7795\n","Epoch 11/1000\n","131/131 [==============================] - 1s 7ms/step - loss: 0.2554 - accuracy: 0.6159 - precision_m: 0.8681 - recall_m: 0.8065 - f1_m: 0.8350 - val_loss: 0.2824 - val_accuracy: 0.6826 - val_precision_m: 0.8063 - val_recall_m: 0.7766 - val_f1_m: 0.7895\n","Epoch 12/1000\n","131/131 [==============================] - 1s 8ms/step - loss: 0.2431 - accuracy: 0.6107 - precision_m: 0.8700 - recall_m: 0.8153 - f1_m: 0.8402 - val_loss: 0.2836 - val_accuracy: 0.6797 - val_precision_m: 0.8214 - val_recall_m: 0.7627 - val_f1_m: 0.7891\n","Epoch 13/1000\n","131/131 [==============================] - 1s 7ms/step - loss: 0.2504 - accuracy: 0.6180 - precision_m: 0.8664 - recall_m: 0.8071 - f1_m: 0.8347 - val_loss: 0.2881 - val_accuracy: 0.6854 - val_precision_m: 0.8225 - val_recall_m: 0.7376 - val_f1_m: 0.7758\n","Epoch 14/1000\n","131/131 [==============================] - 1s 7ms/step - loss: 0.2488 - accuracy: 0.5973 - precision_m: 0.8725 - recall_m: 0.8041 - f1_m: 0.8360 - val_loss: 0.2852 - val_accuracy: 0.6997 - val_precision_m: 0.8263 - val_recall_m: 0.7623 - val_f1_m: 0.7914\n","Epoch 15/1000\n","131/131 [==============================] - 1s 7ms/step - loss: 0.2385 - accuracy: 0.6173 - precision_m: 0.8779 - recall_m: 0.8207 - f1_m: 0.8471 - val_loss: 0.2826 - val_accuracy: 0.7007 - val_precision_m: 0.8275 - val_recall_m: 0.7536 - val_f1_m: 0.7869\n","Epoch 16/1000\n","131/131 [==============================] - 1s 7ms/step - loss: 0.2344 - accuracy: 0.6201 - precision_m: 0.8806 - recall_m: 0.8232 - f1_m: 0.8500 - val_loss: 0.2834 - val_accuracy: 0.6921 - val_precision_m: 0.8292 - val_recall_m: 0.7345 - val_f1_m: 0.7772\n","Epoch 17/1000\n","131/131 [==============================] - 1s 7ms/step - loss: 0.2311 - accuracy: 0.6165 - precision_m: 0.8797 - recall_m: 0.8214 - f1_m: 0.8485 - val_loss: 0.2788 - val_accuracy: 0.6902 - val_precision_m: 0.8323 - val_recall_m: 0.7559 - val_f1_m: 0.7905\n","Epoch 18/1000\n","131/131 [==============================] - 1s 7ms/step - loss: 0.2234 - accuracy: 0.6357 - precision_m: 0.8884 - recall_m: 0.8276 - f1_m: 0.8560 - val_loss: 0.2890 - val_accuracy: 0.6988 - val_precision_m: 0.8197 - val_recall_m: 0.7628 - val_f1_m: 0.7886\n","Epoch 19/1000\n","131/131 [==============================] - 1s 7ms/step - loss: 0.2167 - accuracy: 0.6344 - precision_m: 0.8928 - recall_m: 0.8382 - f1_m: 0.8637 - val_loss: 0.2880 - val_accuracy: 0.6930 - val_precision_m: 0.8246 - val_recall_m: 0.7532 - val_f1_m: 0.7855\n","Epoch 20/1000\n","131/131 [==============================] - 1s 7ms/step - loss: 0.2160 - accuracy: 0.6237 - precision_m: 0.8896 - recall_m: 0.8358 - f1_m: 0.8609 - val_loss: 0.2756 - val_accuracy: 0.6864 - val_precision_m: 0.8391 - val_recall_m: 0.7522 - val_f1_m: 0.7914\n","Epoch 21/1000\n","131/131 [==============================] - 1s 7ms/step - loss: 0.2148 - accuracy: 0.6209 - precision_m: 0.8932 - recall_m: 0.8371 - f1_m: 0.8633 - val_loss: 0.2852 - val_accuracy: 0.6997 - val_precision_m: 0.8302 - val_recall_m: 0.7527 - val_f1_m: 0.7876\n","Epoch 22/1000\n","131/131 [==============================] - 1s 7ms/step - loss: 0.2113 - accuracy: 0.6258 - precision_m: 0.8929 - recall_m: 0.8400 - f1_m: 0.8646 - val_loss: 0.2880 - val_accuracy: 0.6969 - val_precision_m: 0.8124 - val_recall_m: 0.7616 - val_f1_m: 0.7845\n","Epoch 23/1000\n","131/131 [==============================] - 1s 7ms/step - loss: 0.2110 - accuracy: 0.6421 - precision_m: 0.8922 - recall_m: 0.8362 - f1_m: 0.8622 - val_loss: 0.2865 - val_accuracy: 0.6911 - val_precision_m: 0.8205 - val_recall_m: 0.7670 - val_f1_m: 0.7912\n","Epoch 24/1000\n","131/131 [==============================] - 1s 7ms/step - loss: 0.2053 - accuracy: 0.6346 - precision_m: 0.8986 - recall_m: 0.8438 - f1_m: 0.8694 - val_loss: 0.2836 - val_accuracy: 0.6883 - val_precision_m: 0.8306 - val_recall_m: 0.7616 - val_f1_m: 0.7928\n","Epoch 25/1000\n","131/131 [==============================] - 1s 7ms/step - loss: 0.1977 - accuracy: 0.6319 - precision_m: 0.9000 - recall_m: 0.8485 - f1_m: 0.8728 - val_loss: 0.2840 - val_accuracy: 0.6845 - val_precision_m: 0.8157 - val_recall_m: 0.7669 - val_f1_m: 0.7888\n","Epoch 26/1000\n","131/131 [==============================] - 1s 7ms/step - loss: 0.1944 - accuracy: 0.6545 - precision_m: 0.9020 - recall_m: 0.8534 - f1_m: 0.8762 - val_loss: 0.2884 - val_accuracy: 0.6902 - val_precision_m: 0.8201 - val_recall_m: 0.7662 - val_f1_m: 0.7906\n","Epoch 27/1000\n","131/131 [==============================] - 1s 7ms/step - loss: 0.1923 - accuracy: 0.6423 - precision_m: 0.9027 - recall_m: 0.8584 - f1_m: 0.8790 - val_loss: 0.2986 - val_accuracy: 0.7064 - val_precision_m: 0.8175 - val_recall_m: 0.7630 - val_f1_m: 0.7876\n","Epoch 28/1000\n","131/131 [==============================] - 1s 7ms/step - loss: 0.1856 - accuracy: 0.6521 - precision_m: 0.9100 - recall_m: 0.8670 - f1_m: 0.8872 - val_loss: 0.2830 - val_accuracy: 0.6768 - val_precision_m: 0.8211 - val_recall_m: 0.7666 - val_f1_m: 0.7912\n","Epoch 29/1000\n","131/131 [==============================] - 1s 7ms/step - loss: 0.1886 - accuracy: 0.6328 - precision_m: 0.9063 - recall_m: 0.8650 - f1_m: 0.8845 - val_loss: 0.2901 - val_accuracy: 0.6988 - val_precision_m: 0.8150 - val_recall_m: 0.7672 - val_f1_m: 0.7888\n","Epoch 30/1000\n","131/131 [==============================] - 1s 7ms/step - loss: 0.1878 - accuracy: 0.6358 - precision_m: 0.9024 - recall_m: 0.8604 - f1_m: 0.8801 - val_loss: 0.2882 - val_accuracy: 0.6959 - val_precision_m: 0.8384 - val_recall_m: 0.7409 - val_f1_m: 0.7846\n","Epoch 31/1000\n","131/131 [==============================] - 1s 7ms/step - loss: 0.1687 - accuracy: 0.6433 - precision_m: 0.9239 - recall_m: 0.8781 - f1_m: 0.8996 - val_loss: 0.2860 - val_accuracy: 0.7016 - val_precision_m: 0.8365 - val_recall_m: 0.7604 - val_f1_m: 0.7948\n","Epoch 32/1000\n","131/131 [==============================] - 1s 7ms/step - loss: 0.1798 - accuracy: 0.6319 - precision_m: 0.9174 - recall_m: 0.8693 - f1_m: 0.8918 - val_loss: 0.2910 - val_accuracy: 0.6969 - val_precision_m: 0.8222 - val_recall_m: 0.7602 - val_f1_m: 0.7884\n","Epoch 33/1000\n","131/131 [==============================] - 1s 8ms/step - loss: 0.1790 - accuracy: 0.6336 - precision_m: 0.9060 - recall_m: 0.8729 - f1_m: 0.8882 - val_loss: 0.2894 - val_accuracy: 0.6997 - val_precision_m: 0.8269 - val_recall_m: 0.7761 - val_f1_m: 0.7988\n","Epoch 34/1000\n","131/131 [==============================] - 1s 7ms/step - loss: 0.1734 - accuracy: 0.6383 - precision_m: 0.9117 - recall_m: 0.8749 - f1_m: 0.8921 - val_loss: 0.2876 - val_accuracy: 0.6892 - val_precision_m: 0.8255 - val_recall_m: 0.7737 - val_f1_m: 0.7969\n","Epoch 35/1000\n","131/131 [==============================] - 1s 7ms/step - loss: 0.1762 - accuracy: 0.6417 - precision_m: 0.9175 - recall_m: 0.8697 - f1_m: 0.8923 - val_loss: 0.2955 - val_accuracy: 0.6978 - val_precision_m: 0.8222 - val_recall_m: 0.7737 - val_f1_m: 0.7952\n","Epoch 36/1000\n","131/131 [==============================] - 1s 7ms/step - loss: 0.1695 - accuracy: 0.6517 - precision_m: 0.9164 - recall_m: 0.8712 - f1_m: 0.8923 - val_loss: 0.2968 - val_accuracy: 0.6826 - val_precision_m: 0.8312 - val_recall_m: 0.7393 - val_f1_m: 0.7807\n","Epoch 37/1000\n","131/131 [==============================] - 1s 7ms/step - loss: 0.1632 - accuracy: 0.6596 - precision_m: 0.9201 - recall_m: 0.8734 - f1_m: 0.8954 - val_loss: 0.2960 - val_accuracy: 0.7054 - val_precision_m: 0.8213 - val_recall_m: 0.7773 - val_f1_m: 0.7968\n","Epoch 38/1000\n","131/131 [==============================] - 1s 7ms/step - loss: 0.1632 - accuracy: 0.6399 - precision_m: 0.9244 - recall_m: 0.8790 - f1_m: 0.9005 - val_loss: 0.2989 - val_accuracy: 0.6892 - val_precision_m: 0.8135 - val_recall_m: 0.7682 - val_f1_m: 0.7884\n","Epoch 39/1000\n","131/131 [==============================] - 1s 7ms/step - loss: 0.1584 - accuracy: 0.6398 - precision_m: 0.9178 - recall_m: 0.8791 - f1_m: 0.8974 - val_loss: 0.3049 - val_accuracy: 0.6949 - val_precision_m: 0.8205 - val_recall_m: 0.7446 - val_f1_m: 0.7788\n","Epoch 40/1000\n","131/131 [==============================] - 1s 7ms/step - loss: 0.1516 - accuracy: 0.6550 - precision_m: 0.9273 - recall_m: 0.8866 - f1_m: 0.9058 - val_loss: 0.2995 - val_accuracy: 0.7035 - val_precision_m: 0.8193 - val_recall_m: 0.7613 - val_f1_m: 0.7876\n","Epoch 41/1000\n","131/131 [==============================] - 1s 7ms/step - loss: 0.1558 - accuracy: 0.6569 - precision_m: 0.9215 - recall_m: 0.8871 - f1_m: 0.9032 - val_loss: 0.2947 - val_accuracy: 0.6978 - val_precision_m: 0.8284 - val_recall_m: 0.7580 - val_f1_m: 0.7899\n","Epoch 42/1000\n","131/131 [==============================] - 1s 7ms/step - loss: 0.1527 - accuracy: 0.6455 - precision_m: 0.9213 - recall_m: 0.8890 - f1_m: 0.9042 - val_loss: 0.3017 - val_accuracy: 0.6902 - val_precision_m: 0.8121 - val_recall_m: 0.7678 - val_f1_m: 0.7872\n","Epoch 43/1000\n","131/131 [==============================] - 1s 7ms/step - loss: 0.1556 - accuracy: 0.6484 - precision_m: 0.9286 - recall_m: 0.8856 - f1_m: 0.9060 - val_loss: 0.3084 - val_accuracy: 0.7007 - val_precision_m: 0.8172 - val_recall_m: 0.7531 - val_f1_m: 0.7821\n","Epoch 44/1000\n","131/131 [==============================] - 1s 7ms/step - loss: 0.1492 - accuracy: 0.6594 - precision_m: 0.9266 - recall_m: 0.8895 - f1_m: 0.9071 - val_loss: 0.3013 - val_accuracy: 0.6940 - val_precision_m: 0.8142 - val_recall_m: 0.7695 - val_f1_m: 0.7893\n","Epoch 45/1000\n","131/131 [==============================] - 1s 7ms/step - loss: 0.1507 - accuracy: 0.6396 - precision_m: 0.9220 - recall_m: 0.8986 - f1_m: 0.9092 - val_loss: 0.3079 - val_accuracy: 0.6988 - val_precision_m: 0.8002 - val_recall_m: 0.7823 - val_f1_m: 0.7895\n","Epoch 46/1000\n","131/131 [==============================] - 1s 7ms/step - loss: 0.1511 - accuracy: 0.6580 - precision_m: 0.9290 - recall_m: 0.8935 - f1_m: 0.9103 - val_loss: 0.3191 - val_accuracy: 0.7064 - val_precision_m: 0.8012 - val_recall_m: 0.7600 - val_f1_m: 0.7783\n","Epoch 47/1000\n","131/131 [==============================] - 1s 7ms/step - loss: 0.1438 - accuracy: 0.6483 - precision_m: 0.9277 - recall_m: 0.9005 - f1_m: 0.9126 - val_loss: 0.3010 - val_accuracy: 0.6826 - val_precision_m: 0.8173 - val_recall_m: 0.7693 - val_f1_m: 0.7905\n","Epoch 48/1000\n","131/131 [==============================] - 1s 7ms/step - loss: 0.1502 - accuracy: 0.6516 - precision_m: 0.9291 - recall_m: 0.8879 - f1_m: 0.9073 - val_loss: 0.2944 - val_accuracy: 0.6883 - val_precision_m: 0.8254 - val_recall_m: 0.7646 - val_f1_m: 0.7917\n","Epoch 49/1000\n","131/131 [==============================] - 1s 7ms/step - loss: 0.1395 - accuracy: 0.6551 - precision_m: 0.9387 - recall_m: 0.8944 - f1_m: 0.9153 - val_loss: 0.3048 - val_accuracy: 0.7026 - val_precision_m: 0.8136 - val_recall_m: 0.7784 - val_f1_m: 0.7937\n","Epoch 50/1000\n","131/131 [==============================] - 1s 7ms/step - loss: 0.1411 - accuracy: 0.6341 - precision_m: 0.9348 - recall_m: 0.9011 - f1_m: 0.9171 - val_loss: 0.3026 - val_accuracy: 0.7054 - val_precision_m: 0.8201 - val_recall_m: 0.7674 - val_f1_m: 0.7910\n","Epoch 51/1000\n","131/131 [==============================] - 1s 7ms/step - loss: 0.1453 - accuracy: 0.6607 - precision_m: 0.9326 - recall_m: 0.8964 - f1_m: 0.9135 - val_loss: 0.3119 - val_accuracy: 0.7121 - val_precision_m: 0.8150 - val_recall_m: 0.7579 - val_f1_m: 0.7837\n","Epoch 52/1000\n","131/131 [==============================] - 1s 7ms/step - loss: 0.1406 - accuracy: 0.6528 - precision_m: 0.9306 - recall_m: 0.9006 - f1_m: 0.9146 - val_loss: 0.3204 - val_accuracy: 0.6921 - val_precision_m: 0.8153 - val_recall_m: 0.7524 - val_f1_m: 0.7809\n","Epoch 53/1000\n","131/131 [==============================] - 1s 7ms/step - loss: 0.1338 - accuracy: 0.6694 - precision_m: 0.9358 - recall_m: 0.9040 - f1_m: 0.9190 - val_loss: 0.3077 - val_accuracy: 0.6816 - val_precision_m: 0.8067 - val_recall_m: 0.7723 - val_f1_m: 0.7873\n","Epoch 54/1000\n","131/131 [==============================] - 1s 8ms/step - loss: 0.1330 - accuracy: 0.6445 - precision_m: 0.9382 - recall_m: 0.9048 - f1_m: 0.9207 - val_loss: 0.3082 - val_accuracy: 0.6940 - val_precision_m: 0.8168 - val_recall_m: 0.7666 - val_f1_m: 0.7889\n","Epoch 55/1000\n","131/131 [==============================] - 1s 7ms/step - loss: 0.1319 - accuracy: 0.6563 - precision_m: 0.9354 - recall_m: 0.9099 - f1_m: 0.9219 - val_loss: 0.3100 - val_accuracy: 0.7035 - val_precision_m: 0.8294 - val_recall_m: 0.7541 - val_f1_m: 0.7881\n","Epoch 56/1000\n","131/131 [==============================] - 1s 7ms/step - loss: 0.1311 - accuracy: 0.6644 - precision_m: 0.9389 - recall_m: 0.9029 - f1_m: 0.9199 - val_loss: 0.3196 - val_accuracy: 0.6978 - val_precision_m: 0.8086 - val_recall_m: 0.7581 - val_f1_m: 0.7808\n","Epoch 57/1000\n","131/131 [==============================] - 1s 7ms/step - loss: 0.1252 - accuracy: 0.6534 - precision_m: 0.9431 - recall_m: 0.9082 - f1_m: 0.9248 - val_loss: 0.3269 - val_accuracy: 0.6854 - val_precision_m: 0.8037 - val_recall_m: 0.7529 - val_f1_m: 0.7753\n","Epoch 58/1000\n","131/131 [==============================] - 1s 7ms/step - loss: 0.1289 - accuracy: 0.6447 - precision_m: 0.9397 - recall_m: 0.9138 - f1_m: 0.9260 - val_loss: 0.3113 - val_accuracy: 0.6969 - val_precision_m: 0.8132 - val_recall_m: 0.7699 - val_f1_m: 0.7892\n","Epoch 59/1000\n","131/131 [==============================] - 1s 7ms/step - loss: 0.1249 - accuracy: 0.6659 - precision_m: 0.9405 - recall_m: 0.9111 - f1_m: 0.9250 - val_loss: 0.3240 - val_accuracy: 0.6969 - val_precision_m: 0.8085 - val_recall_m: 0.7484 - val_f1_m: 0.7755\n","Epoch 60/1000\n","131/131 [==============================] - 1s 7ms/step - loss: 0.1314 - accuracy: 0.6607 - precision_m: 0.9366 - recall_m: 0.9095 - f1_m: 0.9222 - val_loss: 0.3045 - val_accuracy: 0.6911 - val_precision_m: 0.8343 - val_recall_m: 0.7520 - val_f1_m: 0.7892\n","Epoch 61/1000\n","131/131 [==============================] - 1s 7ms/step - loss: 0.1228 - accuracy: 0.6551 - precision_m: 0.9421 - recall_m: 0.9154 - f1_m: 0.9281 - val_loss: 0.3143 - val_accuracy: 0.6949 - val_precision_m: 0.8185 - val_recall_m: 0.7663 - val_f1_m: 0.7894\n","Epoch 62/1000\n","131/131 [==============================] - 1s 7ms/step - loss: 0.1206 - accuracy: 0.6565 - precision_m: 0.9418 - recall_m: 0.9203 - f1_m: 0.9304 - val_loss: 0.3214 - val_accuracy: 0.7054 - val_precision_m: 0.8052 - val_recall_m: 0.7637 - val_f1_m: 0.7819\n","Epoch 63/1000\n","131/131 [==============================] - 1s 7ms/step - loss: 0.1179 - accuracy: 0.6630 - precision_m: 0.9451 - recall_m: 0.9141 - f1_m: 0.9288 - val_loss: 0.3239 - val_accuracy: 0.6787 - val_precision_m: 0.8067 - val_recall_m: 0.7550 - val_f1_m: 0.7777\n","Epoch 64/1000\n","131/131 [==============================] - 1s 7ms/step - loss: 0.1241 - accuracy: 0.6584 - precision_m: 0.9458 - recall_m: 0.9108 - f1_m: 0.9271 - val_loss: 0.3244 - val_accuracy: 0.6873 - val_precision_m: 0.8110 - val_recall_m: 0.7498 - val_f1_m: 0.7775\n","Epoch 65/1000\n","131/131 [==============================] - 1s 7ms/step - loss: 0.1232 - accuracy: 0.6494 - precision_m: 0.9401 - recall_m: 0.9095 - f1_m: 0.9240 - val_loss: 0.3280 - val_accuracy: 0.6949 - val_precision_m: 0.8186 - val_recall_m: 0.7495 - val_f1_m: 0.7805\n","Epoch 66/1000\n","131/131 [==============================] - 1s 7ms/step - loss: 0.1131 - accuracy: 0.6610 - precision_m: 0.9466 - recall_m: 0.9145 - f1_m: 0.9298 - val_loss: 0.3227 - val_accuracy: 0.6921 - val_precision_m: 0.8098 - val_recall_m: 0.7876 - val_f1_m: 0.7968\n","Epoch 67/1000\n","131/131 [==============================] - 1s 7ms/step - loss: 0.1130 - accuracy: 0.6590 - precision_m: 0.9467 - recall_m: 0.9247 - f1_m: 0.9350 - val_loss: 0.3283 - val_accuracy: 0.6978 - val_precision_m: 0.8083 - val_recall_m: 0.7787 - val_f1_m: 0.7913\n","Epoch 68/1000\n","131/131 [==============================] - 1s 7ms/step - loss: 0.1228 - accuracy: 0.6542 - precision_m: 0.9391 - recall_m: 0.9123 - f1_m: 0.9249 - val_loss: 0.3254 - val_accuracy: 0.6930 - val_precision_m: 0.8149 - val_recall_m: 0.7481 - val_f1_m: 0.7777\n","Epoch 69/1000\n","131/131 [==============================] - 1s 7ms/step - loss: 0.1153 - accuracy: 0.6674 - precision_m: 0.9485 - recall_m: 0.9190 - f1_m: 0.9330 - val_loss: 0.3316 - val_accuracy: 0.6949 - val_precision_m: 0.8041 - val_recall_m: 0.7632 - val_f1_m: 0.7815\n","Epoch 70/1000\n","131/131 [==============================] - 1s 7ms/step - loss: 0.1137 - accuracy: 0.6613 - precision_m: 0.9450 - recall_m: 0.9234 - f1_m: 0.9336 - val_loss: 0.3453 - val_accuracy: 0.7159 - val_precision_m: 0.8051 - val_recall_m: 0.7555 - val_f1_m: 0.7776\n","Epoch 71/1000\n","131/131 [==============================] - 1s 7ms/step - loss: 0.1144 - accuracy: 0.6630 - precision_m: 0.9443 - recall_m: 0.9208 - f1_m: 0.9319 - val_loss: 0.3245 - val_accuracy: 0.6902 - val_precision_m: 0.8115 - val_recall_m: 0.7716 - val_f1_m: 0.7887\n","Epoch 72/1000\n","131/131 [==============================] - 1s 7ms/step - loss: 0.1139 - accuracy: 0.6678 - precision_m: 0.9476 - recall_m: 0.9228 - f1_m: 0.9345 - val_loss: 0.3197 - val_accuracy: 0.7045 - val_precision_m: 0.8207 - val_recall_m: 0.7592 - val_f1_m: 0.7870\n","Epoch 73/1000\n","131/131 [==============================] - 1s 7ms/step - loss: 0.1099 - accuracy: 0.6726 - precision_m: 0.9526 - recall_m: 0.9250 - f1_m: 0.9382 - val_loss: 0.3248 - val_accuracy: 0.7026 - val_precision_m: 0.8087 - val_recall_m: 0.7706 - val_f1_m: 0.7870\n","Epoch 74/1000\n","131/131 [==============================] - 1s 7ms/step - loss: 0.1077 - accuracy: 0.6620 - precision_m: 0.9474 - recall_m: 0.9289 - f1_m: 0.9376 - val_loss: 0.3335 - val_accuracy: 0.6949 - val_precision_m: 0.8138 - val_recall_m: 0.7604 - val_f1_m: 0.7842\n","Epoch 75/1000\n","131/131 [==============================] - 1s 8ms/step - loss: 0.1147 - accuracy: 0.6424 - precision_m: 0.9440 - recall_m: 0.9200 - f1_m: 0.9313 - val_loss: 0.3347 - val_accuracy: 0.7035 - val_precision_m: 0.8036 - val_recall_m: 0.7741 - val_f1_m: 0.7867\n","Epoch 76/1000\n","131/131 [==============================] - 1s 7ms/step - loss: 0.1131 - accuracy: 0.6605 - precision_m: 0.9436 - recall_m: 0.9222 - f1_m: 0.9323 - val_loss: 0.3267 - val_accuracy: 0.6911 - val_precision_m: 0.8185 - val_recall_m: 0.7634 - val_f1_m: 0.7882\n","Epoch 77/1000\n","131/131 [==============================] - 1s 7ms/step - loss: 0.1051 - accuracy: 0.6708 - precision_m: 0.9527 - recall_m: 0.9266 - f1_m: 0.9392 - val_loss: 0.3346 - val_accuracy: 0.7035 - val_precision_m: 0.8037 - val_recall_m: 0.7839 - val_f1_m: 0.7918\n","Epoch 78/1000\n","131/131 [==============================] - 1s 7ms/step - loss: 0.1048 - accuracy: 0.6538 - precision_m: 0.9522 - recall_m: 0.9273 - f1_m: 0.9391 - val_loss: 0.3385 - val_accuracy: 0.7045 - val_precision_m: 0.8118 - val_recall_m: 0.7530 - val_f1_m: 0.7793\n","Epoch 79/1000\n","131/131 [==============================] - 1s 7ms/step - loss: 0.1072 - accuracy: 0.6646 - precision_m: 0.9500 - recall_m: 0.9237 - f1_m: 0.9362 - val_loss: 0.3333 - val_accuracy: 0.7016 - val_precision_m: 0.8138 - val_recall_m: 0.7636 - val_f1_m: 0.7856\n","Epoch 80/1000\n","131/131 [==============================] - 1s 7ms/step - loss: 0.1045 - accuracy: 0.6621 - precision_m: 0.9536 - recall_m: 0.9306 - f1_m: 0.9415 - val_loss: 0.3455 - val_accuracy: 0.7007 - val_precision_m: 0.8067 - val_recall_m: 0.7602 - val_f1_m: 0.7806\n","Epoch 81/1000\n","131/131 [==============================] - 1s 7ms/step - loss: 0.1099 - accuracy: 0.6619 - precision_m: 0.9462 - recall_m: 0.9216 - f1_m: 0.9333 - val_loss: 0.3414 - val_accuracy: 0.7131 - val_precision_m: 0.8048 - val_recall_m: 0.7798 - val_f1_m: 0.7902\n","Epoch 82/1000\n","131/131 [==============================] - 1s 7ms/step - loss: 0.1016 - accuracy: 0.6713 - precision_m: 0.9475 - recall_m: 0.9303 - f1_m: 0.9384 - val_loss: 0.3338 - val_accuracy: 0.7064 - val_precision_m: 0.8196 - val_recall_m: 0.7682 - val_f1_m: 0.7911\n","Epoch 83/1000\n","131/131 [==============================] - 1s 7ms/step - loss: 0.0999 - accuracy: 0.6749 - precision_m: 0.9527 - recall_m: 0.9294 - f1_m: 0.9405 - val_loss: 0.3377 - val_accuracy: 0.6921 - val_precision_m: 0.8240 - val_recall_m: 0.7512 - val_f1_m: 0.7842\n","Epoch 00083: early stopping\n","Score for fold 3: loss of 0.30723875761032104; accuracy of 66.52671694755554% ;precision_m of 0.8239316940307617 ;recall_m of 0.7417020797729492 ;            f1_m of 0.7791765928268433\n","------------------------------------------------------------------------\n","Score per fold\n","------------------------------------------------------------------------\n","> Fold 1 - Loss: 0.5433487892150879 - Accuracy: 50.66768527030945% - Precision: 0.8339507579803467 - Recall: 0.7151877880096436 - F1: 0.7678025960922241\n","------------------------------------------------------------------------\n","> Fold 2 - Loss: 0.38222962617874146 - Accuracy: 66.03053212165833% - Precision: 0.7956562638282776 - Recall: 0.7809962630271912 - F1: 0.786693274974823\n","------------------------------------------------------------------------\n","> Fold 3 - Loss: 0.30723875761032104 - Accuracy: 66.52671694755554% - Precision: 0.8239316940307617 - Recall: 0.7417020797729492 - F1: 0.7791765928268433\n","------------------------------------------------------------------------\n","Average scores for all folds:\n","> Accuracy: 61.07497811317444 (+- 7.361854751950503)\n","> Precision: 0.8178462386131287\n","> Recall: 0.7459620436032613\n","> F1: 0.7778908212979635\n","> Loss: 0.4109390576680501\n","------------------------------------------------------------------------\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"ASCqTRPD-yKn"},"source":["# CNN with Cross Validation \r\n","CBOW with size 100"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"WYSYJsy2-vh0","executionInfo":{"elapsed":185475,"status":"ok","timestamp":1614102290709,"user":{"displayName":"Shanaka Chathuranga","photoUrl":"","userId":"01381725564551416324"},"user_tz":-330},"outputId":"79764edb-4c4a-490f-f78d-38b301e047f4"},"source":["N_FOLDS=3 \r\n","EPOCHS=1000\r\n","VALIDATION_SPLIT=0.2\r\n","BATCH_SIZE=32\r\n","PATIENCE=50\r\n","MONITOR='val_f1_m'\r\n","MONITOR_MODE='max'\r\n","shuffle=True\r\n","DROPOUT_VALUE_2=0.5\r\n","\r\n","def create_model():\r\n","    model = Sequential()\r\n","    embedding_layer = Embedding(vocab_length, 100,weights=[embedding_matrix],input_length=length_long_sentence, trainable=False)\r\n","    model.add(embedding_layer)\r\n","    model.add(Conv1D(256,3, activation='relu'))\r\n","    model.add(GlobalMaxPooling1D())\r\n","    model.add(Dropout(DROPOUT_VALUE_2))\r\n","    model.add(Flatten())\r\n","    model.add(Dense(6, activation='sigmoid'))\r\n","    model.compile(loss='binary_crossentropy', optimizer='adam',metrics=[\"accuracy\",precision_m,recall_m,f1_m])\r\n","    return model \r\n","\r\n","# Define per-fold score containers <-- these are new\r\n","acc_per_fold = []\r\n","loss_per_fold = []\r\n","f1_per_fold = []\r\n","precision_per_fold =[]\r\n","recall_per_fold=[]\r\n","\r\n","#Define dependencied for model loading\r\n","dependencies = {\r\n","    'recall_m': recall_m,\r\n","    'f1_m':f1_m,\r\n","    'precision_m':precision_m    \r\n","}\r\n","\r\n","vocab_length,padded_sentences,length_long_sentence,embedding_matrix=loadembedding_matrix(x,mainloc+'word_embeddings/w2v_cbow_100.txt',100)\r\n","\r\n","kf = KFold(n_splits=N_FOLDS)\r\n","fold_no = 1\r\n","for train_index, test_index in kf.split(padded_sentences, y):\r\n","    model=create_model()\r\n","    es = EarlyStopping(monitor=MONITOR, mode=MONITOR_MODE, verbose=1,patience= PATIENCE )\r\n","    history = model.fit(padded_sentences[train_index],y.values[train_index],epochs=EPOCHS,callbacks=[es],batch_size=BATCH_SIZE,shuffle=True,validation_split=VALIDATION_SPLIT)\r\n","    \r\n","    # Generate generalization metrics\r\n","    scores = model.evaluate(padded_sentences[test_index], y.values[test_index], verbose=0)\r\n","    print(f'Score for fold {fold_no}: {model.metrics_names[0]} of {scores[0]}; {model.metrics_names[1]} of {scores[1]*100}% ;{model.metrics_names[2]} of {scores[2]} ;{model.metrics_names[3]} of {scores[3]} ; \\\r\n","           {model.metrics_names[4]} of {scores[4]}')\r\n","    loss_per_fold.append(scores[0])\r\n","    acc_per_fold.append(scores[1] * 100)\r\n","    precision_per_fold.append(scores[2])\r\n","    recall_per_fold.append(scores[3])\r\n","    f1_per_fold.append(scores[4])\r\n","\r\n","    # Increase fold number\r\n","    fold_no = fold_no + 1\r\n","    \r\n","accuracy_crossval(acc_per_fold,loss_per_fold,f1_per_fold,precision_per_fold,recall_per_fold)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Epoch 1/1000\n","131/131 [==============================] - 2s 8ms/step - loss: 0.5261 - accuracy: 0.3374 - precision_m: 0.5869 - recall_m: 0.3214 - f1_m: 0.4023 - val_loss: 0.3419 - val_accuracy: 0.5906 - val_precision_m: 0.7855 - val_recall_m: 0.6614 - val_f1_m: 0.7162\n","Epoch 2/1000\n","131/131 [==============================] - 1s 5ms/step - loss: 0.3611 - accuracy: 0.5649 - precision_m: 0.7762 - recall_m: 0.6127 - f1_m: 0.6824 - val_loss: 0.2813 - val_accuracy: 0.6250 - val_precision_m: 0.8140 - val_recall_m: 0.7204 - val_f1_m: 0.7625\n","Epoch 3/1000\n","131/131 [==============================] - 1s 5ms/step - loss: 0.3169 - accuracy: 0.5977 - precision_m: 0.7991 - recall_m: 0.6746 - f1_m: 0.7301 - val_loss: 0.2706 - val_accuracy: 0.6508 - val_precision_m: 0.8262 - val_recall_m: 0.7342 - val_f1_m: 0.7757\n","Epoch 4/1000\n","131/131 [==============================] - 1s 5ms/step - loss: 0.3012 - accuracy: 0.6114 - precision_m: 0.8102 - recall_m: 0.7055 - f1_m: 0.7532 - val_loss: 0.2546 - val_accuracy: 0.6565 - val_precision_m: 0.8327 - val_recall_m: 0.7515 - val_f1_m: 0.7883\n","Epoch 5/1000\n","131/131 [==============================] - 1s 5ms/step - loss: 0.2793 - accuracy: 0.6150 - precision_m: 0.8279 - recall_m: 0.7362 - f1_m: 0.7775 - val_loss: 0.2519 - val_accuracy: 0.6594 - val_precision_m: 0.8451 - val_recall_m: 0.7388 - val_f1_m: 0.7863\n","Epoch 6/1000\n","131/131 [==============================] - 1s 5ms/step - loss: 0.2761 - accuracy: 0.6316 - precision_m: 0.8305 - recall_m: 0.7353 - f1_m: 0.7786 - val_loss: 0.2494 - val_accuracy: 0.6794 - val_precision_m: 0.8385 - val_recall_m: 0.7550 - val_f1_m: 0.7931\n","Epoch 7/1000\n","131/131 [==============================] - 1s 5ms/step - loss: 0.2717 - accuracy: 0.6384 - precision_m: 0.8369 - recall_m: 0.7474 - f1_m: 0.7883 - val_loss: 0.2404 - val_accuracy: 0.6536 - val_precision_m: 0.8283 - val_recall_m: 0.7768 - val_f1_m: 0.8008\n","Epoch 8/1000\n","131/131 [==============================] - 1s 5ms/step - loss: 0.2574 - accuracy: 0.6503 - precision_m: 0.8411 - recall_m: 0.7618 - f1_m: 0.7981 - val_loss: 0.2442 - val_accuracy: 0.6746 - val_precision_m: 0.8319 - val_recall_m: 0.7726 - val_f1_m: 0.7997\n","Epoch 9/1000\n","131/131 [==============================] - 1s 5ms/step - loss: 0.2517 - accuracy: 0.6568 - precision_m: 0.8444 - recall_m: 0.7650 - f1_m: 0.8016 - val_loss: 0.2412 - val_accuracy: 0.6727 - val_precision_m: 0.8351 - val_recall_m: 0.7834 - val_f1_m: 0.8074\n","Epoch 10/1000\n","131/131 [==============================] - 1s 5ms/step - loss: 0.2454 - accuracy: 0.6561 - precision_m: 0.8524 - recall_m: 0.7778 - f1_m: 0.8120 - val_loss: 0.2419 - val_accuracy: 0.6574 - val_precision_m: 0.8295 - val_recall_m: 0.7777 - val_f1_m: 0.8014\n","Epoch 11/1000\n","131/131 [==============================] - 1s 6ms/step - loss: 0.2411 - accuracy: 0.6447 - precision_m: 0.8510 - recall_m: 0.7726 - f1_m: 0.8087 - val_loss: 0.2382 - val_accuracy: 0.6584 - val_precision_m: 0.8340 - val_recall_m: 0.7756 - val_f1_m: 0.8025\n","Epoch 12/1000\n","131/131 [==============================] - 1s 5ms/step - loss: 0.2376 - accuracy: 0.6474 - precision_m: 0.8517 - recall_m: 0.7798 - f1_m: 0.8132 - val_loss: 0.2367 - val_accuracy: 0.6775 - val_precision_m: 0.8379 - val_recall_m: 0.7783 - val_f1_m: 0.8061\n","Epoch 13/1000\n","131/131 [==============================] - 1s 5ms/step - loss: 0.2299 - accuracy: 0.6542 - precision_m: 0.8612 - recall_m: 0.7868 - f1_m: 0.8211 - val_loss: 0.2390 - val_accuracy: 0.6746 - val_precision_m: 0.8407 - val_recall_m: 0.7726 - val_f1_m: 0.8039\n","Epoch 14/1000\n","131/131 [==============================] - 1s 5ms/step - loss: 0.2274 - accuracy: 0.6733 - precision_m: 0.8646 - recall_m: 0.7959 - f1_m: 0.8276 - val_loss: 0.2351 - val_accuracy: 0.6727 - val_precision_m: 0.8232 - val_recall_m: 0.7987 - val_f1_m: 0.8098\n","Epoch 15/1000\n","131/131 [==============================] - 1s 5ms/step - loss: 0.2132 - accuracy: 0.6779 - precision_m: 0.8649 - recall_m: 0.8116 - f1_m: 0.8361 - val_loss: 0.2348 - val_accuracy: 0.6574 - val_precision_m: 0.8322 - val_recall_m: 0.7758 - val_f1_m: 0.8018\n","Epoch 16/1000\n","131/131 [==============================] - 1s 5ms/step - loss: 0.2170 - accuracy: 0.6676 - precision_m: 0.8731 - recall_m: 0.8033 - f1_m: 0.8352 - val_loss: 0.2351 - val_accuracy: 0.6546 - val_precision_m: 0.8528 - val_recall_m: 0.7581 - val_f1_m: 0.8009\n","Epoch 17/1000\n","131/131 [==============================] - 1s 5ms/step - loss: 0.2125 - accuracy: 0.6636 - precision_m: 0.8763 - recall_m: 0.8052 - f1_m: 0.8375 - val_loss: 0.2383 - val_accuracy: 0.6899 - val_precision_m: 0.8216 - val_recall_m: 0.8011 - val_f1_m: 0.8101\n","Epoch 18/1000\n","131/131 [==============================] - 1s 5ms/step - loss: 0.2155 - accuracy: 0.6761 - precision_m: 0.8792 - recall_m: 0.8070 - f1_m: 0.8403 - val_loss: 0.2331 - val_accuracy: 0.6813 - val_precision_m: 0.8363 - val_recall_m: 0.7716 - val_f1_m: 0.8017\n","Epoch 19/1000\n","131/131 [==============================] - 1s 5ms/step - loss: 0.2044 - accuracy: 0.7002 - precision_m: 0.8766 - recall_m: 0.8175 - f1_m: 0.8450 - val_loss: 0.2357 - val_accuracy: 0.6718 - val_precision_m: 0.8303 - val_recall_m: 0.7926 - val_f1_m: 0.8102\n","Epoch 20/1000\n","131/131 [==============================] - 1s 5ms/step - loss: 0.1985 - accuracy: 0.6804 - precision_m: 0.8828 - recall_m: 0.8181 - f1_m: 0.8478 - val_loss: 0.2368 - val_accuracy: 0.6765 - val_precision_m: 0.8348 - val_recall_m: 0.7839 - val_f1_m: 0.8077\n","Epoch 21/1000\n","131/131 [==============================] - 1s 5ms/step - loss: 0.1886 - accuracy: 0.6822 - precision_m: 0.8954 - recall_m: 0.8319 - f1_m: 0.8614 - val_loss: 0.2345 - val_accuracy: 0.6641 - val_precision_m: 0.8454 - val_recall_m: 0.7801 - val_f1_m: 0.8105\n","Epoch 22/1000\n","131/131 [==============================] - 1s 5ms/step - loss: 0.1926 - accuracy: 0.6896 - precision_m: 0.8846 - recall_m: 0.8273 - f1_m: 0.8540 - val_loss: 0.2374 - val_accuracy: 0.6632 - val_precision_m: 0.8449 - val_recall_m: 0.7829 - val_f1_m: 0.8117\n","Epoch 23/1000\n","131/131 [==============================] - 1s 5ms/step - loss: 0.1867 - accuracy: 0.6837 - precision_m: 0.8916 - recall_m: 0.8289 - f1_m: 0.8581 - val_loss: 0.2376 - val_accuracy: 0.6756 - val_precision_m: 0.8359 - val_recall_m: 0.7739 - val_f1_m: 0.8025\n","Epoch 24/1000\n","131/131 [==============================] - 1s 5ms/step - loss: 0.1855 - accuracy: 0.6775 - precision_m: 0.8940 - recall_m: 0.8367 - f1_m: 0.8631 - val_loss: 0.2416 - val_accuracy: 0.6689 - val_precision_m: 0.8273 - val_recall_m: 0.7873 - val_f1_m: 0.8058\n","Epoch 25/1000\n","131/131 [==============================] - 1s 5ms/step - loss: 0.1782 - accuracy: 0.6831 - precision_m: 0.8977 - recall_m: 0.8487 - f1_m: 0.8713 - val_loss: 0.2350 - val_accuracy: 0.6832 - val_precision_m: 0.8372 - val_recall_m: 0.7855 - val_f1_m: 0.8094\n","Epoch 26/1000\n","131/131 [==============================] - 1s 5ms/step - loss: 0.1742 - accuracy: 0.6999 - precision_m: 0.9022 - recall_m: 0.8399 - f1_m: 0.8686 - val_loss: 0.2415 - val_accuracy: 0.6708 - val_precision_m: 0.8378 - val_recall_m: 0.7742 - val_f1_m: 0.8034\n","Epoch 27/1000\n","131/131 [==============================] - 1s 5ms/step - loss: 0.1719 - accuracy: 0.6956 - precision_m: 0.9009 - recall_m: 0.8423 - f1_m: 0.8696 - val_loss: 0.2391 - val_accuracy: 0.6727 - val_precision_m: 0.8299 - val_recall_m: 0.7887 - val_f1_m: 0.8076\n","Epoch 28/1000\n","131/131 [==============================] - 1s 5ms/step - loss: 0.1677 - accuracy: 0.6977 - precision_m: 0.8998 - recall_m: 0.8534 - f1_m: 0.8749 - val_loss: 0.2445 - val_accuracy: 0.6756 - val_precision_m: 0.8113 - val_recall_m: 0.8106 - val_f1_m: 0.8097\n","Epoch 29/1000\n","131/131 [==============================] - 1s 5ms/step - loss: 0.1737 - accuracy: 0.6930 - precision_m: 0.8984 - recall_m: 0.8544 - f1_m: 0.8748 - val_loss: 0.2430 - val_accuracy: 0.6565 - val_precision_m: 0.8344 - val_recall_m: 0.7733 - val_f1_m: 0.8014\n","Epoch 30/1000\n","131/131 [==============================] - 1s 5ms/step - loss: 0.1656 - accuracy: 0.6949 - precision_m: 0.9045 - recall_m: 0.8515 - f1_m: 0.8765 - val_loss: 0.2414 - val_accuracy: 0.6870 - val_precision_m: 0.8284 - val_recall_m: 0.7837 - val_f1_m: 0.8044\n","Epoch 31/1000\n","131/131 [==============================] - 1s 5ms/step - loss: 0.1570 - accuracy: 0.6996 - precision_m: 0.9090 - recall_m: 0.8660 - f1_m: 0.8861 - val_loss: 0.2444 - val_accuracy: 0.6956 - val_precision_m: 0.8330 - val_recall_m: 0.7777 - val_f1_m: 0.8032\n","Epoch 32/1000\n","131/131 [==============================] - 1s 5ms/step - loss: 0.1611 - accuracy: 0.7090 - precision_m: 0.9099 - recall_m: 0.8614 - f1_m: 0.8840 - val_loss: 0.2402 - val_accuracy: 0.6708 - val_precision_m: 0.8436 - val_recall_m: 0.7830 - val_f1_m: 0.8111\n","Epoch 33/1000\n","131/131 [==============================] - 1s 5ms/step - loss: 0.1533 - accuracy: 0.7058 - precision_m: 0.9147 - recall_m: 0.8624 - f1_m: 0.8870 - val_loss: 0.2437 - val_accuracy: 0.6603 - val_precision_m: 0.8283 - val_recall_m: 0.7914 - val_f1_m: 0.8081\n","Epoch 34/1000\n","131/131 [==============================] - 1s 5ms/step - loss: 0.1505 - accuracy: 0.6972 - precision_m: 0.9124 - recall_m: 0.8722 - f1_m: 0.8911 - val_loss: 0.2452 - val_accuracy: 0.6727 - val_precision_m: 0.8282 - val_recall_m: 0.7892 - val_f1_m: 0.8068\n","Epoch 35/1000\n","131/131 [==============================] - 1s 5ms/step - loss: 0.1549 - accuracy: 0.6978 - precision_m: 0.9125 - recall_m: 0.8638 - f1_m: 0.8869 - val_loss: 0.2460 - val_accuracy: 0.6660 - val_precision_m: 0.8358 - val_recall_m: 0.7728 - val_f1_m: 0.8019\n","Epoch 36/1000\n","131/131 [==============================] - 1s 5ms/step - loss: 0.1496 - accuracy: 0.7064 - precision_m: 0.9162 - recall_m: 0.8689 - f1_m: 0.8912 - val_loss: 0.2533 - val_accuracy: 0.6861 - val_precision_m: 0.8124 - val_recall_m: 0.7866 - val_f1_m: 0.7983\n","Epoch 37/1000\n","131/131 [==============================] - 1s 5ms/step - loss: 0.1537 - accuracy: 0.7061 - precision_m: 0.9147 - recall_m: 0.8725 - f1_m: 0.8922 - val_loss: 0.2529 - val_accuracy: 0.7032 - val_precision_m: 0.8209 - val_recall_m: 0.7960 - val_f1_m: 0.8069\n","Epoch 38/1000\n","131/131 [==============================] - 1s 5ms/step - loss: 0.1429 - accuracy: 0.7013 - precision_m: 0.9184 - recall_m: 0.8783 - f1_m: 0.8971 - val_loss: 0.2459 - val_accuracy: 0.6947 - val_precision_m: 0.8322 - val_recall_m: 0.7805 - val_f1_m: 0.8043\n","Epoch 39/1000\n","131/131 [==============================] - 1s 6ms/step - loss: 0.1444 - accuracy: 0.7007 - precision_m: 0.9170 - recall_m: 0.8758 - f1_m: 0.8953 - val_loss: 0.2500 - val_accuracy: 0.6632 - val_precision_m: 0.8338 - val_recall_m: 0.7858 - val_f1_m: 0.8080\n","Epoch 40/1000\n","131/131 [==============================] - 1s 5ms/step - loss: 0.1389 - accuracy: 0.6957 - precision_m: 0.9211 - recall_m: 0.8839 - f1_m: 0.9013 - val_loss: 0.2497 - val_accuracy: 0.6765 - val_precision_m: 0.8239 - val_recall_m: 0.7964 - val_f1_m: 0.8087\n","Epoch 41/1000\n","131/131 [==============================] - 1s 5ms/step - loss: 0.1345 - accuracy: 0.7112 - precision_m: 0.9228 - recall_m: 0.8902 - f1_m: 0.9055 - val_loss: 0.2519 - val_accuracy: 0.6775 - val_precision_m: 0.8262 - val_recall_m: 0.7787 - val_f1_m: 0.8005\n","Epoch 42/1000\n","131/131 [==============================] - 1s 5ms/step - loss: 0.1342 - accuracy: 0.7124 - precision_m: 0.9250 - recall_m: 0.8786 - f1_m: 0.9004 - val_loss: 0.2591 - val_accuracy: 0.6718 - val_precision_m: 0.8371 - val_recall_m: 0.7744 - val_f1_m: 0.8030\n","Epoch 43/1000\n","131/131 [==============================] - 1s 5ms/step - loss: 0.1335 - accuracy: 0.6981 - precision_m: 0.9236 - recall_m: 0.8875 - f1_m: 0.9045 - val_loss: 0.2551 - val_accuracy: 0.6603 - val_precision_m: 0.8403 - val_recall_m: 0.7662 - val_f1_m: 0.7999\n","Epoch 44/1000\n","131/131 [==============================] - 1s 5ms/step - loss: 0.1313 - accuracy: 0.7055 - precision_m: 0.9280 - recall_m: 0.8857 - f1_m: 0.9057 - val_loss: 0.2507 - val_accuracy: 0.6823 - val_precision_m: 0.8310 - val_recall_m: 0.7765 - val_f1_m: 0.8017\n","Epoch 45/1000\n","131/131 [==============================] - 1s 5ms/step - loss: 0.1260 - accuracy: 0.7240 - precision_m: 0.9319 - recall_m: 0.8854 - f1_m: 0.9075 - val_loss: 0.2593 - val_accuracy: 0.6832 - val_precision_m: 0.8368 - val_recall_m: 0.7649 - val_f1_m: 0.7981\n","Epoch 46/1000\n","131/131 [==============================] - 1s 5ms/step - loss: 0.1240 - accuracy: 0.7066 - precision_m: 0.9277 - recall_m: 0.9013 - f1_m: 0.9135 - val_loss: 0.2777 - val_accuracy: 0.6947 - val_precision_m: 0.8178 - val_recall_m: 0.7697 - val_f1_m: 0.7919\n","Epoch 47/1000\n","131/131 [==============================] - 1s 5ms/step - loss: 0.1259 - accuracy: 0.7208 - precision_m: 0.9342 - recall_m: 0.8984 - f1_m: 0.9150 - val_loss: 0.2601 - val_accuracy: 0.6679 - val_precision_m: 0.8193 - val_recall_m: 0.7933 - val_f1_m: 0.8050\n","Epoch 48/1000\n","131/131 [==============================] - 1s 5ms/step - loss: 0.1209 - accuracy: 0.7159 - precision_m: 0.9255 - recall_m: 0.9021 - f1_m: 0.9126 - val_loss: 0.2587 - val_accuracy: 0.6555 - val_precision_m: 0.8327 - val_recall_m: 0.7819 - val_f1_m: 0.8055\n","Epoch 49/1000\n","131/131 [==============================] - 1s 5ms/step - loss: 0.1214 - accuracy: 0.7265 - precision_m: 0.9322 - recall_m: 0.9013 - f1_m: 0.9157 - val_loss: 0.2628 - val_accuracy: 0.6832 - val_precision_m: 0.8265 - val_recall_m: 0.7762 - val_f1_m: 0.7994\n","Epoch 50/1000\n","131/131 [==============================] - 1s 5ms/step - loss: 0.1162 - accuracy: 0.7224 - precision_m: 0.9353 - recall_m: 0.9065 - f1_m: 0.9201 - val_loss: 0.2585 - val_accuracy: 0.6813 - val_precision_m: 0.8318 - val_recall_m: 0.7713 - val_f1_m: 0.7993\n","Epoch 51/1000\n","131/131 [==============================] - 1s 5ms/step - loss: 0.1237 - accuracy: 0.7111 - precision_m: 0.9296 - recall_m: 0.8937 - f1_m: 0.9105 - val_loss: 0.2610 - val_accuracy: 0.6737 - val_precision_m: 0.8366 - val_recall_m: 0.7732 - val_f1_m: 0.8023\n","Epoch 52/1000\n","131/131 [==============================] - 1s 5ms/step - loss: 0.1158 - accuracy: 0.7263 - precision_m: 0.9348 - recall_m: 0.9012 - f1_m: 0.9171 - val_loss: 0.2605 - val_accuracy: 0.6698 - val_precision_m: 0.8273 - val_recall_m: 0.7901 - val_f1_m: 0.8071\n","Epoch 53/1000\n","131/131 [==============================] - 1s 5ms/step - loss: 0.1168 - accuracy: 0.7203 - precision_m: 0.9351 - recall_m: 0.9019 - f1_m: 0.9177 - val_loss: 0.2691 - val_accuracy: 0.6803 - val_precision_m: 0.8378 - val_recall_m: 0.7662 - val_f1_m: 0.7992\n","Epoch 54/1000\n","131/131 [==============================] - 1s 5ms/step - loss: 0.1166 - accuracy: 0.7142 - precision_m: 0.9362 - recall_m: 0.8988 - f1_m: 0.9165 - val_loss: 0.2646 - val_accuracy: 0.6784 - val_precision_m: 0.8226 - val_recall_m: 0.7865 - val_f1_m: 0.8028\n","Epoch 55/1000\n","131/131 [==============================] - 1s 5ms/step - loss: 0.1194 - accuracy: 0.7153 - precision_m: 0.9287 - recall_m: 0.9042 - f1_m: 0.9157 - val_loss: 0.2703 - val_accuracy: 0.6584 - val_precision_m: 0.8230 - val_recall_m: 0.7825 - val_f1_m: 0.8008\n","Epoch 56/1000\n","131/131 [==============================] - 1s 5ms/step - loss: 0.1159 - accuracy: 0.7150 - precision_m: 0.9343 - recall_m: 0.9033 - f1_m: 0.9178 - val_loss: 0.2674 - val_accuracy: 0.6679 - val_precision_m: 0.8322 - val_recall_m: 0.7668 - val_f1_m: 0.7967\n","Epoch 57/1000\n","131/131 [==============================] - 1s 5ms/step - loss: 0.1061 - accuracy: 0.7251 - precision_m: 0.9406 - recall_m: 0.9170 - f1_m: 0.9282 - val_loss: 0.2741 - val_accuracy: 0.6746 - val_precision_m: 0.8347 - val_recall_m: 0.7631 - val_f1_m: 0.7956\n","Epoch 58/1000\n","131/131 [==============================] - 1s 5ms/step - loss: 0.1087 - accuracy: 0.7181 - precision_m: 0.9430 - recall_m: 0.9106 - f1_m: 0.9260 - val_loss: 0.2735 - val_accuracy: 0.6746 - val_precision_m: 0.8293 - val_recall_m: 0.7709 - val_f1_m: 0.7975\n","Epoch 59/1000\n","131/131 [==============================] - 1s 5ms/step - loss: 0.1064 - accuracy: 0.7047 - precision_m: 0.9440 - recall_m: 0.9129 - f1_m: 0.9276 - val_loss: 0.2730 - val_accuracy: 0.6613 - val_precision_m: 0.8315 - val_recall_m: 0.7736 - val_f1_m: 0.8000\n","Epoch 60/1000\n","131/131 [==============================] - 1s 5ms/step - loss: 0.1081 - accuracy: 0.7184 - precision_m: 0.9416 - recall_m: 0.9130 - f1_m: 0.9265 - val_loss: 0.2672 - val_accuracy: 0.6679 - val_precision_m: 0.8257 - val_recall_m: 0.7772 - val_f1_m: 0.7992\n","Epoch 61/1000\n","131/131 [==============================] - 1s 5ms/step - loss: 0.1109 - accuracy: 0.7180 - precision_m: 0.9358 - recall_m: 0.9086 - f1_m: 0.9215 - val_loss: 0.2797 - val_accuracy: 0.6574 - val_precision_m: 0.8219 - val_recall_m: 0.7739 - val_f1_m: 0.7958\n","Epoch 62/1000\n","131/131 [==============================] - 1s 5ms/step - loss: 0.1040 - accuracy: 0.7121 - precision_m: 0.9380 - recall_m: 0.9166 - f1_m: 0.9264 - val_loss: 0.2756 - val_accuracy: 0.6737 - val_precision_m: 0.8249 - val_recall_m: 0.7752 - val_f1_m: 0.7981\n","Epoch 63/1000\n","131/131 [==============================] - 1s 5ms/step - loss: 0.1071 - accuracy: 0.7188 - precision_m: 0.9394 - recall_m: 0.9129 - f1_m: 0.9253 - val_loss: 0.2796 - val_accuracy: 0.6584 - val_precision_m: 0.8179 - val_recall_m: 0.7785 - val_f1_m: 0.7965\n","Epoch 64/1000\n","131/131 [==============================] - 1s 5ms/step - loss: 0.1020 - accuracy: 0.7173 - precision_m: 0.9436 - recall_m: 0.9167 - f1_m: 0.9294 - val_loss: 0.2766 - val_accuracy: 0.6708 - val_precision_m: 0.8318 - val_recall_m: 0.7733 - val_f1_m: 0.8001\n","Epoch 65/1000\n","131/131 [==============================] - 1s 5ms/step - loss: 0.1048 - accuracy: 0.7136 - precision_m: 0.9417 - recall_m: 0.9147 - f1_m: 0.9275 - val_loss: 0.2793 - val_accuracy: 0.6641 - val_precision_m: 0.8270 - val_recall_m: 0.7713 - val_f1_m: 0.7965\n","Epoch 66/1000\n","131/131 [==============================] - 1s 5ms/step - loss: 0.1008 - accuracy: 0.7207 - precision_m: 0.9412 - recall_m: 0.9166 - f1_m: 0.9281 - val_loss: 0.2800 - val_accuracy: 0.6546 - val_precision_m: 0.8211 - val_recall_m: 0.7788 - val_f1_m: 0.7980\n","Epoch 67/1000\n","131/131 [==============================] - 1s 6ms/step - loss: 0.1030 - accuracy: 0.7185 - precision_m: 0.9399 - recall_m: 0.9164 - f1_m: 0.9273 - val_loss: 0.2770 - val_accuracy: 0.6727 - val_precision_m: 0.8325 - val_recall_m: 0.7740 - val_f1_m: 0.8010\n","Epoch 68/1000\n","131/131 [==============================] - 1s 5ms/step - loss: 0.0976 - accuracy: 0.7236 - precision_m: 0.9479 - recall_m: 0.9221 - f1_m: 0.9343 - val_loss: 0.2733 - val_accuracy: 0.6794 - val_precision_m: 0.8297 - val_recall_m: 0.7629 - val_f1_m: 0.7935\n","Epoch 69/1000\n","131/131 [==============================] - 1s 5ms/step - loss: 0.0986 - accuracy: 0.7274 - precision_m: 0.9458 - recall_m: 0.9196 - f1_m: 0.9320 - val_loss: 0.2843 - val_accuracy: 0.6498 - val_precision_m: 0.8276 - val_recall_m: 0.7853 - val_f1_m: 0.8048\n","Epoch 70/1000\n","131/131 [==============================] - 1s 5ms/step - loss: 0.1024 - accuracy: 0.7187 - precision_m: 0.9435 - recall_m: 0.9175 - f1_m: 0.9294 - val_loss: 0.2840 - val_accuracy: 0.6708 - val_precision_m: 0.8195 - val_recall_m: 0.7807 - val_f1_m: 0.7987\n","Epoch 71/1000\n","131/131 [==============================] - 1s 5ms/step - loss: 0.0934 - accuracy: 0.7360 - precision_m: 0.9458 - recall_m: 0.9184 - f1_m: 0.9313 - val_loss: 0.2793 - val_accuracy: 0.6679 - val_precision_m: 0.8208 - val_recall_m: 0.7755 - val_f1_m: 0.7962\n","Epoch 72/1000\n","131/131 [==============================] - 1s 5ms/step - loss: 0.0937 - accuracy: 0.7190 - precision_m: 0.9448 - recall_m: 0.9229 - f1_m: 0.9333 - val_loss: 0.2827 - val_accuracy: 0.6660 - val_precision_m: 0.8183 - val_recall_m: 0.7750 - val_f1_m: 0.7950\n","Epoch 00072: early stopping\n","Score for fold 1: loss of 0.5463671088218689; accuracy of 50.40060877799988% ;precision_m of 0.8486261963844299 ;recall_m of 0.6860843896865845 ;            f1_m of 0.7560235261917114\n","Epoch 1/1000\n","131/131 [==============================] - 1s 7ms/step - loss: 0.5879 - accuracy: 0.3145 - precision_m: 0.5612 - recall_m: 0.3242 - f1_m: 0.3960 - val_loss: 0.3444 - val_accuracy: 0.6082 - val_precision_m: 0.7733 - val_recall_m: 0.6819 - val_f1_m: 0.7229\n","Epoch 2/1000\n","131/131 [==============================] - 1s 5ms/step - loss: 0.3960 - accuracy: 0.5700 - precision_m: 0.7687 - recall_m: 0.6171 - f1_m: 0.6802 - val_loss: 0.2893 - val_accuracy: 0.6520 - val_precision_m: 0.7852 - val_recall_m: 0.7643 - val_f1_m: 0.7728\n","Epoch 3/1000\n","131/131 [==============================] - 1s 5ms/step - loss: 0.3404 - accuracy: 0.5712 - precision_m: 0.7963 - recall_m: 0.7076 - f1_m: 0.7478 - val_loss: 0.2746 - val_accuracy: 0.6854 - val_precision_m: 0.8079 - val_recall_m: 0.7594 - val_f1_m: 0.7813\n","Epoch 4/1000\n","131/131 [==============================] - 1s 5ms/step - loss: 0.3198 - accuracy: 0.5972 - precision_m: 0.8120 - recall_m: 0.7356 - f1_m: 0.7709 - val_loss: 0.2651 - val_accuracy: 0.6683 - val_precision_m: 0.8135 - val_recall_m: 0.7641 - val_f1_m: 0.7862\n","Epoch 5/1000\n","131/131 [==============================] - 1s 5ms/step - loss: 0.3063 - accuracy: 0.5883 - precision_m: 0.8217 - recall_m: 0.7536 - f1_m: 0.7846 - val_loss: 0.2559 - val_accuracy: 0.6864 - val_precision_m: 0.8229 - val_recall_m: 0.7753 - val_f1_m: 0.7969\n","Epoch 6/1000\n","131/131 [==============================] - 1s 5ms/step - loss: 0.2960 - accuracy: 0.6060 - precision_m: 0.8355 - recall_m: 0.7616 - f1_m: 0.7958 - val_loss: 0.2556 - val_accuracy: 0.6959 - val_precision_m: 0.8188 - val_recall_m: 0.7743 - val_f1_m: 0.7948\n","Epoch 7/1000\n","131/131 [==============================] - 1s 5ms/step - loss: 0.2808 - accuracy: 0.6178 - precision_m: 0.8365 - recall_m: 0.7730 - f1_m: 0.8024 - val_loss: 0.2442 - val_accuracy: 0.6902 - val_precision_m: 0.8299 - val_recall_m: 0.7757 - val_f1_m: 0.8002\n","Epoch 8/1000\n","131/131 [==============================] - 1s 5ms/step - loss: 0.2724 - accuracy: 0.6135 - precision_m: 0.8569 - recall_m: 0.7861 - f1_m: 0.8187 - val_loss: 0.2425 - val_accuracy: 0.6816 - val_precision_m: 0.8440 - val_recall_m: 0.7684 - val_f1_m: 0.8031\n","Epoch 9/1000\n","131/131 [==============================] - 1s 5ms/step - loss: 0.2661 - accuracy: 0.6265 - precision_m: 0.8456 - recall_m: 0.7827 - f1_m: 0.8117 - val_loss: 0.2381 - val_accuracy: 0.6921 - val_precision_m: 0.8425 - val_recall_m: 0.7750 - val_f1_m: 0.8060\n","Epoch 10/1000\n","131/131 [==============================] - 1s 5ms/step - loss: 0.2607 - accuracy: 0.6355 - precision_m: 0.8554 - recall_m: 0.7848 - f1_m: 0.8175 - val_loss: 0.2355 - val_accuracy: 0.6902 - val_precision_m: 0.8376 - val_recall_m: 0.7851 - val_f1_m: 0.8095\n","Epoch 11/1000\n","131/131 [==============================] - 1s 5ms/step - loss: 0.2575 - accuracy: 0.6259 - precision_m: 0.8513 - recall_m: 0.7958 - f1_m: 0.8214 - val_loss: 0.2372 - val_accuracy: 0.7035 - val_precision_m: 0.8276 - val_recall_m: 0.7913 - val_f1_m: 0.8079\n","Epoch 12/1000\n","131/131 [==============================] - 1s 5ms/step - loss: 0.2514 - accuracy: 0.6254 - precision_m: 0.8562 - recall_m: 0.7996 - f1_m: 0.8259 - val_loss: 0.2359 - val_accuracy: 0.7026 - val_precision_m: 0.8383 - val_recall_m: 0.7861 - val_f1_m: 0.8098\n","Epoch 13/1000\n","131/131 [==============================] - 1s 5ms/step - loss: 0.2419 - accuracy: 0.6373 - precision_m: 0.8673 - recall_m: 0.8112 - f1_m: 0.8374 - val_loss: 0.2361 - val_accuracy: 0.7026 - val_precision_m: 0.8420 - val_recall_m: 0.7778 - val_f1_m: 0.8072\n","Epoch 14/1000\n","131/131 [==============================] - 1s 5ms/step - loss: 0.2479 - accuracy: 0.6326 - precision_m: 0.8629 - recall_m: 0.8098 - f1_m: 0.8345 - val_loss: 0.2348 - val_accuracy: 0.7045 - val_precision_m: 0.8437 - val_recall_m: 0.7877 - val_f1_m: 0.8133\n","Epoch 15/1000\n","131/131 [==============================] - 1s 6ms/step - loss: 0.2301 - accuracy: 0.6257 - precision_m: 0.8760 - recall_m: 0.8184 - f1_m: 0.8449 - val_loss: 0.2355 - val_accuracy: 0.6930 - val_precision_m: 0.8562 - val_recall_m: 0.7533 - val_f1_m: 0.8003\n","Epoch 16/1000\n","131/131 [==============================] - 1s 5ms/step - loss: 0.2260 - accuracy: 0.6323 - precision_m: 0.8796 - recall_m: 0.8276 - f1_m: 0.8519 - val_loss: 0.2372 - val_accuracy: 0.7178 - val_precision_m: 0.8452 - val_recall_m: 0.7696 - val_f1_m: 0.8041\n","Epoch 17/1000\n","131/131 [==============================] - 1s 5ms/step - loss: 0.2369 - accuracy: 0.6211 - precision_m: 0.8764 - recall_m: 0.8154 - f1_m: 0.8439 - val_loss: 0.2374 - val_accuracy: 0.7188 - val_precision_m: 0.8382 - val_recall_m: 0.7880 - val_f1_m: 0.8114\n","Epoch 18/1000\n","131/131 [==============================] - 1s 5ms/step - loss: 0.2242 - accuracy: 0.6514 - precision_m: 0.8804 - recall_m: 0.8198 - f1_m: 0.8482 - val_loss: 0.2317 - val_accuracy: 0.6854 - val_precision_m: 0.8450 - val_recall_m: 0.7891 - val_f1_m: 0.8149\n","Epoch 19/1000\n","131/131 [==============================] - 1s 5ms/step - loss: 0.2183 - accuracy: 0.6484 - precision_m: 0.8801 - recall_m: 0.8259 - f1_m: 0.8510 - val_loss: 0.2360 - val_accuracy: 0.6930 - val_precision_m: 0.8256 - val_recall_m: 0.8131 - val_f1_m: 0.8182\n","Epoch 20/1000\n","131/131 [==============================] - 1s 5ms/step - loss: 0.2144 - accuracy: 0.6389 - precision_m: 0.8818 - recall_m: 0.8368 - f1_m: 0.8574 - val_loss: 0.2319 - val_accuracy: 0.7054 - val_precision_m: 0.8443 - val_recall_m: 0.7985 - val_f1_m: 0.8196\n","Epoch 21/1000\n","131/131 [==============================] - 1s 5ms/step - loss: 0.2117 - accuracy: 0.6555 - precision_m: 0.8836 - recall_m: 0.8342 - f1_m: 0.8573 - val_loss: 0.2349 - val_accuracy: 0.7102 - val_precision_m: 0.8417 - val_recall_m: 0.7945 - val_f1_m: 0.8158\n","Epoch 22/1000\n","131/131 [==============================] - 1s 5ms/step - loss: 0.2079 - accuracy: 0.6456 - precision_m: 0.8896 - recall_m: 0.8396 - f1_m: 0.8632 - val_loss: 0.2386 - val_accuracy: 0.7112 - val_precision_m: 0.8417 - val_recall_m: 0.7989 - val_f1_m: 0.8182\n","Epoch 23/1000\n","131/131 [==============================] - 1s 5ms/step - loss: 0.2032 - accuracy: 0.6520 - precision_m: 0.8927 - recall_m: 0.8501 - f1_m: 0.8698 - val_loss: 0.2323 - val_accuracy: 0.7083 - val_precision_m: 0.8438 - val_recall_m: 0.7930 - val_f1_m: 0.8164\n","Epoch 24/1000\n","131/131 [==============================] - 1s 5ms/step - loss: 0.2019 - accuracy: 0.6554 - precision_m: 0.8918 - recall_m: 0.8415 - f1_m: 0.8650 - val_loss: 0.2341 - val_accuracy: 0.6978 - val_precision_m: 0.8468 - val_recall_m: 0.7900 - val_f1_m: 0.8161\n","Epoch 25/1000\n","131/131 [==============================] - 1s 5ms/step - loss: 0.1987 - accuracy: 0.6429 - precision_m: 0.8965 - recall_m: 0.8496 - f1_m: 0.8716 - val_loss: 0.2384 - val_accuracy: 0.6740 - val_precision_m: 0.8416 - val_recall_m: 0.7702 - val_f1_m: 0.8028\n","Epoch 26/1000\n","131/131 [==============================] - 1s 5ms/step - loss: 0.2026 - accuracy: 0.6457 - precision_m: 0.8917 - recall_m: 0.8449 - f1_m: 0.8670 - val_loss: 0.2349 - val_accuracy: 0.7150 - val_precision_m: 0.8447 - val_recall_m: 0.7998 - val_f1_m: 0.8206\n","Epoch 27/1000\n","131/131 [==============================] - 1s 5ms/step - loss: 0.1922 - accuracy: 0.6457 - precision_m: 0.8979 - recall_m: 0.8567 - f1_m: 0.8758 - val_loss: 0.2360 - val_accuracy: 0.7083 - val_precision_m: 0.8340 - val_recall_m: 0.7937 - val_f1_m: 0.8119\n","Epoch 28/1000\n","131/131 [==============================] - 1s 5ms/step - loss: 0.1857 - accuracy: 0.6646 - precision_m: 0.9025 - recall_m: 0.8567 - f1_m: 0.8782 - val_loss: 0.2390 - val_accuracy: 0.6845 - val_precision_m: 0.8254 - val_recall_m: 0.7930 - val_f1_m: 0.8076\n","Epoch 29/1000\n","131/131 [==============================] - 1s 5ms/step - loss: 0.1809 - accuracy: 0.6488 - precision_m: 0.9001 - recall_m: 0.8602 - f1_m: 0.8787 - val_loss: 0.2376 - val_accuracy: 0.7054 - val_precision_m: 0.8320 - val_recall_m: 0.7797 - val_f1_m: 0.8038\n","Epoch 30/1000\n","131/131 [==============================] - 1s 6ms/step - loss: 0.1815 - accuracy: 0.6673 - precision_m: 0.9070 - recall_m: 0.8669 - f1_m: 0.8857 - val_loss: 0.2386 - val_accuracy: 0.7159 - val_precision_m: 0.8259 - val_recall_m: 0.8025 - val_f1_m: 0.8129\n","Epoch 31/1000\n","131/131 [==============================] - 1s 5ms/step - loss: 0.1784 - accuracy: 0.6437 - precision_m: 0.9069 - recall_m: 0.8646 - f1_m: 0.8843 - val_loss: 0.2429 - val_accuracy: 0.7274 - val_precision_m: 0.8375 - val_recall_m: 0.8016 - val_f1_m: 0.8180\n","Epoch 32/1000\n","131/131 [==============================] - 1s 5ms/step - loss: 0.1829 - accuracy: 0.6620 - precision_m: 0.8998 - recall_m: 0.8630 - f1_m: 0.8803 - val_loss: 0.2381 - val_accuracy: 0.7112 - val_precision_m: 0.8446 - val_recall_m: 0.8005 - val_f1_m: 0.8205\n","Epoch 33/1000\n","131/131 [==============================] - 1s 5ms/step - loss: 0.1760 - accuracy: 0.6583 - precision_m: 0.9117 - recall_m: 0.8665 - f1_m: 0.8879 - val_loss: 0.2386 - val_accuracy: 0.6873 - val_precision_m: 0.8382 - val_recall_m: 0.7748 - val_f1_m: 0.8037\n","Epoch 34/1000\n","131/131 [==============================] - 1s 5ms/step - loss: 0.1702 - accuracy: 0.6664 - precision_m: 0.9170 - recall_m: 0.8723 - f1_m: 0.8934 - val_loss: 0.2365 - val_accuracy: 0.6988 - val_precision_m: 0.8507 - val_recall_m: 0.7746 - val_f1_m: 0.8096\n","Epoch 35/1000\n","131/131 [==============================] - 1s 5ms/step - loss: 0.1783 - accuracy: 0.6544 - precision_m: 0.9067 - recall_m: 0.8682 - f1_m: 0.8864 - val_loss: 0.2384 - val_accuracy: 0.6978 - val_precision_m: 0.8420 - val_recall_m: 0.7805 - val_f1_m: 0.8085\n","Epoch 36/1000\n","131/131 [==============================] - 1s 5ms/step - loss: 0.1655 - accuracy: 0.6559 - precision_m: 0.9177 - recall_m: 0.8759 - f1_m: 0.8955 - val_loss: 0.2379 - val_accuracy: 0.6969 - val_precision_m: 0.8462 - val_recall_m: 0.7724 - val_f1_m: 0.8063\n","Epoch 37/1000\n","131/131 [==============================] - 1s 5ms/step - loss: 0.1634 - accuracy: 0.6591 - precision_m: 0.9188 - recall_m: 0.8746 - f1_m: 0.8955 - val_loss: 0.2438 - val_accuracy: 0.7140 - val_precision_m: 0.8294 - val_recall_m: 0.7939 - val_f1_m: 0.8101\n","Epoch 38/1000\n","131/131 [==============================] - 1s 6ms/step - loss: 0.1600 - accuracy: 0.6697 - precision_m: 0.9211 - recall_m: 0.8847 - f1_m: 0.9020 - val_loss: 0.2379 - val_accuracy: 0.6949 - val_precision_m: 0.8348 - val_recall_m: 0.7921 - val_f1_m: 0.8115\n","Epoch 39/1000\n","131/131 [==============================] - 1s 5ms/step - loss: 0.1688 - accuracy: 0.6537 - precision_m: 0.9096 - recall_m: 0.8739 - f1_m: 0.8908 - val_loss: 0.2416 - val_accuracy: 0.7197 - val_precision_m: 0.8485 - val_recall_m: 0.7864 - val_f1_m: 0.8150\n","Epoch 40/1000\n","131/131 [==============================] - 1s 5ms/step - loss: 0.1619 - accuracy: 0.6760 - precision_m: 0.9146 - recall_m: 0.8823 - f1_m: 0.8973 - val_loss: 0.2389 - val_accuracy: 0.7054 - val_precision_m: 0.8377 - val_recall_m: 0.7877 - val_f1_m: 0.8106\n","Epoch 41/1000\n","131/131 [==============================] - 1s 5ms/step - loss: 0.1547 - accuracy: 0.6639 - precision_m: 0.9169 - recall_m: 0.8782 - f1_m: 0.8963 - val_loss: 0.2394 - val_accuracy: 0.6978 - val_precision_m: 0.8434 - val_recall_m: 0.7750 - val_f1_m: 0.8065\n","Epoch 42/1000\n","131/131 [==============================] - 1s 5ms/step - loss: 0.1527 - accuracy: 0.6655 - precision_m: 0.9222 - recall_m: 0.8887 - f1_m: 0.9045 - val_loss: 0.2477 - val_accuracy: 0.7016 - val_precision_m: 0.8334 - val_recall_m: 0.7801 - val_f1_m: 0.8042\n","Epoch 43/1000\n","131/131 [==============================] - 1s 5ms/step - loss: 0.1509 - accuracy: 0.6673 - precision_m: 0.9216 - recall_m: 0.8865 - f1_m: 0.9029 - val_loss: 0.2409 - val_accuracy: 0.7016 - val_precision_m: 0.8521 - val_recall_m: 0.7658 - val_f1_m: 0.8049\n","Epoch 44/1000\n","131/131 [==============================] - 1s 6ms/step - loss: 0.1511 - accuracy: 0.6742 - precision_m: 0.9264 - recall_m: 0.8854 - f1_m: 0.9047 - val_loss: 0.2462 - val_accuracy: 0.7207 - val_precision_m: 0.8319 - val_recall_m: 0.7840 - val_f1_m: 0.8060\n","Epoch 45/1000\n","131/131 [==============================] - 1s 5ms/step - loss: 0.1463 - accuracy: 0.6725 - precision_m: 0.9254 - recall_m: 0.8931 - f1_m: 0.9083 - val_loss: 0.2453 - val_accuracy: 0.6911 - val_precision_m: 0.8312 - val_recall_m: 0.7887 - val_f1_m: 0.8082\n","Epoch 46/1000\n","131/131 [==============================] - 1s 5ms/step - loss: 0.1558 - accuracy: 0.6543 - precision_m: 0.9233 - recall_m: 0.8845 - f1_m: 0.9029 - val_loss: 0.2454 - val_accuracy: 0.6969 - val_precision_m: 0.8388 - val_recall_m: 0.7796 - val_f1_m: 0.8070\n","Epoch 47/1000\n","131/131 [==============================] - 1s 5ms/step - loss: 0.1453 - accuracy: 0.6783 - precision_m: 0.9286 - recall_m: 0.8871 - f1_m: 0.9066 - val_loss: 0.2447 - val_accuracy: 0.6978 - val_precision_m: 0.8319 - val_recall_m: 0.7901 - val_f1_m: 0.8091\n","Epoch 48/1000\n","131/131 [==============================] - 1s 5ms/step - loss: 0.1450 - accuracy: 0.6615 - precision_m: 0.9231 - recall_m: 0.8937 - f1_m: 0.9074 - val_loss: 0.2463 - val_accuracy: 0.7064 - val_precision_m: 0.8381 - val_recall_m: 0.7781 - val_f1_m: 0.8055\n","Epoch 49/1000\n","131/131 [==============================] - 1s 5ms/step - loss: 0.1411 - accuracy: 0.6691 - precision_m: 0.9270 - recall_m: 0.8955 - f1_m: 0.9104 - val_loss: 0.2478 - val_accuracy: 0.7159 - val_precision_m: 0.8392 - val_recall_m: 0.7745 - val_f1_m: 0.8045\n","Epoch 50/1000\n","131/131 [==============================] - 1s 6ms/step - loss: 0.1378 - accuracy: 0.6858 - precision_m: 0.9330 - recall_m: 0.8989 - f1_m: 0.9150 - val_loss: 0.2468 - val_accuracy: 0.7131 - val_precision_m: 0.8353 - val_recall_m: 0.7949 - val_f1_m: 0.8131\n","Epoch 51/1000\n","131/131 [==============================] - 1s 5ms/step - loss: 0.1406 - accuracy: 0.6707 - precision_m: 0.9312 - recall_m: 0.8967 - f1_m: 0.9130 - val_loss: 0.2463 - val_accuracy: 0.6997 - val_precision_m: 0.8417 - val_recall_m: 0.7746 - val_f1_m: 0.8052\n","Epoch 52/1000\n","131/131 [==============================] - 1s 5ms/step - loss: 0.1389 - accuracy: 0.6563 - precision_m: 0.9277 - recall_m: 0.8953 - f1_m: 0.9103 - val_loss: 0.2487 - val_accuracy: 0.6978 - val_precision_m: 0.8429 - val_recall_m: 0.7730 - val_f1_m: 0.8050\n","Epoch 53/1000\n","131/131 [==============================] - 1s 5ms/step - loss: 0.1317 - accuracy: 0.6879 - precision_m: 0.9382 - recall_m: 0.8997 - f1_m: 0.9179 - val_loss: 0.2549 - val_accuracy: 0.7207 - val_precision_m: 0.8138 - val_recall_m: 0.8047 - val_f1_m: 0.8081\n","Epoch 54/1000\n","131/131 [==============================] - 1s 5ms/step - loss: 0.1349 - accuracy: 0.6842 - precision_m: 0.9307 - recall_m: 0.9031 - f1_m: 0.9160 - val_loss: 0.2499 - val_accuracy: 0.7102 - val_precision_m: 0.8281 - val_recall_m: 0.8035 - val_f1_m: 0.8145\n","Epoch 55/1000\n","131/131 [==============================] - 1s 5ms/step - loss: 0.1303 - accuracy: 0.6782 - precision_m: 0.9351 - recall_m: 0.9065 - f1_m: 0.9201 - val_loss: 0.2540 - val_accuracy: 0.7140 - val_precision_m: 0.8338 - val_recall_m: 0.7958 - val_f1_m: 0.8132\n","Epoch 56/1000\n","131/131 [==============================] - 1s 5ms/step - loss: 0.1380 - accuracy: 0.6720 - precision_m: 0.9331 - recall_m: 0.8969 - f1_m: 0.9139 - val_loss: 0.2518 - val_accuracy: 0.7016 - val_precision_m: 0.8438 - val_recall_m: 0.7677 - val_f1_m: 0.8027\n","Epoch 57/1000\n","131/131 [==============================] - 1s 5ms/step - loss: 0.1326 - accuracy: 0.6747 - precision_m: 0.9338 - recall_m: 0.9075 - f1_m: 0.9199 - val_loss: 0.2492 - val_accuracy: 0.7007 - val_precision_m: 0.8303 - val_recall_m: 0.7939 - val_f1_m: 0.8101\n","Epoch 58/1000\n","131/131 [==============================] - 1s 5ms/step - loss: 0.1303 - accuracy: 0.6770 - precision_m: 0.9321 - recall_m: 0.9047 - f1_m: 0.9176 - val_loss: 0.2508 - val_accuracy: 0.7064 - val_precision_m: 0.8362 - val_recall_m: 0.8011 - val_f1_m: 0.8168\n","Epoch 59/1000\n","131/131 [==============================] - 1s 5ms/step - loss: 0.1248 - accuracy: 0.6761 - precision_m: 0.9352 - recall_m: 0.9100 - f1_m: 0.9219 - val_loss: 0.2502 - val_accuracy: 0.7045 - val_precision_m: 0.8494 - val_recall_m: 0.7735 - val_f1_m: 0.8080\n","Epoch 60/1000\n","131/131 [==============================] - 1s 6ms/step - loss: 0.1278 - accuracy: 0.6744 - precision_m: 0.9408 - recall_m: 0.8981 - f1_m: 0.9183 - val_loss: 0.2563 - val_accuracy: 0.6988 - val_precision_m: 0.8266 - val_recall_m: 0.7863 - val_f1_m: 0.8046\n","Epoch 61/1000\n","131/131 [==============================] - 1s 6ms/step - loss: 0.1222 - accuracy: 0.6842 - precision_m: 0.9415 - recall_m: 0.9071 - f1_m: 0.9233 - val_loss: 0.2568 - val_accuracy: 0.6845 - val_precision_m: 0.8345 - val_recall_m: 0.7802 - val_f1_m: 0.8046\n","Epoch 62/1000\n","131/131 [==============================] - 1s 5ms/step - loss: 0.1229 - accuracy: 0.6783 - precision_m: 0.9409 - recall_m: 0.9107 - f1_m: 0.9248 - val_loss: 0.2555 - val_accuracy: 0.7026 - val_precision_m: 0.8351 - val_recall_m: 0.7934 - val_f1_m: 0.8123\n","Epoch 63/1000\n","131/131 [==============================] - 1s 5ms/step - loss: 0.1211 - accuracy: 0.6876 - precision_m: 0.9387 - recall_m: 0.9154 - f1_m: 0.9264 - val_loss: 0.2561 - val_accuracy: 0.7121 - val_precision_m: 0.8379 - val_recall_m: 0.7790 - val_f1_m: 0.8062\n","Epoch 64/1000\n","131/131 [==============================] - 1s 5ms/step - loss: 0.1254 - accuracy: 0.6747 - precision_m: 0.9331 - recall_m: 0.9121 - f1_m: 0.9218 - val_loss: 0.2578 - val_accuracy: 0.7274 - val_precision_m: 0.8319 - val_recall_m: 0.7861 - val_f1_m: 0.8075\n","Epoch 65/1000\n","131/131 [==============================] - 1s 5ms/step - loss: 0.1196 - accuracy: 0.6844 - precision_m: 0.9423 - recall_m: 0.9134 - f1_m: 0.9271 - val_loss: 0.2553 - val_accuracy: 0.7035 - val_precision_m: 0.8300 - val_recall_m: 0.7897 - val_f1_m: 0.8082\n","Epoch 66/1000\n","131/131 [==============================] - 1s 5ms/step - loss: 0.1152 - accuracy: 0.6751 - precision_m: 0.9426 - recall_m: 0.9179 - f1_m: 0.9293 - val_loss: 0.2606 - val_accuracy: 0.7045 - val_precision_m: 0.8378 - val_recall_m: 0.7825 - val_f1_m: 0.8080\n","Epoch 67/1000\n","131/131 [==============================] - 1s 5ms/step - loss: 0.1140 - accuracy: 0.6710 - precision_m: 0.9466 - recall_m: 0.9199 - f1_m: 0.9325 - val_loss: 0.2593 - val_accuracy: 0.7245 - val_precision_m: 0.8346 - val_recall_m: 0.7707 - val_f1_m: 0.8001\n","Epoch 68/1000\n","131/131 [==============================] - 1s 5ms/step - loss: 0.1190 - accuracy: 0.6918 - precision_m: 0.9468 - recall_m: 0.9107 - f1_m: 0.9275 - val_loss: 0.2584 - val_accuracy: 0.7064 - val_precision_m: 0.8254 - val_recall_m: 0.7877 - val_f1_m: 0.8046\n","Epoch 69/1000\n","131/131 [==============================] - 1s 5ms/step - loss: 0.1140 - accuracy: 0.6719 - precision_m: 0.9409 - recall_m: 0.9155 - f1_m: 0.9276 - val_loss: 0.2608 - val_accuracy: 0.6959 - val_precision_m: 0.8229 - val_recall_m: 0.7935 - val_f1_m: 0.8067\n","Epoch 70/1000\n","131/131 [==============================] - 1s 5ms/step - loss: 0.1108 - accuracy: 0.6746 - precision_m: 0.9431 - recall_m: 0.9202 - f1_m: 0.9309 - val_loss: 0.2641 - val_accuracy: 0.7264 - val_precision_m: 0.8269 - val_recall_m: 0.7896 - val_f1_m: 0.8064\n","Epoch 71/1000\n","131/131 [==============================] - 1s 5ms/step - loss: 0.1142 - accuracy: 0.6797 - precision_m: 0.9437 - recall_m: 0.9173 - f1_m: 0.9299 - val_loss: 0.2604 - val_accuracy: 0.7064 - val_precision_m: 0.8322 - val_recall_m: 0.7909 - val_f1_m: 0.8098\n","Epoch 72/1000\n","131/131 [==============================] - 1s 5ms/step - loss: 0.1092 - accuracy: 0.6977 - precision_m: 0.9448 - recall_m: 0.9249 - f1_m: 0.9342 - val_loss: 0.2643 - val_accuracy: 0.6978 - val_precision_m: 0.8249 - val_recall_m: 0.7931 - val_f1_m: 0.8073\n","Epoch 73/1000\n","131/131 [==============================] - 1s 5ms/step - loss: 0.1076 - accuracy: 0.6786 - precision_m: 0.9453 - recall_m: 0.9216 - f1_m: 0.9329 - val_loss: 0.2673 - val_accuracy: 0.7007 - val_precision_m: 0.8179 - val_recall_m: 0.8016 - val_f1_m: 0.8082\n","Epoch 74/1000\n","131/131 [==============================] - 1s 6ms/step - loss: 0.1071 - accuracy: 0.6744 - precision_m: 0.9446 - recall_m: 0.9217 - f1_m: 0.9324 - val_loss: 0.2654 - val_accuracy: 0.7197 - val_precision_m: 0.8207 - val_recall_m: 0.7989 - val_f1_m: 0.8084\n","Epoch 75/1000\n","131/131 [==============================] - 1s 5ms/step - loss: 0.1087 - accuracy: 0.6760 - precision_m: 0.9456 - recall_m: 0.9225 - f1_m: 0.9334 - val_loss: 0.2667 - val_accuracy: 0.6959 - val_precision_m: 0.8360 - val_recall_m: 0.7744 - val_f1_m: 0.8024\n","Epoch 76/1000\n","131/131 [==============================] - 1s 5ms/step - loss: 0.1079 - accuracy: 0.6898 - precision_m: 0.9469 - recall_m: 0.9233 - f1_m: 0.9345 - val_loss: 0.2639 - val_accuracy: 0.7102 - val_precision_m: 0.8250 - val_recall_m: 0.7952 - val_f1_m: 0.8087\n","Epoch 00076: early stopping\n","Score for fold 2: loss of 0.3638717532157898; accuracy of 68.24427247047424% ;precision_m of 0.8016425371170044 ;recall_m of 0.7732803821563721 ;            f1_m of 0.7855929136276245\n","Epoch 1/1000\n","131/131 [==============================] - 1s 7ms/step - loss: 0.6019 - accuracy: 0.2948 - precision_m: 0.5410 - recall_m: 0.2976 - f1_m: 0.3635 - val_loss: 0.3704 - val_accuracy: 0.6378 - val_precision_m: 0.7770 - val_recall_m: 0.6768 - val_f1_m: 0.7218\n","Epoch 2/1000\n","131/131 [==============================] - 1s 6ms/step - loss: 0.4053 - accuracy: 0.5405 - precision_m: 0.7654 - recall_m: 0.6270 - f1_m: 0.6872 - val_loss: 0.3267 - val_accuracy: 0.6549 - val_precision_m: 0.7831 - val_recall_m: 0.7304 - val_f1_m: 0.7540\n","Epoch 3/1000\n","131/131 [==============================] - 1s 5ms/step - loss: 0.3560 - accuracy: 0.5549 - precision_m: 0.8002 - recall_m: 0.6962 - f1_m: 0.7428 - val_loss: 0.3062 - val_accuracy: 0.6520 - val_precision_m: 0.7799 - val_recall_m: 0.7379 - val_f1_m: 0.7561\n","Epoch 4/1000\n","131/131 [==============================] - 1s 6ms/step - loss: 0.3286 - accuracy: 0.5801 - precision_m: 0.8181 - recall_m: 0.7316 - f1_m: 0.7709 - val_loss: 0.3062 - val_accuracy: 0.6740 - val_precision_m: 0.7995 - val_recall_m: 0.7203 - val_f1_m: 0.7560\n","Epoch 5/1000\n","131/131 [==============================] - 1s 7ms/step - loss: 0.3157 - accuracy: 0.5803 - precision_m: 0.8296 - recall_m: 0.7454 - f1_m: 0.7839 - val_loss: 0.2950 - val_accuracy: 0.6759 - val_precision_m: 0.8069 - val_recall_m: 0.7525 - val_f1_m: 0.7773\n","Epoch 6/1000\n","131/131 [==============================] - 1s 5ms/step - loss: 0.3026 - accuracy: 0.5752 - precision_m: 0.8381 - recall_m: 0.7620 - f1_m: 0.7970 - val_loss: 0.2911 - val_accuracy: 0.6721 - val_precision_m: 0.8060 - val_recall_m: 0.7632 - val_f1_m: 0.7823\n","Epoch 7/1000\n","131/131 [==============================] - 1s 6ms/step - loss: 0.2969 - accuracy: 0.5896 - precision_m: 0.8315 - recall_m: 0.7692 - f1_m: 0.7983 - val_loss: 0.2886 - val_accuracy: 0.6749 - val_precision_m: 0.8187 - val_recall_m: 0.7504 - val_f1_m: 0.7811\n","Epoch 8/1000\n","131/131 [==============================] - 1s 6ms/step - loss: 0.2837 - accuracy: 0.5965 - precision_m: 0.8443 - recall_m: 0.7829 - f1_m: 0.8113 - val_loss: 0.2952 - val_accuracy: 0.6826 - val_precision_m: 0.7895 - val_recall_m: 0.7796 - val_f1_m: 0.7829\n","Epoch 9/1000\n","131/131 [==============================] - 1s 5ms/step - loss: 0.2810 - accuracy: 0.5918 - precision_m: 0.8473 - recall_m: 0.7841 - f1_m: 0.8133 - val_loss: 0.2917 - val_accuracy: 0.6759 - val_precision_m: 0.8259 - val_recall_m: 0.7253 - val_f1_m: 0.7709\n","Epoch 10/1000\n","131/131 [==============================] - 1s 6ms/step - loss: 0.2673 - accuracy: 0.6051 - precision_m: 0.8564 - recall_m: 0.7923 - f1_m: 0.8218 - val_loss: 0.2844 - val_accuracy: 0.6854 - val_precision_m: 0.8350 - val_recall_m: 0.7316 - val_f1_m: 0.7781\n","Epoch 11/1000\n","131/131 [==============================] - 1s 6ms/step - loss: 0.2653 - accuracy: 0.5933 - precision_m: 0.8672 - recall_m: 0.7941 - f1_m: 0.8281 - val_loss: 0.2792 - val_accuracy: 0.6683 - val_precision_m: 0.8355 - val_recall_m: 0.7299 - val_f1_m: 0.7771\n","Epoch 12/1000\n","131/131 [==============================] - 1s 6ms/step - loss: 0.2554 - accuracy: 0.6095 - precision_m: 0.8646 - recall_m: 0.7957 - f1_m: 0.8276 - val_loss: 0.2831 - val_accuracy: 0.6768 - val_precision_m: 0.8200 - val_recall_m: 0.7582 - val_f1_m: 0.7861\n","Epoch 13/1000\n","131/131 [==============================] - 1s 6ms/step - loss: 0.2549 - accuracy: 0.6052 - precision_m: 0.8656 - recall_m: 0.8020 - f1_m: 0.8316 - val_loss: 0.2833 - val_accuracy: 0.6797 - val_precision_m: 0.8171 - val_recall_m: 0.7533 - val_f1_m: 0.7820\n","Epoch 14/1000\n","131/131 [==============================] - 1s 6ms/step - loss: 0.2489 - accuracy: 0.5994 - precision_m: 0.8723 - recall_m: 0.8120 - f1_m: 0.8401 - val_loss: 0.2798 - val_accuracy: 0.6873 - val_precision_m: 0.8270 - val_recall_m: 0.7542 - val_f1_m: 0.7872\n","Epoch 15/1000\n","131/131 [==============================] - 1s 6ms/step - loss: 0.2531 - accuracy: 0.6067 - precision_m: 0.8657 - recall_m: 0.8084 - f1_m: 0.8351 - val_loss: 0.2785 - val_accuracy: 0.6930 - val_precision_m: 0.8428 - val_recall_m: 0.7306 - val_f1_m: 0.7809\n","Epoch 16/1000\n","131/131 [==============================] - 1s 6ms/step - loss: 0.2436 - accuracy: 0.6149 - precision_m: 0.8781 - recall_m: 0.8054 - f1_m: 0.8392 - val_loss: 0.2727 - val_accuracy: 0.6892 - val_precision_m: 0.8367 - val_recall_m: 0.7495 - val_f1_m: 0.7892\n","Epoch 17/1000\n","131/131 [==============================] - 1s 6ms/step - loss: 0.2383 - accuracy: 0.6226 - precision_m: 0.8803 - recall_m: 0.8151 - f1_m: 0.8457 - val_loss: 0.2775 - val_accuracy: 0.6997 - val_precision_m: 0.8388 - val_recall_m: 0.7381 - val_f1_m: 0.7835\n","Epoch 18/1000\n","131/131 [==============================] - 1s 6ms/step - loss: 0.2389 - accuracy: 0.6167 - precision_m: 0.8771 - recall_m: 0.8160 - f1_m: 0.8445 - val_loss: 0.2802 - val_accuracy: 0.6864 - val_precision_m: 0.8130 - val_recall_m: 0.7737 - val_f1_m: 0.7912\n","Epoch 19/1000\n","131/131 [==============================] - 1s 6ms/step - loss: 0.2291 - accuracy: 0.6020 - precision_m: 0.8802 - recall_m: 0.8302 - f1_m: 0.8536 - val_loss: 0.2845 - val_accuracy: 0.6988 - val_precision_m: 0.8200 - val_recall_m: 0.7595 - val_f1_m: 0.7866\n","Epoch 20/1000\n","131/131 [==============================] - 1s 6ms/step - loss: 0.2276 - accuracy: 0.6202 - precision_m: 0.8853 - recall_m: 0.8248 - f1_m: 0.8528 - val_loss: 0.2768 - val_accuracy: 0.6835 - val_precision_m: 0.8231 - val_recall_m: 0.7590 - val_f1_m: 0.7882\n","Epoch 21/1000\n","131/131 [==============================] - 1s 6ms/step - loss: 0.2239 - accuracy: 0.6439 - precision_m: 0.8826 - recall_m: 0.8298 - f1_m: 0.8545 - val_loss: 0.2749 - val_accuracy: 0.6854 - val_precision_m: 0.8181 - val_recall_m: 0.7728 - val_f1_m: 0.7934\n","Epoch 22/1000\n","131/131 [==============================] - 1s 6ms/step - loss: 0.2154 - accuracy: 0.6235 - precision_m: 0.8900 - recall_m: 0.8373 - f1_m: 0.8621 - val_loss: 0.2788 - val_accuracy: 0.6959 - val_precision_m: 0.8343 - val_recall_m: 0.7561 - val_f1_m: 0.7914\n","Epoch 23/1000\n","131/131 [==============================] - 1s 5ms/step - loss: 0.2184 - accuracy: 0.6230 - precision_m: 0.8902 - recall_m: 0.8265 - f1_m: 0.8562 - val_loss: 0.2842 - val_accuracy: 0.7016 - val_precision_m: 0.8306 - val_recall_m: 0.7513 - val_f1_m: 0.7873\n","Epoch 24/1000\n","131/131 [==============================] - 1s 6ms/step - loss: 0.2119 - accuracy: 0.6365 - precision_m: 0.8916 - recall_m: 0.8421 - f1_m: 0.8650 - val_loss: 0.2879 - val_accuracy: 0.6978 - val_precision_m: 0.8040 - val_recall_m: 0.7887 - val_f1_m: 0.7945\n","Epoch 25/1000\n","131/131 [==============================] - 1s 5ms/step - loss: 0.2057 - accuracy: 0.6446 - precision_m: 0.8927 - recall_m: 0.8520 - f1_m: 0.8705 - val_loss: 0.2853 - val_accuracy: 0.7007 - val_precision_m: 0.8360 - val_recall_m: 0.7603 - val_f1_m: 0.7946\n","Epoch 26/1000\n","131/131 [==============================] - 1s 6ms/step - loss: 0.2042 - accuracy: 0.6365 - precision_m: 0.8987 - recall_m: 0.8440 - f1_m: 0.8697 - val_loss: 0.2816 - val_accuracy: 0.7064 - val_precision_m: 0.8209 - val_recall_m: 0.7698 - val_f1_m: 0.7928\n","Epoch 27/1000\n","131/131 [==============================] - 1s 6ms/step - loss: 0.1975 - accuracy: 0.6383 - precision_m: 0.9021 - recall_m: 0.8538 - f1_m: 0.8764 - val_loss: 0.2842 - val_accuracy: 0.6940 - val_precision_m: 0.8244 - val_recall_m: 0.7573 - val_f1_m: 0.7876\n","Epoch 28/1000\n","131/131 [==============================] - 1s 5ms/step - loss: 0.1910 - accuracy: 0.6382 - precision_m: 0.9048 - recall_m: 0.8631 - f1_m: 0.8826 - val_loss: 0.2730 - val_accuracy: 0.6988 - val_precision_m: 0.8411 - val_recall_m: 0.7549 - val_f1_m: 0.7941\n","Epoch 29/1000\n","131/131 [==============================] - 1s 6ms/step - loss: 0.1969 - accuracy: 0.6200 - precision_m: 0.9043 - recall_m: 0.8487 - f1_m: 0.8747 - val_loss: 0.2871 - val_accuracy: 0.6930 - val_precision_m: 0.8176 - val_recall_m: 0.7493 - val_f1_m: 0.7801\n","Epoch 30/1000\n","131/131 [==============================] - 1s 5ms/step - loss: 0.1900 - accuracy: 0.6262 - precision_m: 0.9093 - recall_m: 0.8565 - f1_m: 0.8814 - val_loss: 0.2942 - val_accuracy: 0.6988 - val_precision_m: 0.8199 - val_recall_m: 0.7539 - val_f1_m: 0.7838\n","Epoch 31/1000\n","131/131 [==============================] - 1s 5ms/step - loss: 0.1848 - accuracy: 0.6353 - precision_m: 0.9011 - recall_m: 0.8663 - f1_m: 0.8825 - val_loss: 0.2793 - val_accuracy: 0.6988 - val_precision_m: 0.8247 - val_recall_m: 0.7586 - val_f1_m: 0.7888\n","Epoch 32/1000\n","131/131 [==============================] - 1s 6ms/step - loss: 0.1896 - accuracy: 0.6323 - precision_m: 0.9071 - recall_m: 0.8593 - f1_m: 0.8818 - val_loss: 0.2920 - val_accuracy: 0.6949 - val_precision_m: 0.8131 - val_recall_m: 0.7788 - val_f1_m: 0.7939\n","Epoch 33/1000\n","131/131 [==============================] - 1s 6ms/step - loss: 0.1856 - accuracy: 0.6591 - precision_m: 0.9044 - recall_m: 0.8657 - f1_m: 0.8838 - val_loss: 0.2819 - val_accuracy: 0.7035 - val_precision_m: 0.8403 - val_recall_m: 0.7560 - val_f1_m: 0.7943\n","Epoch 34/1000\n","131/131 [==============================] - 1s 5ms/step - loss: 0.1789 - accuracy: 0.6409 - precision_m: 0.9121 - recall_m: 0.8704 - f1_m: 0.8901 - val_loss: 0.2892 - val_accuracy: 0.6835 - val_precision_m: 0.8164 - val_recall_m: 0.7602 - val_f1_m: 0.7858\n","Epoch 35/1000\n","131/131 [==============================] - 1s 6ms/step - loss: 0.1827 - accuracy: 0.6388 - precision_m: 0.9112 - recall_m: 0.8652 - f1_m: 0.8869 - val_loss: 0.2766 - val_accuracy: 0.7035 - val_precision_m: 0.8381 - val_recall_m: 0.7496 - val_f1_m: 0.7899\n","Epoch 36/1000\n","131/131 [==============================] - 1s 6ms/step - loss: 0.1742 - accuracy: 0.6455 - precision_m: 0.9095 - recall_m: 0.8697 - f1_m: 0.8884 - val_loss: 0.2903 - val_accuracy: 0.7054 - val_precision_m: 0.8199 - val_recall_m: 0.7627 - val_f1_m: 0.7886\n","Epoch 37/1000\n","131/131 [==============================] - 1s 6ms/step - loss: 0.1734 - accuracy: 0.6457 - precision_m: 0.9110 - recall_m: 0.8723 - f1_m: 0.8903 - val_loss: 0.2920 - val_accuracy: 0.7045 - val_precision_m: 0.8191 - val_recall_m: 0.7593 - val_f1_m: 0.7865\n","Epoch 38/1000\n","131/131 [==============================] - 1s 6ms/step - loss: 0.1755 - accuracy: 0.6426 - precision_m: 0.9133 - recall_m: 0.8761 - f1_m: 0.8935 - val_loss: 0.2945 - val_accuracy: 0.7226 - val_precision_m: 0.8132 - val_recall_m: 0.7647 - val_f1_m: 0.7863\n","Epoch 39/1000\n","131/131 [==============================] - 1s 5ms/step - loss: 0.1745 - accuracy: 0.6390 - precision_m: 0.9186 - recall_m: 0.8800 - f1_m: 0.8979 - val_loss: 0.2937 - val_accuracy: 0.7054 - val_precision_m: 0.8238 - val_recall_m: 0.7553 - val_f1_m: 0.7863\n","Epoch 40/1000\n","131/131 [==============================] - 1s 6ms/step - loss: 0.1641 - accuracy: 0.6546 - precision_m: 0.9209 - recall_m: 0.8739 - f1_m: 0.8959 - val_loss: 0.2933 - val_accuracy: 0.7121 - val_precision_m: 0.8275 - val_recall_m: 0.7562 - val_f1_m: 0.7885\n","Epoch 41/1000\n","131/131 [==============================] - 1s 6ms/step - loss: 0.1662 - accuracy: 0.6413 - precision_m: 0.9133 - recall_m: 0.8789 - f1_m: 0.8950 - val_loss: 0.3051 - val_accuracy: 0.7073 - val_precision_m: 0.7967 - val_recall_m: 0.7698 - val_f1_m: 0.7810\n","Epoch 42/1000\n","131/131 [==============================] - 1s 6ms/step - loss: 0.1652 - accuracy: 0.6597 - precision_m: 0.9145 - recall_m: 0.8862 - f1_m: 0.8990 - val_loss: 0.2977 - val_accuracy: 0.6930 - val_precision_m: 0.8288 - val_recall_m: 0.7436 - val_f1_m: 0.7822\n","Epoch 43/1000\n","131/131 [==============================] - 1s 6ms/step - loss: 0.1606 - accuracy: 0.6557 - precision_m: 0.9237 - recall_m: 0.8852 - f1_m: 0.9034 - val_loss: 0.2945 - val_accuracy: 0.7073 - val_precision_m: 0.8152 - val_recall_m: 0.7719 - val_f1_m: 0.7912\n","Epoch 44/1000\n","131/131 [==============================] - 1s 6ms/step - loss: 0.1558 - accuracy: 0.6530 - precision_m: 0.9234 - recall_m: 0.8880 - f1_m: 0.9046 - val_loss: 0.2986 - val_accuracy: 0.6988 - val_precision_m: 0.8165 - val_recall_m: 0.7750 - val_f1_m: 0.7934\n","Epoch 45/1000\n","131/131 [==============================] - 1s 6ms/step - loss: 0.1570 - accuracy: 0.6485 - precision_m: 0.9229 - recall_m: 0.8893 - f1_m: 0.9053 - val_loss: 0.3045 - val_accuracy: 0.7045 - val_precision_m: 0.8120 - val_recall_m: 0.7608 - val_f1_m: 0.7839\n","Epoch 46/1000\n","131/131 [==============================] - 1s 6ms/step - loss: 0.1651 - accuracy: 0.6583 - precision_m: 0.9183 - recall_m: 0.8792 - f1_m: 0.8973 - val_loss: 0.2958 - val_accuracy: 0.6969 - val_precision_m: 0.8212 - val_recall_m: 0.7736 - val_f1_m: 0.7949\n","Epoch 47/1000\n","131/131 [==============================] - 1s 6ms/step - loss: 0.1482 - accuracy: 0.6571 - precision_m: 0.9255 - recall_m: 0.8952 - f1_m: 0.9094 - val_loss: 0.2938 - val_accuracy: 0.6911 - val_precision_m: 0.8288 - val_recall_m: 0.7665 - val_f1_m: 0.7948\n","Epoch 48/1000\n","131/131 [==============================] - 1s 6ms/step - loss: 0.1507 - accuracy: 0.6476 - precision_m: 0.9257 - recall_m: 0.8919 - f1_m: 0.9076 - val_loss: 0.2969 - val_accuracy: 0.7092 - val_precision_m: 0.8358 - val_recall_m: 0.7500 - val_f1_m: 0.7888\n","Epoch 49/1000\n","131/131 [==============================] - 1s 6ms/step - loss: 0.1560 - accuracy: 0.6613 - precision_m: 0.9238 - recall_m: 0.8867 - f1_m: 0.9043 - val_loss: 0.2944 - val_accuracy: 0.7054 - val_precision_m: 0.8203 - val_recall_m: 0.7644 - val_f1_m: 0.7898\n","Epoch 50/1000\n","131/131 [==============================] - 1s 5ms/step - loss: 0.1518 - accuracy: 0.6477 - precision_m: 0.9259 - recall_m: 0.8907 - f1_m: 0.9072 - val_loss: 0.2965 - val_accuracy: 0.7035 - val_precision_m: 0.8178 - val_recall_m: 0.7572 - val_f1_m: 0.7845\n","Epoch 51/1000\n","131/131 [==============================] - 1s 5ms/step - loss: 0.1437 - accuracy: 0.6579 - precision_m: 0.9306 - recall_m: 0.9000 - f1_m: 0.9144 - val_loss: 0.3058 - val_accuracy: 0.6969 - val_precision_m: 0.8140 - val_recall_m: 0.7607 - val_f1_m: 0.7848\n","Epoch 52/1000\n","131/131 [==============================] - 1s 6ms/step - loss: 0.1474 - accuracy: 0.6702 - precision_m: 0.9244 - recall_m: 0.9000 - f1_m: 0.9111 - val_loss: 0.3067 - val_accuracy: 0.7131 - val_precision_m: 0.8233 - val_recall_m: 0.7455 - val_f1_m: 0.7806\n","Epoch 53/1000\n","131/131 [==============================] - 1s 5ms/step - loss: 0.1460 - accuracy: 0.6426 - precision_m: 0.9295 - recall_m: 0.8923 - f1_m: 0.9100 - val_loss: 0.3012 - val_accuracy: 0.6930 - val_precision_m: 0.8116 - val_recall_m: 0.7590 - val_f1_m: 0.7831\n","Epoch 54/1000\n","131/131 [==============================] - 1s 5ms/step - loss: 0.1406 - accuracy: 0.6569 - precision_m: 0.9285 - recall_m: 0.9017 - f1_m: 0.9143 - val_loss: 0.3003 - val_accuracy: 0.7102 - val_precision_m: 0.8370 - val_recall_m: 0.7461 - val_f1_m: 0.7874\n","Epoch 55/1000\n","131/131 [==============================] - 1s 6ms/step - loss: 0.1392 - accuracy: 0.6641 - precision_m: 0.9360 - recall_m: 0.8950 - f1_m: 0.9142 - val_loss: 0.3082 - val_accuracy: 0.7026 - val_precision_m: 0.8169 - val_recall_m: 0.7579 - val_f1_m: 0.7842\n","Epoch 56/1000\n","131/131 [==============================] - 1s 6ms/step - loss: 0.1406 - accuracy: 0.6569 - precision_m: 0.9313 - recall_m: 0.8986 - f1_m: 0.9142 - val_loss: 0.3061 - val_accuracy: 0.7064 - val_precision_m: 0.8317 - val_recall_m: 0.7404 - val_f1_m: 0.7816\n","Epoch 57/1000\n","131/131 [==============================] - 1s 6ms/step - loss: 0.1357 - accuracy: 0.6524 - precision_m: 0.9374 - recall_m: 0.9018 - f1_m: 0.9187 - val_loss: 0.3037 - val_accuracy: 0.7092 - val_precision_m: 0.8268 - val_recall_m: 0.7591 - val_f1_m: 0.7896\n","Epoch 58/1000\n","131/131 [==============================] - 1s 6ms/step - loss: 0.1384 - accuracy: 0.6552 - precision_m: 0.9335 - recall_m: 0.8984 - f1_m: 0.9150 - val_loss: 0.2981 - val_accuracy: 0.7007 - val_precision_m: 0.8273 - val_recall_m: 0.7548 - val_f1_m: 0.7876\n","Epoch 59/1000\n","131/131 [==============================] - 1s 5ms/step - loss: 0.1282 - accuracy: 0.6531 - precision_m: 0.9366 - recall_m: 0.9109 - f1_m: 0.9231 - val_loss: 0.3033 - val_accuracy: 0.7092 - val_precision_m: 0.8283 - val_recall_m: 0.7488 - val_f1_m: 0.7847\n","Epoch 60/1000\n","131/131 [==============================] - 1s 5ms/step - loss: 0.1341 - accuracy: 0.6757 - precision_m: 0.9364 - recall_m: 0.9074 - f1_m: 0.9211 - val_loss: 0.3070 - val_accuracy: 0.6873 - val_precision_m: 0.8244 - val_recall_m: 0.7485 - val_f1_m: 0.7832\n","Epoch 61/1000\n","131/131 [==============================] - 1s 5ms/step - loss: 0.1285 - accuracy: 0.6663 - precision_m: 0.9389 - recall_m: 0.9086 - f1_m: 0.9229 - val_loss: 0.3068 - val_accuracy: 0.7035 - val_precision_m: 0.8235 - val_recall_m: 0.7598 - val_f1_m: 0.7887\n","Epoch 62/1000\n","131/131 [==============================] - 1s 6ms/step - loss: 0.1352 - accuracy: 0.6560 - precision_m: 0.9364 - recall_m: 0.9016 - f1_m: 0.9181 - val_loss: 0.3019 - val_accuracy: 0.6949 - val_precision_m: 0.8273 - val_recall_m: 0.7598 - val_f1_m: 0.7902\n","Epoch 63/1000\n","131/131 [==============================] - 1s 6ms/step - loss: 0.1272 - accuracy: 0.6568 - precision_m: 0.9358 - recall_m: 0.9072 - f1_m: 0.9207 - val_loss: 0.3120 - val_accuracy: 0.7150 - val_precision_m: 0.8164 - val_recall_m: 0.7611 - val_f1_m: 0.7860\n","Epoch 64/1000\n","131/131 [==============================] - 1s 6ms/step - loss: 0.1220 - accuracy: 0.6732 - precision_m: 0.9422 - recall_m: 0.9190 - f1_m: 0.9300 - val_loss: 0.3098 - val_accuracy: 0.7102 - val_precision_m: 0.8144 - val_recall_m: 0.7703 - val_f1_m: 0.7897\n","Epoch 65/1000\n","131/131 [==============================] - 1s 6ms/step - loss: 0.1214 - accuracy: 0.6555 - precision_m: 0.9411 - recall_m: 0.9175 - f1_m: 0.9287 - val_loss: 0.3073 - val_accuracy: 0.7007 - val_precision_m: 0.8303 - val_recall_m: 0.7478 - val_f1_m: 0.7850\n","Epoch 66/1000\n","131/131 [==============================] - 1s 6ms/step - loss: 0.1233 - accuracy: 0.6656 - precision_m: 0.9383 - recall_m: 0.9106 - f1_m: 0.9235 - val_loss: 0.3113 - val_accuracy: 0.7083 - val_precision_m: 0.8284 - val_recall_m: 0.7486 - val_f1_m: 0.7845\n","Epoch 67/1000\n","131/131 [==============================] - 1s 6ms/step - loss: 0.1168 - accuracy: 0.6663 - precision_m: 0.9471 - recall_m: 0.9178 - f1_m: 0.9317 - val_loss: 0.3227 - val_accuracy: 0.7045 - val_precision_m: 0.8093 - val_recall_m: 0.7609 - val_f1_m: 0.7825\n","Epoch 68/1000\n","131/131 [==============================] - 1s 7ms/step - loss: 0.1209 - accuracy: 0.6639 - precision_m: 0.9427 - recall_m: 0.9179 - f1_m: 0.9296 - val_loss: 0.3095 - val_accuracy: 0.6911 - val_precision_m: 0.8275 - val_recall_m: 0.7586 - val_f1_m: 0.7897\n","Epoch 69/1000\n","131/131 [==============================] - 1s 6ms/step - loss: 0.1228 - accuracy: 0.6518 - precision_m: 0.9390 - recall_m: 0.9132 - f1_m: 0.9252 - val_loss: 0.3195 - val_accuracy: 0.7007 - val_precision_m: 0.8020 - val_recall_m: 0.7794 - val_f1_m: 0.7889\n","Epoch 70/1000\n","131/131 [==============================] - 1s 6ms/step - loss: 0.1213 - accuracy: 0.6645 - precision_m: 0.9428 - recall_m: 0.9148 - f1_m: 0.9281 - val_loss: 0.3068 - val_accuracy: 0.6816 - val_precision_m: 0.8296 - val_recall_m: 0.7601 - val_f1_m: 0.7919\n","Epoch 71/1000\n","131/131 [==============================] - 1s 6ms/step - loss: 0.1222 - accuracy: 0.6598 - precision_m: 0.9381 - recall_m: 0.9100 - f1_m: 0.9232 - val_loss: 0.3085 - val_accuracy: 0.6902 - val_precision_m: 0.8286 - val_recall_m: 0.7515 - val_f1_m: 0.7864\n","Epoch 72/1000\n","131/131 [==============================] - 1s 6ms/step - loss: 0.1211 - accuracy: 0.6549 - precision_m: 0.9446 - recall_m: 0.9154 - f1_m: 0.9290 - val_loss: 0.3171 - val_accuracy: 0.7016 - val_precision_m: 0.8140 - val_recall_m: 0.7564 - val_f1_m: 0.7820\n","Epoch 73/1000\n","131/131 [==============================] - 1s 6ms/step - loss: 0.1184 - accuracy: 0.6722 - precision_m: 0.9488 - recall_m: 0.9141 - f1_m: 0.9305 - val_loss: 0.3116 - val_accuracy: 0.6911 - val_precision_m: 0.8239 - val_recall_m: 0.7594 - val_f1_m: 0.7887\n","Epoch 74/1000\n","131/131 [==============================] - 1s 6ms/step - loss: 0.1163 - accuracy: 0.6718 - precision_m: 0.9465 - recall_m: 0.9174 - f1_m: 0.9312 - val_loss: 0.3176 - val_accuracy: 0.7035 - val_precision_m: 0.8170 - val_recall_m: 0.7677 - val_f1_m: 0.7897\n","Epoch 75/1000\n","131/131 [==============================] - 1s 6ms/step - loss: 0.1166 - accuracy: 0.6735 - precision_m: 0.9428 - recall_m: 0.9180 - f1_m: 0.9298 - val_loss: 0.3209 - val_accuracy: 0.6930 - val_precision_m: 0.8092 - val_recall_m: 0.7695 - val_f1_m: 0.7870\n","Epoch 76/1000\n","131/131 [==============================] - 1s 6ms/step - loss: 0.1131 - accuracy: 0.6638 - precision_m: 0.9432 - recall_m: 0.9159 - f1_m: 0.9288 - val_loss: 0.3324 - val_accuracy: 0.7045 - val_precision_m: 0.8184 - val_recall_m: 0.7481 - val_f1_m: 0.7795\n","Epoch 77/1000\n","131/131 [==============================] - 1s 6ms/step - loss: 0.1146 - accuracy: 0.6568 - precision_m: 0.9459 - recall_m: 0.9200 - f1_m: 0.9323 - val_loss: 0.3212 - val_accuracy: 0.6969 - val_precision_m: 0.8137 - val_recall_m: 0.7678 - val_f1_m: 0.7882\n","Epoch 78/1000\n","131/131 [==============================] - 1s 6ms/step - loss: 0.1133 - accuracy: 0.6742 - precision_m: 0.9448 - recall_m: 0.9220 - f1_m: 0.9326 - val_loss: 0.3212 - val_accuracy: 0.6940 - val_precision_m: 0.8273 - val_recall_m: 0.7549 - val_f1_m: 0.7874\n","Epoch 79/1000\n","131/131 [==============================] - 1s 6ms/step - loss: 0.1067 - accuracy: 0.6595 - precision_m: 0.9500 - recall_m: 0.9223 - f1_m: 0.9354 - val_loss: 0.3334 - val_accuracy: 0.7064 - val_precision_m: 0.8128 - val_recall_m: 0.7514 - val_f1_m: 0.7788\n","Epoch 80/1000\n","131/131 [==============================] - 1s 6ms/step - loss: 0.1103 - accuracy: 0.6770 - precision_m: 0.9469 - recall_m: 0.9265 - f1_m: 0.9361 - val_loss: 0.3222 - val_accuracy: 0.6949 - val_precision_m: 0.8129 - val_recall_m: 0.7539 - val_f1_m: 0.7804\n","Epoch 81/1000\n","131/131 [==============================] - 1s 6ms/step - loss: 0.1092 - accuracy: 0.6682 - precision_m: 0.9491 - recall_m: 0.9223 - f1_m: 0.9348 - val_loss: 0.3370 - val_accuracy: 0.7083 - val_precision_m: 0.8168 - val_recall_m: 0.7508 - val_f1_m: 0.7802\n","Epoch 82/1000\n","131/131 [==============================] - 1s 6ms/step - loss: 0.1096 - accuracy: 0.6498 - precision_m: 0.9465 - recall_m: 0.9254 - f1_m: 0.9354 - val_loss: 0.3225 - val_accuracy: 0.6949 - val_precision_m: 0.8194 - val_recall_m: 0.7555 - val_f1_m: 0.7840\n","Epoch 83/1000\n","131/131 [==============================] - 1s 6ms/step - loss: 0.1080 - accuracy: 0.6568 - precision_m: 0.9486 - recall_m: 0.9264 - f1_m: 0.9369 - val_loss: 0.3176 - val_accuracy: 0.6864 - val_precision_m: 0.8184 - val_recall_m: 0.7520 - val_f1_m: 0.7819\n","Epoch 84/1000\n","131/131 [==============================] - 1s 6ms/step - loss: 0.1096 - accuracy: 0.6752 - precision_m: 0.9511 - recall_m: 0.9263 - f1_m: 0.9381 - val_loss: 0.3314 - val_accuracy: 0.7026 - val_precision_m: 0.8180 - val_recall_m: 0.7470 - val_f1_m: 0.7791\n","Epoch 85/1000\n","131/131 [==============================] - 1s 6ms/step - loss: 0.1026 - accuracy: 0.6570 - precision_m: 0.9517 - recall_m: 0.9228 - f1_m: 0.9365 - val_loss: 0.3373 - val_accuracy: 0.7064 - val_precision_m: 0.8114 - val_recall_m: 0.7483 - val_f1_m: 0.7763\n","Epoch 86/1000\n","131/131 [==============================] - 1s 6ms/step - loss: 0.1024 - accuracy: 0.6637 - precision_m: 0.9539 - recall_m: 0.9300 - f1_m: 0.9414 - val_loss: 0.3324 - val_accuracy: 0.6978 - val_precision_m: 0.8061 - val_recall_m: 0.7599 - val_f1_m: 0.7805\n","Epoch 87/1000\n","131/131 [==============================] - 1s 6ms/step - loss: 0.1055 - accuracy: 0.6694 - precision_m: 0.9497 - recall_m: 0.9306 - f1_m: 0.9396 - val_loss: 0.3323 - val_accuracy: 0.6969 - val_precision_m: 0.8088 - val_recall_m: 0.7579 - val_f1_m: 0.7805\n","Epoch 88/1000\n","131/131 [==============================] - 1s 6ms/step - loss: 0.1061 - accuracy: 0.6632 - precision_m: 0.9503 - recall_m: 0.9291 - f1_m: 0.9392 - val_loss: 0.3392 - val_accuracy: 0.7016 - val_precision_m: 0.8000 - val_recall_m: 0.7772 - val_f1_m: 0.7865\n","Epoch 89/1000\n","131/131 [==============================] - 1s 7ms/step - loss: 0.1006 - accuracy: 0.6553 - precision_m: 0.9497 - recall_m: 0.9320 - f1_m: 0.9403 - val_loss: 0.3347 - val_accuracy: 0.6949 - val_precision_m: 0.8097 - val_recall_m: 0.7457 - val_f1_m: 0.7747\n","Epoch 90/1000\n","131/131 [==============================] - 1s 6ms/step - loss: 0.1055 - accuracy: 0.6580 - precision_m: 0.9536 - recall_m: 0.9280 - f1_m: 0.9402 - val_loss: 0.3315 - val_accuracy: 0.6883 - val_precision_m: 0.8114 - val_recall_m: 0.7544 - val_f1_m: 0.7798\n","Epoch 91/1000\n","131/131 [==============================] - 1s 6ms/step - loss: 0.1023 - accuracy: 0.6692 - precision_m: 0.9507 - recall_m: 0.9310 - f1_m: 0.9404 - val_loss: 0.3317 - val_accuracy: 0.6911 - val_precision_m: 0.8111 - val_recall_m: 0.7619 - val_f1_m: 0.7840\n","Epoch 92/1000\n","131/131 [==============================] - 1s 6ms/step - loss: 0.0954 - accuracy: 0.6544 - precision_m: 0.9587 - recall_m: 0.9360 - f1_m: 0.9468 - val_loss: 0.3404 - val_accuracy: 0.6997 - val_precision_m: 0.8187 - val_recall_m: 0.7464 - val_f1_m: 0.7793\n","Epoch 93/1000\n","131/131 [==============================] - 1s 6ms/step - loss: 0.0976 - accuracy: 0.6619 - precision_m: 0.9560 - recall_m: 0.9344 - f1_m: 0.9446 - val_loss: 0.3404 - val_accuracy: 0.6949 - val_precision_m: 0.8146 - val_recall_m: 0.7514 - val_f1_m: 0.7798\n","Epoch 94/1000\n","131/131 [==============================] - 1s 6ms/step - loss: 0.1015 - accuracy: 0.6728 - precision_m: 0.9574 - recall_m: 0.9342 - f1_m: 0.9452 - val_loss: 0.3402 - val_accuracy: 0.7045 - val_precision_m: 0.8054 - val_recall_m: 0.7633 - val_f1_m: 0.7819\n","Epoch 95/1000\n","131/131 [==============================] - 1s 6ms/step - loss: 0.0964 - accuracy: 0.6804 - precision_m: 0.9539 - recall_m: 0.9344 - f1_m: 0.9435 - val_loss: 0.3491 - val_accuracy: 0.7026 - val_precision_m: 0.7973 - val_recall_m: 0.7620 - val_f1_m: 0.7773\n","Epoch 96/1000\n","131/131 [==============================] - 1s 6ms/step - loss: 0.0930 - accuracy: 0.6593 - precision_m: 0.9556 - recall_m: 0.9386 - f1_m: 0.9465 - val_loss: 0.3392 - val_accuracy: 0.6911 - val_precision_m: 0.8262 - val_recall_m: 0.7439 - val_f1_m: 0.7812\n","Epoch 00096: early stopping\n","Score for fold 3: loss of 0.3051169216632843; accuracy of 67.78625845909119% ;precision_m of 0.8302257061004639 ;recall_m of 0.7345558404922485 ;            f1_m of 0.7779879570007324\n","------------------------------------------------------------------------\n","Score per fold\n","------------------------------------------------------------------------\n","> Fold 1 - Loss: 0.5463671088218689 - Accuracy: 50.40060877799988% - Precision: 0.8486261963844299 - Recall: 0.6860843896865845 - F1: 0.7560235261917114\n","------------------------------------------------------------------------\n","> Fold 2 - Loss: 0.3638717532157898 - Accuracy: 68.24427247047424% - Precision: 0.8016425371170044 - Recall: 0.7732803821563721 - F1: 0.7855929136276245\n","------------------------------------------------------------------------\n","> Fold 3 - Loss: 0.3051169216632843 - Accuracy: 67.78625845909119% - Precision: 0.8302257061004639 - Recall: 0.7345558404922485 - F1: 0.7779879570007324\n","------------------------------------------------------------------------\n","Average scores for all folds:\n","> Accuracy: 62.1437132358551 (+- 8.305733800202132)\n","> Precision: 0.8268314798672994\n","> Recall: 0.7313068707784017\n","> F1: 0.7732014656066895\n","> Loss: 0.405118594566981\n","------------------------------------------------------------------------\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"xm30GhiyCwgB"},"source":["# CNN Model with Train/Test/Val \r\n"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"A33OEtfuCvZc","executionInfo":{"elapsed":44744,"status":"ok","timestamp":1613901673162,"user":{"displayName":"Shanaka Chathuranga","photoUrl":"","userId":"01381725564551416324"},"user_tz":-330},"outputId":"80994d55-2b46-4420-b43d-c5242d80557d"},"source":["N_FOLDS=3 \r\n","EPOCHS=100\r\n","VALIDATION_SPLIT=0.2\r\n","BATCH_SIZE=32\r\n","PATIENCE=20\r\n","MONITOR='val_f1_m'\r\n","MONITOR_MODE='max'\r\n","SHUFFLE=True\r\n","BEST_MODEL=mainloc+'best_model.hdf5'\r\n","EMBEDDING_SIZE=300\r\n","NB_FILTERS=128\r\n","KERNEL_SIZE=3\r\n","\r\n","#128 gives good acucrayc with epoch=50 and patience =10 \r\n","\r\n","def create_model():\r\n","    model = Sequential()\r\n","    embedding_layer = Embedding(vocab_length, 400,weights=[embedding_matrix],input_length=length_long_sentence, trainable=False)\r\n","    model.add(embedding_layer)\r\n","    model.add(Conv1D(NB_FILTERS,KERNEL_SIZE, activation='relu'))\r\n","    model.add(GlobalMaxPooling1D())\r\n","    model.add(Dropout(DROPOUT_VALUE_2))\r\n","    model.add(Flatten())\r\n","    model.add(Dense(3, activation='softmax'))\r\n","    model.compile(loss='categorical_crossentropy', optimizer='adam',metrics=[\"accuracy\",precision_m,recall_m,f1_m])\r\n","    return model \r\n","\r\n","# Define per-fold score containers \r\n","acc_per_fold = []\r\n","loss_per_fold = []\r\n","f1_per_fold = []\r\n","precision_per_fold =[]\r\n","recall_per_fold=[]\r\n","\r\n","#Define dependencied for model loading\r\n","dependencies = {\r\n","    'recall_m': recall_m,\r\n","    'f1_m':f1_m,\r\n","    'precision_m':precision_m    \r\n","}\r\n","\r\n","x, y, x_train,x_test,y_train,y_test,y_train_c,y_test_c = splitdata(padded_sentences,y,0.2,False)\r\n","model=create_model()\r\n","es = EarlyStopping(monitor=MONITOR, mode=MONITOR_MODE, verbose=1,patience= PATIENCE )\r\n","mc = ModelCheckpoint(BEST_MODEL, monitor=MONITOR, mode=MONITOR_MODE, verbose=1, save_best_only=True)\r\n","history = model.fit(x_train, y_train_c,validation_split=VALIDATION_SPLIT,callbacks=[es,mc],epochs=EPOCHS,batch_size=BATCH_SIZE,shuffle=SHUFFLE)\r\n","\r\n","#Load the best model \r\n","model_path=mainloc+'best_model.hdf5'\r\n","model = load_model(model_path,custom_objects=dependencies,compile=True)\r\n","model.compile(loss='categorical_crossentropy', optimizer='adam',metrics=[\"accuracy\",precision_m,recall_m,f1_m])\r\n","\r\n","accuracy_scores_neural(model,x_train,y_train,y_train_c,x_test,y_test,y_test_c,['Neutral', 'Negative', 'Positive'])\r\n","accuracy_curve(history,'loss','loss')\r\n","accuracy_curve(history,'accuracy','accuracy')\r\n","accuracy_curve(history,'f1_m','F1')\r\n","accuracy_curve(history,'precision_m','Precision')\r\n","accuracy_curve(history,'recall_m','Recall')"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Epoch 1/100\n","158/158 [==============================] - 2s 11ms/step - loss: 0.6091 - accuracy: 0.7450 - precision_m: 0.7612 - recall_m: 0.7245 - f1_m: 0.7408 - val_loss: 0.4349 - val_accuracy: 0.8299 - val_precision_m: 0.8368 - val_recall_m: 0.8206 - val_f1_m: 0.8285\n","\n","Epoch 00001: val_f1_m improved from -inf to 0.82847, saving model to /content/drive/My Drive/Research/ABSA_Project/best_model.hdf5\n","Epoch 2/100\n","158/158 [==============================] - 1s 8ms/step - loss: 0.4462 - accuracy: 0.8268 - precision_m: 0.8377 - recall_m: 0.8113 - f1_m: 0.8241 - val_loss: 0.4276 - val_accuracy: 0.8378 - val_precision_m: 0.8412 - val_recall_m: 0.8253 - val_f1_m: 0.8331\n","\n","Epoch 00002: val_f1_m improved from 0.82847 to 0.83308, saving model to /content/drive/My Drive/Research/ABSA_Project/best_model.hdf5\n","Epoch 3/100\n","158/158 [==============================] - 1s 8ms/step - loss: 0.3831 - accuracy: 0.8554 - precision_m: 0.8657 - recall_m: 0.8467 - f1_m: 0.8559 - val_loss: 0.4047 - val_accuracy: 0.8450 - val_precision_m: 0.8552 - val_recall_m: 0.8277 - val_f1_m: 0.8408\n","\n","Epoch 00003: val_f1_m improved from 0.83308 to 0.84079, saving model to /content/drive/My Drive/Research/ABSA_Project/best_model.hdf5\n","Epoch 4/100\n","158/158 [==============================] - 1s 8ms/step - loss: 0.3534 - accuracy: 0.8686 - precision_m: 0.8780 - recall_m: 0.8590 - f1_m: 0.8682 - val_loss: 0.4054 - val_accuracy: 0.8370 - val_precision_m: 0.8428 - val_recall_m: 0.8270 - val_f1_m: 0.8347\n","\n","Epoch 00004: val_f1_m did not improve from 0.84079\n","Epoch 5/100\n","158/158 [==============================] - 1s 8ms/step - loss: 0.3326 - accuracy: 0.8755 - precision_m: 0.8824 - recall_m: 0.8694 - f1_m: 0.8757 - val_loss: 0.4129 - val_accuracy: 0.8339 - val_precision_m: 0.8390 - val_recall_m: 0.8270 - val_f1_m: 0.8329\n","\n","Epoch 00005: val_f1_m did not improve from 0.84079\n","Epoch 6/100\n","158/158 [==============================] - 1s 7ms/step - loss: 0.3218 - accuracy: 0.8743 - precision_m: 0.8810 - recall_m: 0.8691 - f1_m: 0.8749 - val_loss: 0.4067 - val_accuracy: 0.8386 - val_precision_m: 0.8433 - val_recall_m: 0.8308 - val_f1_m: 0.8369\n","\n","Epoch 00006: val_f1_m did not improve from 0.84079\n","Epoch 7/100\n","158/158 [==============================] - 1s 8ms/step - loss: 0.3134 - accuracy: 0.8826 - precision_m: 0.8941 - recall_m: 0.8752 - f1_m: 0.8844 - val_loss: 0.4088 - val_accuracy: 0.8386 - val_precision_m: 0.8436 - val_recall_m: 0.8277 - val_f1_m: 0.8354\n","\n","Epoch 00007: val_f1_m did not improve from 0.84079\n","Epoch 8/100\n","158/158 [==============================] - 1s 7ms/step - loss: 0.3192 - accuracy: 0.8796 - precision_m: 0.8863 - recall_m: 0.8732 - f1_m: 0.8796 - val_loss: 0.4063 - val_accuracy: 0.8442 - val_precision_m: 0.8543 - val_recall_m: 0.8302 - val_f1_m: 0.8419\n","\n","Epoch 00008: val_f1_m improved from 0.84079 to 0.84193, saving model to /content/drive/My Drive/Research/ABSA_Project/best_model.hdf5\n","Epoch 9/100\n","158/158 [==============================] - 1s 8ms/step - loss: 0.3027 - accuracy: 0.8886 - precision_m: 0.8934 - recall_m: 0.8804 - f1_m: 0.8867 - val_loss: 0.4159 - val_accuracy: 0.8347 - val_precision_m: 0.8362 - val_recall_m: 0.8222 - val_f1_m: 0.8290\n","\n","Epoch 00009: val_f1_m did not improve from 0.84193\n","Epoch 10/100\n","158/158 [==============================] - 1s 7ms/step - loss: 0.3029 - accuracy: 0.8838 - precision_m: 0.8898 - recall_m: 0.8765 - f1_m: 0.8830 - val_loss: 0.4217 - val_accuracy: 0.8402 - val_precision_m: 0.8452 - val_recall_m: 0.8364 - val_f1_m: 0.8407\n","\n","Epoch 00010: val_f1_m did not improve from 0.84193\n","Epoch 11/100\n","158/158 [==============================] - 1s 8ms/step - loss: 0.2575 - accuracy: 0.9033 - precision_m: 0.9083 - recall_m: 0.8960 - f1_m: 0.9020 - val_loss: 0.4195 - val_accuracy: 0.8323 - val_precision_m: 0.8377 - val_recall_m: 0.8245 - val_f1_m: 0.8309\n","\n","Epoch 00011: val_f1_m did not improve from 0.84193\n","Epoch 12/100\n","158/158 [==============================] - 1s 8ms/step - loss: 0.2559 - accuracy: 0.9034 - precision_m: 0.9078 - recall_m: 0.8987 - f1_m: 0.9031 - val_loss: 0.4334 - val_accuracy: 0.8402 - val_precision_m: 0.8438 - val_recall_m: 0.8325 - val_f1_m: 0.8380\n","\n","Epoch 00012: val_f1_m did not improve from 0.84193\n","Epoch 13/100\n","158/158 [==============================] - 1s 8ms/step - loss: 0.2578 - accuracy: 0.9041 - precision_m: 0.9101 - recall_m: 0.8982 - f1_m: 0.9040 - val_loss: 0.4225 - val_accuracy: 0.8307 - val_precision_m: 0.8367 - val_recall_m: 0.8239 - val_f1_m: 0.8302\n","\n","Epoch 00013: val_f1_m did not improve from 0.84193\n","Epoch 14/100\n","158/158 [==============================] - 1s 8ms/step - loss: 0.2349 - accuracy: 0.9032 - precision_m: 0.9074 - recall_m: 0.8958 - f1_m: 0.9015 - val_loss: 0.4234 - val_accuracy: 0.8275 - val_precision_m: 0.8371 - val_recall_m: 0.8231 - val_f1_m: 0.8299\n","\n","Epoch 00014: val_f1_m did not improve from 0.84193\n","Epoch 15/100\n","158/158 [==============================] - 1s 8ms/step - loss: 0.2292 - accuracy: 0.9189 - precision_m: 0.9236 - recall_m: 0.9134 - f1_m: 0.9184 - val_loss: 0.4396 - val_accuracy: 0.8331 - val_precision_m: 0.8372 - val_recall_m: 0.8270 - val_f1_m: 0.8320\n","\n","Epoch 00015: val_f1_m did not improve from 0.84193\n","Epoch 16/100\n","158/158 [==============================] - 1s 8ms/step - loss: 0.2293 - accuracy: 0.9166 - precision_m: 0.9216 - recall_m: 0.9079 - f1_m: 0.9146 - val_loss: 0.4226 - val_accuracy: 0.8378 - val_precision_m: 0.8448 - val_recall_m: 0.8270 - val_f1_m: 0.8357\n","\n","Epoch 00016: val_f1_m did not improve from 0.84193\n","Epoch 17/100\n","158/158 [==============================] - 1s 8ms/step - loss: 0.2175 - accuracy: 0.9147 - precision_m: 0.9215 - recall_m: 0.9084 - f1_m: 0.9148 - val_loss: 0.4368 - val_accuracy: 0.8355 - val_precision_m: 0.8413 - val_recall_m: 0.8255 - val_f1_m: 0.8332\n","\n","Epoch 00017: val_f1_m did not improve from 0.84193\n","Epoch 18/100\n","158/158 [==============================] - 1s 8ms/step - loss: 0.2115 - accuracy: 0.9177 - precision_m: 0.9224 - recall_m: 0.9105 - f1_m: 0.9163 - val_loss: 0.4660 - val_accuracy: 0.8307 - val_precision_m: 0.8340 - val_recall_m: 0.8286 - val_f1_m: 0.8312\n","\n","Epoch 00018: val_f1_m did not improve from 0.84193\n","Epoch 19/100\n","158/158 [==============================] - 1s 8ms/step - loss: 0.1996 - accuracy: 0.9266 - precision_m: 0.9306 - recall_m: 0.9232 - f1_m: 0.9268 - val_loss: 0.4571 - val_accuracy: 0.8370 - val_precision_m: 0.8370 - val_recall_m: 0.8270 - val_f1_m: 0.8319\n","\n","Epoch 00019: val_f1_m did not improve from 0.84193\n","Epoch 20/100\n","158/158 [==============================] - 1s 8ms/step - loss: 0.1817 - accuracy: 0.9342 - precision_m: 0.9393 - recall_m: 0.9300 - f1_m: 0.9346 - val_loss: 0.4795 - val_accuracy: 0.8347 - val_precision_m: 0.8402 - val_recall_m: 0.8294 - val_f1_m: 0.8346\n","\n","Epoch 00020: val_f1_m did not improve from 0.84193\n","Epoch 21/100\n","158/158 [==============================] - 1s 8ms/step - loss: 0.1837 - accuracy: 0.9295 - precision_m: 0.9327 - recall_m: 0.9240 - f1_m: 0.9282 - val_loss: 0.4806 - val_accuracy: 0.8339 - val_precision_m: 0.8397 - val_recall_m: 0.8325 - val_f1_m: 0.8360\n","\n","Epoch 00021: val_f1_m did not improve from 0.84193\n","Epoch 22/100\n","158/158 [==============================] - 1s 8ms/step - loss: 0.1779 - accuracy: 0.9284 - precision_m: 0.9315 - recall_m: 0.9238 - f1_m: 0.9276 - val_loss: 0.4684 - val_accuracy: 0.8283 - val_precision_m: 0.8354 - val_recall_m: 0.8216 - val_f1_m: 0.8283\n","\n","Epoch 00022: val_f1_m did not improve from 0.84193\n","Epoch 23/100\n","158/158 [==============================] - 1s 8ms/step - loss: 0.1857 - accuracy: 0.9280 - precision_m: 0.9334 - recall_m: 0.9255 - f1_m: 0.9294 - val_loss: 0.4903 - val_accuracy: 0.8339 - val_precision_m: 0.8381 - val_recall_m: 0.8294 - val_f1_m: 0.8336\n","\n","Epoch 00023: val_f1_m did not improve from 0.84193\n","Epoch 24/100\n","158/158 [==============================] - 1s 8ms/step - loss: 0.1588 - accuracy: 0.9410 - precision_m: 0.9460 - recall_m: 0.9374 - f1_m: 0.9416 - val_loss: 0.4874 - val_accuracy: 0.8370 - val_precision_m: 0.8407 - val_recall_m: 0.8302 - val_f1_m: 0.8353\n","\n","Epoch 00024: val_f1_m did not improve from 0.84193\n","Epoch 25/100\n","158/158 [==============================] - 1s 8ms/step - loss: 0.1610 - accuracy: 0.9374 - precision_m: 0.9411 - recall_m: 0.9339 - f1_m: 0.9374 - val_loss: 0.5131 - val_accuracy: 0.8227 - val_precision_m: 0.8266 - val_recall_m: 0.8192 - val_f1_m: 0.8228\n","\n","Epoch 00025: val_f1_m did not improve from 0.84193\n","Epoch 26/100\n","158/158 [==============================] - 1s 8ms/step - loss: 0.1636 - accuracy: 0.9382 - precision_m: 0.9408 - recall_m: 0.9342 - f1_m: 0.9374 - val_loss: 0.5080 - val_accuracy: 0.8251 - val_precision_m: 0.8281 - val_recall_m: 0.8223 - val_f1_m: 0.8252\n","\n","Epoch 00026: val_f1_m did not improve from 0.84193\n","Epoch 27/100\n","158/158 [==============================] - 1s 8ms/step - loss: 0.1592 - accuracy: 0.9408 - precision_m: 0.9467 - recall_m: 0.9387 - f1_m: 0.9426 - val_loss: 0.5367 - val_accuracy: 0.8148 - val_precision_m: 0.8168 - val_recall_m: 0.8122 - val_f1_m: 0.8145\n","\n","Epoch 00027: val_f1_m did not improve from 0.84193\n","Epoch 28/100\n","158/158 [==============================] - 1s 8ms/step - loss: 0.1340 - accuracy: 0.9495 - precision_m: 0.9515 - recall_m: 0.9452 - f1_m: 0.9483 - val_loss: 0.5247 - val_accuracy: 0.8323 - val_precision_m: 0.8354 - val_recall_m: 0.8302 - val_f1_m: 0.8327\n","\n","Epoch 00028: val_f1_m did not improve from 0.84193\n","Epoch 00028: early stopping\n","Basic model evaluation: \n","--------------------------------------------\n","Loss==> Train: 0.287, Test: 0.376\n","Accuracy==> Train: 0.892, Test: 0.855\n","F1==> Train: 0.901, Test: 0.864\n","Precision==> Train: 0.880, Test: 0.845\n","Recall==> Train: 0.890, Test: 0.855\n","Accuracy of Neural Network Model\n","--------------------------------------------\n","\n","Training accuracy\n","--------------------------------------------\n","Accuracy Score:  0.8915394402035624\n","Precision:  0.8915394402035624\n","Recall:  0.8915394402035624\n","F1 score:  0.8915394402035624\n","\n","Classification report\n","---------------------\n","              precision    recall  f1-score   support\n","\n","     Neutral       0.90      0.73      0.81      1773\n","    Negative       0.89      0.97      0.93      4361\n","    Positive       0.79      0.51      0.62       154\n","\n","    accuracy                           0.89      6288\n","   macro avg       0.86      0.74      0.78      6288\n","weighted avg       0.89      0.89      0.89      6288\n","\n","\n"," Testing accuracy\n","--------------------------------------------\n","Accuracy Score:  0.8550540368722187\n","Precision:  0.8550540368722187\n","Recall:  0.8550540368722187\n","F1 score:  0.8550540368722187\n","\n","Classification report\n","---------------------\n","              precision    recall  f1-score   support\n","\n","     Neutral       0.83      0.66      0.73       444\n","    Negative       0.87      0.95      0.91      1091\n","    Positive       0.59      0.50      0.54        38\n","\n","    accuracy                           0.86      1573\n","   macro avg       0.76      0.70      0.73      1573\n","weighted avg       0.85      0.86      0.85      1573\n","\n"],"name":"stdout"},{"output_type":"display_data","data":{"image/png":"iVBORw0KGgoAAAANSUhEUgAAAYgAAAEWCAYAAAB8LwAVAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nOzdeVhUZf/H8feZGWYYQEBNBzXASi0LXEp9zNAUREoiLUFzSUvJ1MrKFpen8ElT09QkLZc0KrcWczc3cK8sTROXNisUU0YTQdlmPb8/UIqfuCHjsHxf18XFzJxzZr6H0fnMOfd97ltRVVVFCCGE+H807i5ACCFE+SQBIYQQokQSEEIIIUokASGEEKJEEhBCCCFKJAEhhBCiRBIQQpRSeHg433zzjbvLEMJlJCCEEEKUSAJCCCFEiSQghLhOVquVcePGERYWRlhYGOPGjcNqtQKQmZnJ008/TYsWLWjVqhW9evXC6XQCMGfOHNq2bUvz5s2Jiori22+/deduCHERnbsLEKKimzlzJvv27WPFihUoisKQIUN4//33eeGFF0hKSsJkMhV9+O/btw9FUfjjjz9YuHAhS5YswWQycezYsaLgEKK8kCMIIa7TqlWreOaZZ6hZsyY1atTgmWeeYeXKlQDodDpOnTrF8ePH8fDwoEWLFiiKglarxWq18vvvv2Oz2bj55psJCgpy854IUZwEhBDX6eTJk9StW7foft26dTl58iQAAwYMIDg4mP79+xMREcGcOXMACA4OZtSoUUyfPp02bdrw4osvYjab3VK/EJciASHEdapduzbHjx8vun/ixAlq164NgI+PDyNGjCAlJYWZM2eSlJRUdLopJiaGxYsXs3nzZhRFYfLkyW6pX4hLkYAQ4jpFR0czc+ZMMjMzyczM5L333iMmJgaAzZs3c+TIEVRVpVq1ami12qI2iG+//Rar1Yper8dgMKDRyH9HUb5II7UQ12nIkCHk5uby8MMPA/DAAw8wZMgQAI4cOcLYsWPJzMzE19eXnj170rp1a37++WemTJnC77//joeHB82bN2fMmDHu3A0hLqLIhEFCCCFKIse0QgghSiQBIYQQokQSEEIIIUokASGEEKJELu3FtG3bNsaNG4fT6SQuLo6BAwcWW7506VImTZqEyWQCoE+fPsTFxQHQuHFjGjVqBECdOnWYNWvWZV/L6XTicEh7uxBCXAsPD+0ll7ksIBwOB2PGjCkaiyY2Npbw8HAaNGhQbL3OnTuTkJBw0faenp6sWLHiGl5PJSsr77rrFkKIqqRWrWqXXOayU0ypqakEBwcTGBiIXq8nOjqalJQUV72cEEKIMuaygDCbzQQEBBTdN5lMJY41s2HDBmJiYhg6dCgnTpwoetxisfDoo4/SvXt3kpOTXVWmEEKIS3DrldQdOnTgoYceQq/X8+mnnzJ8+HA++eQToHCIApPJRHp6Ov369aNRo0Yy2qUQQtxALjuCMJlMZGRkFN03m81FjdEXVK9eHb1eD0BcXBwHDx4stj1AYGAgrVq14tChQ64qVQghRAlcFhChoaGkpaWRnp6O1WplzZo1hIeHF1vnwpDIAJs2beK2224DIDs7u9iMXHv27LmocVsIIYRruewUk06nIyEhgfj4eBwOB926daNhw4YkJiYSEhJCREQE8+fPZ9OmTWi1Wvz8/JgwYQIAv//+O6NHj0ZRFFRV5amnnpKAEEKIG6zSDNZnszmkm6sQQlwjt3RzFUIIUTpffKHjhx/c//Hs/gqEEEIUWbDAg2eeMfLgg9707+/J4cOK22qRgBBCiHJi3z4NI0cauP9+O6+8YmHTJh1t23rzyisGzOYbHxTSBiGEEOVAZiZERnqjqrBxYx41a6qcPKkwdaqeTz7xQK+HQYOsPPOMlWqXbja4Zpdrg5CAEEIIN3M4oFcvI19/rWXVqjyaN3cWW/7HHwpvvWVg+XIPatZ0MmyYlX79bJy/jOy6SCO1EEKUY5Mn69m8Wcf48ZaLwgHg1ltV5swpYMOGXO6808l//+tJmzbeLF2qw3nx6mVGAkJV8Rn2HNqff3J3JUKIKig5WcuUKQYee8zG44/bLrtus2ZOlizJ57PP8vD1VRk0yEhkpBc//uiaj3IJCIcDzyWf4blovrsrEUJUMUeOKAwZYiQkxMHEiQUoV9EOrSjQoYOD5OQ8Zs7M5+xZhY8+8nBJfdIGAfg/1AmcTrK+klFjhRA3Rn4+PPSQF0ePati4MZf69d3zUSxtEFdga9EK3f59YLG4uxQhRBUxcqSB/fu1vPdevtvC4UokIADbPS1RLBZ0B1LdXYoQogpYsMCDRYv0DBtmoVMnh7vLuSQJCMDeshUAHj/scnMlQojK7sLFcO3b23nlFau7y7ksCQjAGVAHR72b0e3+3t2lCCEqiF9/1fDuu3o2bdKSnX1122RmQv/+RmrVUpk5swCt1rU1Xi+3zihXnthatMLjh93uLkMIUQGkpSl07Wrk778Lv2Mrisrttztp2dJBy5YOWrRwcNttarFeSQ4HDBlixGxWWLWq8Erp8k4C4jz7PS3wXLEUjTkDpyngyhsIIaqkM2cKr3p2OBSSk3PJzlbYtUvLrl1aVq70YP78wsuba9Rwcs89/4TGtm1aNm3S8fbbBSVeDFceSUCcZ2tR2A6h270La3SMm6sRQpRHFgv062fk6FENS5bk06RJ4Qd927aFDc1OJxw+rDkfGBp279aycaOhaPsePWz07Xv5i+HKEwmI8+yhTVH1ejx2fy8BIYS4iNMJzz/vyc6dOmbPzqd164t7H2k00KiRk0aNnPTuXfjYmTOwZ4+WP//U0Lu37aouhisvXNpIvW3bNqKiooiMjGTOnDkXLV+6dCmtW7emS5cudOnShS+++KJo2bJly+jUqROdOnVi2bJlriyzkMGAPbQpOunJJIQowYQJepYu9eC11yw88oj9qrerXh0iIhzEx9swGl1YoAu47AjC4XAwZswYkpKSMJlMxMbGEh4eftHc0p07dyYhIaHYY1lZWcyYMYMvv/wSRVF49NFHCQ8Px8/Pz1XlAmBr0RLjJ0lgs4GHay5dF0JUPJ984kFiooHHH7fy3HPlu2tqWXLZEURqairBwcEEBgai1+uJjo4mJSXlqrbdsWMH9913H/7+/vj5+XHfffexfft2V5VaxN6iFUp+PrpDB1z+WkKIiiElRcvw4QbCw+1MnGipUKeIrpfLAsJsNhMQ8E9vIJPJhNlsvmi9DRs2EBMTw9ChQzlx4sQ1bVvWbPe0BJDrIYQQAOzfryE+3kjjxk7mzs1HV8Vabd16oVyHDh3YtGkTq1atok2bNgwfPtyd5eCsdzOOgDp47JKAEKKq++svhd69jfj5qSxalI+Pj7sruvFcFhAmk4mMjIyi+2azGZPJVGyd6tWroz8/JVJcXBwHDx686m1dQlGw39NShtwQooo7e7bwWoecHIVFi/IJCCj/F7W5gssCIjQ0lLS0NNLT07FaraxZs4bw8PBi65w8ebLo9qZNm7jtttsACAsLY8eOHWRnZ5Odnc2OHTsICwtzVanF2Fq0QnskDeXUqRvyekII17rWCQ1sNhgwwMhvv2n48MN87ryzYlzU5gouO6Om0+lISEggPj4eh8NBt27daNiwIYmJiYSEhBAREcH8+fPZtGkTWq0WPz8/JkyYAIC/vz9DhgwhNjYWgGeeeQZ/f39XlVrMhXYIjx92YX2g8w15TSGEa+zapaF/fyMOBwQGqgQFOQkMdP7rtsrNNzvx8ipcX1Xh5Zc92bpVR2JiPu3bl9+RVm8EmTDo/8vP56bb6pE/ZCi5r/3v+p9PCOEWO3dq6dnTSO3aKmFhdtLTNed/FKzW4l2RatVyEhSk4uWlsn27jmHDLIwYUTW6s15uwqAq1iZ/FYxG7CGhcsGcEBXY119r6d3bSL16Tr78sngbgtMJJ08qHD2qkJ6u4ejRwtA4elTDsWMaBg60Mnx41QiHK5GAKIGtRSuMi+aD3U6V69cmRAW3dauWvn2NBAUVhkPt2sVPkmg0EBCgEhCg0qpV1W1fuBoyH0QJ7Pe0RMnLQ/vTIXeXIkSlpqqFczP//bdCfv71P9+mTVoef9xI/fpOli27OBzEtZGvxyW4MLKrx+7vcYQ2cXM1QlQ8qgoff+zB3r1acnMhL08hNxdyc5XzPxT9djoL2wN8fVWef95KfLy1VGMWbdyo5cknjTRq5OSLL/IrxHwL5Z00UpdEVal5VwOs4R05N2N22TynEFWEqsKYMQbee09P7dpOfH1VvL3B2/vfv4s/5uWlsnmzjo0bddSr52T4cAtxcfarnnFt7Vod8fGe3Hmnk88/z6N6ddfuY2VyuUZqCYhL8O3bE+2vP3Nm594ye04hKjtVhbFj9cyYYeDJJ6289da1jV309dda3njDwI8/arnzTgcJCRY6dHBc9jlWrdLx9NOeNGni5LPP8nDxmJ6VzuUCQtogLsHWoiW6P35HyTzt7lKEqBBUFd58szAcnnji2sMB4L77HKxbl8ecOfnk5Cg89pgXcXFG9u8v+aNq+XIdAwd60qxZ4ZGDhEPZkoC4BPuFdgjp7irEFakqjBunZ/p0A/36lS4cLtBooGtXO998k8u4cQUcOKAhIsKbwYM9OXr0nyddskTHoEGetGzp4PPP8/D1LaOdEUXkFNOl5OZyU4ObyXt+GHkjXi+75xWikrkQDu++a6BvXyuTJlnQlOFXz7NnYfp0PbNn63E6oX9/G/XrOxk50kCbNg4WLMjH27vsXq+qkTaIUvKPaIvqX53sL1eW6fMKUVmoKowfry+aTOftt8s2HP7t+HGFSZP0LF7sgaoqtGtn55NP8ouGyRClI20QpWS/pwW6vT+Ao2qPxyIqr507tcTHe7JqlQ7rNV48rKqF03DeiHAAqFtXZdo0C5s35zF6dAHz50s4uJocQVyG4fPF+D77NJlbvsVx511l+txCuNvx4woREV6cOaPgdCrcdJOTxx6z0aePjVtvvfzHgqrCW2/peecdA336WJk82bXhIFxHjiBKyd7in5FdhahMbDZ46ikj+fkKW7bksWhRHi1aOJg5U0/r1j5062Zk+XIdFsvF26oqTJwo4VAVyNt6GY5bbsNZo4ZMQSoqnbFjDezapeWddwq44w4nHTs6+OSTAvbuzWXkSAtHjmgYONBIs2bejB5t4PDhwt5DF8Jh6lQDvXtLOFR2corpCnx7x6E9ksaZHXIUISqH1at19O9vpH//wu6oJXE6Cwe9mz/fg3XrdNjtCvfea+eWW5wsWqSnVy8rU6dKOFQG0ovpOni98zbeE8by969HUP3l+n1Rsf3xh0JkpDcNGjhZuTIPg+HK25w8qfDppx4sWOBBWppGwqGScVsbxLZt24iKiiIyMpI5c+Zccr3169dz++23s3//fgCOHTtGkyZN6NKlC126dCEhIcGVZV7WhRnmdHt+cFsNQpSF/PzCqTS1Wpg7N/+qwgGgdm2VoUOt7NyZy/btuRIOVYjLRnN1OByMGTOGpKQkTCYTsbGxhIeH06BBg2Lr5eTk8Mknn9C0adNijwcFBbFixQpXlXfV7Hffg6ooeOz+Hlt4R3eXI0SpjRpl4OBBLQsX5hEYeO0nDjQauP12mT+hKnHZ94DU1FSCg4MJDAxEr9cTHR1NSkrKReslJiby1FNPYbjarzM3mOpTDccdd0pPJlGhffqpjoUL9bzwgoXISLmuR1wdlwWE2WwmICCg6L7JZMJsNhdb5+DBg2RkZNC+ffuLtj927Bhdu3alT58+7N6921VlXhVbi1bofthd2HInRAVz8KCG4cM9ue8+O6++KlNpiqvntjOJTqeTt956i+HDh1+0rHbt2mzevJnly5czYsQIXnrpJXJyctxQZSFbi5ZozmajPfyb22oQojTOnStsd6hWTWXWrAKZQVdcE5cFhMlkIiMjo+i+2WzGZDIV3c/NzeXXX3+lb9++hIeH8+OPPzJ48GD279+PXq+n+vkZP0JCQggKCuLPP/90ValXZP/XDHNCVBSqCi++6MmRIwoffFCAyVQpOiyKG8hlAREaGkpaWhrp6elYrVbWrFlDeHh40fJq1arx3XffsWnTJjZt2kSzZs2YOXMmoaGhZGZm4jg//lF6ejppaWkEBga6qtQrctzWAKefPzpphxAVyNy5Hqxc6cHIkVbuvVfaHcS1c9kBp06nIyEhgfj4eBwOB926daNhw4YkJiYSEhJCRETEJbfdtWsX7777LjqdDo1GwxtvvIG/v7+rSr0yjQb7PS3kCEKUmdxcSE7W0amTvVTzL1/J7t0aRo82EBVl59lnpd1BlI5cKHeVvN6egNfktzh9OB21msxMIkrvwAENTz/tyW+/aQkNdTB3bj633FJ2/w1Pn1bo2NELrRaSk3Nx53crUf7JYH1lwNaiFYqqygVzotRUFebN8+DBB704e1Zh9OgC0tM1REZ689VXZXMwf+CAhu7djZw6pTBvXr6Eg7guVT4gHA4IC/MiOtqLWbM8OHas5HkS7XffA8jIrpXB4cMKea472CxRZib06+fJyJGetG3rYPPmPJ55xkZyci633urkiSeM/O9/Bmy20j1/fn7hrG6dOnlx4oTC3Ln5NG0q3bLF9anyAaHVFk5hmJcHCQme3H23D1FRXkyfrufPP/8JC9XPH/vtd8jIrhXYX38p9OvnSZs2PrRo4c306XpuRO/pb7/VEh7uTUqKjrFjC1i4MJ+bbio8pRQUpLJqVR5PPmnl/ff1dOtmJCPj2iZz/uYbLR06eJOYaKBbNzs7duTywAPSKC2un7RB/MsffyisXu3B6tU6fvxRC0BIiIOYGDsxMTaazRiCYe1qTv+cRqlnZBc3nMNReGpnwgQDTicMHmxl714tmzfrqFHDyaBBNgYMsFLt0qdiS8Vuh6lT9Uydqqd+fZU5c/Jp0uTS3+q//FLHSy954uWlMmdOAWFhl/+Qz86GMWMMzJ+vJyjIyeTJBbRvL8Egro2M5loKR48qrFmjY9UqD3bvLgyLxgGn6Z4xnW7LuxHQpn6ZvZZwnX37NLz8sif79mkJD7czcWIBwcGF/+T37NEwdaqBDRt0+PmpDBxo5amnrGVy3v6vvxQGD/Zk504d3bvbeOutAnx8rrzdL79o6N/fk99/1zBihJWhQ60lDoy3erWOESMM/P23wqBBNl55xYK39/XXLaoeCYjrdPy4wldf6Vj9mZVv9/lQ2zef5etVbrutUvzpKqWcHJg40cAHH3hw000q48ZZePhhe4kHfvv2aZg6Vc/atR5Uq6YSH2/l6aet1KhRutdeu1bHCy94YrXCpEkFxMXZr7n2l17yZNkyDyIj7cyYkc/560Y5cUJhxAgDa9d6EBLi4J13CqStQVwXCYiy4nSScWsnIhwb0dXwYfnyvDLtnijKxtq1OkaNMnD8uEK/fjb++18Lfn5X3u7gQQ3vvKNn1SodRiP0729l8GAbtWqV/B47nYWNw/n5StHvDz/04MMP9TRt6mD27Pwrzu18KaoKSUkevP66gYAAlQ8+yGf/fi1jxhQ2ZL/yipVBg6x4eJTq6YUoIgFRhqo9M5Bfl/1CB+/v8aqmYcWK0g2dLC7N6Sz8sDabFWrXVjGZVG66SUWrvfx2x48rjBxZ+O26cWMHkycX0LLltX+7/vlnDdOm6Vm+XIfBACEhTgoKLg6D/PyS26EGDbLy2msW9PprfumL7NmjIT7eyLFjheeZwsLsTJ5cUOrgEeL/k4AoQ8rJk9QIa8Hum7vQKT0Jf3+VFSvyqFu3UvwZ3UJVCzsIbNumY8cOLV9/rSUzs/iJd42mMCRMJvV8aDiLbteurZKervD224WN0C+/XDbfrg8fVnjvPT1Hj2owGsFoVDEawctLvej+hcduvdV52Ybo0sjMhPHjDdxzj4PHHiv5NJkQpSUBUcYMixfg+/wQNj+3mIeTemAyqSxfnieDoV2Dv/5S2L5dy44dOrZv13LiRGEg1K3rpG1bB2FhdurXV/n7bwWzWeHkycIfs7nwyMJsVjh1SsHp/OfT8v83QgshrkwCoqypKn6xD6P7cS/rZ6QSOziIwEAnS5fmX/J8dVXncEByspaNG3Xs2KHjjz8KA6FmTSf33eegbVsHbdvaueUW9aq/ITschcNKmM0KTic0aeKUb9dCXCMJCBfQ/PE7NdrfizU8knUDP6VnTyP16ztZtiyv1L1fKqMzZ2DhQg8++qjwVI2Pj0qbNoVHCGFhDu680ynzGwvhRhIQLmKcPg2fsQlkf7iAjdUeoU8fI7ff7uTLL/OuqtfMtVJVOHRIw4oVOtav11G7tkp4uJ0OHRzcfnv5+vZ86JCGefM8WLLEg/x8hfvuszNggI2oKLv0vBGiHJGAcBW7Hf9O7dGcNHPm610k765Jv35GQkKcfPFFXpldmfvLLxqWL9excqWO337TotGo3Huvg1OnFH79tbBrT926Ttq3txMe7qBdO7tbBmmz22HdOh3z5nnw9dc6jEaV2Fgb/fvbuOsu6asvRHkkAeFCun178Y/qQEHvfuRMSWTdOi39+xtp3tzJZ5/lXdXVsyU5fFhhxQoPVqzQ8fPPWhSl8NRMly52oqPtRW0dx44pbN6sY/NmLdu26Th7VkGjUWne3EmHDnY6dLBz993Ooi6iDgf8/XdhA++Fht+TJzWcOvXPY7m5CiaTk7p1VerWValT58JtJ3XqqHh6Fq81MxMWLNDz0UceHDumITDQyZNPWund21Z0gZcQonySgHAx7/+9htf775K1/CtsbcJYtUrHwIGetG7tYOHCfLy8Lr2tqoLVChYLmM0avvpKx/LlOg4eLAyF//ynMBQeesh+xV5Sdnthv/lNm3Rs2aJj714Nqqrg56dSr56TU6cUTp8u3vOnaB+8C7uL1qrlxMsLzGaF48c1ZGdfvG7NmoVBUbeuisGgsnGjjoIChbAwO/HxhaeRrnTNghCifHBbQGzbto1x48bhdDqJi4tj4MCBJa63fv16hg4dypIlSwgNDQVg9uzZLFmyBI1Gw2uvvUbbtm0v+1ruDAjy8qjRrjWqh44zm78BT0+WLtUxZIgn9eurVK+uYrFw/kehoKDwt8UCBQUXfwC3aOGga1cbMTF26tQp/duTmQnbtunYvFlHZqZC7dpOatVSqVXrn+sHLjx2qSOdnBzIyCgMi+PHFU6c+Of3X38pZGYqdOxYGAyNG8tpJCEqGrcEhMPhICoqiqSkJEwmE7GxsUydOpUGDRoUWy8nJ4enn34am83G66+/TmhoKIcPH2bYsGEsWbIEs9nMk08+yfr169Fe5mupWwMC8NiyCf/uXcl98WXyRiYAsGKFjo8/9kCnA09PFYOB8z+Fp2kMhsLHPD1Br1epVg3at7dz882V4qBOCFEBXC4gXDYndWpqKsHBwQQGBgIQHR1NSkrKRQGRmJjIU089xbx584oeS0lJITo6Gr1eT2BgIMHBwaSmptK8eXNXlXvdbO3DKejeE6/p07A8/CiOu0Lo0sVOly7XNlCbEEKUFy7rgW42mwkICCi6bzKZMJvNxdY5ePAgGRkZtG/f/pq3LY9yxoxH9fen2kvPFbYGCyFEBea2S5ScTidvvfUWw4cPd1cJZU6tUZOcNyfisecHjPNmu7scIYS4Li4LCJPJREZGRtF9s9mMyWQqup+bm8uvv/5K3759CQ8P58cff2Tw4MHs37//ituWZ5ZHYrFEROI9fiya9KPuLkcIIUrNZQERGhpKWloa6enpWK1W1qxZQ3h4eNHyatWq8d1337Fp0yY2bdpEs2bNmDlzJqGhoYSHh7NmzRqsVivp6emkpaXRpEkTV5VathSFnEnvAODz6ouF/ViFEKICclkjtU6nIyEhgfj4eBwOB926daNhw4YkJiYSEhJCRETEJbdt2LAhDz74IJ07d0ar1ZKQkHDZHkzljTMwiNxRr+Pz2ggMS7/A0q27u0sSQohrJhfKuYrDgX90R7S//87ZuR9ju7+DuysSQoiLXK6bq4yj6SpaLWfnfISzTh38ejyCceYMOd0khKhQJCBcyBkUTNZXyVgffAif0aOoNuSpwnkrhRCiApCAcDHVpxpn531C7ojXMCz9Av+YKDTH0t1dlhBCXJEExI2g0ZA37FXOzv8U7Z9/UL3T/Xh8s8PdVQkhxGVJQNxA1k4PkrV+M07/6vjFPoznvNnSLiGEKLckIG4wR4OGZK3bhDUikmojX8HnxWehoMDdZQkhxEUkINxA9fXj7MeLyX1pOMZF8/F/pDOaE8fdXZYQQhQjAeEuGg15w/9LdtJCtD//jH/k/ei+/87dVQkhRBEJCDezRseQtTYF1dsb/0c6o1+5zN0lCSEEIAFRLjjuaEzW+s3Y726B78AnMXy+2N0lCSGEBER5ofpXJ+vTpdjua0e15wbh+UmSu0sSQlRxEhDlibc32Qs/x9qxE9Vefh7j7PfcXZEQogqTgChvPD05m7QQy0Nd8Hl9JF7TJru7IiFEFSUBUR7p9Zydk0RBbA+8x4/Ba8IYuaBOCHHDuWw+CHGddDrOzZiNajTi/c5klLw8csdMAEVxd2VCiCpCAqI802jImZyI6umJ1+z3UfILyJk0FTRy4CeEcD0JiPJOUch9cyJ4eeOVOAUlP49zie+DTt46IYRrufRTZtu2bYwbNw6n00lcXBwDBw4stnzx4sUsWrQIjUaDl5cXY8eOpUGDBhw7dozOnTtzyy23ANC0aVPGjBnjylLLN0Uh97+jUb288J4wFqWggLMz54Je7+7KhBCV2FVNOfrxxx/TrVs3vL29+e9//8tPP/3ESy+9RFhY2CW3cTgcREVFkZSUhMlkIjY2lqlTp9KgQYOidXJycvDx8QEgJSWFRYsWMW/ePI4dO8agQYNYvXr1Ve9IuZty1EWMs2bgkzAKS6cHOPvBx2A0urskIUQFdt1Tjn755Zf4+PiwY8cOzp49y6RJk5gyZcplt0lNTSU4OJjAwED0ej3R0dGkpKQUW+dCOADk5+ejSAPsFeUPepZzk97BsGEdNVo3xzhzBkrOOXeXJYSohK4qIC4cZGzdupUuXbrQsGFDrnTgYTabCQgIKLpvMpkwm80Xrbdw4UI6duzI22+/zWuvvVb0+LFjx+jatSt9+vRh9+7dV7UzVaZWHPMAACAASURBVEXBEwPIWroaR4OG+IweRY3md+H11liUv/92d2lCiErkqgIiJCSE/v37s23bNsLCwsjJyUFTRj1pevfuTXJyMi+//DIzZ84EoHbt2mzevJnly5czYsQIXnrpJXJycsrk9SoLW1g7sr9cxZl1m7CFtcPrncnUvOcufEa8hOZImrvLE0JUAlf1KT9u3DheeukllixZgtFoxG63M378+MtuYzKZyMjIKLpvNpsxmUyXXD86Oprk5GQA9Ho91atXBwrDKSgoiD///PNqSq1y7He34GzSAs7s2EXBI7F4zv+IGq2bU21wPNqDB9xdnhCiAruqgNi7dy+33HILvr6+rFixgpkzZ1Kt2qUbNgBCQ0NJS0sjPT0dq9XKmjVrCA8PL7ZOWlpa0e0tW7YQHBwMQGZmJg6HA4D09HTS0tIIDAy8lv2qchwNG5Ez7T0yd+8nf+AQ9Ou+okaHNvj2isVj5zdyJbYQ4ppdVS+mmJgYVq5cyS+//MKIESOIi4tj7dq1LFiw4LLbbd26lfHjx+NwOOjWrRuDBw8mMTGRkJAQIiIiePPNN/n222/R6XT4+vqSkJBAw4YNWb9+Pe+++y46nQ6NRsNzzz13Ubj8f1WlF9PVUs5kYkyai3HuLDR//401vCNn3/8AtUZNd5cmhChHLteL6aoC4pFHHmHZsmXMmDEDk8lEXFxc0WPlhQTEJeTlYfzkQ7zf/B/OgLpkf7wIx10h7q5KCFFOXHc3V29vb2bPns3KlStp3749TqcTu91eZgUKF/LyIn/Qs2StWAtWC9WjO8qsdUKIq3JVAfHOO++g1+sZP348tWrVIiMjgwEDBri6NlGG7Pe0JGvjVux3huAX3w+v8WPgfDuPEEKU5KpOMQH8/fff7N+/H4AmTZpQs2b5Opctp5iuksWCz6hXMM7/CEvHTpybORfVz9/dVQkh3OS6TzF99dVXxMXFsW7dOtauXVt0W1RABgM5U97l3KR30G/ZhH9UB7S//uLuqoQQ5dBVHUE8/PDDJCUlFR01ZGZm8sQTT7By5UqXF3i15Aji2nns/Abf/o9DQQHn3v8A6wOd3V2SEOIGu+4jCFVVi51S8vf3v+JQG6L8s7Vuw5mNW3Hc1gC/vo/hNfktcDrdXZYQopy4quG+w8LCGDBgANHR0UDhKad27dq5tDBxYzjr3UzWynVUe/l5vCeNR3dgP+dmzEL1qQYOB0p2FprMTJTTp9FkFv4op0+jOZOJknkaxVJA3jMv4Aht4u5dEUKUsatupF6/fj179uwBoEWLFkRGRrq0sGslp5iuk6pinPM+3v97DdXXFxQFJSsL5RJHFKrBgLPmTSi5ueBwcPajhdjatb+xNQshrtt1XyhXEUhAlA2PHdvwXPgJarVqOGvURK1ZE2eNmsVvV68BXl6gKGiO/4Vfz25oD//GuXdnYunW3d27IIS4BqUOiObNm5c4R4OqqiiKUnREUR5IQLiPkp2Fb79e6L/ZQc7oN8kf8hzI3B5CVAhyBCFcr6CAas8+jefKZeQ9PYTcN8ZDGQ0JL4RwncsFhEvnpBZViKcn5+Yk4QwIwGv2+2gyMjg3fRZ4erq7MiFEKUlAiLKj0ZA79i2cderh88ZraE6d5OzHi+RKbSEqKDkHIMqWopD/zFDOvv8BHru+w//hB9GcOO7uqoQQpSABIVzCEtuD7EVL0KQfxb9zR7Q//+TukoQQ10gCQriM7f4OhcOM22z4x0Sh2/mtu0sSQlwDlwbEtm3biIqKIjIykjlz5ly0fPHixcTExNClSxd69uzJ4cOHi5bNnj2byMhIoqKi2L59uyvLFC7kCG1C1lfJOGvVwj/uYTw//hBkLhEhKgSXdXN1OBxERUWRlJSEyWQiNjaWqVOn0qBBg6J1cnJy8PHxASAlJYVFixYxb948Dh8+zLBhw1iyZAlms5knn3yS9evXo9VqL/l60s21fFMyT+M7oC/6r7djb9iI3JEJWKNj5HoJIdzsugfrK43U1FSCg4MJDAxEr9cTHR1NSkpKsXUuhANAfn5+0UV5KSkpREdHo9frCQwMJDg4mNTUVFeVKm4AtUZNspeuJjtpIQB+/fvg3zkCj6/l6FCI8splAWE2mwkICCi6bzKZMJvNF623cOFCOnbsyNtvv81rr712TduKCkZRsEbHcGbrTs69MwPN8eP4PxKN32OPot0vXwCEKG/c3kjdu3dvkpOTefnll5k5c6a7yxE3gk5HQe++ZO7cS07CWHR7dlMjIoxqgwagSfvT3dUJIc5zWUCYTCYyMjKK7pvNZkwm0yXXj46OJjk5uVTbigrKaCT/2efJ3JVK3tBhGNaupsZ9LfAZ+TLKyZPurk6IKs9lAREaGkpaWhrp6elYrVbWrFlDeHh4sXXS0tKKbm/ZsoXg4GAAwsPDWbNmDVarlfT0dNLS0mjSROYbqKxUP39yX/sfmd/9SMFjffD8aB41WzXFmDhFJjASwo1cNtSGTqcjISGB+Ph4HA4H3bp1o2HDhiQmJhISEkJERAQLFizg22+/RafT4evry8SJEwFo2LAhDz74IJ07d0ar1ZKQkHDZHkyicnAG1CFnSiL5Q57Fe+z/8Bn3BrpDBziXOFPGdBLCDWQ0V1E+qSrG6dPweXM0tv/cS/bHi1Br1LzydkKIa+KWbq5CXBdFIX/oi5ydk4Tuxz34d+6I5o/f3V2VEFWKBIQo1yxdu5H1xUo0ZzKpHt0R3a7v3F2SEFWGBIQo9+yt7yVrbQpOXz/8H30I/cpl7i5JiCpBAkJUCI5bG5D1VQr2Js3wi++HcUYiVI7mMyHKLQkIUWGoNWuS9eUqCro8is+Y1/F5dZgM/CeEC8mMcqJi8fTk3OwPcQYF4zX9HTTHjnLug49QfS7dE0MIUTpyBCEqHo2G3Nff4NzkRPRbNuEns9YJ4RISEKLCKuj7JNkLP0f75x/4d2qP15SJMpaTEGVILpQTFZ72wH58Xh+Bxzc7UFQVW8v/UBDbA0uXR+TiOiGu4HIXyklAiEpD89cxDEuX4LnkU3Q/HULV6bBGRGKJ7YGl04NgNLq7RCHKHQkIUeVoDx7Ac8lnGL78HG3GCZw+1bDEdMES2wNbmzCQsb2EACQgRFXmcODxzQ4MSz7DsGoFmpxzOOrUxdb6Xux3heK48y7sd4XiDKgj05+KKkkCQgiA/HwMG9ZiWLEM3b69aNOPFi1y1qiB/a5Q7OcDw3FXCPZGd4DB4MaChXA9CQghSqBkZ6E7dBDtoQPoDh5Ad3A/up9/QsnPB0DVanE0bIQl+mHyhg6TNgxRKUlACHG1HA60f/6B7uB+tIcO4LHnB/RbN2O/5VZypryLLayduysUokxJQAhxHTy2bqbay8+jPZJGfs8+5I4eK91nRaXhtoDYtm0b48aNw+l0EhcXx8CBA4stT0pK4osvvkCr1VKjRg3Gjx9PvXr1AGjcuDGNGjUCoE6dOsyaNeuyryUBIVwqLw/vqZMwvpeIWr06OW9OxPJIrDRsiwrPLQHhcDiIiooiKSkJk8lEbGwsU6dOpUGDBkXr7Ny5k6ZNm2I0Glm0aBHff/8906ZNA6B58+bs3bv3ql9PAkLcCNoD+6n20nN47N2DNbwj5ya9gzMo2N1lCVFqbplRLjU1leDgYAIDA9Hr9URHR5OSklJsndatW2M83/DXrFkzMjIyXFWOEGXCERJK1lcp5IybiMfOb6nR7j8YZ86QUWVFpeSygDCbzQQEBBTdN5lMmM3mS66/ZMkS2rX7pwHQYrHw6KOP0r17d5KTk11VphDXTqsl/6nBZO74HmtYO3xGj8L/wQh0+/e5uzIhylS5GO57xYoVHDhwgAULFhQ9tnnzZkwmE+np6fTr149GjRoRFBTkxiqFKM55cyBn53+GftVyqo18Bf9O7cl/Mp6CJ+JxNLrd3eUJcd1cdgRhMpmKnTIym82YTKaL1vvmm2+YNWsWM2fORK/XF9seIDAwkFatWnHo0CFXlSpE6SkK1ocfIfPrXRT06osxaS41wlriH9Uez3mzUTJPu7tCIUrNZQERGhpKWloa6enpWK1W1qxZQ3h4eLF1Dh06REJCAjNnzqRmzX+6DWZnZ2O1WgHIzMxkz549xRq3hShvVP/q5ExJ5PS+X8gZMx5sdqqNfIWaoY3wfaI3+rVr4Py/aSEqCpd2c926dSvjx4/H4XDQrVs3Bg8eTGJiIiEhIURERPDEE0/w66+/UqtWLeCf7qx79uxh9OjRKIqCqqr07duXuLi4y76W9GIS5Y324AE8P1uE55efozl1EmfNmhQ8EoulRy/sTZpJF1lRLsiFckK4k92OfnMyhs8/xbBuDYrFgv2OxhTE9cT6QGccDRpKWAi3kYAQopxQss5gWLEMz88W4bH7ewAcQfWxRnTEGhGJ9b524O3t5ipFVSIBIUQ5pEk/ij5lI/pNG9Fv24KSl4dqMGBr3QZrx05YIzrhuK2BHF0Il5KAEKK8s1jw2PlNUWDofv0F+H9HF+0j4F89/YQoCxIQQlQwmqNH/jm62L4VJS8P+x2NOZf4Pvbm97i7PFGJSEAIUZFZLOg3rMPnteFozBnkDxlK7isjZX4KUSbcMhaTEKKMGAxYY7pwZvt3FPR6HK8Z06geEYbu++/cXZmo5CQghKggVF8/cqZOJ+vz5SgWC/4xnfB+fQTkyZGzcA0JCCEqGFv7cM5s/ZaCJ+Pxmv0+Ndrfi8fX291dlqiEJCCEqIBUn2rkvDWFrOVfAeD/SDQ+w4eh5Jxzc2WiMpGAEKICs7UJI3PLt+Q9/QyeH82j+v334rFlk7vLEpWEBIQQFZ2XF7ljJ5C1egOqpyf+3btSLb5fYVA4HO6uTlRg0s1ViMqkoACvqZMwJs1Fk52Fo249Crr3xNKjJ47bGrq7OlEOyXUQQlQ1BQUY1n+F4bNF6Dclozid2Fr+h4IevbB0fRTV18/dFYpyQgJCiCpMk3ECw5LP8fxsIbpffkb19MTS+SEKevTG1q49aLXuLlG4kQSEEAJUFd2+vXh+uhDD0i/QZGXhqFOXgsd6kT/4OVT/6u6uULiBBIQQojiLBf2GtXh+uhB98gZUPz/yXniF/AEDwWBwd3XiBnLbUBvbtm0jKiqKyMhI5syZc9HypKQkOnfuTExMDP369eOvv/4qWrZs2TI6depEp06dWLZsmSvLFKLqMRiwxnTl7MIvOLPpa+x3t8Dnf/+lxn0tMHz5OTid7q5QlAMuO4JwOBxERUWRlJSEyWQiNjaWqVOnFptbeufOnTRt2hSj0ciiRYv4/vvvmTZtGllZWXTr1o0vv/wSRVF49NFHWbp0KX5+l25YkyMIIa6Px9bNeI9JwGP/PmxNm5M7eiy2sHbuLku4mFuOIFJTUwkODiYwMBC9Xk90dDQpKSnF1mndujXG8yNSNmvWjIyMDAB27NjBfffdh7+/P35+ftx3331s3y5DCQjhSrb7O5C1cStn35uD5vTf+D/6EL69YtH+dMjdpQk30bnqic1mMwEBAUX3TSYTqampl1x/yZIltGvX7pLbms3ma67B4bBz5swp7HbrNW8rSqbT6alevRZarcv+6Qh30miwxD2GJaYrxrmz8Zo2meod2lDQsw95r47CWaeuuysUN1C5+F++YsUKDhw4wIIFC8r0ec+cOYWnpxfe3gEoMm3jdVNVldzcs5w5c4qbbqrj7nKEK3l6kv/s8xT06oPXO5MxfjgHz6VfkD9wCNb7O+AIro+zbj3pIlvJuSwgTCZT0SkjKDwqMJlMF633zTffMGvWLBYsWID+/HSKJpOJ77//vti2rVq1uuYa7HarhEMZUhQFb29fcnKy3F2KuEHUGjXJHTuB/Pin8R7/Bl6JU/BKnFK4zMMDZ72bcQTXxxF8y/nfwTiD6+MIri/dZisBlwVEaGgoaWlppKenYzKZWLNmDVOmTCm2zqFDh0hISGDu3LnUrFmz6PGwsDCmTp1KdnY2UNgmMWzYsFLVIeFQtuTvWTU5g+tzbnYSuaPfRHv4N7RH0tAePYLmyJ9oj6RhWL0cTWZm8W18/bC1CaOg1+NYIyLBw8NN1YvScllA6HQ6EhISiI+Px+Fw0K1bNxo2bEhiYiIhISFEREQwadIk8vLyeP755wGoU6cOs2bNwt/fnyFDhhAbGwvAM888g7+/v6tKFUJcJWfdejjr1sNWwjLl3Fk0R44UhYf298MY1q7GsG4NjtomLN17UtCzD46GjW543aJ0KvWFchkZRwgICHZTRZCdncXzzw8BIDPzNBqNBv/zh90ffPAxHpf5RvXzz4dYt24NL7zwymVfY9Cg/sya9WHZFX0V3P13FRWIzYY+ZSOei+aj37gOxeEoHBOq1+NYujyC6nPpLpbixqiyV1KXpw+yefNmYzR60avX40WP2e12dLpy0U/gmpSnv6uoOBSzGc8ln+G56BN0v/2K6uWF5eFHKOj1OLb/3Aty+tItJCAAw2eL8Fxctr2kCnr2wdKj11WteyEg/vzzd/R6Pb/++gtNmjQlIqITiYlTsFotGAyejBqVQFBQffbs2c2nny5g0qRpzJs3G7M5g+PH/8JsNtO9e0/i4h4DIDKyLRs3bmfPnt18+OEc/P39+eOP37n99sYkJIxFURS+/XYH06e/g6enkSZNmnL8+F9MmjSt1PstASGui6qi+2EXnosXYFj2JZqcc9hvvQ3b/R0Kl9sd4LCj2O2F81k47Ch2B9jthbcdDlSdDscdd2Jr0hR7aFOc9W+RgCmlywVExfv6WgmcOnWSWbM+RKvVkpubw3vvfYBOp2PXru+YPfs9xo17+6Jtjh49wrvvziIvL49evbrxyCOxFx19/PbbL8yf/zk33VSLwYMHkJq6jzvuaMzbb09gxow51K1bj9GjR92o3RSiZIqCvUUrclq0ImfMBAyrlheGxdIloNOianWF3Wd1hb9Vne78bR2qVgs6LZr8AvSbU/CyFbaGOH39sIc2wR7aFPv50HA0aCjdcK9TlQkIS49eV/1t39U6dOiI9vw/3JycHN58838cO3YURVGw2+0lbnPvvfeh1+vR6/VUr16dzMzT1K5dvNtw48Z3FT3WsGEjMjKO4+VlpG7detStWw+AyMgoVq6Usa1EOeHtjeWx3lge633t21os6H75CV3qPnSpP6Lbvw/jR3NRCgoAUL28sN8Zgr1pM/KeGozz1tvKuPjKr8oERHni6elZdHvu3FncfXcLJkyYzIkTx3nuuadL3MbDQ190W6PR4ChhKskL15Fcbh0hKg2DAXuTZtibNAP6FT5mt6P97deiwNDtT8Vz0XwMX3zGuVlzsXaMcmvJFY3MSe1mOTk51KpVC4CvvlpV5s8fFBTM8eN/ceLEcQBSUjaW+WsIUW7odDga34mlRy9y35xI9oq1ZG7/HkdQML69u+P1ztsyUu01kIBws969+zJr1ns8+WQvl3zjNxg8GTZsOC+99Bz9+/fBy8sLb2+fMn8dIcorZ1AwWas3YHkkFu8JY/Ht/zhKzjl3l1UhVJleTFVZXl4eXl5eqKrKlCkTCQwMpEePUpzzPU/+rqJCUlWMs9/D+43XcdzWgLMfL8JxW0N3V+V2bpswSJQPq1Yt44knevH4493Jzc2hS5du7i5JiBtPUcgf9CzZny9H8/cp/Dt1QL9hrburKtfkCEJcM/m7iopOk34U3yd647F/H7mvjiJv2KugqZrfl+UIQggh/sUZGETW6g0UxPbAe9J4fJ/ojXLurLvLKnckIIQQVZPRyLn35pAzbiL6jevwfyAc7W+/uruqckWugxBCVF2KQv5Tg7HfGYJvfF/8ozpg6dETrDaUvFyU/Pyi3+TloeTnofzrt2o0YmvTFmvb+7Hd3wHHbQ0q1ZAf0gYhrpn8XUVlpDmWju/geLQHD4DRiOrl9c+PsfjvwuXeKJmn0e/YhvboEQAcdepia3t/YWC0a18hpmiVsZjc6LnnnqZPnyf4z3/uLXrs888XcfToEV5+eeRF6z/77ECeffYF7rjjTl5+eSijR4+jWrXib2BJI8P+f9u2bSEwMIhbbrkVKLxiu2nT5rRs+Z8y2jMhKhfnzYFkrVpfqm01aX+i37YFj+1b0adswPPzxQDYGzY6Hxjtsd3bpnB4c622sEG8AhxpSEC4WMeOUaSkbCgWEMnJGxgyZOgVt508+d1Sv+727Vto0yasKCDi4weV+rmEEJfnrH8LBfVvoaDvk+B0oj108HxgbMHz00UYP/ygxO1UjeafwNBoQNEUDkio1WCNfIDc4f/FGeS+o/UqExCffaZj8eKynfKwZ08bPXqUPLjeBR06RPDBBzOx2Wx4eHhw4sRx/v77FMnJ65k+/R0sFgsdOkQwYMDFYzDFxsYwd+58/P39+fjjeaxdu4bq1atTu7aJ229vDMDKlctYuXIZNpuNm2++mddfH8tvv/3Cjh3b+PHHPXz88YeMGzeJjz6aS5s2YXTo0JHdu7/nvfem4XA4zh+pjESv1xMbG8ODDz7E119vw263M3bsRIKD65fp30yISk+jwRESSn5IKPlDngOrFd2eH/DYsxvFaikc6sPpLBzKXHWCU0W5cP/8MuVsNp7LlmBYsZT8/gPJe+El1Bo1r/zaZcylAbFt2zbGjRuH0+kkLi6OgQMHFlu+a9cuxo8fzy+//MLUqVN54IEHipY1btyYRo0Kpya8MBVpReTr68edd97Fzp1f07Zte5KTNxAeHknfvk/i6+uHw+Hg+ecHc/jwbzRoUPJVnT///BMpKRv46KNFOBx2+vfvUxQQ99/fgYcffgSAOXPeZ/Xq5cTGPkZYWLuiQPg3i8XC+PFvMG3a+wQFBTN2bALLly+he/fCkW79/Pz48MOFLF36BYsXz2fEiNdd+NcRogrQ67G3vhd763uvvO6/5A3/L16TxmOc8z6ei+aTN/RF8uMHgZeXiwq9mMsCwuFwMGbMGJKSkjCZTMTGxhIeHk6DBg2K1qlTpw4TJkzgww8vnjLT09OTFStWlFk9PXrYr/ht31U6dowiOXkDbdu2JyVlAyNGvM6mTRtZuXIZDoeD06f/Ji3tj0sGRGrqXtq161A0CmxYWLuiZX/88TsffDCTnJxz5Ofn06pV68vWcvToEerUqUvQ+cPWBx98iKVLvygKiPvvDwfg9tsbs3Xr5uvedyFE6Tjr1iNn2nvkD3oW7/Fv4PPm/zDOm0Peq6Mo6NGrcI4MF3PZdRCpqakEBwcTGBiIXq8nOjqalJSUYuvcfPPN3HHHHWgq+RWMYWH388MPu/jll58pKCjA19eXxYsXMG3aTD7++FPuvTcMq9VaquceP/4NXnzxVT755DOefPKpUj/PBReGFddqNTgc7glUIcQ/HHc05uwnn5K1ch3OejdT7cVnqd6hDfp1X4GLO6G67JPZbDYTEBBQdN9kMmE2m696e4vFwqOPPkr37t1JTk52RYk3jJeX1/k5H8YQGRlFbm4unp5GfHx8yMw8zc6d31x2+6ZN72b79i1YLAXk5eXy9dfbi5bl5eVy0003Ybfb2fCvcWW8vLzIy8u76LmCgoI5ceI4x46lA7B+/Vc0a3Z3Ge2pEMJVbK3bkLVmI9lJC8HhwK/vY/g//AC6779z2WuW20bqzZs3YzKZSE9Pp1+/fjRq1IigoCB3l1VqHTtGMWrUy7zxxniCg+vTqNHt9OoVi8lkIjS06WW3vf32OwgPj6Rfv15Ur16dO+64s2hZfPxgBg58An9/f+68M6QoFCIiOjFp0jiWLPmUN9+cVLS+wWBg1KjRvP768KJG6q5dZfA+ISoERcEaHYM16kE8F83H6+0JVH8osnA8qZdHlP3LuepCub179zJjxgzmzZsHwOzZswF4+umLe+uMGDGC9u3bF2ukvpblIBfK3UjydxWinMjNxfjxhziCgrE+9HCpnsItg/WFhoaSlpZGeno6VquVNWvWEB4eflXbZmdnF51Lz8zMZM+ePcUat4UQQgDe3uQPea7U4XAlLjvFpNPpSEhIID4+HofDQbdu3WjYsCGJiYmEhIQQERFBamoqzz77LGfPnmXz5s1Mnz6dNWvW8PvvvzN69GgURUFVVZ566ikJCCGEuMEq/VhMJlMQSgW4pL2iUFUVs/monGISopKosvNB6HR6cnPPUkky0O1UVSU39yw6nd7dpQghboBy24upLFSvXoszZ06Rk5Pl7lIqDZ1OT/XqtdxdhhDiBqjUAaHV6rjppjruLkMIISqkSn2KSQghROlJQAghhCiRBIQQQogSVZpurkIIIcqWHEEIIYQokQSEEEKIEklACCGEKJEEhBBCiBJJQAghhCiRBIQQQogSSUAIIYQoUaUei+lqbNu2jXHjxuF0OomLi2PgwIHuLqnMhYeH4+3tjUajQavVsnTpUneXdF1GjhzJli1bqFmzJqtXrwYgKyuLF198kb/++ot69eoxbdo0/Pz83Fxp6ZW0j9OnT+fzzz+nRo0aAAwbNoz777/fnWWW2okTJ3j11Vc5ffo0iqLQvXt3+vXrV2nex0vtX4V7D9UqzG63qxEREerRo0dVi8WixsTEqL/99pu7yypzHTp0UE+fPu3uMsrM999/rx44cECNjo4uemzixInq7NmzVVVV1dmzZ6uTJk1yV3lloqR9fPfdd9W5c+e6saqyYzab1QMHDqiqqqrnzp1TO3XqpP7222+V5n281P5VtPewSp9iSk1NJTg4mMDAQPR6PdHR0aSkpLi7LHEFLVu2vOhbZUpKCl27dgWga9euJCcnu6O0MlPSPlYmtWvX5q677gLAx8eHW2+9FbPZXGnex0vtX0VTpQPCbDYTEBBQdN9kMlXIN/FqDBgwgEcffZTPPvvM3aW4xOnTp6lduzYAtWrV4vTp026uyDUWLlxITEwMI0eOJDs7293llIljx47x008/0bRp00r5Pv57/6BivYdVOiCqisWLF7Ns2TI++OADFi5cyK5du9xdkkspilIpp5nt2bMnGzduZMWKFdSuneu1dAAABCxJREFUXZu33nrL3SVdt9zcXIYOHcqoUaPw8fEptqwyvI//f/8q2ntYpQPCZDKRkZFRdN9sNmMymdxYkWtc2KeaNWsSGRlJamqqmysqezVr1uTkyZMAnDx5sqgRsDK56aab0Gq1aDQa4uLi2L9/v7tLui42m42hQ4cSExNDp06dgMr1Ppa0fxXtPazSAREaGkpaWhrp6f/X3t2EQtfGcRz/ZorZjEQolJKXpJSiWNgMC3lJYjUjZUdSmsbCW14SKy8rC2VjIQsyYwwpG0lJxEq2GrJR0kyT5PAs5NTdc9zK4zaP2+9Tp86cUzP/f1fNb8511TUhHh4eCAaDOJ3OWJf1qaLRKJFIxDzf398nLy8vxlV9PqfTic/nA8Dn81FVVRXjij7f6xcnwM7Ozrcex+fnZwYGBsjJyaG9vd28/reM41v9fbcx/PHbfe/u7jIxMYFhGDQ3N9PZ2Rnrkj5VKBSiq6sLAMMwqK+v//Y9ejweDg8Pub29JSUlhe7ubqqrq+np6eH6+pqMjAxmZ2dJSkqKdakfZtXj4eEh5+fnAGRmZjI2NmbO1383R0dHuN1u8vPziYt7+Z3q8XgoLi7+K8bxrf42Nja+1Rj++IAQERFrP3qKSURE3qaAEBERSwoIERGxpIAQERFLCggREbH043dzFXlPYWEh+fn55uu6urpP2/X38vKSjo4Oc8dWkf8TBYTIO+x2O36/P9ZliHw5BYTIBzmdTmpqatjb2yMhIYGpqSmys7O5vLykv7+f29tbkpOTmZycJCMjg5ubG4aHhwmFQgCMjIyQlpaGYRgMDg5ycnJCeno6c3Nz2O12FhcXWV5exmazkZuby8zMTIw7lp9GaxAi77i/v6exsdE8Njc3zXsOh4NAIEBraysTExMAjI+P09TURCAQoKGhgfHxcfN6WVkZ6+vrrK2tmdssXFxc4Ha7CQaDOBwOtre3AZifn8fn8xEIBBgdHf3irkUUECLvep1iej1qa2vNe/X19cDLusTp6SkAJycn5vXGxkaOj48BODg4wOVyAWCz2XA4HABkZWVRWFgIQFFREVdXVwAUFBTg9Xrx+/3YbLYv6FTkVwoIkRiLj483z202G4ZhAC9PEC6Xi7OzM1paWnh8fIxVifJDKSBE/oOtrS0ANjc3KSkpAaCkpIRgMAhAIBCgtLQUgIqKCpaWloCXjRPD4fCb7/v09MT19TXl5eV4vV7C4TDRaPRPtiLyL1qkFnnH6xrEq8rKSrxeLwB3d3c0NDQQHx/P9PQ0AENDQ/T19bGwsGAuUgMMDAwwNDTE6uoqcXFxjIyMkJqaavmZhmHQ29tLJBLh+fmZtrY2EhMT/3CnIr/Sbq4iH+R0OllZWfnWf2oj8juaYhIREUt6ghAREUt6ghAREUsKCBERsaSAEBERSwoIERGxpIAQERFL/wCA6Ptykc8CQAAAAABJRU5ErkJggg==\n","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{"tags":[]}},{"output_type":"display_data","data":{"image/png":"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\n","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{"tags":[]}},{"output_type":"display_data","data":{"image/png":"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\n","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{"tags":[]}},{"output_type":"display_data","data":{"image/png":"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\n","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{"tags":[]}},{"output_type":"display_data","data":{"image/png":"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\n","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{"tags":[]}},{"output_type":"display_data","data":{"text/plain":["<Figure size 432x288 with 0 Axes>"]},"metadata":{"tags":[]}}]},{"cell_type":"markdown","metadata":{"id":"qUL-CztzFr_V"},"source":["# RNN model with Cross Validation \r\n","\r\n","word embedding cbow 100"]},{"cell_type":"code","metadata":{"colab":{"background_save":true,"base_uri":"https://localhost:8080/"},"id":"8bqKr6QXDf0i","outputId":"6389ba19-759a-4cef-8f4e-f48111731347"},"source":["N_FOLDS=3 \r\n","EPOCHS=100\r\n","VALIDATION_SPLIT=0.2\r\n","BATCH_SIZE=32\r\n","PATIENCE=10\r\n","MONITOR='val_f1_m'\r\n","MONITOR_MODE='max'\r\n","SHUFFLE=True\r\n","RNN=GRU\r\n","L2_REG=0.1\r\n","DROPOUT_VALUE_1=0.5\r\n","DROPOUT_VALUE_2=0.5\r\n","NB_FILTERS=200\r\n","HIDDEN_DIMS=NB_FILTERS*2\r\n","VERBOSITY=1\r\n","EMBEDDING_SIZE=300\r\n","\r\n","def create_model():\r\n","    model = Sequential()\r\n","    embedding_layer = Embedding(vocab_length,EMBEDDING_SIZE,weights=[embedding_matrix], input_length=length_long_sentence, trainable=False)\r\n","    model.add(embedding_layer)\r\n","    model.add(Dropout(DROPOUT_VALUE_1))\r\n","    model.add(RNN(HIDDEN_DIMS))\r\n","    model.add(Dense(HIDDEN_DIMS, activation='relu'))\r\n","    model.add(Dropout(DROPOUT_VALUE_2))\r\n","    model.add(Dense(6,activation='sigmoid'))\r\n","    model.compile(loss='binary_crossentropy', optimizer='adam',metrics=[\"accuracy\",precision_m,recall_m,f1_m])\r\n","    return model \r\n","\r\n","# Define per-fold score containers <-- these are new\r\n","acc_per_fold = []\r\n","loss_per_fold = []\r\n","f1_per_fold = []\r\n","precision_per_fold =[]\r\n","recall_per_fold=[]\r\n","\r\n","#Define dependencied for model loading\r\n","dependencies = {\r\n","    'recall_m': recall_m,\r\n","    'f1_m':f1_m,\r\n","    'precision_m':precision_m    \r\n","}\r\n","\r\n","\r\n","\r\n","vocab_length,padded_sentences,length_long_sentence,embedding_matrix=loadembedding_matrix(x,mainloc+'word_embeddings/w2v_cbow_300.txt',300)\r\n","\r\n","# stratified K-fold Cross Validation model evaluation\r\n","#skf = StratifiedKFold(n_splits=N_FOLDS,random_state=None, shuffle=shuffle)\r\n","kf = KFold(n_splits=N_FOLDS)\r\n","fold_no = 1\r\n","for train_index, test_index in kf.split(padded_sentences, y):\r\n","    model=create_model()\r\n","    es = EarlyStopping(monitor=MONITOR, mode=MONITOR_MODE, verbose=1,patience= PATIENCE )\r\n","    history = model.fit(padded_sentences[train_index],y.values[train_index],epochs=EPOCHS,callbacks=[es],batch_size=BATCH_SIZE,shuffle=True,validation_split=VALIDATION_SPLIT)\r\n","    \r\n","    # Generate generalization metrics\r\n","    scores = model.evaluate(padded_sentences[test_index], y.values[test_index], verbose=0)\r\n","    print(f'Score for fold {fold_no}: {model.metrics_names[0]} of {scores[0]}; {model.metrics_names[1]} of {scores[1]*100}% ;{model.metrics_names[2]} of {scores[2]} ;{model.metrics_names[3]} of {scores[3]} ; \\\r\n","           {model.metrics_names[4]} of {scores[4]}')\r\n","    loss_per_fold.append(scores[0])\r\n","    acc_per_fold.append(scores[1] * 100)\r\n","    precision_per_fold.append(scores[2])\r\n","    recall_per_fold.append(scores[3])\r\n","    f1_per_fold.append(scores[4])\r\n","\r\n","    # Increase fold number\r\n","    fold_no = fold_no + 1\r\n","    \r\n","accuracy_crossval(acc_per_fold,loss_per_fold,f1_per_fold,precision_per_fold,recall_per_fold)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Epoch 1/100\n","131/131 [==============================] - 6s 37ms/step - loss: 0.6861 - accuracy: 0.2762 - precision_m: 0.4752 - recall_m: 0.2944 - f1_m: 0.3629 - val_loss: 0.6625 - val_accuracy: 0.3273 - val_precision_m: 0.5824 - val_recall_m: 0.3934 - val_f1_m: 0.4681\n","Epoch 2/100\n","131/131 [==============================] - 4s 34ms/step - loss: 0.6603 - accuracy: 0.2699 - precision_m: 0.5205 - recall_m: 0.3216 - f1_m: 0.3971 - val_loss: 0.6362 - val_accuracy: 0.3273 - val_precision_m: 0.5824 - val_recall_m: 0.3934 - val_f1_m: 0.4681\n","Epoch 3/100\n","131/131 [==============================] - 4s 33ms/step - loss: 0.6397 - accuracy: 0.2613 - precision_m: 0.5113 - recall_m: 0.3127 - f1_m: 0.3875 - val_loss: 0.6142 - val_accuracy: 0.3273 - val_precision_m: 0.5824 - val_recall_m: 0.3934 - val_f1_m: 0.4681\n","Epoch 4/100\n","131/131 [==============================] - 5s 36ms/step - loss: 0.6207 - accuracy: 0.2712 - precision_m: 0.5136 - recall_m: 0.3204 - f1_m: 0.3940 - val_loss: 0.5959 - val_accuracy: 0.3273 - val_precision_m: 0.5824 - val_recall_m: 0.3934 - val_f1_m: 0.4681\n","Epoch 5/100\n","131/131 [==============================] - 4s 34ms/step - loss: 0.6074 - accuracy: 0.2676 - precision_m: 0.5210 - recall_m: 0.3192 - f1_m: 0.3954 - val_loss: 0.5806 - val_accuracy: 0.3273 - val_precision_m: 0.5824 - val_recall_m: 0.3934 - val_f1_m: 0.4681\n","Epoch 6/100\n","131/131 [==============================] - 4s 34ms/step - loss: 0.5946 - accuracy: 0.2671 - precision_m: 0.5181 - recall_m: 0.3199 - f1_m: 0.3950 - val_loss: 0.5678 - val_accuracy: 0.3273 - val_precision_m: 0.5824 - val_recall_m: 0.3934 - val_f1_m: 0.4681\n","Epoch 7/100\n","131/131 [==============================] - 4s 34ms/step - loss: 0.5859 - accuracy: 0.2703 - precision_m: 0.5136 - recall_m: 0.3157 - f1_m: 0.3904 - val_loss: 0.5572 - val_accuracy: 0.3273 - val_precision_m: 0.5824 - val_recall_m: 0.3934 - val_f1_m: 0.4681\n","Epoch 8/100\n","131/131 [==============================] - 4s 34ms/step - loss: 0.5748 - accuracy: 0.2733 - precision_m: 0.5249 - recall_m: 0.3266 - f1_m: 0.4021 - val_loss: 0.5484 - val_accuracy: 0.3273 - val_precision_m: 0.5824 - val_recall_m: 0.3934 - val_f1_m: 0.4681\n","Epoch 9/100\n","131/131 [==============================] - 4s 34ms/step - loss: 0.5699 - accuracy: 0.2734 - precision_m: 0.5197 - recall_m: 0.3222 - f1_m: 0.3973 - val_loss: 0.5411 - val_accuracy: 0.3273 - val_precision_m: 0.5824 - val_recall_m: 0.3934 - val_f1_m: 0.4681\n","Epoch 10/100\n","131/131 [==============================] - 4s 34ms/step - loss: 0.5665 - accuracy: 0.2759 - precision_m: 0.5131 - recall_m: 0.3167 - f1_m: 0.3912 - val_loss: 0.5350 - val_accuracy: 0.3273 - val_precision_m: 0.5824 - val_recall_m: 0.3934 - val_f1_m: 0.4681\n","Epoch 11/100\n","131/131 [==============================] - 4s 34ms/step - loss: 0.5600 - accuracy: 0.2786 - precision_m: 0.5187 - recall_m: 0.3231 - f1_m: 0.3975 - val_loss: 0.5300 - val_accuracy: 0.3273 - val_precision_m: 0.5824 - val_recall_m: 0.3934 - val_f1_m: 0.4681\n","Epoch 00011: early stopping\n","Score for fold 1: loss of 0.6247647404670715; accuracy of 15.566577017307281% ;precision_m of 0.5127865076065063 ;recall_m of 0.2593536674976349 ;            f1_m of 0.34322670102119446\n","Epoch 1/100\n","131/131 [==============================] - 6s 37ms/step - loss: 0.6340 - accuracy: 0.2116 - precision_m: 0.4274 - recall_m: 0.1602 - f1_m: 0.2241 - val_loss: 0.5399 - val_accuracy: 0.3279 - val_precision_m: 0.5827 - val_recall_m: 0.3938 - val_f1_m: 0.4685\n","Epoch 2/100\n","131/131 [==============================] - 4s 34ms/step - loss: 0.5908 - accuracy: 0.2138 - precision_m: 0.5337 - recall_m: 0.2055 - f1_m: 0.2945 - val_loss: 0.5220 - val_accuracy: 0.3279 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00 - val_f1_m: 0.0000e+00\n","Epoch 3/100\n","131/131 [==============================] - 4s 34ms/step - loss: 0.5918 - accuracy: 0.2161 - precision_m: 0.4946 - recall_m: 0.1733 - f1_m: 0.2533 - val_loss: 0.5158 - val_accuracy: 0.3279 - val_precision_m: 0.5827 - val_recall_m: 0.3938 - val_f1_m: 0.4685\n","Epoch 4/100\n","131/131 [==============================] - 4s 34ms/step - loss: 0.5905 - accuracy: 0.2169 - precision_m: 0.5184 - recall_m: 0.2375 - f1_m: 0.3235 - val_loss: 0.5183 - val_accuracy: 0.3279 - val_precision_m: 0.5827 - val_recall_m: 0.3938 - val_f1_m: 0.4685\n","Epoch 5/100\n","131/131 [==============================] - 4s 34ms/step - loss: 0.5964 - accuracy: 0.1938 - precision_m: 0.5218 - recall_m: 0.1853 - f1_m: 0.2691 - val_loss: 0.5232 - val_accuracy: 0.3279 - val_precision_m: 0.5827 - val_recall_m: 0.3938 - val_f1_m: 0.4685\n","Epoch 6/100\n","131/131 [==============================] - 4s 34ms/step - loss: 0.5924 - accuracy: 0.2165 - precision_m: 0.5162 - recall_m: 0.2090 - f1_m: 0.2950 - val_loss: 0.5281 - val_accuracy: 0.3279 - val_precision_m: 0.5827 - val_recall_m: 0.3938 - val_f1_m: 0.4685\n","Epoch 7/100\n","131/131 [==============================] - 4s 34ms/step - loss: 0.5939 - accuracy: 0.2052 - precision_m: 0.5033 - recall_m: 0.1648 - f1_m: 0.2387 - val_loss: 0.5146 - val_accuracy: 0.3279 - val_precision_m: 0.5827 - val_recall_m: 0.3938 - val_f1_m: 0.4685\n","Epoch 8/100\n","131/131 [==============================] - 4s 34ms/step - loss: 0.5954 - accuracy: 0.2046 - precision_m: 0.5149 - recall_m: 0.2217 - f1_m: 0.3068 - val_loss: 0.5135 - val_accuracy: 0.3279 - val_precision_m: 0.5827 - val_recall_m: 0.3938 - val_f1_m: 0.4685\n","Epoch 9/100\n","131/131 [==============================] - 4s 34ms/step - loss: 0.5904 - accuracy: 0.2113 - precision_m: 0.5288 - recall_m: 0.2399 - f1_m: 0.3282 - val_loss: 0.5216 - val_accuracy: 0.3279 - val_precision_m: 0.5827 - val_recall_m: 0.3938 - val_f1_m: 0.4685\n","Epoch 10/100\n","131/131 [==============================] - 4s 34ms/step - loss: 0.5903 - accuracy: 0.2088 - precision_m: 0.5109 - recall_m: 0.2032 - f1_m: 0.2888 - val_loss: 0.5255 - val_accuracy: 0.3279 - val_precision_m: 0.5827 - val_recall_m: 0.3938 - val_f1_m: 0.4685\n","Epoch 11/100\n","131/131 [==============================] - 4s 34ms/step - loss: 0.5900 - accuracy: 0.2079 - precision_m: 0.5248 - recall_m: 0.2041 - f1_m: 0.2924 - val_loss: 0.5198 - val_accuracy: 0.3279 - val_precision_m: 0.5827 - val_recall_m: 0.3938 - val_f1_m: 0.4685\n","Epoch 00011: early stopping\n","Score for fold 2: loss of 0.5662268996238708; accuracy of 25.076335668563843% ;precision_m of 0.5106163024902344 ;recall_m of 0.3112577795982361 ;            f1_m of 0.3850182890892029\n","Epoch 1/100\n","131/131 [==============================] - 7s 38ms/step - loss: 0.6294 - accuracy: 0.1946 - precision_m: 0.4742 - recall_m: 0.1562 - f1_m: 0.2288 - val_loss: 0.5647 - val_accuracy: 0.2822 - val_precision_m: 0.5127 - val_recall_m: 0.3279 - val_f1_m: 0.3987\n","Epoch 2/100\n","131/131 [==============================] - 4s 34ms/step - loss: 0.6069 - accuracy: 0.1862 - precision_m: 0.5229 - recall_m: 0.1842 - f1_m: 0.2704 - val_loss: 0.5567 - val_accuracy: 0.2822 - val_precision_m: 0.5127 - val_recall_m: 0.3279 - val_f1_m: 0.3987\n","Epoch 3/100\n","131/131 [==============================] - 4s 34ms/step - loss: 0.6051 - accuracy: 0.1845 - precision_m: 0.4891 - recall_m: 0.1695 - f1_m: 0.2465 - val_loss: 0.5590 - val_accuracy: 0.2822 - val_precision_m: 0.5127 - val_recall_m: 0.3279 - val_f1_m: 0.3987\n","Epoch 4/100\n","131/131 [==============================] - 4s 34ms/step - loss: 0.6060 - accuracy: 0.1821 - precision_m: 0.5187 - recall_m: 0.1964 - f1_m: 0.2812 - val_loss: 0.5663 - val_accuracy: 0.2822 - val_precision_m: 0.5127 - val_recall_m: 0.3279 - val_f1_m: 0.3987\n","Epoch 5/100\n","131/131 [==============================] - 4s 34ms/step - loss: 0.6077 - accuracy: 0.1823 - precision_m: 0.5145 - recall_m: 0.1986 - f1_m: 0.2833 - val_loss: 0.5643 - val_accuracy: 0.2822 - val_precision_m: 0.5127 - val_recall_m: 0.3279 - val_f1_m: 0.3987\n","Epoch 6/100\n","131/131 [==============================] - 4s 34ms/step - loss: 0.6036 - accuracy: 0.1828 - precision_m: 0.5104 - recall_m: 0.1779 - f1_m: 0.2560 - val_loss: 0.5664 - val_accuracy: 0.2822 - val_precision_m: 0.5127 - val_recall_m: 0.3279 - val_f1_m: 0.3987\n","Epoch 7/100\n","131/131 [==============================] - 4s 34ms/step - loss: 0.6080 - accuracy: 0.1810 - precision_m: 0.5099 - recall_m: 0.1699 - f1_m: 0.2523 - val_loss: 0.5591 - val_accuracy: 0.2822 - val_precision_m: 0.5127 - val_recall_m: 0.3279 - val_f1_m: 0.3987\n","Epoch 8/100\n","131/131 [==============================] - 4s 34ms/step - loss: 0.6066 - accuracy: 0.1761 - precision_m: 0.5141 - recall_m: 0.2287 - f1_m: 0.3130 - val_loss: 0.5602 - val_accuracy: 0.2822 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00 - val_f1_m: 0.0000e+00\n","Epoch 9/100\n","131/131 [==============================] - 4s 34ms/step - loss: 0.6067 - accuracy: 0.1833 - precision_m: 0.5013 - recall_m: 0.1324 - f1_m: 0.2036 - val_loss: 0.5605 - val_accuracy: 0.2822 - val_precision_m: 0.5127 - val_recall_m: 0.3279 - val_f1_m: 0.3987\n","Epoch 10/100\n","131/131 [==============================] - 4s 34ms/step - loss: 0.6054 - accuracy: 0.1855 - precision_m: 0.5163 - recall_m: 0.2259 - f1_m: 0.3081 - val_loss: 0.5614 - val_accuracy: 0.2822 - val_precision_m: 0.5127 - val_recall_m: 0.3279 - val_f1_m: 0.3987\n","Epoch 11/100\n","131/131 [==============================] - 4s 34ms/step - loss: 0.6017 - accuracy: 0.1881 - precision_m: 0.5216 - recall_m: 0.2349 - f1_m: 0.3188 - val_loss: 0.5582 - val_accuracy: 0.2822 - val_precision_m: 0.5127 - val_recall_m: 0.3279 - val_f1_m: 0.3987\n","Epoch 00011: early stopping\n","Score for fold 3: loss of 0.5363395810127258; accuracy of 31.068703532218933% ;precision_m of 0.5502504706382751 ;recall_m of 0.36772269010543823 ;            f1_m of 0.43958553671836853\n","------------------------------------------------------------------------\n","Score per fold\n","------------------------------------------------------------------------\n","> Fold 1 - Loss: 0.6247647404670715 - Accuracy: 15.566577017307281% - Precision: 0.5127865076065063 - Recall: 0.2593536674976349 - F1: 0.34322670102119446\n","------------------------------------------------------------------------\n","> Fold 2 - Loss: 0.5662268996238708 - Accuracy: 25.076335668563843% - Precision: 0.5106163024902344 - Recall: 0.3112577795982361 - F1: 0.3850182890892029\n","------------------------------------------------------------------------\n","> Fold 3 - Loss: 0.5363395810127258 - Accuracy: 31.068703532218933% - Precision: 0.5502504706382751 - Recall: 0.36772269010543823 - F1: 0.43958553671836853\n","------------------------------------------------------------------------\n","Average scores for all folds:\n","> Accuracy: 23.903872072696686 (+- 6.382788564246144)\n","> Precision: 0.5245510935783386\n","> Recall: 0.3127780457337697\n","> F1: 0.3892768422762553\n","> Loss: 0.5757770737012228\n","------------------------------------------------------------------------\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"ywtwvhgfMm97"},"source":["# LSTM Model with Cross Validation \r\n"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"BR0QNQSBKiIX","executionInfo":{"elapsed":80390,"status":"ok","timestamp":1614008020774,"user":{"displayName":"Shanaka Chathuranga","photoUrl":"","userId":"01381725564551416324"},"user_tz":-330},"outputId":"f99816bc-18f3-45b9-8d3e-ca0682044ddb"},"source":["N_FOLDS=3 \r\n","EPOCHS=50\r\n","VALIDATION_SPLIT=0.2\r\n","BATCH_SIZE=32\r\n","PATIENCE=2\r\n","MONITOR='val_f1_m'\r\n","MONITOR_MODE='max'\r\n","SHUFFLE=True\r\n","RNN=LSTM\r\n","L2_REG=0.1\r\n","DROPOUT_VALUE_1=0.5\r\n","DROPOUT_VALUE_2=0.5\r\n","NB_FILTERS=200\r\n","HIDDEN_DIMS=NB_FILTERS*2\r\n","VERBOSITY=1\r\n","EMBEDDING_SIZE=300\r\n","\r\n","\r\n","\r\n","\r\n","def create_model():\r\n","    model = Sequential()\r\n","    embedding_layer = Embedding(vocab_length,EMBEDDING_SIZE,weights=[embedding_matrix], input_length=length_long_sentence, trainable=False)\r\n","    model.add(embedding_layer)\r\n","    model.add(Dropout(DROPOUT_VALUE_1))\r\n","    model.add(RNN(HIDDEN_DIMS))\r\n","    model.add(Dense(HIDDEN_DIMS, activation='relu'))\r\n","    model.add(Dropout(DROPOUT_VALUE_2))\r\n","    model.add(Dense(6,activation='sigmoid'))\r\n","    model.compile(loss='binary_crossentropy', optimizer='adam',metrics=[\"accuracy\",precision_m,recall_m,f1_m])\r\n","    return model \r\n","\r\n","# Define per-fold score containers <-- these are new\r\n","acc_per_fold = []\r\n","loss_per_fold = []\r\n","f1_per_fold = []\r\n","precision_per_fold =[]\r\n","recall_per_fold=[]\r\n","\r\n","#Define dependencied for model loading\r\n","dependencies = {\r\n","    'recall_m': recall_m,\r\n","    'f1_m':f1_m,\r\n","    'precision_m':precision_m    \r\n","}\r\n","\r\n","# stratified K-fold Cross Validation model evaluation\r\n","#skf = StratifiedKFold(n_splits=N_FOLDS,random_state=None, shuffle=shuffle)\r\n","kf = KFold(n_splits=N_FOLDS)\r\n","fold_no = 1\r\n","for train_index, test_index in kf.split(padded_sentences, y):\r\n","    model=create_model()\r\n","    es = EarlyStopping(monitor=MONITOR, mode=MONITOR_MODE, verbose=1,patience= PATIENCE )\r\n","    history = model.fit(padded_sentences[train_index],y.values[train_index],epochs=EPOCHS,callbacks=[es],batch_size=BATCH_SIZE,shuffle=True,validation_split=VALIDATION_SPLIT)\r\n","    \r\n","    # Generate generalization metrics\r\n","    scores = model.evaluate(padded_sentences[test_index], y.values[test_index], verbose=0)\r\n","    print(f'Score for fold {fold_no}: {model.metrics_names[0]} of {scores[0]}; {model.metrics_names[1]} of {scores[1]*100}% ;{model.metrics_names[2]} of {scores[2]} ;{model.metrics_names[3]} of {scores[3]} ; \\\r\n","           {model.metrics_names[4]} of {scores[4]}')\r\n","    loss_per_fold.append(scores[0])\r\n","    acc_per_fold.append(scores[1] * 100)\r\n","    f1_per_fold.append(scores[2])\r\n","    precision_per_fold.append(scores[3])\r\n","    recall_per_fold.append(scores[4])\r\n","\r\n","    # Increase fold number\r\n","    fold_no = fold_no + 1\r\n","    \r\n","accuracy_crossval(acc_per_fold,loss_per_fold,f1_per_fold,precision_per_fold,recall_per_fold)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Epoch 1/50\n","131/131 [==============================] - 7s 43ms/step - loss: 0.5824 - accuracy: 0.2538 - precision_m: 0.4959 - recall_m: 0.2072 - f1_m: 0.2870 - val_loss: 0.5034 - val_accuracy: 0.3273 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00 - val_f1_m: 0.0000e+00\n","Epoch 2/50\n","131/131 [==============================] - 5s 40ms/step - loss: 0.5435 - accuracy: 0.2833 - precision_m: 0.5468 - recall_m: 0.2047 - f1_m: 0.2857 - val_loss: 0.5007 - val_accuracy: 0.3273 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00 - val_f1_m: 0.0000e+00\n","Epoch 3/50\n","131/131 [==============================] - 5s 40ms/step - loss: 0.5513 - accuracy: 0.2653 - precision_m: 0.4942 - recall_m: 0.1825 - f1_m: 0.2611 - val_loss: 0.5003 - val_accuracy: 0.3273 - val_precision_m: 0.5824 - val_recall_m: 0.3934 - val_f1_m: 0.4681\n","Epoch 4/50\n","131/131 [==============================] - 5s 40ms/step - loss: 0.5459 - accuracy: 0.2693 - precision_m: 0.5349 - recall_m: 0.2275 - f1_m: 0.3104 - val_loss: 0.5067 - val_accuracy: 0.3273 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00 - val_f1_m: 0.0000e+00\n","Epoch 5/50\n","131/131 [==============================] - 5s 40ms/step - loss: 0.5480 - accuracy: 0.2648 - precision_m: 0.5223 - recall_m: 0.1925 - f1_m: 0.2738 - val_loss: 0.4998 - val_accuracy: 0.3273 - val_precision_m: 0.5824 - val_recall_m: 0.3934 - val_f1_m: 0.4681\n","Epoch 00005: early stopping\n","Score for fold 1: loss of 0.6522122025489807; accuracy of 15.566577017307281% ;precision_m of 0.5127865076065063 ;recall_m of 0.2593536674976349 ;            f1_m of 0.34322670102119446\n","Epoch 1/50\n","131/131 [==============================] - 7s 45ms/step - loss: 0.6273 - accuracy: 0.2088 - precision_m: 0.5018 - recall_m: 0.1795 - f1_m: 0.2431 - val_loss: 0.5163 - val_accuracy: 0.3279 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00 - val_f1_m: 0.0000e+00\n","Epoch 2/50\n","131/131 [==============================] - 5s 40ms/step - loss: 0.5918 - accuracy: 0.2063 - precision_m: 0.5129 - recall_m: 0.1985 - f1_m: 0.2797 - val_loss: 0.5277 - val_accuracy: 0.3279 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00 - val_f1_m: 0.0000e+00\n","Epoch 3/50\n","131/131 [==============================] - 5s 40ms/step - loss: 0.5964 - accuracy: 0.2088 - precision_m: 0.5155 - recall_m: 0.1582 - f1_m: 0.2340 - val_loss: 0.5320 - val_accuracy: 0.3279 - val_precision_m: 0.5827 - val_recall_m: 0.3938 - val_f1_m: 0.4685\n","Epoch 4/50\n","131/131 [==============================] - 5s 41ms/step - loss: 0.5970 - accuracy: 0.1994 - precision_m: 0.5056 - recall_m: 0.1971 - f1_m: 0.2798 - val_loss: 0.5236 - val_accuracy: 0.3279 - val_precision_m: 0.5827 - val_recall_m: 0.3938 - val_f1_m: 0.4685\n","Epoch 5/50\n","131/131 [==============================] - 5s 39ms/step - loss: 0.5903 - accuracy: 0.2120 - precision_m: 0.5128 - recall_m: 0.2200 - f1_m: 0.3052 - val_loss: 0.5238 - val_accuracy: 0.3279 - val_precision_m: 0.5827 - val_recall_m: 0.3938 - val_f1_m: 0.4685\n","Epoch 00005: early stopping\n","Score for fold 2: loss of 0.5670601725578308; accuracy of 25.076335668563843% ;precision_m of 0.5106163024902344 ;recall_m of 0.3112577795982361 ;            f1_m of 0.3850182890892029\n","Epoch 1/50\n","131/131 [==============================] - 7s 44ms/step - loss: 0.6319 - accuracy: 0.1939 - precision_m: 0.4796 - recall_m: 0.1737 - f1_m: 0.2438 - val_loss: 0.5714 - val_accuracy: 0.2822 - val_precision_m: 0.5127 - val_recall_m: 0.3279 - val_f1_m: 0.3987\n","Epoch 2/50\n","131/131 [==============================] - 5s 40ms/step - loss: 0.6096 - accuracy: 0.1850 - precision_m: 0.5300 - recall_m: 0.1692 - f1_m: 0.2524 - val_loss: 0.5551 - val_accuracy: 0.2822 - val_precision_m: 0.5127 - val_recall_m: 0.3279 - val_f1_m: 0.3987\n","Epoch 3/50\n","131/131 [==============================] - 5s 39ms/step - loss: 0.6088 - accuracy: 0.1841 - precision_m: 0.5161 - recall_m: 0.2077 - f1_m: 0.2924 - val_loss: 0.5603 - val_accuracy: 0.2822 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00 - val_f1_m: 0.0000e+00\n","Epoch 00003: early stopping\n","Score for fold 3: loss of 0.5410941243171692; accuracy of 31.068703532218933% ;precision_m of 0.0 ;recall_m of 0.0 ;            f1_m of 0.0\n","------------------------------------------------------------------------\n","Score per fold\n","------------------------------------------------------------------------\n","> Fold 1 - Loss: 0.6522122025489807 - Accuracy: 15.566577017307281% - Precision: 0.2593536674976349 - Recall: 0.34322670102119446 - F1: 0.5127865076065063\n","------------------------------------------------------------------------\n","> Fold 2 - Loss: 0.5670601725578308 - Accuracy: 25.076335668563843% - Precision: 0.3112577795982361 - Recall: 0.3850182890892029 - F1: 0.5106163024902344\n","------------------------------------------------------------------------\n","> Fold 3 - Loss: 0.5410941243171692 - Accuracy: 31.068703532218933% - Precision: 0.0 - Recall: 0.0 - F1: 0.0\n","------------------------------------------------------------------------\n","Average scores for all folds:\n","> Accuracy: 23.903872072696686 (+- 6.382788564246144)\n","> Precision: 0.19020381569862366\n","> Recall: 0.2427483300367991\n","> F1: 0.3411342700322469\n","> Loss: 0.5867888331413269\n","------------------------------------------------------------------------\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"EAJ5ANNGNqRn"},"source":["# CNN_RNN/LSTM/GRU Model with Cross Vlidation "]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"7RUY5b0jNonl","executionInfo":{"elapsed":138928,"status":"ok","timestamp":1614008286801,"user":{"displayName":"Shanaka Chathuranga","photoUrl":"","userId":"01381725564551416324"},"user_tz":-330},"outputId":"72b14801-788b-4bdf-fe52-4b622e4b0881"},"source":["N_FOLDS=3 \r\n","EPOCHS=50\r\n","VALIDATION_SPLIT=0.2\r\n","BATCH_SIZE=32\r\n","PATIENCE=10\r\n","MONITOR='val_f1_m'\r\n","MONITOR_MODE='max'\r\n","SHUFFLE=True\r\n","RNN=LSTM\r\n","L2_REG=0.1\r\n","DROPOUT_VALUE_1=0.7\r\n","DROPOUT_VALUE_2=0.7\r\n","NB_FILTERS=128\r\n","KERNEL_SIZE=5\r\n","HIDDEN_DIMS=NB_FILTERS*2\r\n","VERBOSITY=1\r\n","EMBEDDING_SIZE=300\r\n","\r\n","def create_model():\r\n","  model = Sequential()\r\n","  embedding_layer = Embedding(vocab_length,EMBEDDING_SIZE,weights=[embedding_matrix], input_length=length_long_sentence, trainable=False)\r\n","  model.add(embedding_layer)\r\n","  model.add(Conv1D(filters=NB_FILTERS,kernel_size=KERNEL_SIZE, padding='same', activation='relu'))\r\n","  model.add(MaxPooling1D(pool_size=2))\r\n","  model.add(Dropout(DROPOUT_VALUE_2))\r\n","  model.add(RNN(HIDDEN_DIMS,return_sequences=True))\r\n","  model.add(RNN(HIDDEN_DIMS))\r\n","  model.add(Dropout(DROPOUT_VALUE_2))\r\n","  model.add(Dense(6, activation='sigmoid'))\r\n","  model.compile(loss='binary_crossentropy', optimizer='adam',metrics=[\"accuracy\",precision_m,recall_m,f1_m])\r\n","  return model \r\n","\r\n","# Define per-fold score containers \r\n","acc_per_fold = []\r\n","loss_per_fold = []\r\n","f1_per_fold = []\r\n","precision_per_fold =[]\r\n","recall_per_fold=[]\r\n","\r\n","#Define dependencied for model loading\r\n","dependencies = {\r\n","    'recall_m': recall_m,\r\n","    'f1_m':f1_m,\r\n","    'precision_m':precision_m    \r\n","}\r\n","\r\n","# stratified K-fold Cross Validation model evaluation\r\n","#skf = StratifiedKFold(n_splits=N_FOLDS,random_state=None, shuffle=shuffle)\r\n","kf = KFold(n_splits=N_FOLDS)\r\n","fold_no = 1\r\n","for train_index, test_index in kf.split(padded_sentences, y):\r\n","    model=create_model()\r\n","    es = EarlyStopping(monitor=MONITOR, mode=MONITOR_MODE, verbose=1,patience= PATIENCE )\r\n","    history = model.fit(padded_sentences[train_index],y.values[train_index],epochs=EPOCHS,callbacks=[es],batch_size=BATCH_SIZE,shuffle=True,validation_split=VALIDATION_SPLIT)\r\n","    \r\n","    # Generate generalization metrics\r\n","    scores = model.evaluate(padded_sentences[test_index], y.values[test_index], verbose=0)\r\n","    print(f'Score for fold {fold_no}: {model.metrics_names[0]} of {scores[0]}; {model.metrics_names[1]} of {scores[1]*100}% ;{model.metrics_names[2]} of {scores[2]} ;{model.metrics_names[3]} of {scores[3]} ; \\\r\n","           {model.metrics_names[4]} of {scores[4]}')\r\n","    loss_per_fold.append(scores[0])\r\n","    acc_per_fold.append(scores[1] * 100)\r\n","    f1_per_fold.append(scores[2])\r\n","    precision_per_fold.append(scores[3])\r\n","    recall_per_fold.append(scores[4])\r\n","\r\n","    # Increase fold number\r\n","    fold_no = fold_no + 1\r\n","    \r\n","accuracy_crossval(acc_per_fold,loss_per_fold,f1_per_fold,precision_per_fold,recall_per_fold)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Epoch 1/50\n","131/131 [==============================] - 7s 36ms/step - loss: 0.5808 - accuracy: 0.2662 - precision_m: 0.4890 - recall_m: 0.2015 - f1_m: 0.2779 - val_loss: 0.5247 - val_accuracy: 0.3273 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00 - val_f1_m: 0.0000e+00\n","Epoch 2/50\n","131/131 [==============================] - 4s 27ms/step - loss: 0.5565 - accuracy: 0.2594 - precision_m: 0.5128 - recall_m: 0.1712 - f1_m: 0.2514 - val_loss: 0.5023 - val_accuracy: 0.3273 - val_precision_m: 0.5824 - val_recall_m: 0.3934 - val_f1_m: 0.4681\n","Epoch 3/50\n","131/131 [==============================] - 4s 28ms/step - loss: 0.5502 - accuracy: 0.2723 - precision_m: 0.5109 - recall_m: 0.2005 - f1_m: 0.2850 - val_loss: 0.5013 - val_accuracy: 0.3273 - val_precision_m: 0.5824 - val_recall_m: 0.3934 - val_f1_m: 0.4681\n","Epoch 4/50\n","131/131 [==============================] - 4s 28ms/step - loss: 0.5528 - accuracy: 0.2581 - precision_m: 0.5237 - recall_m: 0.1794 - f1_m: 0.2640 - val_loss: 0.4994 - val_accuracy: 0.3273 - val_precision_m: 0.5824 - val_recall_m: 0.3934 - val_f1_m: 0.4681\n","Epoch 5/50\n","131/131 [==============================] - 4s 28ms/step - loss: 0.5462 - accuracy: 0.2704 - precision_m: 0.5337 - recall_m: 0.2391 - f1_m: 0.3284 - val_loss: 0.5022 - val_accuracy: 0.3273 - val_precision_m: 0.5824 - val_recall_m: 0.3934 - val_f1_m: 0.4681\n","Epoch 6/50\n","131/131 [==============================] - 4s 28ms/step - loss: 0.5416 - accuracy: 0.2866 - precision_m: 0.5240 - recall_m: 0.2351 - f1_m: 0.3226 - val_loss: 0.5040 - val_accuracy: 0.3273 - val_precision_m: 0.5824 - val_recall_m: 0.3934 - val_f1_m: 0.4681\n","Epoch 7/50\n","131/131 [==============================] - 4s 28ms/step - loss: 0.5468 - accuracy: 0.2699 - precision_m: 0.4980 - recall_m: 0.1890 - f1_m: 0.2708 - val_loss: 0.5037 - val_accuracy: 0.3273 - val_precision_m: 0.5824 - val_recall_m: 0.3934 - val_f1_m: 0.4681\n","Epoch 8/50\n","131/131 [==============================] - 4s 28ms/step - loss: 0.5459 - accuracy: 0.2695 - precision_m: 0.5363 - recall_m: 0.2412 - f1_m: 0.3305 - val_loss: 0.5031 - val_accuracy: 0.3273 - val_precision_m: 0.5824 - val_recall_m: 0.3934 - val_f1_m: 0.4681\n","Epoch 9/50\n","131/131 [==============================] - 4s 28ms/step - loss: 0.5451 - accuracy: 0.2754 - precision_m: 0.5384 - recall_m: 0.2458 - f1_m: 0.3351 - val_loss: 0.5026 - val_accuracy: 0.3273 - val_precision_m: 0.5824 - val_recall_m: 0.3934 - val_f1_m: 0.4681\n","Epoch 10/50\n","131/131 [==============================] - 4s 28ms/step - loss: 0.5502 - accuracy: 0.2648 - precision_m: 0.5139 - recall_m: 0.1724 - f1_m: 0.2527 - val_loss: 0.5016 - val_accuracy: 0.3273 - val_precision_m: 0.5824 - val_recall_m: 0.3934 - val_f1_m: 0.4681\n","Epoch 11/50\n","131/131 [==============================] - 4s 28ms/step - loss: 0.5496 - accuracy: 0.2651 - precision_m: 0.5117 - recall_m: 0.2563 - f1_m: 0.3403 - val_loss: 0.5026 - val_accuracy: 0.3273 - val_precision_m: 0.5824 - val_recall_m: 0.3934 - val_f1_m: 0.4681\n","Epoch 12/50\n","131/131 [==============================] - 4s 28ms/step - loss: 0.5487 - accuracy: 0.2661 - precision_m: 0.5178 - recall_m: 0.2079 - f1_m: 0.2932 - val_loss: 0.5032 - val_accuracy: 0.3273 - val_precision_m: 0.5824 - val_recall_m: 0.3934 - val_f1_m: 0.4681\n","Epoch 00012: early stopping\n","Score for fold 1: loss of 0.6444118618965149; accuracy of 15.566577017307281% ;precision_m of 0.5127865076065063 ;recall_m of 0.2593536674976349 ;            f1_m of 0.34322670102119446\n","Epoch 1/50\n","131/131 [==============================] - 7s 36ms/step - loss: 0.6151 - accuracy: 0.2248 - precision_m: 0.5053 - recall_m: 0.1835 - f1_m: 0.2570 - val_loss: 0.5302 - val_accuracy: 0.3279 - val_precision_m: 0.5827 - val_recall_m: 0.3938 - val_f1_m: 0.4685\n","Epoch 2/50\n","131/131 [==============================] - 4s 27ms/step - loss: 0.5956 - accuracy: 0.2137 - precision_m: 0.5145 - recall_m: 0.1775 - f1_m: 0.2594 - val_loss: 0.5224 - val_accuracy: 0.3279 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00 - val_f1_m: 0.0000e+00\n","Epoch 3/50\n","131/131 [==============================] - 4s 27ms/step - loss: 0.5962 - accuracy: 0.2140 - precision_m: 0.5216 - recall_m: 0.1697 - f1_m: 0.2523 - val_loss: 0.5197 - val_accuracy: 0.3279 - val_precision_m: 0.5827 - val_recall_m: 0.3938 - val_f1_m: 0.4685\n","Epoch 4/50\n","131/131 [==============================] - 4s 27ms/step - loss: 0.5943 - accuracy: 0.2136 - precision_m: 0.5305 - recall_m: 0.2226 - f1_m: 0.3104 - val_loss: 0.5208 - val_accuracy: 0.3279 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00 - val_f1_m: 0.0000e+00\n","Epoch 5/50\n","131/131 [==============================] - 4s 28ms/step - loss: 0.5934 - accuracy: 0.2023 - precision_m: 0.5224 - recall_m: 0.1673 - f1_m: 0.2505 - val_loss: 0.5146 - val_accuracy: 0.3279 - val_precision_m: 0.5827 - val_recall_m: 0.3938 - val_f1_m: 0.4685\n","Epoch 6/50\n","131/131 [==============================] - 4s 27ms/step - loss: 0.5928 - accuracy: 0.2055 - precision_m: 0.5131 - recall_m: 0.2163 - f1_m: 0.3014 - val_loss: 0.5246 - val_accuracy: 0.3279 - val_precision_m: 0.5827 - val_recall_m: 0.3938 - val_f1_m: 0.4685\n","Epoch 7/50\n","131/131 [==============================] - 4s 27ms/step - loss: 0.5960 - accuracy: 0.2006 - precision_m: 0.4999 - recall_m: 0.1715 - f1_m: 0.2528 - val_loss: 0.5063 - val_accuracy: 0.3279 - val_precision_m: 0.5827 - val_recall_m: 0.3938 - val_f1_m: 0.4685\n","Epoch 8/50\n","131/131 [==============================] - 4s 27ms/step - loss: 0.5926 - accuracy: 0.2149 - precision_m: 0.5193 - recall_m: 0.2262 - f1_m: 0.3126 - val_loss: 0.5241 - val_accuracy: 0.3279 - val_precision_m: 0.5827 - val_recall_m: 0.3938 - val_f1_m: 0.4685\n","Epoch 9/50\n","131/131 [==============================] - 4s 27ms/step - loss: 0.5949 - accuracy: 0.2015 - precision_m: 0.4981 - recall_m: 0.1799 - f1_m: 0.2619 - val_loss: 0.5170 - val_accuracy: 0.3279 - val_precision_m: 0.5827 - val_recall_m: 0.3938 - val_f1_m: 0.4685\n","Epoch 10/50\n","131/131 [==============================] - 4s 27ms/step - loss: 0.5904 - accuracy: 0.2137 - precision_m: 0.5172 - recall_m: 0.2389 - f1_m: 0.3241 - val_loss: 0.5158 - val_accuracy: 0.3279 - val_precision_m: 0.5827 - val_recall_m: 0.3938 - val_f1_m: 0.4685\n","Epoch 11/50\n","131/131 [==============================] - 4s 28ms/step - loss: 0.5999 - accuracy: 0.1928 - precision_m: 0.5157 - recall_m: 0.2045 - f1_m: 0.2915 - val_loss: 0.5144 - val_accuracy: 0.3279 - val_precision_m: 0.5827 - val_recall_m: 0.3938 - val_f1_m: 0.4685\n","Epoch 00011: early stopping\n","Score for fold 2: loss of 0.5647878050804138; accuracy of 25.076335668563843% ;precision_m of 0.5106163024902344 ;recall_m of 0.3112577795982361 ;            f1_m of 0.3850182890892029\n","Epoch 1/50\n","131/131 [==============================] - 7s 34ms/step - loss: 0.6291 - accuracy: 0.1947 - precision_m: 0.4735 - recall_m: 0.1748 - f1_m: 0.2472 - val_loss: 0.5727 - val_accuracy: 0.2822 - val_precision_m: 0.5127 - val_recall_m: 0.3279 - val_f1_m: 0.3987\n","Epoch 2/50\n","131/131 [==============================] - 4s 30ms/step - loss: 0.6120 - accuracy: 0.1828 - precision_m: 0.4913 - recall_m: 0.1446 - f1_m: 0.2193 - val_loss: 0.5647 - val_accuracy: 0.2822 - val_precision_m: 0.5127 - val_recall_m: 0.3279 - val_f1_m: 0.3987\n","Epoch 3/50\n","131/131 [==============================] - 4s 28ms/step - loss: 0.6090 - accuracy: 0.1880 - precision_m: 0.5109 - recall_m: 0.1617 - f1_m: 0.2412 - val_loss: 0.5629 - val_accuracy: 0.2822 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00 - val_f1_m: 0.0000e+00\n","Epoch 4/50\n","131/131 [==============================] - 4s 28ms/step - loss: 0.6100 - accuracy: 0.1805 - precision_m: 0.5202 - recall_m: 0.1242 - f1_m: 0.1913 - val_loss: 0.5599 - val_accuracy: 0.2822 - val_precision_m: 0.5127 - val_recall_m: 0.3279 - val_f1_m: 0.3987\n","Epoch 5/50\n","131/131 [==============================] - 4s 28ms/step - loss: 0.6061 - accuracy: 0.1884 - precision_m: 0.5168 - recall_m: 0.1749 - f1_m: 0.2598 - val_loss: 0.5651 - val_accuracy: 0.2822 - val_precision_m: 0.5127 - val_recall_m: 0.3279 - val_f1_m: 0.3987\n","Epoch 6/50\n","131/131 [==============================] - 4s 28ms/step - loss: 0.6083 - accuracy: 0.1825 - precision_m: 0.4992 - recall_m: 0.1425 - f1_m: 0.2159 - val_loss: 0.5573 - val_accuracy: 0.2822 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00 - val_f1_m: 0.0000e+00\n","Epoch 7/50\n","131/131 [==============================] - 4s 28ms/step - loss: 0.6059 - accuracy: 0.1801 - precision_m: 0.4823 - recall_m: 0.1167 - f1_m: 0.1758 - val_loss: 0.5617 - val_accuracy: 0.2822 - val_precision_m: 0.5127 - val_recall_m: 0.3279 - val_f1_m: 0.3987\n","Epoch 8/50\n","131/131 [==============================] - 4s 28ms/step - loss: 0.6073 - accuracy: 0.1782 - precision_m: 0.5088 - recall_m: 0.1909 - f1_m: 0.2740 - val_loss: 0.5572 - val_accuracy: 0.2822 - val_precision_m: 0.5127 - val_recall_m: 0.3279 - val_f1_m: 0.3987\n","Epoch 9/50\n","131/131 [==============================] - 4s 28ms/step - loss: 0.6067 - accuracy: 0.1804 - precision_m: 0.5050 - recall_m: 0.1960 - f1_m: 0.2789 - val_loss: 0.5563 - val_accuracy: 0.2822 - val_precision_m: 0.5127 - val_recall_m: 0.3279 - val_f1_m: 0.3987\n","Epoch 10/50\n","131/131 [==============================] - 4s 28ms/step - loss: 0.6077 - accuracy: 0.1839 - precision_m: 0.5108 - recall_m: 0.1958 - f1_m: 0.2817 - val_loss: 0.5611 - val_accuracy: 0.2822 - val_precision_m: 0.5127 - val_recall_m: 0.3279 - val_f1_m: 0.3987\n","Epoch 11/50\n","131/131 [==============================] - 4s 28ms/step - loss: 0.6049 - accuracy: 0.1905 - precision_m: 0.5380 - recall_m: 0.2130 - f1_m: 0.2996 - val_loss: 0.5555 - val_accuracy: 0.2822 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00 - val_f1_m: 0.0000e+00\n","Epoch 00011: early stopping\n","Score for fold 3: loss of 0.532717227935791; accuracy of 31.068703532218933% ;precision_m of 0.0 ;recall_m of 0.0 ;            f1_m of 0.0\n","------------------------------------------------------------------------\n","Score per fold\n","------------------------------------------------------------------------\n","> Fold 1 - Loss: 0.6444118618965149 - Accuracy: 15.566577017307281% - Precision: 0.2593536674976349 - Recall: 0.34322670102119446 - F1: 0.5127865076065063\n","------------------------------------------------------------------------\n","> Fold 2 - Loss: 0.5647878050804138 - Accuracy: 25.076335668563843% - Precision: 0.3112577795982361 - Recall: 0.3850182890892029 - F1: 0.5106163024902344\n","------------------------------------------------------------------------\n","> Fold 3 - Loss: 0.532717227935791 - Accuracy: 31.068703532218933% - Precision: 0.0 - Recall: 0.0 - F1: 0.0\n","------------------------------------------------------------------------\n","Average scores for all folds:\n","> Accuracy: 23.903872072696686 (+- 6.382788564246144)\n","> Precision: 0.19020381569862366\n","> Recall: 0.2427483300367991\n","> F1: 0.3411342700322469\n","> Loss: 0.5806389649709066\n","------------------------------------------------------------------------\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"oZDy_GVTJE9R"},"source":["# RNN model with train/test/val method \r\n","One RNN layer "]},{"cell_type":"code","metadata":{"id":"ZF_T8qY7JCjb"},"source":["N_FOLDS=3 \r\n","EPOCHS=1\r\n","VALIDATION_SPLIT=0.2\r\n","BATCH_SIZE=32\r\n","PATIENCE=2\r\n","MONITOR='val_f1_m'\r\n","MONITOR_MODE='max'\r\n","SHUFFLE=True\r\n","RNN=GRU\r\n","L2_REG=0.1\r\n","DROPOUT_VALUE_1=0.5\r\n","DROPOUT_VALUE_2=0.5\r\n","NB_FILTERS=200\r\n","HIDDEN_DIMS=NB_FILTERS*2\r\n","VERBOSITY=1\r\n","EMBEDDING_SIZE=300\r\n","\r\n","def create_model():\r\n","    model = Sequential()\r\n","    embedding_layer = Embedding(vocab_length,EMBEDDING_SIZE,weights=[embedding_matrix], input_length=length_long_sentence, trainable=False)\r\n","    model.add(embedding_layer)\r\n","    model.add(Dropout(DROPOUT_VALUE_1))\r\n","    model.add(RNN(HIDDEN_DIMS))\r\n","    model.add(Dense(HIDDEN_DIMS, activation='relu'))\r\n","    model.add(Dropout(DROPOUT_VALUE_2))\r\n","    model.add(Dense(3,activation='softmax'))\r\n","    model.compile(loss='categorical_crossentropy', optimizer='adam',metrics=[\"accuracy\",precision_m,recall_m,f1_m])\r\n","    return model \r\n","\r\n","# Define per-fold score containers <-- these are new\r\n","acc_per_fold = []\r\n","loss_per_fold = []\r\n","f1_per_fold = []\r\n","precision_per_fold =[]\r\n","recall_per_fold=[]\r\n","\r\n","#Define dependencied for model loading\r\n","dependencies = {\r\n","    'recall_m': recall_m,\r\n","    'f1_m':f1_m,\r\n","    'precision_m':precision_m    \r\n","}\r\n","\r\n","x, y, x_train,x_test,y_train,y_test,y_train_c,y_test_c = splitdata(padded_sentences,y,0.2,False)\r\n","model=create_model()\r\n","es = EarlyStopping(monitor=MONITOR, mode=MONITOR_MODE, verbose=1,patience= PATIENCE )\r\n","mc = ModelCheckpoint(BEST_MODEL, monitor=MONITOR, mode=MONITOR_MODE, verbose=1, save_best_only=True)\r\n","history = model.fit(x_train, y_train_c,validation_split=VALIDATION_SPLIT,callbacks=[es,mc],epochs=EPOCHS,batch_size=BATCH_SIZE,shuffle=SHUFFLE)\r\n","model = load_model(mainloc+'best_model.h5',custom_objects=dependencies)\r\n","\r\n","accuracy_scores_neural(model,x_train,y_train,y_train_c,x_test,y_test,y_test_c,['Neutral', 'Negative', 'Positive'])\r\n","accuracy_curve(history,'loss','loss')\r\n","accuracy_curve(history,'accuracy','accuracy')\r\n","accuracy_curve(history,'f1_m','F1')\r\n","accuracy_curve(history,'precision_m','Precision')\r\n","accuracy_curve(history,'recall_m','Recall')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"o0JxA3a9mTY_"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"SfgaVKarmUJL"},"source":["# Bi-LSTM model with cross validation "]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Oc0KZfqZmR6O","executionInfo":{"status":"ok","timestamp":1614183636064,"user_tz":-330,"elapsed":695992,"user":{"displayName":"Shanaka Chathuranga","photoUrl":"","userId":"01381725564551416324"}},"outputId":"82a486fb-7765-425d-98dd-6e60cfd2f7b1"},"source":["N_FOLDS=3\r\n","EPOCHS=10\r\n","VALIDATION_SPLIT=0.2\r\n","BATCH_SIZE=32\r\n","PATIENCE=20\r\n","MONITOR='val_accuracy'\r\n","MONITOR_MODE='max'\r\n","SHUFFLE=True\r\n","RNN=LSTM\r\n","L2_REG=0.1\r\n","DROPOUT_VALUE_1=0.7\r\n","DROPOUT_VALUE_2=0.7\r\n","NB_FILTERS=128\r\n","KERNEL_SIZE=5\r\n","HIDDEN_DIMS=NB_FILTERS*2\r\n","VERBOSITY=1\r\n","EMBEDDING_SIZE=300\r\n","\r\n","from keras.layers import Bidirectional\r\n","\r\n","def create_model():\r\n","  model = Sequential()\r\n","  embedding_layer = Embedding(vocab_length,EMBEDDING_SIZE,weights=[embedding_matrix], input_length=length_long_sentence, trainable=False)\r\n","  model.add(embedding_layer)\r\n","  model.add(Dropout(DROPOUT_VALUE_1))\r\n","  model.add(Bidirectional(LSTM(HIDDEN_DIMS,return_sequences=True)))\r\n","  model.add(Bidirectional(LSTM(HIDDEN_DIMS,return_sequences=True)))\r\n","  model.add(Bidirectional(LSTM(HIDDEN_DIMS)))\r\n","  #model.add(RNN(HIDDEN_DIMS))\r\n","  model.add(Dense(HIDDEN_DIMS, activation='relu'))\r\n","  model.add(Dropout(DROPOUT_VALUE_2))\r\n","  model.add(Dense(NUM_CLASSES,activation='sigmoid'))\r\n","  model.compile(loss='binary_crossentropy', optimizer='adam',metrics=[\"accuracy\",precision_m,recall_m,f1_m])\r\n","  return model \r\n","\r\n","# Define per-fold score containers \r\n","acc_per_fold = []\r\n","loss_per_fold = []\r\n","f1_per_fold = []\r\n","precision_per_fold =[]\r\n","recall_per_fold=[]\r\n","\r\n","#Define dependencied for model loading\r\n","dependencies = {\r\n","    'recall_m': recall_m,\r\n","    'f1_m':f1_m,\r\n","    'precision_m':precision_m    \r\n","}\r\n","\r\n","vocab_length,padded_sentences,length_long_sentence,embedding_matrix=loadembedding_matrix(x,mainloc+'word_embeddings/w2v_cbow_300.txt',300)\r\n","\r\n","# stratified K-fold Cross Validation model evaluation\r\n","#skf = StratifiedKFold(n_splits=N_FOLDS,random_state=None, shuffle=shuffle)\r\n","kf = KFold(n_splits=N_FOLDS)\r\n","fold_no = 1\r\n","for train_index, test_index in kf.split(padded_sentences, y):\r\n","    model=create_model()\r\n","    es = EarlyStopping(monitor=MONITOR, mode=MONITOR_MODE, verbose=1,patience= PATIENCE )\r\n","    history = model.fit(padded_sentences[train_index],y.values[train_index],epochs=EPOCHS,callbacks=[es],batch_size=BATCH_SIZE,shuffle=True,validation_split=VALIDATION_SPLIT)\r\n","    \r\n","    # Generate generalization metrics\r\n","    scores = model.evaluate(padded_sentences[test_index], y.values[test_index], verbose=0)\r\n","    print(f'Score for fold {fold_no}: {model.metrics_names[0]} of {scores[0]}; {model.metrics_names[1]} of {scores[1]*100}% ;{model.metrics_names[2]} of {scores[2]} ;{model.metrics_names[3]} of {scores[3]} ; \\\r\n","           {model.metrics_names[4]} of {scores[4]}')\r\n","    loss_per_fold.append(scores[0])\r\n","    acc_per_fold.append(scores[1] * 100)\r\n","    f1_per_fold.append(scores[4])\r\n","    precision_per_fold.append(scores[2])\r\n","    recall_per_fold.append(scores[3])\r\n","\r\n","    # Increase fold number\r\n","    fold_no = fold_no + 1\r\n","    \r\n","accuracy_crossval(acc_per_fold,loss_per_fold,f1_per_fold,precision_per_fold,recall_per_fold)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Epoch 1/10\n","131/131 [==============================] - 29s 177ms/step - loss: 0.5342 - accuracy: 0.3333 - precision_m: 0.5534 - recall_m: 0.3360 - f1_m: 0.4035 - val_loss: 0.3642 - val_accuracy: 0.4933 - val_precision_m: 0.7519 - val_recall_m: 0.5504 - val_f1_m: 0.6338\n","Epoch 2/10\n","131/131 [==============================] - 22s 165ms/step - loss: 0.4304 - accuracy: 0.4824 - precision_m: 0.6940 - recall_m: 0.5347 - f1_m: 0.6015 - val_loss: 0.3259 - val_accuracy: 0.5725 - val_precision_m: 0.7539 - val_recall_m: 0.6557 - val_f1_m: 0.7007\n","Epoch 3/10\n","131/131 [==============================] - 21s 163ms/step - loss: 0.3904 - accuracy: 0.5270 - precision_m: 0.7276 - recall_m: 0.6068 - f1_m: 0.6600 - val_loss: 0.2949 - val_accuracy: 0.6164 - val_precision_m: 0.8075 - val_recall_m: 0.6584 - val_f1_m: 0.7241\n","Epoch 4/10\n","131/131 [==============================] - 21s 162ms/step - loss: 0.3647 - accuracy: 0.5519 - precision_m: 0.7592 - recall_m: 0.6352 - f1_m: 0.6899 - val_loss: 0.2740 - val_accuracy: 0.6240 - val_precision_m: 0.8164 - val_recall_m: 0.7028 - val_f1_m: 0.7540\n","Epoch 5/10\n","131/131 [==============================] - 21s 163ms/step - loss: 0.3489 - accuracy: 0.5814 - precision_m: 0.7631 - recall_m: 0.6699 - f1_m: 0.7117 - val_loss: 0.2613 - val_accuracy: 0.6756 - val_precision_m: 0.8096 - val_recall_m: 0.7687 - val_f1_m: 0.7872\n","Epoch 6/10\n","131/131 [==============================] - 21s 163ms/step - loss: 0.3241 - accuracy: 0.5931 - precision_m: 0.7746 - recall_m: 0.7039 - f1_m: 0.7363 - val_loss: 0.2526 - val_accuracy: 0.6679 - val_precision_m: 0.8290 - val_recall_m: 0.7539 - val_f1_m: 0.7888\n","Epoch 7/10\n","131/131 [==============================] - 21s 164ms/step - loss: 0.3124 - accuracy: 0.6353 - precision_m: 0.7777 - recall_m: 0.7108 - f1_m: 0.7415 - val_loss: 0.2518 - val_accuracy: 0.6823 - val_precision_m: 0.8287 - val_recall_m: 0.7622 - val_f1_m: 0.7926\n","Epoch 8/10\n","131/131 [==============================] - 21s 163ms/step - loss: 0.3077 - accuracy: 0.6150 - precision_m: 0.7997 - recall_m: 0.7203 - f1_m: 0.7564 - val_loss: 0.2515 - val_accuracy: 0.6823 - val_precision_m: 0.8166 - val_recall_m: 0.7926 - val_f1_m: 0.8035\n","Epoch 9/10\n","131/131 [==============================] - 21s 163ms/step - loss: 0.2994 - accuracy: 0.6261 - precision_m: 0.7988 - recall_m: 0.7292 - f1_m: 0.7609 - val_loss: 0.2443 - val_accuracy: 0.6880 - val_precision_m: 0.8267 - val_recall_m: 0.7742 - val_f1_m: 0.7986\n","Epoch 10/10\n","131/131 [==============================] - 21s 162ms/step - loss: 0.2900 - accuracy: 0.6223 - precision_m: 0.8023 - recall_m: 0.7435 - f1_m: 0.7705 - val_loss: 0.2337 - val_accuracy: 0.6889 - val_precision_m: 0.8439 - val_recall_m: 0.7793 - val_f1_m: 0.8093\n","Score for fold 1: loss of 0.356376051902771; accuracy of 53.18580865859985% ;precision_m of 0.8438124060630798 ;recall_m of 0.6893050670623779 ;            f1_m of 0.7562295794487\n","Epoch 1/10\n","131/131 [==============================] - 30s 179ms/step - loss: 0.5920 - accuracy: 0.2868 - precision_m: 0.5065 - recall_m: 0.2851 - f1_m: 0.3517 - val_loss: 0.3938 - val_accuracy: 0.5024 - val_precision_m: 0.6875 - val_recall_m: 0.5898 - val_f1_m: 0.6333\n","Epoch 2/10\n","131/131 [==============================] - 22s 167ms/step - loss: 0.4667 - accuracy: 0.4744 - precision_m: 0.6807 - recall_m: 0.5466 - f1_m: 0.6038 - val_loss: 0.3240 - val_accuracy: 0.5663 - val_precision_m: 0.7332 - val_recall_m: 0.6596 - val_f1_m: 0.6932\n","Epoch 3/10\n","131/131 [==============================] - 22s 165ms/step - loss: 0.4343 - accuracy: 0.5269 - precision_m: 0.7002 - recall_m: 0.6135 - f1_m: 0.6520 - val_loss: 0.3279 - val_accuracy: 0.5882 - val_precision_m: 0.7457 - val_recall_m: 0.7002 - val_f1_m: 0.7210\n","Epoch 4/10\n","131/131 [==============================] - 22s 166ms/step - loss: 0.3990 - accuracy: 0.5495 - precision_m: 0.7327 - recall_m: 0.6552 - f1_m: 0.6903 - val_loss: 0.2888 - val_accuracy: 0.6520 - val_precision_m: 0.7837 - val_recall_m: 0.7199 - val_f1_m: 0.7482\n","Epoch 5/10\n","131/131 [==============================] - 22s 165ms/step - loss: 0.3749 - accuracy: 0.5732 - precision_m: 0.7607 - recall_m: 0.6771 - f1_m: 0.7151 - val_loss: 0.2692 - val_accuracy: 0.6578 - val_precision_m: 0.8262 - val_recall_m: 0.7168 - val_f1_m: 0.7660\n","Epoch 6/10\n","131/131 [==============================] - 22s 166ms/step - loss: 0.3579 - accuracy: 0.5890 - precision_m: 0.7750 - recall_m: 0.6940 - f1_m: 0.7309 - val_loss: 0.2596 - val_accuracy: 0.6606 - val_precision_m: 0.8178 - val_recall_m: 0.7622 - val_f1_m: 0.7877\n","Epoch 7/10\n","131/131 [==============================] - 22s 165ms/step - loss: 0.3449 - accuracy: 0.5712 - precision_m: 0.7811 - recall_m: 0.7271 - f1_m: 0.7517 - val_loss: 0.2555 - val_accuracy: 0.6540 - val_precision_m: 0.8245 - val_recall_m: 0.7544 - val_f1_m: 0.7863\n","Epoch 8/10\n","131/131 [==============================] - 22s 166ms/step - loss: 0.3282 - accuracy: 0.5773 - precision_m: 0.7980 - recall_m: 0.7443 - f1_m: 0.7689 - val_loss: 0.2487 - val_accuracy: 0.6883 - val_precision_m: 0.8370 - val_recall_m: 0.7439 - val_f1_m: 0.7861\n","Epoch 9/10\n","131/131 [==============================] - 22s 165ms/step - loss: 0.3192 - accuracy: 0.6032 - precision_m: 0.8052 - recall_m: 0.7426 - f1_m: 0.7715 - val_loss: 0.2378 - val_accuracy: 0.7007 - val_precision_m: 0.8221 - val_recall_m: 0.7796 - val_f1_m: 0.7992\n","Epoch 10/10\n","131/131 [==============================] - 22s 166ms/step - loss: 0.3109 - accuracy: 0.6088 - precision_m: 0.8047 - recall_m: 0.7683 - f1_m: 0.7851 - val_loss: 0.2354 - val_accuracy: 0.7045 - val_precision_m: 0.8245 - val_recall_m: 0.8019 - val_f1_m: 0.8119\n","Score for fold 2: loss of 0.2878342866897583; accuracy of 65.64885377883911% ;precision_m of 0.7872484922409058 ;recall_m of 0.7778849601745605 ;            f1_m of 0.7806970477104187\n","Epoch 1/10\n","131/131 [==============================] - 29s 177ms/step - loss: 0.6177 - accuracy: 0.2466 - precision_m: 0.4665 - recall_m: 0.2373 - f1_m: 0.2987 - val_loss: 0.4086 - val_accuracy: 0.5243 - val_precision_m: 0.7034 - val_recall_m: 0.6340 - val_f1_m: 0.6655\n","Epoch 2/10\n","131/131 [==============================] - 22s 166ms/step - loss: 0.4928 - accuracy: 0.4665 - precision_m: 0.6734 - recall_m: 0.5180 - f1_m: 0.5838 - val_loss: 0.3813 - val_accuracy: 0.5653 - val_precision_m: 0.7324 - val_recall_m: 0.5764 - val_f1_m: 0.6436\n","Epoch 3/10\n","131/131 [==============================] - 22s 164ms/step - loss: 0.4665 - accuracy: 0.4996 - precision_m: 0.6975 - recall_m: 0.5559 - f1_m: 0.6161 - val_loss: 0.3482 - val_accuracy: 0.5577 - val_precision_m: 0.7809 - val_recall_m: 0.6209 - val_f1_m: 0.6899\n","Epoch 4/10\n","131/131 [==============================] - 22s 165ms/step - loss: 0.4295 - accuracy: 0.5123 - precision_m: 0.7323 - recall_m: 0.6106 - f1_m: 0.6637 - val_loss: 0.3384 - val_accuracy: 0.5834 - val_precision_m: 0.7781 - val_recall_m: 0.6607 - val_f1_m: 0.7130\n","Epoch 5/10\n","131/131 [==============================] - 21s 164ms/step - loss: 0.4092 - accuracy: 0.5340 - precision_m: 0.7466 - recall_m: 0.6371 - f1_m: 0.6855 - val_loss: 0.3236 - val_accuracy: 0.6663 - val_precision_m: 0.7617 - val_recall_m: 0.7268 - val_f1_m: 0.7414\n","Epoch 6/10\n","131/131 [==============================] - 22s 166ms/step - loss: 0.3770 - accuracy: 0.5450 - precision_m: 0.7808 - recall_m: 0.6956 - f1_m: 0.7338 - val_loss: 0.2987 - val_accuracy: 0.6406 - val_precision_m: 0.8157 - val_recall_m: 0.6912 - val_f1_m: 0.7459\n","Epoch 7/10\n","131/131 [==============================] - 22s 165ms/step - loss: 0.3622 - accuracy: 0.5618 - precision_m: 0.7812 - recall_m: 0.7010 - f1_m: 0.7374 - val_loss: 0.2943 - val_accuracy: 0.6397 - val_precision_m: 0.8006 - val_recall_m: 0.7229 - val_f1_m: 0.7567\n","Epoch 8/10\n","131/131 [==============================] - 22s 165ms/step - loss: 0.3467 - accuracy: 0.5830 - precision_m: 0.7857 - recall_m: 0.7412 - f1_m: 0.7617 - val_loss: 0.2977 - val_accuracy: 0.6530 - val_precision_m: 0.8294 - val_recall_m: 0.7131 - val_f1_m: 0.7645\n","Epoch 9/10\n","131/131 [==============================] - 22s 164ms/step - loss: 0.3370 - accuracy: 0.5804 - precision_m: 0.8055 - recall_m: 0.7379 - f1_m: 0.7686 - val_loss: 0.2887 - val_accuracy: 0.6578 - val_precision_m: 0.8046 - val_recall_m: 0.7402 - val_f1_m: 0.7688\n","Epoch 10/10\n","131/131 [==============================] - 22s 165ms/step - loss: 0.3354 - accuracy: 0.5825 - precision_m: 0.8038 - recall_m: 0.7362 - f1_m: 0.7670 - val_loss: 0.2720 - val_accuracy: 0.6826 - val_precision_m: 0.8231 - val_recall_m: 0.7563 - val_f1_m: 0.7862\n","Score for fold 3: loss of 0.26080647110939026; accuracy of 67.36640930175781% ;precision_m of 0.8245793581008911 ;recall_m of 0.7430033087730408 ;            f1_m of 0.7802456617355347\n","------------------------------------------------------------------------\n","Score per fold\n","------------------------------------------------------------------------\n","> Fold 1 - Loss: 0.356376051902771 - Accuracy: 53.18580865859985% - Precision: 0.8438124060630798 - Recall: 0.6893050670623779 - F1: 0.7562295794487\n","------------------------------------------------------------------------\n","> Fold 2 - Loss: 0.2878342866897583 - Accuracy: 65.64885377883911% - Precision: 0.7872484922409058 - Recall: 0.7778849601745605 - F1: 0.7806970477104187\n","------------------------------------------------------------------------\n","> Fold 3 - Loss: 0.26080647110939026 - Accuracy: 67.36640930175781% - Precision: 0.8245793581008911 - Recall: 0.7430033087730408 - F1: 0.7802456617355347\n","------------------------------------------------------------------------\n","Average scores for all folds:\n","> Accuracy: 62.06702391306559 (+- 6.3189918784931365)\n","> Precision: 0.8185467521349589\n","> Recall: 0.7367311120033264\n","> F1: 0.7723907629648844\n","> Loss: 0.30167226990063983\n","------------------------------------------------------------------------\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["(62.06702391306559,\n"," 0.8185467521349589,\n"," 0.7367311120033264,\n"," 0.7723907629648844,\n"," 0.30167226990063983)"]},"metadata":{"tags":[]},"execution_count":24}]},{"cell_type":"markdown","metadata":{"id":"MPlDWbupM1l9"},"source":["# Compre deep learing models \r\n"]},{"cell_type":"code","metadata":{"id":"mwfwOR6TM5dC","executionInfo":{"status":"ok","timestamp":1615349252728,"user_tz":-330,"elapsed":857,"user":{"displayName":"Shanaka Chathuranga","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjyvtaGYdZLH66p14soI4ti6MLZ3PDDlHx64Gbx2A=s64","userId":"15044035539828571150"}}},"source":["\r\n","def getXY(df,x,y):\r\n","    x=df[x]\r\n","    y=df[y]\r\n","    return x,y\r\n","\r\n","def encodeY(y,classes):\r\n","    encoder = preprocessing.LabelEncoder()\r\n","    y_c = encoder.fit_transform(y)\r\n","    y_c = label_binarize(y_c, classes=classes)\r\n","    return y_c\r\n","\r\n","def emb_dictionary(filename):\r\n","    embedding_dictionary = dict()\r\n","    f = open(filename)\r\n","    for line in f:\r\n","        values = line.split()\r\n","        word = values[0]\r\n","        coefs = asarray(values[1:], dtype='float32')\r\n","        embedding_dictionary[word] = coefs\r\n","    f.close()\r\n","    return embedding_dictionary\r\n","\r\n","def emb_matrix(vocab_length,word_tokenizer,embeddings_dictionary,we_size):\r\n","    embedding_matrix = zeros((vocab_length, we_size))\r\n","    for word, index in word_tokenizer.word_index.items():\r\n","        embedding_vector = embeddings_dictionary.get(word)\r\n","        if embedding_vector is not None:\r\n","            embedding_matrix[index] = embedding_vector\r\n","    return  embedding_matrix\r\n","\r\n","def get_emb_sentences(X):\r\n","    word_tokenizer = Tokenizer()\r\n","    word_tokenizer.fit_on_texts(x)\r\n","    vocab_length = len(word_tokenizer.word_index) + 1\r\n","    embedded_sentences = word_tokenizer.texts_to_sequences(x)\r\n","    return word_tokenizer,embedded_sentences,vocab_length\r\n","\r\n","def get_padded_sequence(x,embedded_sentences):\r\n","    word_count = lambda sentence: len(word_tokenize(sentence))\r\n","    longest_sentence = max(x, key=word_count)\r\n","    length_long_sentence = len(word_tokenize(longest_sentence))\r\n","    padded_sentences = pad_sequences(embedded_sentences, length_long_sentence, padding='post')\r\n","    return length_long_sentence,padded_sentences \r\n","\r\n","def recall_m(y_true, y_pred):\r\n","    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\r\n","    possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\r\n","    recall = true_positives / (possible_positives + K.epsilon())\r\n","    return recall\r\n","\r\n","def precision_m(y_true, y_pred):\r\n","    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\r\n","    predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\r\n","    precision = true_positives / (predicted_positives + K.epsilon())\r\n","    return precision\r\n","\r\n","def f1_m(y_true, y_pred):\r\n","    precision = precision_m(y_true, y_pred)\r\n","    recall = recall_m(y_true, y_pred)\r\n","    return 2*((precision*recall)/(precision+recall+K.epsilon()))\r\n","\r\n","\r\n","def train_model(model,x_train, y_train, cross_validation = False):\r\n","    print('Model Trainin and testing')\r\n","    es = EarlyStopping(monitor='val_f1_m', mode='max', verbose=1, patience=patience)\r\n","    mc = ModelCheckpoint(model_save_path, monitor='val_f1_m', verbose=1, save_best_only=True, mode='max')\r\n","    callbacks_list = [es,mc]\r\n","    if(cross_validation):\r\n","        callbacks_list=[es]\r\n","    history = model.fit(x_train, y_train, validation_split=validation_split, epochs=epochs, batch_size=batch_size, \r\n","                    callbacks=callbacks_list, verbose=1)\r\n","    return model,history "],"execution_count":22,"outputs":[]},{"cell_type":"code","metadata":{"id":"rHNr3HM2M98a","executionInfo":{"status":"ok","timestamp":1615349263987,"user_tz":-330,"elapsed":1604,"user":{"displayName":"Shanaka Chathuranga","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjyvtaGYdZLH66p14soI4ti6MLZ3PDDlHx64Gbx2A=s64","userId":"15044035539828571150"}}},"source":["def loadembedding_matrix(x,loc,emb_size):\r\n","  word_tokenizer,embedded_sentences,vocab_length=get_emb_sentences(x)\r\n","  length_long_sentence,padded_sentences = get_padded_sequence(x,embedded_sentences)\r\n","  embeddings_dictionary=emb_dictionary(loc)\r\n","  embedding_matrix=emb_matrix(vocab_length,word_tokenizer,embeddings_dictionary,emb_size)\r\n","  return vocab_length,padded_sentences,length_long_sentence,embedding_matrix\r\n","\r\n","def cnn_model():\r\n","    model = Sequential()\r\n","    embedding_layer = Embedding(vocab_length,EMBEDDING_SIZE,weights=[embedding_matrix],input_length=length_long_sentence, trainable=False)\r\n","    model.add(embedding_layer)\r\n","    model.add(Conv1D(256,3, activation='relu'))\r\n","    model.add(GlobalMaxPooling1D())\r\n","    model.add(Dropout(DROPOUT_VALUE_2))\r\n","    model.add(Flatten())\r\n","    model.add(Dense(NUM_CLASSES, activation='sigmoid'))\r\n","    model.compile(loss='binary_crossentropy', optimizer='adam',metrics=[\"accuracy\",precision_m,recall_m,f1_m])\r\n","    return model \r\n","\r\n","#GRU/LSTM/\r\n","def rnn_model():\r\n","    model = Sequential()\r\n","    embedding_layer = Embedding(vocab_length,EMBEDDING_SIZE,weights=[embedding_matrix], input_length=length_long_sentence, trainable=False)\r\n","    model.add(embedding_layer)\r\n","    model.add(Dropout(DROPOUT_VALUE_1))\r\n","    model.add(RNN(HIDDEN_DIMS))\r\n","    model.add(Dense(HIDDEN_DIMS, activation='relu'))\r\n","    model.add(Dropout(DROPOUT_VALUE_2))\r\n","    model.add(Dense(NUM_CLASSES, activation='sigmoid'))\r\n","    model.compile(loss='binary_crossentropy', optimizer='adam',metrics=[\"accuracy\",precision_m,recall_m,f1_m])\r\n","    return model \r\n","\r\n","def simplernn_model():\r\n","    model = Sequential()\r\n","    embedding_layer = Embedding(vocab_length,EMBEDDING_SIZE,weights=[embedding_matrix], input_length=length_long_sentence, trainable=False)\r\n","    model.add(embedding_layer)\r\n","    model.add(Dropout(DROPOUT_VALUE_1))\r\n","    model.add(SimpleRNN(HIDDEN_DIMS))\r\n","    model.add(Dense(HIDDEN_DIMS, activation='relu'))\r\n","    model.add(Dropout(DROPOUT_VALUE_2))\r\n","    model.add(Dense(NUM_CLASSES, activation='sigmoid'))\r\n","    model.compile(loss='binary_crossentropy', optimizer='adam',metrics=[\"accuracy\",precision_m,recall_m,f1_m])\r\n","    return model \r\n","\r\n","\r\n","def stack_lstm2():\r\n","    model = Sequential()\r\n","    embedding_layer = Embedding(vocab_length,EMBEDDING_SIZE,weights=[embedding_matrix], input_length=length_long_sentence, trainable=False)\r\n","    model.add(embedding_layer)\r\n","    model.add(Dropout(DROPOUT_VALUE_1))\r\n","    model.add(LSTM(HIDDEN_DIMS,return_sequences=True))\r\n","    model.add(LSTM(HIDDEN_DIMS))\r\n","    model.add(Dense(HIDDEN_DIMS, activation='relu'))\r\n","    model.add(Dropout(DROPOUT_VALUE_2))\r\n","    model.add(Dense(NUM_CLASSES, activation='sigmoid'))\r\n","    model.compile(loss='binary_crossentropy', optimizer='adam',metrics=[\"accuracy\",precision_m,recall_m,f1_m])\r\n","    return model \r\n","\r\n","def stack_lstm3():\r\n","    model = Sequential()\r\n","    embedding_layer = Embedding(vocab_length,EMBEDDING_SIZE,weights=[embedding_matrix], input_length=length_long_sentence, trainable=False)\r\n","    model.add(embedding_layer)\r\n","    model.add(Dropout(DROPOUT_VALUE_1))\r\n","    model.add(LSTM(HIDDEN_DIMS,return_sequences=True))\r\n","    model.add(LSTM(HIDDEN_DIMS,return_sequences=True))\r\n","    model.add(LSTM(HIDDEN_DIMS))\r\n","    model.add(Dense(HIDDEN_DIMS, activation='relu'))\r\n","    model.add(Dropout(DROPOUT_VALUE_2))\r\n","    model.add(Dense(NUM_CLASSES, activation='sigmoid'))\r\n","    model.compile(loss='binary_crossentropy', optimizer='adam',metrics=[\"accuracy\",precision_m,recall_m,f1_m])\r\n","    return model\r\n","\r\n","def bilstm():\r\n","    model = Sequential()\r\n","    embedding_layer = Embedding(vocab_length,EMBEDDING_SIZE,weights=[embedding_matrix], input_length=length_long_sentence, trainable=False)\r\n","    model.add(embedding_layer)\r\n","    model.add(Dropout(DROPOUT_VALUE_1))\r\n","    model.add(Bidirectional(LSTM(HIDDEN_DIMS)))\r\n","    model.add(Dense(HIDDEN_DIMS, activation='relu'))\r\n","    model.add(Dropout(DROPOUT_VALUE_2))\r\n","    model.add(Dense(NUM_CLASSES, activation='sigmoid'))\r\n","    model.compile(loss='binary_crossentropy', optimizer='adam',metrics=[\"accuracy\",precision_m,recall_m,f1_m])\r\n","    return model\r\n","\r\n","def stacked_bilstm2():\r\n","    model = Sequential()\r\n","    embedding_layer = Embedding(vocab_length,EMBEDDING_SIZE,weights=[embedding_matrix], input_length=length_long_sentence, trainable=False)\r\n","    model.add(embedding_layer)\r\n","    model.add(Dropout(DROPOUT_VALUE_1))\r\n","    model.add(Bidirectional(LSTM(HIDDEN_DIMS,return_sequences=True)))\r\n","    model.add(Bidirectional(LSTM(HIDDEN_DIMS)))\r\n","    model.add(Dense(HIDDEN_DIMS, activation='relu'))\r\n","    model.add(Dropout(DROPOUT_VALUE_2))\r\n","    model.add(Dense(NUM_CLASSES, activation='sigmoid'))\r\n","    model.compile(loss='binary_crossentropy', optimizer='adam',metrics=[\"accuracy\",precision_m,recall_m,f1_m])\r\n","    return model\r\n","\r\n","def stacked_bilstm3():\r\n","    model = Sequential()\r\n","    embedding_layer = Embedding(vocab_length,EMBEDDING_SIZE,weights=[embedding_matrix], input_length=length_long_sentence, trainable=False)\r\n","    model.add(embedding_layer)\r\n","    model.add(Dropout(DROPOUT_VALUE_1))\r\n","    model.add(Bidirectional(LSTM(HIDDEN_DIMS,return_sequences=True)))\r\n","    model.add(Bidirectional(LSTM(HIDDEN_DIMS,return_sequences=True)))\r\n","    model.add(Bidirectional(LSTM(HIDDEN_DIMS)))\r\n","    model.add(Dense(HIDDEN_DIMS, activation='relu'))\r\n","    model.add(Dropout(DROPOUT_VALUE_2))\r\n","    model.add(Dense(NUM_CLASSES, activation='sigmoid'))\r\n","    model.compile(loss='binary_crossentropy', optimizer='adam',metrics=[\"accuracy\",precision_m,recall_m,f1_m])\r\n","    return model\r\n","\r\n","def cnn_rnn_model():\r\n","  model = Sequential()\r\n","  embedding_layer = Embedding(vocab_length,EMBEDDING_SIZE,weights=[embedding_matrix], input_length=length_long_sentence, trainable=False)\r\n","  model.add(embedding_layer)\r\n","  model.add(Conv1D(filters=NB_FILTERS,kernel_size=KERNEL_SIZE, padding='same', activation='relu'))\r\n","  model.add(MaxPooling1D(pool_size=2))\r\n","  model.add(Dropout(DROPOUT_VALUE_2))\r\n","  model.add(RNN(HIDDEN_DIMS,return_sequences=True))\r\n","  model.add(RNN(HIDDEN_DIMS))\r\n","  model.add(Dropout(DROPOUT_VALUE_2))\r\n","  model.add(Dense(NUM_CLASSES, activation='sigmoid'))\r\n","  model.compile(loss='binary_crossentropy', optimizer='adam',metrics=[\"accuracy\",precision_m,recall_m,f1_m])\r\n","  return model \r\n","\r\n","def cnn_bilstm_model():\r\n","  model = Sequential()\r\n","  embedding_layer = Embedding(vocab_length,EMBEDDING_SIZE,weights=[embedding_matrix], input_length=length_long_sentence, trainable=False)\r\n","  model.add(embedding_layer)\r\n","  model.add(Conv1D(filters=NB_FILTERS,kernel_size=KERNEL_SIZE, padding='same', activation='relu'))\r\n","  model.add(MaxPooling1D(pool_size=2))\r\n","  model.add(Dropout(DROPOUT_VALUE_2))\r\n","  model.add(Bidirectional(LSTM(HIDDEN_DIMS)))\r\n","  model.add(Dropout(DROPOUT_VALUE_2))\r\n","  model.add(Dense(NUM_CLASSES, activation='sigmoid'))\r\n","  model.compile(loss='binary_crossentropy', optimizer='adam',metrics=[\"accuracy\",precision_m,recall_m,f1_m])\r\n","  return model \r\n","\r\n","\r\n","def cnn_stackedbilstm2_model():\r\n","  model = Sequential()\r\n","  embedding_layer = Embedding(vocab_length,EMBEDDING_SIZE,weights=[embedding_matrix], input_length=length_long_sentence, trainable=False)\r\n","  model.add(embedding_layer)\r\n","  model.add(Conv1D(filters=NB_FILTERS,kernel_size=KERNEL_SIZE, padding='same', activation='relu'))\r\n","  model.add(MaxPooling1D(pool_size=2))\r\n","  model.add(Dropout(DROPOUT_VALUE_2))\r\n","  model.add(Bidirectional(LSTM(HIDDEN_DIMS,return_sequences=True)))\r\n","  model.add(Bidirectional(LSTM(HIDDEN_DIMS)))\r\n","  model.add(Dropout(DROPOUT_VALUE_2))\r\n","  model.add(Dense(NUM_CLASSES, activation='sigmoid'))\r\n","  model.compile(loss='binary_crossentropy', optimizer='adam',metrics=[\"accuracy\",precision_m,recall_m,f1_m])\r\n","  return model \r\n","\r\n","def cnn_stackedbilstm3_model():\r\n","  model = Sequential()\r\n","  embedding_layer = Embedding(vocab_length,EMBEDDING_SIZE,weights=[embedding_matrix], input_length=length_long_sentence, trainable=False)\r\n","  model.add(embedding_layer)\r\n","  model.add(Conv1D(filters=NB_FILTERS,kernel_size=KERNEL_SIZE, padding='same', activation='relu'))\r\n","  model.add(MaxPooling1D(pool_size=2))\r\n","  model.add(Dropout(DROPOUT_VALUE_2))\r\n","  model.add(Bidirectional(LSTM(HIDDEN_DIMS,return_sequences=True)))\r\n","  model.add(Bidirectional(LSTM(HIDDEN_DIMS,return_sequences=True)))\r\n","  model.add(Bidirectional(LSTM(HIDDEN_DIMS)))\r\n","  model.add(Dropout(DROPOUT_VALUE_2))\r\n","  model.add(Dense(NUM_CLASSES, activation='sigmoid'))\r\n","  model.compile(loss='binary_crossentropy', optimizer='adam',metrics=[\"accuracy\",precision_m,recall_m,f1_m])\r\n","  return model \r\n","\r\n","def crossval(model_name):\r\n","\r\n","  # Define per-fold score containers <-- these are new\r\n","  acc_per_fold = []\r\n","  loss_per_fold = []\r\n","  f1_per_fold = []\r\n","  precision_per_fold =[]\r\n","  recall_per_fold=[]\r\n","\r\n","  kf = KFold(n_splits=N_FOLDS)  \r\n","  fold_no = 1\r\n","  for train_index, test_index in kf.split(padded_sentences,y):\r\n","    if model_name=='cnn':\r\n","      model=cnn_model()\r\n","    elif model_name=='rnn':\r\n","      model=rnn_model()\r\n","    elif model_name=='stacklstm2':\r\n","      model=stack_lstm2()\r\n","    elif model_name=='stacklstm3':\r\n","      model=stack_lstm3()\r\n","    elif model_name=='bilstm':\r\n","      model=bilstm()\r\n","    elif model_name=='stackbilstm2':\r\n","      model=stacked_bilstm2()\r\n","    elif model_name=='stackbilstm3':\r\n","      model=stacked_bilstm3()\r\n","    elif model_name=='cnnbilstm':\r\n","      model=cnn_bilstm_model()\r\n","    elif model_name=='cnnstackbilstm2':\r\n","      model=cnn_stackedbilstm2_model()\r\n","    elif model_name=='cnnstackbilstm3':\r\n","      model=cnn_stackedbilstm3_model()\r\n","    elif model_name=='simplernn':\r\n","      model=simplernn_model()\r\n","    else:\r\n","      model=cnn_rnn_model()\r\n","\r\n","    es = EarlyStopping(monitor=MONITOR, mode=MONITOR_MODE, verbose=1,patience= PATIENCE )\r\n","    history = model.fit(padded_sentences[train_index],y.values[train_index],epochs=EPOCHS,callbacks=[es],batch_size=BATCH_SIZE,shuffle=SHUFFLE,validation_split=VALIDATION_SPLIT)\r\n","    \r\n","    # Generate generalization metrics\r\n","    scores = model.evaluate(padded_sentences[test_index], y.values[test_index], verbose=0)\r\n","    print(f'Score for fold {fold_no}: {model.metrics_names[0]} of {scores[0]}; {model.metrics_names[1]} of {scores[1]*100}% ;{model.metrics_names[2]} of {scores[2]} ;{model.metrics_names[3]} of {scores[3]} ; \\\r\n","           {model.metrics_names[4]} of {scores[4]}')\r\n","    loss_per_fold.append(scores[0])\r\n","    acc_per_fold.append(scores[1] * 100)\r\n","    precision_per_fold.append(scores[2])\r\n","    recall_per_fold.append(scores[3])\r\n","    f1_per_fold.append(scores[4])\r\n","\r\n","    # Increase fold number\r\n","    fold_no = fold_no + 1\r\n","\r\n","  acc=np.mean(acc_per_fold)\r\n","  precision=np.mean(precision_per_fold)\r\n","  recall=np.mean(recall_per_fold)\r\n","  f1=np.mean(f1_per_fold)\r\n","  loss=np.mean(loss_per_fold)\r\n","  return acc,precision,recall,f1,loss"],"execution_count":23,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"8XMqJAWMNAVR","outputId":"ce1e619a-1eb5-4e09-aedf-06b4f05096c5"},"source":["MODELS_LIST=['cnn','cnnbilstm','cnnstackbilstm2','cnnstackbilstm3','rnn_gru','rnn_lstm','simplernn','stacklstm2','stacklstm3','bilstm','stackbilstm2','stackbilstm3','cnn_gru','cnn_lstm']\r\n","#MODELS_LIST=['cnn','cnnstackbilstm2']\r\n","\r\n","N_FOLDS=3\r\n","EPOCHS=10\r\n","VALIDATION_SPLIT=0.2 \r\n","BATCH_SIZE=32 \r\n","PATIENCE=10\r\n","MONITOR='val_f1_m' \r\n","MONITOR_MODE='max' \r\n","shuffle=True \r\n","DROPOUT_VALUE_2=0.5 \r\n","DROPOUT_VALUE_1=0.5 \r\n","NUM_CLASSES=6\r\n","NB_FILTERS=200 \r\n","KERNEL_SIZE=5\r\n","SHUFFLE=True\r\n","HIDDEN_DIMS=NB_FILTERS*2\r\n","L2_REG=0.1\r\n","EMBEDDING_SIZE=400\r\n","we_type='cbow'\r\n","\r\n","categories=['network','billing_price','package','customer_service','data','service_product']   \r\n","x=df['cleanAnswer']\r\n","y=df[categories]\r\n","\r\n","acclist=[] ; prelist=[]  ; reclist=[]  ; f1list=[]  ; losslist=[] ; modelname=[] ; wename=[] ; wesize = []\r\n","\r\n","for mod in MODELS_LIST:\r\n","  we_path=mainloc+'word_embeddings/w2v_'+we_type+'_'+str(EMBEDDING_SIZE)+'.txt'\r\n","  vocab_length,padded_sentences,length_long_sentence,embedding_matrix=loadembedding_matrix(x,we_path,EMBEDDING_SIZE)\r\n","  if (mod=='cnn'):\r\n","    acc,precision,recall,f1,loss=crossval(mod)\r\n","  elif (mod=='rnn_gru' or  mod=='rnn_lstm'):\r\n","    print(1)\r\n","    if (mod.split('_')[1]=='gru'):\r\n","      print(1.1)\r\n","      RNN=GRU\r\n","    else:\r\n","      print(1.2)\r\n","      RNN=LSTM\r\n","    acc,precision,recall,f1,loss=crossval('rnn')\r\n","  elif (mod=='stacklstm2'):\r\n","    print(3)\r\n","    acc,precision,recall,f1,loss=crossval('stacklstm2')\r\n","  elif (mod=='stacklstm3'):\r\n","    print(4)\r\n","    acc,precision,recall,f1,loss=crossval('stacklstm3')\r\n","  elif (mod=='bilstm'):\r\n","    acc,precision,recall,f1,loss=crossval('bilstm')\r\n","  elif (mod=='stackbilstm2'):\r\n","    acc,precision,recall,f1,loss=crossval('stackbilstm2')\r\n","  elif (mod=='stackbilstm3'):\r\n","    acc,precision,recall,f1,loss=crossval('stackbilstm3')\r\n","  elif (mod=='cnnbilstm'):\r\n","    acc,precision,recall,f1,loss=crossval('cnnbilstm')\r\n","  elif (mod=='cnnstackbilstm2'):\r\n","    acc,precision,recall,f1,loss=crossval('cnnstackbilstm2')\r\n","  elif (mod=='cnnstackbilstm3'):\r\n","    acc,precision,recall,f1,loss=crossval('cnnstackbilstm3')\r\n","  elif (mod=='simplernn'):\r\n","    print(2)\r\n","    acc,precision,recall,f1,loss=crossval('simplernn')\r\n","  else:\r\n","    print(\"issue\")\r\n","    if (mod.split('_')[1]=='gru'):\r\n","      RNN=GRU\r\n","    else:\r\n","      RNN=LSTM\r\n","    acc,precision,recall,f1,loss=crossval('cnn_rnn')\r\n","    \r\n","  modelname.append(mod)\r\n","  wename.append(we_type)\r\n","  wesize.append(EMBEDDING_SIZE)\r\n","  acclist.append(acc)\r\n","  prelist.append(precision)\r\n","  reclist.append(recall)\r\n","  f1list.append(f1)\r\n","  losslist.append(loss)        \r\n","  \r\n","  accdf=pd.DataFrame({'Model':modelname,'Word_Embedding':wename, 'Embedding_Size':wesize,'Accuracy':acclist,'Precision':prelist,'Recall':reclist, 'F1':f1list})\r\n","  accdf.to_csv(mainloc+\"Aspect_Accuracies.csv\",index=False)\r\n","\r\n","accdf=pd.DataFrame({'Model':modelname,'Word_Embedding':wename, 'Embedding_Size':wesize,'Accuracy':acclist,'Precision':prelist,'Recall':reclist, 'F1':f1list})\r\n","accdf.to_csv(mainloc+\"Aspect_Accuracies.csv\",index=False)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Epoch 1/10\n","168/168 [==============================] - 35s 14ms/step - loss: 0.4588 - accuracy: 0.4497 - precision_m: 0.6786 - recall_m: 0.4320 - f1_m: 0.5151 - val_loss: 0.2624 - val_accuracy: 0.6652 - val_precision_m: 0.8406 - val_recall_m: 0.7543 - val_f1_m: 0.7933\n","Epoch 2/10\n","168/168 [==============================] - 2s 11ms/step - loss: 0.3128 - accuracy: 0.6129 - precision_m: 0.7995 - recall_m: 0.6760 - f1_m: 0.7311 - val_loss: 0.2432 - val_accuracy: 0.6831 - val_precision_m: 0.8669 - val_recall_m: 0.7549 - val_f1_m: 0.8051\n","Epoch 3/10\n","168/168 [==============================] - 2s 11ms/step - loss: 0.2904 - accuracy: 0.6255 - precision_m: 0.8175 - recall_m: 0.7081 - f1_m: 0.7571 - val_loss: 0.2335 - val_accuracy: 0.6943 - val_precision_m: 0.8662 - val_recall_m: 0.7683 - val_f1_m: 0.8125\n","Epoch 4/10\n","168/168 [==============================] - 2s 11ms/step - loss: 0.2691 - accuracy: 0.6484 - precision_m: 0.8277 - recall_m: 0.7360 - f1_m: 0.7778 - val_loss: 0.2255 - val_accuracy: 0.7047 - val_precision_m: 0.8660 - val_recall_m: 0.7838 - val_f1_m: 0.8213\n","Epoch 5/10\n","168/168 [==============================] - 2s 11ms/step - loss: 0.2509 - accuracy: 0.6546 - precision_m: 0.8362 - recall_m: 0.7606 - f1_m: 0.7950 - val_loss: 0.2263 - val_accuracy: 0.6957 - val_precision_m: 0.8622 - val_recall_m: 0.7961 - val_f1_m: 0.8261\n","Epoch 6/10\n","168/168 [==============================] - 2s 11ms/step - loss: 0.2521 - accuracy: 0.6573 - precision_m: 0.8394 - recall_m: 0.7649 - f1_m: 0.7991 - val_loss: 0.2239 - val_accuracy: 0.7025 - val_precision_m: 0.8703 - val_recall_m: 0.7821 - val_f1_m: 0.8219\n","Epoch 7/10\n","168/168 [==============================] - 2s 11ms/step - loss: 0.2416 - accuracy: 0.6735 - precision_m: 0.8388 - recall_m: 0.7689 - f1_m: 0.8012 - val_loss: 0.2218 - val_accuracy: 0.7054 - val_precision_m: 0.8712 - val_recall_m: 0.7963 - val_f1_m: 0.8303\n","Epoch 8/10\n","168/168 [==============================] - 2s 12ms/step - loss: 0.2359 - accuracy: 0.6677 - precision_m: 0.8498 - recall_m: 0.7746 - f1_m: 0.8094 - val_loss: 0.2310 - val_accuracy: 0.7248 - val_precision_m: 0.8633 - val_recall_m: 0.7927 - val_f1_m: 0.8248\n","Epoch 9/10\n","168/168 [==============================] - 2s 11ms/step - loss: 0.2319 - accuracy: 0.6799 - precision_m: 0.8525 - recall_m: 0.7809 - f1_m: 0.8139 - val_loss: 0.2267 - val_accuracy: 0.7092 - val_precision_m: 0.8680 - val_recall_m: 0.7846 - val_f1_m: 0.8222\n","Epoch 10/10\n","168/168 [==============================] - 2s 11ms/step - loss: 0.2224 - accuracy: 0.6904 - precision_m: 0.8659 - recall_m: 0.7874 - f1_m: 0.8233 - val_loss: 0.2160 - val_accuracy: 0.7062 - val_precision_m: 0.8727 - val_recall_m: 0.8019 - val_f1_m: 0.8342\n","Score for fold 1: loss of 0.4502495527267456; accuracy of 50.730687379837036% ;precision_m of 0.8467902541160583 ;recall_m of 0.6260448694229126 ;            f1_m of 0.7153035998344421\n","Epoch 1/10\n","168/168 [==============================] - 3s 13ms/step - loss: 0.5094 - accuracy: 0.4172 - precision_m: 0.6458 - recall_m: 0.4233 - f1_m: 0.4991 - val_loss: 0.2735 - val_accuracy: 0.6749 - val_precision_m: 0.8397 - val_recall_m: 0.7513 - val_f1_m: 0.7913\n","Epoch 2/10\n","168/168 [==============================] - 2s 11ms/step - loss: 0.3454 - accuracy: 0.5825 - precision_m: 0.7936 - recall_m: 0.6952 - f1_m: 0.7393 - val_loss: 0.2553 - val_accuracy: 0.7069 - val_precision_m: 0.8592 - val_recall_m: 0.7619 - val_f1_m: 0.8059\n","Epoch 3/10\n","168/168 [==============================] - 2s 11ms/step - loss: 0.3081 - accuracy: 0.5994 - precision_m: 0.8246 - recall_m: 0.7345 - f1_m: 0.7754 - val_loss: 0.2515 - val_accuracy: 0.7166 - val_precision_m: 0.8683 - val_recall_m: 0.7511 - val_f1_m: 0.8035\n","Epoch 4/10\n","168/168 [==============================] - 2s 12ms/step - loss: 0.2994 - accuracy: 0.6131 - precision_m: 0.8287 - recall_m: 0.7449 - f1_m: 0.7829 - val_loss: 0.2477 - val_accuracy: 0.6913 - val_precision_m: 0.8327 - val_recall_m: 0.7878 - val_f1_m: 0.8080\n","Epoch 5/10\n","168/168 [==============================] - 2s 12ms/step - loss: 0.2823 - accuracy: 0.6225 - precision_m: 0.8340 - recall_m: 0.7682 - f1_m: 0.7983 - val_loss: 0.2346 - val_accuracy: 0.7040 - val_precision_m: 0.8716 - val_recall_m: 0.7575 - val_f1_m: 0.8084\n","Epoch 6/10\n","168/168 [==============================] - 2s 12ms/step - loss: 0.2815 - accuracy: 0.6180 - precision_m: 0.8431 - recall_m: 0.7720 - f1_m: 0.8049 - val_loss: 0.2424 - val_accuracy: 0.7099 - val_precision_m: 0.8701 - val_recall_m: 0.7751 - val_f1_m: 0.8182\n","Epoch 7/10\n","168/168 [==============================] - 2s 12ms/step - loss: 0.2671 - accuracy: 0.6390 - precision_m: 0.8494 - recall_m: 0.7839 - f1_m: 0.8136 - val_loss: 0.2280 - val_accuracy: 0.6950 - val_precision_m: 0.8697 - val_recall_m: 0.7690 - val_f1_m: 0.8145\n","Epoch 8/10\n","168/168 [==============================] - 2s 11ms/step - loss: 0.2563 - accuracy: 0.6293 - precision_m: 0.8524 - recall_m: 0.7843 - f1_m: 0.8156 - val_loss: 0.2275 - val_accuracy: 0.7107 - val_precision_m: 0.8686 - val_recall_m: 0.7813 - val_f1_m: 0.8213\n","Epoch 9/10\n","168/168 [==============================] - 2s 11ms/step - loss: 0.2494 - accuracy: 0.6378 - precision_m: 0.8605 - recall_m: 0.8009 - f1_m: 0.8287 - val_loss: 0.2321 - val_accuracy: 0.7263 - val_precision_m: 0.8688 - val_recall_m: 0.7791 - val_f1_m: 0.8197\n","Epoch 10/10\n","168/168 [==============================] - 2s 11ms/step - loss: 0.2502 - accuracy: 0.6413 - precision_m: 0.8638 - recall_m: 0.8030 - f1_m: 0.8309 - val_loss: 0.2258 - val_accuracy: 0.7077 - val_precision_m: 0.8753 - val_recall_m: 0.7716 - val_f1_m: 0.8183\n","Score for fold 2: loss of 0.2833753526210785; accuracy of 66.11989140510559% ;precision_m of 0.825810968875885 ;recall_m of 0.7386165857315063 ;            f1_m of 0.7780327796936035\n","Epoch 1/10\n","168/168 [==============================] - 3s 13ms/step - loss: 0.5196 - accuracy: 0.3998 - precision_m: 0.6521 - recall_m: 0.4219 - f1_m: 0.4876 - val_loss: 0.3154 - val_accuracy: 0.6244 - val_precision_m: 0.7874 - val_recall_m: 0.7215 - val_f1_m: 0.7517\n","Epoch 2/10\n","168/168 [==============================] - 2s 11ms/step - loss: 0.3473 - accuracy: 0.5939 - precision_m: 0.7970 - recall_m: 0.7045 - f1_m: 0.7463 - val_loss: 0.2934 - val_accuracy: 0.6304 - val_precision_m: 0.8196 - val_recall_m: 0.7151 - val_f1_m: 0.7624\n","Epoch 3/10\n","168/168 [==============================] - 2s 12ms/step - loss: 0.3259 - accuracy: 0.5823 - precision_m: 0.8113 - recall_m: 0.7288 - f1_m: 0.7665 - val_loss: 0.2846 - val_accuracy: 0.6393 - val_precision_m: 0.8206 - val_recall_m: 0.7207 - val_f1_m: 0.7662\n","Epoch 4/10\n","168/168 [==============================] - 2s 12ms/step - loss: 0.3162 - accuracy: 0.5869 - precision_m: 0.8190 - recall_m: 0.7417 - f1_m: 0.7771 - val_loss: 0.2835 - val_accuracy: 0.6587 - val_precision_m: 0.8383 - val_recall_m: 0.7050 - val_f1_m: 0.7643\n","Epoch 5/10\n","168/168 [==============================] - 2s 12ms/step - loss: 0.3019 - accuracy: 0.6049 - precision_m: 0.8307 - recall_m: 0.7558 - f1_m: 0.7902 - val_loss: 0.2751 - val_accuracy: 0.6431 - val_precision_m: 0.8266 - val_recall_m: 0.7176 - val_f1_m: 0.7671\n","Epoch 6/10\n","168/168 [==============================] - 2s 12ms/step - loss: 0.2932 - accuracy: 0.6000 - precision_m: 0.8374 - recall_m: 0.7636 - f1_m: 0.7974 - val_loss: 0.2762 - val_accuracy: 0.6602 - val_precision_m: 0.8212 - val_recall_m: 0.7570 - val_f1_m: 0.7864\n","Epoch 7/10\n","168/168 [==============================] - 2s 12ms/step - loss: 0.2864 - accuracy: 0.6104 - precision_m: 0.8470 - recall_m: 0.7668 - f1_m: 0.8038 - val_loss: 0.2693 - val_accuracy: 0.6461 - val_precision_m: 0.8249 - val_recall_m: 0.7407 - val_f1_m: 0.7790\n","Epoch 8/10\n","168/168 [==============================] - 2s 12ms/step - loss: 0.2745 - accuracy: 0.6171 - precision_m: 0.8536 - recall_m: 0.7828 - f1_m: 0.8158 - val_loss: 0.2674 - val_accuracy: 0.6505 - val_precision_m: 0.8446 - val_recall_m: 0.7250 - val_f1_m: 0.7787\n","Epoch 9/10\n","168/168 [==============================] - 2s 11ms/step - loss: 0.2695 - accuracy: 0.6158 - precision_m: 0.8538 - recall_m: 0.7734 - f1_m: 0.8101 - val_loss: 0.2725 - val_accuracy: 0.6647 - val_precision_m: 0.8287 - val_recall_m: 0.7347 - val_f1_m: 0.7776\n","Epoch 10/10\n","168/168 [==============================] - 2s 11ms/step - loss: 0.2668 - accuracy: 0.6251 - precision_m: 0.8576 - recall_m: 0.7850 - f1_m: 0.8187 - val_loss: 0.2627 - val_accuracy: 0.6572 - val_precision_m: 0.8396 - val_recall_m: 0.7289 - val_f1_m: 0.7792\n","Score for fold 3: loss of 0.24447773396968842; accuracy of 69.77923512458801% ;precision_m of 0.8543187379837036 ;recall_m of 0.7545785903930664 ;            f1_m of 0.7993634343147278\n","Epoch 1/10\n","168/168 [==============================] - 12s 54ms/step - loss: 0.4690 - accuracy: 0.4056 - precision_m: 0.6229 - recall_m: 0.3990 - f1_m: 0.4657 - val_loss: 0.2874 - val_accuracy: 0.5831 - val_precision_m: 0.7984 - val_recall_m: 0.6493 - val_f1_m: 0.7146\n","Epoch 2/10\n","168/168 [==============================] - 8s 48ms/step - loss: 0.3176 - accuracy: 0.5936 - precision_m: 0.7744 - recall_m: 0.6700 - f1_m: 0.7167 - val_loss: 0.2412 - val_accuracy: 0.6846 - val_precision_m: 0.8333 - val_recall_m: 0.7676 - val_f1_m: 0.7975\n","Epoch 3/10\n","168/168 [==============================] - 8s 49ms/step - loss: 0.2808 - accuracy: 0.6404 - precision_m: 0.8112 - recall_m: 0.7274 - f1_m: 0.7654 - val_loss: 0.2251 - val_accuracy: 0.6741 - val_precision_m: 0.8567 - val_recall_m: 0.7705 - val_f1_m: 0.8099\n","Epoch 4/10\n","168/168 [==============================] - 8s 49ms/step - loss: 0.2684 - accuracy: 0.6644 - precision_m: 0.8232 - recall_m: 0.7363 - f1_m: 0.7752 - val_loss: 0.2223 - val_accuracy: 0.6861 - val_precision_m: 0.8683 - val_recall_m: 0.7593 - val_f1_m: 0.8085\n","Epoch 5/10\n","168/168 [==============================] - 8s 49ms/step - loss: 0.2591 - accuracy: 0.6721 - precision_m: 0.8206 - recall_m: 0.7554 - f1_m: 0.7852 - val_loss: 0.2160 - val_accuracy: 0.7054 - val_precision_m: 0.8653 - val_recall_m: 0.7826 - val_f1_m: 0.8204\n","Epoch 6/10\n","168/168 [==============================] - 8s 49ms/step - loss: 0.2485 - accuracy: 0.6711 - precision_m: 0.8248 - recall_m: 0.7645 - f1_m: 0.7923 - val_loss: 0.2157 - val_accuracy: 0.7159 - val_precision_m: 0.8454 - val_recall_m: 0.7965 - val_f1_m: 0.8188\n","Epoch 7/10\n","168/168 [==============================] - 8s 49ms/step - loss: 0.2314 - accuracy: 0.6775 - precision_m: 0.8372 - recall_m: 0.7870 - f1_m: 0.8105 - val_loss: 0.2100 - val_accuracy: 0.7077 - val_precision_m: 0.8721 - val_recall_m: 0.7832 - val_f1_m: 0.8236\n","Epoch 8/10\n","168/168 [==============================] - 8s 49ms/step - loss: 0.2371 - accuracy: 0.6693 - precision_m: 0.8403 - recall_m: 0.7793 - f1_m: 0.8071 - val_loss: 0.2034 - val_accuracy: 0.7077 - val_precision_m: 0.8704 - val_recall_m: 0.7918 - val_f1_m: 0.8279\n","Epoch 9/10\n","168/168 [==============================] - 8s 49ms/step - loss: 0.2273 - accuracy: 0.6865 - precision_m: 0.8401 - recall_m: 0.7884 - f1_m: 0.8120 - val_loss: 0.2090 - val_accuracy: 0.7092 - val_precision_m: 0.8734 - val_recall_m: 0.7861 - val_f1_m: 0.8258\n","Epoch 10/10\n","168/168 [==============================] - 8s 49ms/step - loss: 0.2168 - accuracy: 0.6773 - precision_m: 0.8532 - recall_m: 0.8016 - f1_m: 0.8252 - val_loss: 0.2134 - val_accuracy: 0.6920 - val_precision_m: 0.8618 - val_recall_m: 0.7797 - val_f1_m: 0.8168\n","Score for fold 1: loss of 0.3758701980113983; accuracy of 48.58335852622986% ;precision_m of 0.8153780102729797 ;recall_m of 0.6976576447486877 ;            f1_m of 0.7501656413078308\n","Epoch 1/10\n","168/168 [==============================] - 12s 55ms/step - loss: 0.5300 - accuracy: 0.3631 - precision_m: 0.6005 - recall_m: 0.3559 - f1_m: 0.4207 - val_loss: 0.2816 - val_accuracy: 0.6368 - val_precision_m: 0.8194 - val_recall_m: 0.6836 - val_f1_m: 0.7440\n","Epoch 2/10\n","168/168 [==============================] - 8s 50ms/step - loss: 0.3684 - accuracy: 0.5659 - precision_m: 0.7547 - recall_m: 0.6465 - f1_m: 0.6943 - val_loss: 0.2440 - val_accuracy: 0.6793 - val_precision_m: 0.8253 - val_recall_m: 0.7689 - val_f1_m: 0.7944\n","Epoch 3/10\n","168/168 [==============================] - 8s 50ms/step - loss: 0.3273 - accuracy: 0.5933 - precision_m: 0.7924 - recall_m: 0.7211 - f1_m: 0.7535 - val_loss: 0.2234 - val_accuracy: 0.6875 - val_precision_m: 0.8665 - val_recall_m: 0.7634 - val_f1_m: 0.8103\n","Epoch 4/10\n","168/168 [==============================] - 8s 50ms/step - loss: 0.2914 - accuracy: 0.6026 - precision_m: 0.8227 - recall_m: 0.7637 - f1_m: 0.7907 - val_loss: 0.2190 - val_accuracy: 0.6793 - val_precision_m: 0.8574 - val_recall_m: 0.7772 - val_f1_m: 0.8141\n","Epoch 5/10\n","168/168 [==============================] - 8s 50ms/step - loss: 0.2815 - accuracy: 0.6204 - precision_m: 0.8313 - recall_m: 0.7661 - f1_m: 0.7961 - val_loss: 0.2157 - val_accuracy: 0.6950 - val_precision_m: 0.8645 - val_recall_m: 0.7828 - val_f1_m: 0.8200\n","Epoch 6/10\n","168/168 [==============================] - 8s 50ms/step - loss: 0.2711 - accuracy: 0.6304 - precision_m: 0.8322 - recall_m: 0.7887 - f1_m: 0.8086 - val_loss: 0.5095 - val_accuracy: 0.5041 - val_precision_m: 0.4042 - val_recall_m: 0.7647 - val_f1_m: 0.5276\n","Epoch 7/10\n","168/168 [==============================] - 8s 50ms/step - loss: 0.2807 - accuracy: 0.6345 - precision_m: 0.8245 - recall_m: 0.7689 - f1_m: 0.7930 - val_loss: 0.2212 - val_accuracy: 0.7107 - val_precision_m: 0.8886 - val_recall_m: 0.7571 - val_f1_m: 0.8158\n","Epoch 8/10\n","168/168 [==============================] - 8s 50ms/step - loss: 0.2496 - accuracy: 0.6317 - precision_m: 0.8541 - recall_m: 0.7972 - f1_m: 0.8234 - val_loss: 0.2102 - val_accuracy: 0.7092 - val_precision_m: 0.8758 - val_recall_m: 0.7838 - val_f1_m: 0.8258\n","Epoch 9/10\n","168/168 [==============================] - 8s 50ms/step - loss: 0.2375 - accuracy: 0.6543 - precision_m: 0.8532 - recall_m: 0.8169 - f1_m: 0.8335 - val_loss: 0.2112 - val_accuracy: 0.7092 - val_precision_m: 0.8760 - val_recall_m: 0.7848 - val_f1_m: 0.8264\n","Epoch 10/10\n","168/168 [==============================] - 8s 50ms/step - loss: 0.2216 - accuracy: 0.6631 - precision_m: 0.8653 - recall_m: 0.8256 - f1_m: 0.8443 - val_loss: 0.2113 - val_accuracy: 0.6987 - val_precision_m: 0.8833 - val_recall_m: 0.7795 - val_f1_m: 0.8266\n","Score for fold 2: loss of 0.27659183740615845; accuracy of 64.62869048118591% ;precision_m of 0.8265543580055237 ;recall_m of 0.743717610836029 ;            f1_m of 0.7811592221260071\n","Epoch 1/10\n","168/168 [==============================] - 12s 55ms/step - loss: 0.5282 - accuracy: 0.3484 - precision_m: 0.6266 - recall_m: 0.3690 - f1_m: 0.4314 - val_loss: 0.3308 - val_accuracy: 0.5805 - val_precision_m: 0.7676 - val_recall_m: 0.6864 - val_f1_m: 0.7231\n","Epoch 2/10\n","168/168 [==============================] - 8s 50ms/step - loss: 0.3746 - accuracy: 0.5588 - precision_m: 0.7602 - recall_m: 0.6674 - f1_m: 0.7089 - val_loss: 0.2935 - val_accuracy: 0.6095 - val_precision_m: 0.8084 - val_recall_m: 0.7100 - val_f1_m: 0.7548\n","Epoch 3/10\n","168/168 [==============================] - 8s 50ms/step - loss: 0.3325 - accuracy: 0.5964 - precision_m: 0.7900 - recall_m: 0.7171 - f1_m: 0.7499 - val_loss: 0.2795 - val_accuracy: 0.6177 - val_precision_m: 0.8248 - val_recall_m: 0.6975 - val_f1_m: 0.7546\n","Epoch 4/10\n","168/168 [==============================] - 8s 50ms/step - loss: 0.3107 - accuracy: 0.5863 - precision_m: 0.8083 - recall_m: 0.7570 - f1_m: 0.7808 - val_loss: 0.2696 - val_accuracy: 0.6349 - val_precision_m: 0.8073 - val_recall_m: 0.7472 - val_f1_m: 0.7752\n","Epoch 5/10\n","168/168 [==============================] - 8s 50ms/step - loss: 0.2983 - accuracy: 0.6051 - precision_m: 0.8166 - recall_m: 0.7674 - f1_m: 0.7897 - val_loss: 0.2681 - val_accuracy: 0.6133 - val_precision_m: 0.8158 - val_recall_m: 0.7339 - val_f1_m: 0.7714\n","Epoch 6/10\n","168/168 [==============================] - 8s 50ms/step - loss: 0.2795 - accuracy: 0.6274 - precision_m: 0.8324 - recall_m: 0.7814 - f1_m: 0.8049 - val_loss: 0.2599 - val_accuracy: 0.6304 - val_precision_m: 0.8354 - val_recall_m: 0.7250 - val_f1_m: 0.7750\n","Epoch 7/10\n","168/168 [==============================] - 8s 50ms/step - loss: 0.2703 - accuracy: 0.6344 - precision_m: 0.8436 - recall_m: 0.7958 - f1_m: 0.8177 - val_loss: 0.2509 - val_accuracy: 0.6401 - val_precision_m: 0.8343 - val_recall_m: 0.7616 - val_f1_m: 0.7954\n","Epoch 8/10\n","168/168 [==============================] - 8s 50ms/step - loss: 0.2674 - accuracy: 0.6244 - precision_m: 0.8348 - recall_m: 0.7989 - f1_m: 0.8152 - val_loss: 0.2675 - val_accuracy: 0.6185 - val_precision_m: 0.8298 - val_recall_m: 0.7414 - val_f1_m: 0.7821\n","Epoch 9/10\n","168/168 [==============================] - 8s 50ms/step - loss: 0.2582 - accuracy: 0.6206 - precision_m: 0.8448 - recall_m: 0.8095 - f1_m: 0.8255 - val_loss: 0.2524 - val_accuracy: 0.6475 - val_precision_m: 0.8378 - val_recall_m: 0.7552 - val_f1_m: 0.7930\n","Epoch 10/10\n","168/168 [==============================] - 8s 50ms/step - loss: 0.2428 - accuracy: 0.6305 - precision_m: 0.8577 - recall_m: 0.8169 - f1_m: 0.8358 - val_loss: 0.2674 - val_accuracy: 0.6140 - val_precision_m: 0.8370 - val_recall_m: 0.7424 - val_f1_m: 0.7858\n","Score for fold 3: loss of 0.2393208146095276; accuracy of 65.3341293334961% ;precision_m of 0.8380621671676636 ;recall_m of 0.7698881030082703 ;            f1_m of 0.8006355166435242\n","Epoch 1/10\n","168/168 [==============================] - 24s 112ms/step - loss: 0.4879 - accuracy: 0.3740 - precision_m: 0.5707 - recall_m: 0.3468 - f1_m: 0.4170 - val_loss: 0.2851 - val_accuracy: 0.6204 - val_precision_m: 0.7924 - val_recall_m: 0.6681 - val_f1_m: 0.7235\n","Epoch 2/10\n","168/168 [==============================] - 18s 105ms/step - loss: 0.3406 - accuracy: 0.5804 - precision_m: 0.7540 - recall_m: 0.6360 - f1_m: 0.6883 - val_loss: 0.2540 - val_accuracy: 0.6421 - val_precision_m: 0.8303 - val_recall_m: 0.7496 - val_f1_m: 0.7864\n","Epoch 3/10\n","168/168 [==============================] - 18s 105ms/step - loss: 0.2927 - accuracy: 0.6413 - precision_m: 0.7897 - recall_m: 0.7115 - f1_m: 0.7467 - val_loss: 0.2328 - val_accuracy: 0.6957 - val_precision_m: 0.8475 - val_recall_m: 0.7692 - val_f1_m: 0.8048\n","Epoch 4/10\n","168/168 [==============================] - 18s 106ms/step - loss: 0.2620 - accuracy: 0.6543 - precision_m: 0.8206 - recall_m: 0.7521 - f1_m: 0.7833 - val_loss: 0.2297 - val_accuracy: 0.7010 - val_precision_m: 0.8625 - val_recall_m: 0.7570 - val_f1_m: 0.8048\n","Epoch 5/10\n","168/168 [==============================] - 18s 106ms/step - loss: 0.2549 - accuracy: 0.6696 - precision_m: 0.8160 - recall_m: 0.7603 - f1_m: 0.7859 - val_loss: 0.2166 - val_accuracy: 0.6816 - val_precision_m: 0.8366 - val_recall_m: 0.8100 - val_f1_m: 0.8217\n","Epoch 6/10\n","168/168 [==============================] - 18s 106ms/step - loss: 0.2614 - accuracy: 0.6748 - precision_m: 0.8178 - recall_m: 0.7558 - f1_m: 0.7837 - val_loss: 0.2161 - val_accuracy: 0.7010 - val_precision_m: 0.8683 - val_recall_m: 0.7807 - val_f1_m: 0.8208\n","Epoch 7/10\n","168/168 [==============================] - 18s 106ms/step - loss: 0.2420 - accuracy: 0.6731 - precision_m: 0.8325 - recall_m: 0.7765 - f1_m: 0.8022 - val_loss: 0.2212 - val_accuracy: 0.6682 - val_precision_m: 0.8526 - val_recall_m: 0.7800 - val_f1_m: 0.8131\n","Epoch 8/10\n","168/168 [==============================] - 18s 106ms/step - loss: 0.2343 - accuracy: 0.6795 - precision_m: 0.8304 - recall_m: 0.7928 - f1_m: 0.8097 - val_loss: 0.2184 - val_accuracy: 0.6741 - val_precision_m: 0.8633 - val_recall_m: 0.7832 - val_f1_m: 0.8196\n","Epoch 9/10\n","168/168 [==============================] - 18s 106ms/step - loss: 0.2257 - accuracy: 0.6884 - precision_m: 0.8425 - recall_m: 0.7987 - f1_m: 0.8190 - val_loss: 0.2220 - val_accuracy: 0.6935 - val_precision_m: 0.8784 - val_recall_m: 0.7828 - val_f1_m: 0.8262\n","Epoch 10/10\n","168/168 [==============================] - 18s 106ms/step - loss: 0.2075 - accuracy: 0.7029 - precision_m: 0.8612 - recall_m: 0.8148 - f1_m: 0.8363 - val_loss: 0.2136 - val_accuracy: 0.6935 - val_precision_m: 0.8622 - val_recall_m: 0.7910 - val_f1_m: 0.8234\n","Score for fold 1: loss of 0.3606427013874054; accuracy of 57.44109749794006% ;precision_m of 0.7992302179336548 ;recall_m of 0.717007577419281 ;            f1_m of 0.7540823221206665\n","Epoch 1/10\n","168/168 [==============================] - 24s 113ms/step - loss: 0.5108 - accuracy: 0.4080 - precision_m: 0.5877 - recall_m: 0.4134 - f1_m: 0.4684 - val_loss: 0.2781 - val_accuracy: 0.6443 - val_precision_m: 0.8035 - val_recall_m: 0.6838 - val_f1_m: 0.7373\n","Epoch 2/10\n","168/168 [==============================] - 18s 106ms/step - loss: 0.3661 - accuracy: 0.6031 - precision_m: 0.7567 - recall_m: 0.6714 - f1_m: 0.7095 - val_loss: 0.2349 - val_accuracy: 0.6808 - val_precision_m: 0.8552 - val_recall_m: 0.7546 - val_f1_m: 0.7999\n","Epoch 3/10\n","168/168 [==============================] - 18s 106ms/step - loss: 0.3127 - accuracy: 0.6359 - precision_m: 0.8041 - recall_m: 0.7444 - f1_m: 0.7717 - val_loss: 0.2309 - val_accuracy: 0.7069 - val_precision_m: 0.8447 - val_recall_m: 0.7814 - val_f1_m: 0.8103\n","Epoch 4/10\n","168/168 [==============================] - 18s 107ms/step - loss: 0.2872 - accuracy: 0.6274 - precision_m: 0.8261 - recall_m: 0.7720 - f1_m: 0.7969 - val_loss: 0.2185 - val_accuracy: 0.6890 - val_precision_m: 0.8690 - val_recall_m: 0.7721 - val_f1_m: 0.8164\n","Epoch 5/10\n","168/168 [==============================] - 18s 107ms/step - loss: 0.2798 - accuracy: 0.6141 - precision_m: 0.8289 - recall_m: 0.7767 - f1_m: 0.8008 - val_loss: 0.2187 - val_accuracy: 0.6957 - val_precision_m: 0.8664 - val_recall_m: 0.7843 - val_f1_m: 0.8219\n","Epoch 6/10\n","168/168 [==============================] - 18s 106ms/step - loss: 0.2595 - accuracy: 0.6362 - precision_m: 0.8432 - recall_m: 0.7920 - f1_m: 0.8156 - val_loss: 0.2113 - val_accuracy: 0.7077 - val_precision_m: 0.8644 - val_recall_m: 0.7871 - val_f1_m: 0.8222\n","Epoch 7/10\n","168/168 [==============================] - 18s 107ms/step - loss: 0.2527 - accuracy: 0.6410 - precision_m: 0.8469 - recall_m: 0.8027 - f1_m: 0.8232 - val_loss: 0.2137 - val_accuracy: 0.7114 - val_precision_m: 0.8675 - val_recall_m: 0.7890 - val_f1_m: 0.8249\n","Epoch 8/10\n","168/168 [==============================] - 18s 107ms/step - loss: 0.2432 - accuracy: 0.6488 - precision_m: 0.8530 - recall_m: 0.8158 - f1_m: 0.8332 - val_loss: 0.2163 - val_accuracy: 0.7129 - val_precision_m: 0.8717 - val_recall_m: 0.7704 - val_f1_m: 0.8165\n","Epoch 9/10\n","168/168 [==============================] - 18s 107ms/step - loss: 0.2384 - accuracy: 0.6532 - precision_m: 0.8586 - recall_m: 0.8191 - f1_m: 0.8371 - val_loss: 0.2220 - val_accuracy: 0.7226 - val_precision_m: 0.8744 - val_recall_m: 0.7760 - val_f1_m: 0.8206\n","Epoch 10/10\n","168/168 [==============================] - 18s 107ms/step - loss: 0.2327 - accuracy: 0.6504 - precision_m: 0.8596 - recall_m: 0.8253 - f1_m: 0.8412 - val_loss: 0.2179 - val_accuracy: 0.7129 - val_precision_m: 0.8763 - val_recall_m: 0.7852 - val_f1_m: 0.8265\n","Score for fold 2: loss of 0.2850547432899475; accuracy of 66.11989140510559% ;precision_m of 0.8203115463256836 ;recall_m of 0.7574286460876465 ;            f1_m of 0.7858461737632751\n","Epoch 1/10\n","168/168 [==============================] - 24s 114ms/step - loss: 0.5266 - accuracy: 0.3693 - precision_m: 0.5971 - recall_m: 0.3975 - f1_m: 0.4551 - val_loss: 0.3397 - val_accuracy: 0.5551 - val_precision_m: 0.7355 - val_recall_m: 0.6658 - val_f1_m: 0.6975\n","Epoch 2/10\n","168/168 [==============================] - 18s 106ms/step - loss: 0.4017 - accuracy: 0.5525 - precision_m: 0.7459 - recall_m: 0.6333 - f1_m: 0.6823 - val_loss: 0.2984 - val_accuracy: 0.6498 - val_precision_m: 0.7967 - val_recall_m: 0.7002 - val_f1_m: 0.7437\n","Epoch 3/10\n","168/168 [==============================] - 18s 106ms/step - loss: 0.3441 - accuracy: 0.6076 - precision_m: 0.7843 - recall_m: 0.7135 - f1_m: 0.7460 - val_loss: 0.2768 - val_accuracy: 0.6088 - val_precision_m: 0.8143 - val_recall_m: 0.7313 - val_f1_m: 0.7695\n","Epoch 4/10\n","168/168 [==============================] - 18s 105ms/step - loss: 0.3037 - accuracy: 0.6077 - precision_m: 0.8146 - recall_m: 0.7639 - f1_m: 0.7873 - val_loss: 0.2744 - val_accuracy: 0.6595 - val_precision_m: 0.8226 - val_recall_m: 0.7100 - val_f1_m: 0.7607\n","Epoch 5/10\n","168/168 [==============================] - 18s 106ms/step - loss: 0.2984 - accuracy: 0.6177 - precision_m: 0.8170 - recall_m: 0.7635 - f1_m: 0.7878 - val_loss: 0.2745 - val_accuracy: 0.6170 - val_precision_m: 0.8190 - val_recall_m: 0.7315 - val_f1_m: 0.7716\n","Epoch 6/10\n","168/168 [==============================] - 18s 107ms/step - loss: 0.2816 - accuracy: 0.6057 - precision_m: 0.8283 - recall_m: 0.7836 - f1_m: 0.8042 - val_loss: 0.2595 - val_accuracy: 0.6565 - val_precision_m: 0.8350 - val_recall_m: 0.7379 - val_f1_m: 0.7824\n","Epoch 7/10\n","168/168 [==============================] - 18s 107ms/step - loss: 0.2792 - accuracy: 0.6228 - precision_m: 0.8335 - recall_m: 0.7907 - f1_m: 0.8104 - val_loss: 0.2627 - val_accuracy: 0.6364 - val_precision_m: 0.8129 - val_recall_m: 0.7551 - val_f1_m: 0.7818\n","Epoch 8/10\n","168/168 [==============================] - 18s 107ms/step - loss: 0.2669 - accuracy: 0.6189 - precision_m: 0.8304 - recall_m: 0.8016 - f1_m: 0.8145 - val_loss: 0.2514 - val_accuracy: 0.6513 - val_precision_m: 0.8485 - val_recall_m: 0.7341 - val_f1_m: 0.7860\n","Epoch 9/10\n","168/168 [==============================] - 18s 106ms/step - loss: 0.2553 - accuracy: 0.6278 - precision_m: 0.8491 - recall_m: 0.8096 - f1_m: 0.8271 - val_loss: 0.2647 - val_accuracy: 0.6304 - val_precision_m: 0.8338 - val_recall_m: 0.7448 - val_f1_m: 0.7857\n","Epoch 10/10\n","168/168 [==============================] - 18s 107ms/step - loss: 0.2416 - accuracy: 0.6209 - precision_m: 0.8541 - recall_m: 0.8261 - f1_m: 0.8389 - val_loss: 0.2681 - val_accuracy: 0.6282 - val_precision_m: 0.8433 - val_recall_m: 0.7414 - val_f1_m: 0.7880\n","Score for fold 3: loss of 0.2562284469604492; accuracy of 67.27327108383179% ;precision_m of 0.8369463682174683 ;recall_m of 0.754253625869751 ;            f1_m of 0.7914876341819763\n","Epoch 1/10\n","168/168 [==============================] - 36s 171ms/step - loss: 0.5083 - accuracy: 0.3496 - precision_m: 0.5552 - recall_m: 0.3152 - f1_m: 0.3827 - val_loss: 0.2931 - val_accuracy: 0.6130 - val_precision_m: 0.8061 - val_recall_m: 0.6427 - val_f1_m: 0.7134\n","Epoch 2/10\n","168/168 [==============================] - 27s 161ms/step - loss: 0.3646 - accuracy: 0.5281 - precision_m: 0.7214 - recall_m: 0.5889 - f1_m: 0.6463 - val_loss: 0.2739 - val_accuracy: 0.6249 - val_precision_m: 0.8124 - val_recall_m: 0.6909 - val_f1_m: 0.7449\n","Epoch 3/10\n","168/168 [==============================] - 27s 162ms/step - loss: 0.3243 - accuracy: 0.6119 - precision_m: 0.7596 - recall_m: 0.6671 - f1_m: 0.7084 - val_loss: 0.2411 - val_accuracy: 0.7054 - val_precision_m: 0.8452 - val_recall_m: 0.7594 - val_f1_m: 0.7986\n","Epoch 4/10\n","168/168 [==============================] - 27s 161ms/step - loss: 0.3039 - accuracy: 0.6439 - precision_m: 0.7761 - recall_m: 0.7113 - f1_m: 0.7403 - val_loss: 0.2322 - val_accuracy: 0.6808 - val_precision_m: 0.8591 - val_recall_m: 0.7527 - val_f1_m: 0.8004\n","Epoch 5/10\n","168/168 [==============================] - 27s 163ms/step - loss: 0.2689 - accuracy: 0.6602 - precision_m: 0.8133 - recall_m: 0.7501 - f1_m: 0.7788 - val_loss: 0.2209 - val_accuracy: 0.7181 - val_precision_m: 0.8614 - val_recall_m: 0.7773 - val_f1_m: 0.8154\n","Epoch 6/10\n","168/168 [==============================] - 27s 163ms/step - loss: 0.2593 - accuracy: 0.6636 - precision_m: 0.8182 - recall_m: 0.7594 - f1_m: 0.7861 - val_loss: 0.2162 - val_accuracy: 0.7054 - val_precision_m: 0.8575 - val_recall_m: 0.7871 - val_f1_m: 0.8192\n","Epoch 7/10\n","168/168 [==============================] - 27s 163ms/step - loss: 0.2490 - accuracy: 0.6785 - precision_m: 0.8323 - recall_m: 0.7734 - f1_m: 0.8008 - val_loss: 0.2170 - val_accuracy: 0.7062 - val_precision_m: 0.8546 - val_recall_m: 0.7845 - val_f1_m: 0.8165\n","Epoch 8/10\n","168/168 [==============================] - 27s 163ms/step - loss: 0.2368 - accuracy: 0.6882 - precision_m: 0.8335 - recall_m: 0.7838 - f1_m: 0.8067 - val_loss: 0.2115 - val_accuracy: 0.6764 - val_precision_m: 0.8741 - val_recall_m: 0.7954 - val_f1_m: 0.8314\n","Epoch 9/10\n","168/168 [==============================] - 27s 163ms/step - loss: 0.2332 - accuracy: 0.6923 - precision_m: 0.8381 - recall_m: 0.7870 - f1_m: 0.8105 - val_loss: 0.2138 - val_accuracy: 0.7196 - val_precision_m: 0.8585 - val_recall_m: 0.7829 - val_f1_m: 0.8175\n","Epoch 10/10\n","168/168 [==============================] - 27s 163ms/step - loss: 0.2196 - accuracy: 0.6781 - precision_m: 0.8460 - recall_m: 0.7973 - f1_m: 0.8199 - val_loss: 0.2142 - val_accuracy: 0.7196 - val_precision_m: 0.8610 - val_recall_m: 0.7853 - val_f1_m: 0.8202\n","Score for fold 1: loss of 0.378788024187088; accuracy of 57.76916146278381% ;precision_m of 0.8111826777458191 ;recall_m of 0.6686329245567322 ;            f1_m of 0.7310100793838501\n","Epoch 1/10\n","168/168 [==============================] - 36s 171ms/step - loss: 0.5585 - accuracy: 0.3133 - precision_m: 0.5648 - recall_m: 0.3050 - f1_m: 0.3777 - val_loss: 0.2942 - val_accuracy: 0.6257 - val_precision_m: 0.8212 - val_recall_m: 0.6191 - val_f1_m: 0.7044\n","Epoch 2/10\n","168/168 [==============================] - 27s 160ms/step - loss: 0.3975 - accuracy: 0.5454 - precision_m: 0.7212 - recall_m: 0.6279 - f1_m: 0.6690 - val_loss: 0.2958 - val_accuracy: 0.6495 - val_precision_m: 0.7614 - val_recall_m: 0.7205 - val_f1_m: 0.7386\n","Epoch 3/10\n","168/168 [==============================] - 27s 161ms/step - loss: 0.3631 - accuracy: 0.5796 - precision_m: 0.7482 - recall_m: 0.6804 - f1_m: 0.7113 - val_loss: 0.2452 - val_accuracy: 0.6741 - val_precision_m: 0.8404 - val_recall_m: 0.7397 - val_f1_m: 0.7852\n","Epoch 4/10\n","168/168 [==============================] - 28s 170ms/step - loss: 0.3320 - accuracy: 0.6191 - precision_m: 0.7876 - recall_m: 0.7176 - f1_m: 0.7496 - val_loss: 0.2364 - val_accuracy: 0.7174 - val_precision_m: 0.8738 - val_recall_m: 0.7466 - val_f1_m: 0.8036\n","Epoch 5/10\n","168/168 [==============================] - 28s 168ms/step - loss: 0.3020 - accuracy: 0.6306 - precision_m: 0.8166 - recall_m: 0.7541 - f1_m: 0.7831 - val_loss: 0.2533 - val_accuracy: 0.6861 - val_precision_m: 0.8162 - val_recall_m: 0.7748 - val_f1_m: 0.7938\n","Epoch 6/10\n","168/168 [==============================] - 28s 167ms/step - loss: 0.2924 - accuracy: 0.6269 - precision_m: 0.8184 - recall_m: 0.7705 - f1_m: 0.7926 - val_loss: 0.2222 - val_accuracy: 0.7077 - val_precision_m: 0.8793 - val_recall_m: 0.7694 - val_f1_m: 0.8194\n","Epoch 7/10\n","168/168 [==============================] - 28s 168ms/step - loss: 0.2712 - accuracy: 0.6431 - precision_m: 0.8400 - recall_m: 0.7866 - f1_m: 0.8114 - val_loss: 0.2161 - val_accuracy: 0.7166 - val_precision_m: 0.8639 - val_recall_m: 0.7893 - val_f1_m: 0.8237\n","Epoch 8/10\n","168/168 [==============================] - 28s 168ms/step - loss: 0.2596 - accuracy: 0.6503 - precision_m: 0.8501 - recall_m: 0.7975 - f1_m: 0.8219 - val_loss: 0.2224 - val_accuracy: 0.7010 - val_precision_m: 0.8740 - val_recall_m: 0.7787 - val_f1_m: 0.8220\n","Epoch 9/10\n","168/168 [==============================] - 28s 168ms/step - loss: 0.2512 - accuracy: 0.6450 - precision_m: 0.8505 - recall_m: 0.8110 - f1_m: 0.8291 - val_loss: 0.2185 - val_accuracy: 0.7069 - val_precision_m: 0.8596 - val_recall_m: 0.8067 - val_f1_m: 0.8312\n","Epoch 10/10\n","168/168 [==============================] - 28s 168ms/step - loss: 0.2434 - accuracy: 0.6534 - precision_m: 0.8545 - recall_m: 0.8160 - f1_m: 0.8341 - val_loss: 0.2178 - val_accuracy: 0.7062 - val_precision_m: 0.8723 - val_recall_m: 0.7794 - val_f1_m: 0.8217\n","Score for fold 2: loss of 0.29134514927864075; accuracy of 65.61288237571716% ;precision_m of 0.8138431310653687 ;recall_m of 0.7430984377861023 ;            f1_m of 0.7751848697662354\n","Epoch 1/10\n","168/168 [==============================] - 37s 178ms/step - loss: 0.5618 - accuracy: 0.3081 - precision_m: 0.5713 - recall_m: 0.3298 - f1_m: 0.3881 - val_loss: 0.3725 - val_accuracy: 0.5484 - val_precision_m: 0.7329 - val_recall_m: 0.5893 - val_f1_m: 0.6522\n","Epoch 2/10\n","168/168 [==============================] - 28s 166ms/step - loss: 0.4119 - accuracy: 0.5360 - precision_m: 0.7225 - recall_m: 0.6260 - f1_m: 0.6687 - val_loss: 0.3228 - val_accuracy: 0.6080 - val_precision_m: 0.7371 - val_recall_m: 0.6799 - val_f1_m: 0.7060\n","Epoch 3/10\n","168/168 [==============================] - 28s 166ms/step - loss: 0.3647 - accuracy: 0.5873 - precision_m: 0.7680 - recall_m: 0.6968 - f1_m: 0.7290 - val_loss: 0.2852 - val_accuracy: 0.6177 - val_precision_m: 0.7997 - val_recall_m: 0.7155 - val_f1_m: 0.7539\n","Epoch 4/10\n","168/168 [==============================] - 28s 167ms/step - loss: 0.3288 - accuracy: 0.6072 - precision_m: 0.8002 - recall_m: 0.7363 - f1_m: 0.7655 - val_loss: 0.2843 - val_accuracy: 0.6095 - val_precision_m: 0.8104 - val_recall_m: 0.7140 - val_f1_m: 0.7577\n","Epoch 5/10\n","168/168 [==============================] - 28s 167ms/step - loss: 0.3114 - accuracy: 0.5997 - precision_m: 0.8191 - recall_m: 0.7483 - f1_m: 0.7810 - val_loss: 0.2784 - val_accuracy: 0.5991 - val_precision_m: 0.8297 - val_recall_m: 0.7149 - val_f1_m: 0.7668\n","Epoch 6/10\n","168/168 [==============================] - 28s 167ms/step - loss: 0.2895 - accuracy: 0.6116 - precision_m: 0.8261 - recall_m: 0.7775 - f1_m: 0.7993 - val_loss: 0.2722 - val_accuracy: 0.6475 - val_precision_m: 0.8261 - val_recall_m: 0.7134 - val_f1_m: 0.7645\n","Epoch 7/10\n","168/168 [==============================] - 28s 167ms/step - loss: 0.2982 - accuracy: 0.6045 - precision_m: 0.8253 - recall_m: 0.7665 - f1_m: 0.7935 - val_loss: 0.2699 - val_accuracy: 0.6453 - val_precision_m: 0.8083 - val_recall_m: 0.7622 - val_f1_m: 0.7834\n","Epoch 8/10\n","168/168 [==============================] - 28s 167ms/step - loss: 0.2806 - accuracy: 0.6069 - precision_m: 0.8328 - recall_m: 0.7835 - f1_m: 0.8064 - val_loss: 0.2697 - val_accuracy: 0.6244 - val_precision_m: 0.8239 - val_recall_m: 0.7463 - val_f1_m: 0.7821\n","Epoch 9/10\n","168/168 [==============================] - 28s 167ms/step - loss: 0.2718 - accuracy: 0.6357 - precision_m: 0.8325 - recall_m: 0.7930 - f1_m: 0.8113 - val_loss: 0.2628 - val_accuracy: 0.6416 - val_precision_m: 0.8333 - val_recall_m: 0.7557 - val_f1_m: 0.7913\n","Epoch 10/10\n","168/168 [==============================] - 28s 167ms/step - loss: 0.2639 - accuracy: 0.6225 - precision_m: 0.8400 - recall_m: 0.8012 - f1_m: 0.8191 - val_loss: 0.2701 - val_accuracy: 0.6498 - val_precision_m: 0.8443 - val_recall_m: 0.7217 - val_f1_m: 0.7773\n","Score for fold 3: loss of 0.2430695742368698; accuracy of 67.78042912483215% ;precision_m of 0.855340301990509 ;recall_m of 0.7477216720581055 ;            f1_m of 0.7961856722831726\n","1\n","1.1\n","Epoch 1/10\n","168/168 [==============================] - 8s 41ms/step - loss: 0.6832 - accuracy: 0.2922 - precision_m: 0.5144 - recall_m: 0.3335 - f1_m: 0.4041 - val_loss: 0.6461 - val_accuracy: 0.4318 - val_precision_m: 0.6636 - val_recall_m: 0.4957 - val_f1_m: 0.5664\n","Epoch 2/10\n","168/168 [==============================] - 6s 38ms/step - loss: 0.6480 - accuracy: 0.3032 - precision_m: 0.5355 - recall_m: 0.3490 - f1_m: 0.4219 - val_loss: 0.6083 - val_accuracy: 0.4318 - val_precision_m: 0.6636 - val_recall_m: 0.4957 - val_f1_m: 0.5664\n","Epoch 3/10\n","168/168 [==============================] - 6s 38ms/step - loss: 0.6206 - accuracy: 0.2964 - precision_m: 0.5310 - recall_m: 0.3443 - f1_m: 0.4172 - val_loss: 0.5775 - val_accuracy: 0.4318 - val_precision_m: 0.6636 - val_recall_m: 0.4957 - val_f1_m: 0.5664\n","Epoch 4/10\n","168/168 [==============================] - 6s 38ms/step - loss: 0.5953 - accuracy: 0.3115 - precision_m: 0.5443 - recall_m: 0.3596 - f1_m: 0.4326 - val_loss: 0.5528 - val_accuracy: 0.4318 - val_precision_m: 0.6636 - val_recall_m: 0.4957 - val_f1_m: 0.5664\n","Epoch 5/10\n","168/168 [==============================] - 6s 38ms/step - loss: 0.5798 - accuracy: 0.3069 - precision_m: 0.5406 - recall_m: 0.3529 - f1_m: 0.4264 - val_loss: 0.5330 - val_accuracy: 0.4318 - val_precision_m: 0.6636 - val_recall_m: 0.4957 - val_f1_m: 0.5664\n","Epoch 6/10\n","168/168 [==============================] - 6s 38ms/step - loss: 0.5630 - accuracy: 0.3213 - precision_m: 0.5476 - recall_m: 0.3619 - f1_m: 0.4353 - val_loss: 0.5168 - val_accuracy: 0.4318 - val_precision_m: 0.6636 - val_recall_m: 0.4957 - val_f1_m: 0.5664\n","Epoch 7/10\n","168/168 [==============================] - 6s 38ms/step - loss: 0.5536 - accuracy: 0.3148 - precision_m: 0.5441 - recall_m: 0.3568 - f1_m: 0.4304 - val_loss: 0.5041 - val_accuracy: 0.4318 - val_precision_m: 0.6636 - val_recall_m: 0.4957 - val_f1_m: 0.5664\n","Epoch 8/10\n","168/168 [==============================] - 6s 38ms/step - loss: 0.5487 - accuracy: 0.3052 - precision_m: 0.5246 - recall_m: 0.3436 - f1_m: 0.4148 - val_loss: 0.4938 - val_accuracy: 0.4318 - val_precision_m: 0.6636 - val_recall_m: 0.4957 - val_f1_m: 0.5664\n","Epoch 9/10\n","168/168 [==============================] - 6s 38ms/step - loss: 0.5416 - accuracy: 0.3030 - precision_m: 0.5377 - recall_m: 0.3502 - f1_m: 0.4237 - val_loss: 0.4856 - val_accuracy: 0.4318 - val_precision_m: 0.6636 - val_recall_m: 0.4957 - val_f1_m: 0.5664\n","Epoch 10/10\n","168/168 [==============================] - 6s 38ms/step - loss: 0.5382 - accuracy: 0.2978 - precision_m: 0.5311 - recall_m: 0.3460 - f1_m: 0.4184 - val_loss: 0.4790 - val_accuracy: 0.4318 - val_precision_m: 0.6636 - val_recall_m: 0.4957 - val_f1_m: 0.5664\n","Score for fold 1: loss of 0.6202220916748047; accuracy of 16.373397409915924% ;precision_m of 0.5160476565361023 ;recall_m of 0.26589879393577576 ;            f1_m of 0.34966719150543213\n","Epoch 1/10\n","168/168 [==============================] - 9s 42ms/step - loss: 0.6038 - accuracy: 0.2200 - precision_m: 0.5219 - recall_m: 0.2404 - f1_m: 0.3246 - val_loss: 0.4523 - val_accuracy: 0.4318 - val_precision_m: 0.6636 - val_recall_m: 0.4957 - val_f1_m: 0.5664\n","Epoch 2/10\n","168/168 [==============================] - 7s 39ms/step - loss: 0.5846 - accuracy: 0.2240 - precision_m: 0.5292 - recall_m: 0.2363 - f1_m: 0.3186 - val_loss: 0.4769 - val_accuracy: 0.4318 - val_precision_m: 0.6636 - val_recall_m: 0.4957 - val_f1_m: 0.5664\n","Epoch 3/10\n","168/168 [==============================] - 6s 39ms/step - loss: 0.5757 - accuracy: 0.2391 - precision_m: 0.5346 - recall_m: 0.2690 - f1_m: 0.3566 - val_loss: 0.4746 - val_accuracy: 0.4318 - val_precision_m: 0.6636 - val_recall_m: 0.4957 - val_f1_m: 0.5664\n","Epoch 4/10\n","168/168 [==============================] - 7s 39ms/step - loss: 0.5771 - accuracy: 0.2308 - precision_m: 0.5363 - recall_m: 0.2696 - f1_m: 0.3563 - val_loss: 0.4675 - val_accuracy: 0.4318 - val_precision_m: 0.6636 - val_recall_m: 0.4957 - val_f1_m: 0.5664\n","Epoch 5/10\n","168/168 [==============================] - 7s 39ms/step - loss: 0.5810 - accuracy: 0.2296 - precision_m: 0.5479 - recall_m: 0.2928 - f1_m: 0.3808 - val_loss: 0.4828 - val_accuracy: 0.4318 - val_precision_m: 0.6636 - val_recall_m: 0.4957 - val_f1_m: 0.5664\n","Epoch 6/10\n","168/168 [==============================] - 7s 39ms/step - loss: 0.5840 - accuracy: 0.2167 - precision_m: 0.5242 - recall_m: 0.2484 - f1_m: 0.3344 - val_loss: 0.4661 - val_accuracy: 0.4318 - val_precision_m: 0.6636 - val_recall_m: 0.4957 - val_f1_m: 0.5664\n","Epoch 7/10\n","168/168 [==============================] - 7s 39ms/step - loss: 0.5771 - accuracy: 0.2323 - precision_m: 0.5380 - recall_m: 0.2984 - f1_m: 0.3832 - val_loss: 0.4710 - val_accuracy: 0.4318 - val_precision_m: 0.6636 - val_recall_m: 0.4957 - val_f1_m: 0.5664\n","Epoch 8/10\n","168/168 [==============================] - 7s 39ms/step - loss: 0.5778 - accuracy: 0.2286 - precision_m: 0.5342 - recall_m: 0.2881 - f1_m: 0.3736 - val_loss: 0.4629 - val_accuracy: 0.4318 - val_precision_m: 0.6636 - val_recall_m: 0.4957 - val_f1_m: 0.5664\n","Epoch 9/10\n","168/168 [==============================] - 7s 39ms/step - loss: 0.5795 - accuracy: 0.2301 - precision_m: 0.5371 - recall_m: 0.2978 - f1_m: 0.3826 - val_loss: 0.4711 - val_accuracy: 0.4318 - val_precision_m: 0.6636 - val_recall_m: 0.4957 - val_f1_m: 0.5664\n","Epoch 10/10\n","168/168 [==============================] - 7s 39ms/step - loss: 0.5812 - accuracy: 0.2261 - precision_m: 0.5371 - recall_m: 0.2992 - f1_m: 0.3837 - val_loss: 0.4723 - val_accuracy: 0.4318 - val_precision_m: 0.6636 - val_recall_m: 0.4957 - val_f1_m: 0.5664\n","Score for fold 2: loss of 0.541931688785553; accuracy of 28.511780500411987% ;precision_m of 0.5150595307350159 ;recall_m of 0.33347252011299133 ;            f1_m of 0.40342390537261963\n","Epoch 1/10\n","168/168 [==============================] - 9s 41ms/step - loss: 0.6200 - accuracy: 0.2043 - precision_m: 0.4650 - recall_m: 0.1475 - f1_m: 0.2110 - val_loss: 0.5325 - val_accuracy: 0.3040 - val_precision_m: 0.5332 - val_recall_m: 0.3561 - val_f1_m: 0.4257\n","Epoch 2/10\n","168/168 [==============================] - 6s 38ms/step - loss: 0.5978 - accuracy: 0.2095 - precision_m: 0.5132 - recall_m: 0.1898 - f1_m: 0.2715 - val_loss: 0.5421 - val_accuracy: 0.3040 - val_precision_m: 0.5332 - val_recall_m: 0.3561 - val_f1_m: 0.4257\n","Epoch 3/10\n","168/168 [==============================] - 6s 37ms/step - loss: 0.5982 - accuracy: 0.1994 - precision_m: 0.5065 - recall_m: 0.1884 - f1_m: 0.2681 - val_loss: 0.5402 - val_accuracy: 0.3040 - val_precision_m: 0.5332 - val_recall_m: 0.3561 - val_f1_m: 0.4257\n","Epoch 4/10\n","168/168 [==============================] - 6s 38ms/step - loss: 0.6009 - accuracy: 0.1902 - precision_m: 0.4944 - recall_m: 0.1397 - f1_m: 0.2110 - val_loss: 0.5278 - val_accuracy: 0.3040 - val_precision_m: 0.5332 - val_recall_m: 0.3561 - val_f1_m: 0.4257\n","Epoch 5/10\n","168/168 [==============================] - 6s 38ms/step - loss: 0.5972 - accuracy: 0.2044 - precision_m: 0.4911 - recall_m: 0.1831 - f1_m: 0.2596 - val_loss: 0.5336 - val_accuracy: 0.3040 - val_precision_m: 0.5332 - val_recall_m: 0.3561 - val_f1_m: 0.4257\n","Epoch 6/10\n","168/168 [==============================] - 6s 38ms/step - loss: 0.5911 - accuracy: 0.2113 - precision_m: 0.5168 - recall_m: 0.1907 - f1_m: 0.2756 - val_loss: 0.5362 - val_accuracy: 0.3040 - val_precision_m: 0.5332 - val_recall_m: 0.3561 - val_f1_m: 0.4257\n","Epoch 7/10\n","168/168 [==============================] - 6s 38ms/step - loss: 0.5931 - accuracy: 0.2125 - precision_m: 0.5220 - recall_m: 0.2459 - f1_m: 0.3329 - val_loss: 0.5309 - val_accuracy: 0.3040 - val_precision_m: 0.5332 - val_recall_m: 0.3561 - val_f1_m: 0.4257\n","Epoch 8/10\n","168/168 [==============================] - 6s 38ms/step - loss: 0.5918 - accuracy: 0.2175 - precision_m: 0.4973 - recall_m: 0.1636 - f1_m: 0.2419 - val_loss: 0.5355 - val_accuracy: 0.3040 - val_precision_m: 0.5332 - val_recall_m: 0.3561 - val_f1_m: 0.4257\n","Epoch 9/10\n","168/168 [==============================] - 6s 38ms/step - loss: 0.5971 - accuracy: 0.2021 - precision_m: 0.5114 - recall_m: 0.1716 - f1_m: 0.2500 - val_loss: 0.5334 - val_accuracy: 0.3040 - val_precision_m: 0.5332 - val_recall_m: 0.3561 - val_f1_m: 0.4257\n","Epoch 10/10\n","168/168 [==============================] - 6s 38ms/step - loss: 0.5966 - accuracy: 0.1990 - precision_m: 0.5011 - recall_m: 0.1926 - f1_m: 0.2732 - val_loss: 0.5232 - val_accuracy: 0.3040 - val_precision_m: 0.5332 - val_recall_m: 0.3561 - val_f1_m: 0.4257\n","Score for fold 3: loss of 0.49062833189964294; accuracy of 37.47016787528992% ;precision_m of 0.6107142567634583 ;recall_m of 0.43802905082702637 ;            f1_m of 0.5087757110595703\n","1\n","1.2\n","Epoch 1/10\n","168/168 [==============================] - 11s 51ms/step - loss: 0.5614 - accuracy: 0.3035 - precision_m: 0.5283 - recall_m: 0.2247 - f1_m: 0.2980 - val_loss: 0.4611 - val_accuracy: 0.4318 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00 - val_f1_m: 0.0000e+00\n","Epoch 2/10\n","168/168 [==============================] - 8s 48ms/step - loss: 0.5255 - accuracy: 0.3093 - precision_m: 0.5305 - recall_m: 0.2294 - f1_m: 0.3112 - val_loss: 0.4575 - val_accuracy: 0.4318 - val_precision_m: 0.6636 - val_recall_m: 0.4957 - val_f1_m: 0.5664\n","Epoch 3/10\n","168/168 [==============================] - 8s 47ms/step - loss: 0.5235 - accuracy: 0.3056 - precision_m: 0.5418 - recall_m: 0.2809 - f1_m: 0.3671 - val_loss: 0.4532 - val_accuracy: 0.4318 - val_precision_m: 0.6636 - val_recall_m: 0.4957 - val_f1_m: 0.5664\n","Epoch 4/10\n","168/168 [==============================] - 8s 48ms/step - loss: 0.5257 - accuracy: 0.3007 - precision_m: 0.5381 - recall_m: 0.2906 - f1_m: 0.3747 - val_loss: 0.4615 - val_accuracy: 0.4318 - val_precision_m: 0.6636 - val_recall_m: 0.4957 - val_f1_m: 0.5664\n","Epoch 5/10\n","168/168 [==============================] - 8s 48ms/step - loss: 0.5220 - accuracy: 0.3039 - precision_m: 0.5370 - recall_m: 0.3036 - f1_m: 0.3830 - val_loss: 0.4540 - val_accuracy: 0.4318 - val_precision_m: 0.6636 - val_recall_m: 0.4957 - val_f1_m: 0.5664\n","Epoch 6/10\n","168/168 [==============================] - 8s 48ms/step - loss: 0.5199 - accuracy: 0.3010 - precision_m: 0.5221 - recall_m: 0.2668 - f1_m: 0.3479 - val_loss: 0.4528 - val_accuracy: 0.4318 - val_precision_m: 0.6636 - val_recall_m: 0.4957 - val_f1_m: 0.5664\n","Epoch 7/10\n","168/168 [==============================] - 8s 47ms/step - loss: 0.5181 - accuracy: 0.3103 - precision_m: 0.5361 - recall_m: 0.3344 - f1_m: 0.4104 - val_loss: 0.4574 - val_accuracy: 0.4318 - val_precision_m: 0.6636 - val_recall_m: 0.4957 - val_f1_m: 0.5664\n","Epoch 8/10\n","168/168 [==============================] - 8s 48ms/step - loss: 0.5253 - accuracy: 0.2982 - precision_m: 0.5216 - recall_m: 0.2609 - f1_m: 0.3423 - val_loss: 0.4546 - val_accuracy: 0.4318 - val_precision_m: 0.6636 - val_recall_m: 0.4957 - val_f1_m: 0.5664\n","Epoch 9/10\n","168/168 [==============================] - 8s 48ms/step - loss: 0.5196 - accuracy: 0.3076 - precision_m: 0.5395 - recall_m: 0.3378 - f1_m: 0.4146 - val_loss: 0.4574 - val_accuracy: 0.4318 - val_precision_m: 0.6636 - val_recall_m: 0.4957 - val_f1_m: 0.5664\n","Epoch 10/10\n","168/168 [==============================] - 8s 48ms/step - loss: 0.5186 - accuracy: 0.3039 - precision_m: 0.5348 - recall_m: 0.3163 - f1_m: 0.3959 - val_loss: 0.4568 - val_accuracy: 0.4318 - val_precision_m: 0.6636 - val_recall_m: 0.4957 - val_f1_m: 0.5664\n","Score for fold 1: loss of 0.6447307467460632; accuracy of 16.373397409915924% ;precision_m of 0.5160476565361023 ;recall_m of 0.26589879393577576 ;            f1_m of 0.34966719150543213\n","Epoch 1/10\n","168/168 [==============================] - 10s 51ms/step - loss: 0.6088 - accuracy: 0.2249 - precision_m: 0.5112 - recall_m: 0.1974 - f1_m: 0.2788 - val_loss: 0.5000 - val_accuracy: 0.4318 - val_precision_m: 0.6636 - val_recall_m: 0.4957 - val_f1_m: 0.5664\n","Epoch 2/10\n","168/168 [==============================] - 8s 48ms/step - loss: 0.5870 - accuracy: 0.2328 - precision_m: 0.5453 - recall_m: 0.2424 - f1_m: 0.3323 - val_loss: 0.4702 - val_accuracy: 0.4318 - val_precision_m: 0.6636 - val_recall_m: 0.4957 - val_f1_m: 0.5664\n","Epoch 3/10\n","168/168 [==============================] - 8s 48ms/step - loss: 0.5853 - accuracy: 0.2177 - precision_m: 0.5235 - recall_m: 0.2460 - f1_m: 0.3323 - val_loss: 0.4722 - val_accuracy: 0.4318 - val_precision_m: 0.6636 - val_recall_m: 0.4957 - val_f1_m: 0.5664\n","Epoch 4/10\n","168/168 [==============================] - 8s 48ms/step - loss: 0.5815 - accuracy: 0.2302 - precision_m: 0.5424 - recall_m: 0.2824 - f1_m: 0.3695 - val_loss: 0.4738 - val_accuracy: 0.4318 - val_precision_m: 0.6636 - val_recall_m: 0.4957 - val_f1_m: 0.5664\n","Epoch 5/10\n","168/168 [==============================] - 8s 48ms/step - loss: 0.5811 - accuracy: 0.2287 - precision_m: 0.5352 - recall_m: 0.2733 - f1_m: 0.3605 - val_loss: 0.4683 - val_accuracy: 0.4318 - val_precision_m: 0.6636 - val_recall_m: 0.4957 - val_f1_m: 0.5664\n","Epoch 6/10\n","168/168 [==============================] - 8s 47ms/step - loss: 0.5801 - accuracy: 0.2264 - precision_m: 0.5392 - recall_m: 0.2939 - f1_m: 0.3797 - val_loss: 0.4815 - val_accuracy: 0.4318 - val_precision_m: 0.6636 - val_recall_m: 0.4957 - val_f1_m: 0.5664\n","Epoch 7/10\n","168/168 [==============================] - 8s 48ms/step - loss: 0.5811 - accuracy: 0.2327 - precision_m: 0.5337 - recall_m: 0.2859 - f1_m: 0.3713 - val_loss: 0.4633 - val_accuracy: 0.4318 - val_precision_m: 0.6636 - val_recall_m: 0.4957 - val_f1_m: 0.5664\n","Epoch 8/10\n","168/168 [==============================] - 8s 47ms/step - loss: 0.5833 - accuracy: 0.2227 - precision_m: 0.5362 - recall_m: 0.2876 - f1_m: 0.3736 - val_loss: 0.4827 - val_accuracy: 0.4318 - val_precision_m: 0.6636 - val_recall_m: 0.4957 - val_f1_m: 0.5664\n","Epoch 9/10\n","168/168 [==============================] - 8s 48ms/step - loss: 0.5774 - accuracy: 0.2340 - precision_m: 0.5413 - recall_m: 0.2952 - f1_m: 0.3810 - val_loss: 0.4782 - val_accuracy: 0.4318 - val_precision_m: 0.6636 - val_recall_m: 0.4957 - val_f1_m: 0.5664\n","Epoch 10/10\n","168/168 [==============================] - 8s 47ms/step - loss: 0.5768 - accuracy: 0.2273 - precision_m: 0.5412 - recall_m: 0.3035 - f1_m: 0.3884 - val_loss: 0.4771 - val_accuracy: 0.4318 - val_precision_m: 0.6636 - val_recall_m: 0.4957 - val_f1_m: 0.5664\n","Score for fold 2: loss of 0.5452094674110413; accuracy of 28.511780500411987% ;precision_m of 0.5150595307350159 ;recall_m of 0.33347252011299133 ;            f1_m of 0.40342390537261963\n","Epoch 1/10\n","168/168 [==============================] - 10s 52ms/step - loss: 0.6291 - accuracy: 0.2009 - precision_m: 0.4281 - recall_m: 0.1549 - f1_m: 0.2106 - val_loss: 0.5346 - val_accuracy: 0.3040 - val_precision_m: 0.5332 - val_recall_m: 0.3561 - val_f1_m: 0.4257\n","Epoch 2/10\n","168/168 [==============================] - 8s 49ms/step - loss: 0.5992 - accuracy: 0.2007 - precision_m: 0.5018 - recall_m: 0.1842 - f1_m: 0.2669 - val_loss: 0.5472 - val_accuracy: 0.3040 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00 - val_f1_m: 0.0000e+00\n","Epoch 3/10\n","168/168 [==============================] - 8s 49ms/step - loss: 0.5991 - accuracy: 0.1954 - precision_m: 0.5007 - recall_m: 0.1407 - f1_m: 0.2140 - val_loss: 0.5291 - val_accuracy: 0.3040 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00 - val_f1_m: 0.0000e+00\n","Epoch 4/10\n","168/168 [==============================] - 8s 49ms/step - loss: 0.5898 - accuracy: 0.2127 - precision_m: 0.5167 - recall_m: 0.2128 - f1_m: 0.2965 - val_loss: 0.5352 - val_accuracy: 0.3040 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00 - val_f1_m: 0.0000e+00\n","Epoch 5/10\n","168/168 [==============================] - 8s 49ms/step - loss: 0.5984 - accuracy: 0.2007 - precision_m: 0.3174 - recall_m: 0.1039 - f1_m: 0.1454 - val_loss: 0.5317 - val_accuracy: 0.3040 - val_precision_m: 0.5332 - val_recall_m: 0.3561 - val_f1_m: 0.4257\n","Epoch 6/10\n","168/168 [==============================] - 8s 49ms/step - loss: 0.5966 - accuracy: 0.1982 - precision_m: 0.5050 - recall_m: 0.1444 - f1_m: 0.2195 - val_loss: 0.5315 - val_accuracy: 0.3040 - val_precision_m: 0.5332 - val_recall_m: 0.3561 - val_f1_m: 0.4257\n","Epoch 7/10\n","168/168 [==============================] - 8s 49ms/step - loss: 0.5944 - accuracy: 0.2082 - precision_m: 0.5002 - recall_m: 0.1482 - f1_m: 0.2242 - val_loss: 0.5389 - val_accuracy: 0.3040 - val_precision_m: 0.5332 - val_recall_m: 0.3561 - val_f1_m: 0.4257\n","Epoch 8/10\n","168/168 [==============================] - 8s 48ms/step - loss: 0.5901 - accuracy: 0.2186 - precision_m: 0.5230 - recall_m: 0.2203 - f1_m: 0.3078 - val_loss: 0.5285 - val_accuracy: 0.3040 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00 - val_f1_m: 0.0000e+00\n","Epoch 9/10\n","168/168 [==============================] - 8s 48ms/step - loss: 0.5952 - accuracy: 0.2112 - precision_m: 0.5124 - recall_m: 0.1793 - f1_m: 0.2614 - val_loss: 0.5274 - val_accuracy: 0.3040 - val_precision_m: 0.5332 - val_recall_m: 0.3561 - val_f1_m: 0.4257\n","Epoch 10/10\n","168/168 [==============================] - 8s 48ms/step - loss: 0.5970 - accuracy: 0.2093 - precision_m: 0.5093 - recall_m: 0.2182 - f1_m: 0.3031 - val_loss: 0.5278 - val_accuracy: 0.3040 - val_precision_m: 0.5332 - val_recall_m: 0.3561 - val_f1_m: 0.4257\n","Score for fold 3: loss of 0.49891898036003113; accuracy of 37.47016787528992% ;precision_m of 0.6107142567634583 ;recall_m of 0.43802905082702637 ;            f1_m of 0.5087757110595703\n","2\n","Epoch 1/10\n","168/168 [==============================] - 38s 219ms/step - loss: 0.6008 - accuracy: 0.2535 - precision_m: 0.4559 - recall_m: 0.2767 - f1_m: 0.3158 - val_loss: 0.4607 - val_accuracy: 0.4318 - val_precision_m: 0.6636 - val_recall_m: 0.4957 - val_f1_m: 0.5664\n","Epoch 2/10\n","168/168 [==============================] - 36s 214ms/step - loss: 0.5298 - accuracy: 0.3061 - precision_m: 0.5326 - recall_m: 0.2386 - f1_m: 0.3262 - val_loss: 0.4482 - val_accuracy: 0.4318 - val_precision_m: 0.6636 - val_recall_m: 0.4957 - val_f1_m: 0.5664\n","Epoch 3/10\n","168/168 [==============================] - 36s 214ms/step - loss: 0.5271 - accuracy: 0.3043 - precision_m: 0.5445 - recall_m: 0.2731 - f1_m: 0.3606 - val_loss: 0.4679 - val_accuracy: 0.4318 - val_precision_m: 0.6636 - val_recall_m: 0.4957 - val_f1_m: 0.5664\n","Epoch 4/10\n","168/168 [==============================] - 36s 216ms/step - loss: 0.5311 - accuracy: 0.3006 - precision_m: 0.5206 - recall_m: 0.2242 - f1_m: 0.3076 - val_loss: 0.4651 - val_accuracy: 0.4318 - val_precision_m: 0.6636 - val_recall_m: 0.4957 - val_f1_m: 0.5664\n","Epoch 5/10\n","168/168 [==============================] - 36s 216ms/step - loss: 0.5307 - accuracy: 0.2938 - precision_m: 0.5266 - recall_m: 0.2967 - f1_m: 0.3767 - val_loss: 0.4504 - val_accuracy: 0.4318 - val_precision_m: 0.6636 - val_recall_m: 0.4957 - val_f1_m: 0.5664\n","Epoch 6/10\n","168/168 [==============================] - 36s 213ms/step - loss: 0.5308 - accuracy: 0.2992 - precision_m: 0.5307 - recall_m: 0.3286 - f1_m: 0.4043 - val_loss: 0.4582 - val_accuracy: 0.4318 - val_precision_m: 0.6636 - val_recall_m: 0.4957 - val_f1_m: 0.5664\n","Epoch 7/10\n","168/168 [==============================] - 36s 214ms/step - loss: 0.5239 - accuracy: 0.3162 - precision_m: 0.5462 - recall_m: 0.3483 - f1_m: 0.4243 - val_loss: 0.4698 - val_accuracy: 0.4318 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00 - val_f1_m: 0.0000e+00\n","Epoch 8/10\n","168/168 [==============================] - 36s 215ms/step - loss: 0.5308 - accuracy: 0.2930 - precision_m: 0.5207 - recall_m: 0.2704 - f1_m: 0.3485 - val_loss: 0.4521 - val_accuracy: 0.4318 - val_precision_m: 0.6636 - val_recall_m: 0.4957 - val_f1_m: 0.5664\n","Epoch 9/10\n","168/168 [==============================] - 36s 216ms/step - loss: 0.5236 - accuracy: 0.2959 - precision_m: 0.5358 - recall_m: 0.3409 - f1_m: 0.4156 - val_loss: 0.4523 - val_accuracy: 0.4318 - val_precision_m: 0.6628 - val_recall_m: 0.4952 - val_f1_m: 0.5658\n","Epoch 10/10\n","168/168 [==============================] - 37s 218ms/step - loss: 0.5262 - accuracy: 0.3058 - precision_m: 0.5560 - recall_m: 0.3008 - f1_m: 0.3835 - val_loss: 0.4603 - val_accuracy: 0.4310 - val_precision_m: 0.6621 - val_recall_m: 0.4946 - val_f1_m: 0.5651\n","Score for fold 1: loss of 0.6511932611465454; accuracy of 16.373397409915924% ;precision_m of 0.5160476565361023 ;recall_m of 0.26589879393577576 ;            f1_m of 0.34966719150543213\n","Epoch 1/10\n","168/168 [==============================] - 37s 216ms/step - loss: 0.6233 - accuracy: 0.2242 - precision_m: 0.4610 - recall_m: 0.2617 - f1_m: 0.3128 - val_loss: 0.4886 - val_accuracy: 0.4318 - val_precision_m: 0.6636 - val_recall_m: 0.4957 - val_f1_m: 0.5664\n","Epoch 2/10\n","168/168 [==============================] - 35s 211ms/step - loss: 0.5861 - accuracy: 0.2335 - precision_m: 0.5346 - recall_m: 0.2377 - f1_m: 0.3271 - val_loss: 0.5005 - val_accuracy: 0.4318 - val_precision_m: 0.6636 - val_recall_m: 0.4957 - val_f1_m: 0.5664\n","Epoch 3/10\n","168/168 [==============================] - 36s 213ms/step - loss: 0.5889 - accuracy: 0.2228 - precision_m: 0.5268 - recall_m: 0.2565 - f1_m: 0.3433 - val_loss: 0.4846 - val_accuracy: 0.4318 - val_precision_m: 0.6636 - val_recall_m: 0.4957 - val_f1_m: 0.5664\n","Epoch 4/10\n","168/168 [==============================] - 36s 214ms/step - loss: 0.5868 - accuracy: 0.2317 - precision_m: 0.5388 - recall_m: 0.2821 - f1_m: 0.3691 - val_loss: 0.4704 - val_accuracy: 0.4318 - val_precision_m: 0.6636 - val_recall_m: 0.4957 - val_f1_m: 0.5664\n","Epoch 5/10\n","168/168 [==============================] - 37s 219ms/step - loss: 0.5845 - accuracy: 0.2293 - precision_m: 0.5391 - recall_m: 0.2907 - f1_m: 0.3766 - val_loss: 0.4778 - val_accuracy: 0.4318 - val_precision_m: 0.6636 - val_recall_m: 0.4957 - val_f1_m: 0.5664\n","Epoch 6/10\n","168/168 [==============================] - 36s 217ms/step - loss: 0.5823 - accuracy: 0.2301 - precision_m: 0.5370 - recall_m: 0.2840 - f1_m: 0.3678 - val_loss: 0.4821 - val_accuracy: 0.4318 - val_precision_m: 0.6636 - val_recall_m: 0.4957 - val_f1_m: 0.5664\n","Epoch 7/10\n","168/168 [==============================] - 37s 218ms/step - loss: 0.5822 - accuracy: 0.2357 - precision_m: 0.5421 - recall_m: 0.3051 - f1_m: 0.3897 - val_loss: 0.4866 - val_accuracy: 0.4318 - val_precision_m: 0.6636 - val_recall_m: 0.4957 - val_f1_m: 0.5664\n","Epoch 8/10\n","168/168 [==============================] - 36s 215ms/step - loss: 0.5853 - accuracy: 0.2274 - precision_m: 0.5345 - recall_m: 0.2849 - f1_m: 0.3690 - val_loss: 0.4761 - val_accuracy: 0.4318 - val_precision_m: 0.6636 - val_recall_m: 0.4957 - val_f1_m: 0.5664\n","Epoch 9/10\n","168/168 [==============================] - 37s 219ms/step - loss: 0.5855 - accuracy: 0.2276 - precision_m: 0.5372 - recall_m: 0.2962 - f1_m: 0.3812 - val_loss: 0.4794 - val_accuracy: 0.4318 - val_precision_m: 0.6636 - val_recall_m: 0.4957 - val_f1_m: 0.5664\n","Epoch 10/10\n","168/168 [==============================] - 37s 219ms/step - loss: 0.5840 - accuracy: 0.2312 - precision_m: 0.5423 - recall_m: 0.3018 - f1_m: 0.3873 - val_loss: 0.4783 - val_accuracy: 0.4318 - val_precision_m: 0.6636 - val_recall_m: 0.4957 - val_f1_m: 0.5664\n","Score for fold 2: loss of 0.5447161197662354; accuracy of 28.511780500411987% ;precision_m of 0.5150595307350159 ;recall_m of 0.33347252011299133 ;            f1_m of 0.40342390537261963\n","Epoch 1/10\n","168/168 [==============================] - 38s 221ms/step - loss: 0.6889 - accuracy: 0.1948 - precision_m: 0.3873 - recall_m: 0.2788 - f1_m: 0.3051 - val_loss: 0.5284 - val_accuracy: 0.3040 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00 - val_f1_m: 0.0000e+00\n","Epoch 2/10\n","168/168 [==============================] - 37s 218ms/step - loss: 0.6477 - accuracy: 0.1967 - precision_m: 0.4138 - recall_m: 0.2010 - f1_m: 0.2669 - val_loss: 0.5397 - val_accuracy: 0.2787 - val_precision_m: 0.5260 - val_recall_m: 0.2344 - val_f1_m: 0.3234\n","Epoch 3/10\n","168/168 [==============================] - 37s 220ms/step - loss: 0.6325 - accuracy: 0.1995 - precision_m: 0.4274 - recall_m: 0.1806 - f1_m: 0.2495 - val_loss: 0.5402 - val_accuracy: 0.3040 - val_precision_m: 0.5416 - val_recall_m: 0.1203 - val_f1_m: 0.1920\n","Epoch 4/10\n","168/168 [==============================] - 37s 220ms/step - loss: 0.6247 - accuracy: 0.1899 - precision_m: 0.4450 - recall_m: 0.1577 - f1_m: 0.2283 - val_loss: 0.5227 - val_accuracy: 0.3040 - val_precision_m: 0.5332 - val_recall_m: 0.3561 - val_f1_m: 0.4257\n","Epoch 5/10\n","168/168 [==============================] - 36s 214ms/step - loss: 0.6203 - accuracy: 0.1871 - precision_m: 0.4716 - recall_m: 0.1660 - f1_m: 0.2410 - val_loss: 0.5245 - val_accuracy: 0.3040 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00 - val_f1_m: 0.0000e+00\n","Epoch 6/10\n","168/168 [==============================] - 37s 220ms/step - loss: 0.6064 - accuracy: 0.2103 - precision_m: 0.4779 - recall_m: 0.1485 - f1_m: 0.2175 - val_loss: 0.5358 - val_accuracy: 0.3040 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00 - val_f1_m: 0.0000e+00\n","Epoch 7/10\n","168/168 [==============================] - 37s 219ms/step - loss: 0.6055 - accuracy: 0.2052 - precision_m: 0.4804 - recall_m: 0.1408 - f1_m: 0.2095 - val_loss: 0.5399 - val_accuracy: 0.3040 - val_precision_m: 0.5277 - val_recall_m: 0.2358 - val_f1_m: 0.3251\n","Epoch 8/10\n","168/168 [==============================] - 36s 217ms/step - loss: 0.6038 - accuracy: 0.2077 - precision_m: 0.5074 - recall_m: 0.1641 - f1_m: 0.2390 - val_loss: 0.5275 - val_accuracy: 0.3040 - val_precision_m: 0.5332 - val_recall_m: 0.3561 - val_f1_m: 0.4257\n","Epoch 9/10\n","168/168 [==============================] - 37s 219ms/step - loss: 0.6041 - accuracy: 0.2005 - precision_m: 0.4738 - recall_m: 0.1543 - f1_m: 0.2207 - val_loss: 0.5371 - val_accuracy: 0.3040 - val_precision_m: 0.5332 - val_recall_m: 0.3561 - val_f1_m: 0.4257\n","Epoch 10/10\n","168/168 [==============================] - 36s 216ms/step - loss: 0.6017 - accuracy: 0.1996 - precision_m: 0.5100 - recall_m: 0.1801 - f1_m: 0.2621 - val_loss: 0.5304 - val_accuracy: 0.3040 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00 - val_f1_m: 0.0000e+00\n","Score for fold 3: loss of 0.5037462115287781; accuracy of 37.47016787528992% ;precision_m of 0.0 ;recall_m of 0.0 ;            f1_m of 0.0\n","3\n","Epoch 1/10\n","168/168 [==============================] - 18s 93ms/step - loss: 0.5609 - accuracy: 0.2855 - precision_m: 0.4874 - recall_m: 0.2146 - f1_m: 0.2722 - val_loss: 0.4510 - val_accuracy: 0.4318 - val_precision_m: 0.6636 - val_recall_m: 0.4957 - val_f1_m: 0.5664\n","Epoch 2/10\n","168/168 [==============================] - 15s 89ms/step - loss: 0.5251 - accuracy: 0.2990 - precision_m: 0.5416 - recall_m: 0.2661 - f1_m: 0.3534 - val_loss: 0.4525 - val_accuracy: 0.4318 - val_precision_m: 0.6636 - val_recall_m: 0.4957 - val_f1_m: 0.5664\n","Epoch 3/10\n","168/168 [==============================] - 15s 90ms/step - loss: 0.5249 - accuracy: 0.2989 - precision_m: 0.5332 - recall_m: 0.2645 - f1_m: 0.3482 - val_loss: 0.4522 - val_accuracy: 0.4318 - val_precision_m: 0.6636 - val_recall_m: 0.4957 - val_f1_m: 0.5664\n","Epoch 4/10\n","168/168 [==============================] - 15s 90ms/step - loss: 0.5212 - accuracy: 0.3008 - precision_m: 0.5483 - recall_m: 0.3079 - f1_m: 0.3919 - val_loss: 0.4552 - val_accuracy: 0.4318 - val_precision_m: 0.6636 - val_recall_m: 0.4957 - val_f1_m: 0.5664\n","Epoch 5/10\n","168/168 [==============================] - 15s 90ms/step - loss: 0.5222 - accuracy: 0.3011 - precision_m: 0.5223 - recall_m: 0.2736 - f1_m: 0.3527 - val_loss: 0.4539 - val_accuracy: 0.4318 - val_precision_m: 0.6636 - val_recall_m: 0.4957 - val_f1_m: 0.5664\n","Epoch 6/10\n","168/168 [==============================] - 15s 90ms/step - loss: 0.5221 - accuracy: 0.3045 - precision_m: 0.5405 - recall_m: 0.3166 - f1_m: 0.3969 - val_loss: 0.4551 - val_accuracy: 0.4318 - val_precision_m: 0.6636 - val_recall_m: 0.4957 - val_f1_m: 0.5664\n","Epoch 7/10\n","168/168 [==============================] - 15s 91ms/step - loss: 0.5155 - accuracy: 0.3132 - precision_m: 0.5510 - recall_m: 0.3368 - f1_m: 0.4161 - val_loss: 0.4476 - val_accuracy: 0.4318 - val_precision_m: 0.6636 - val_recall_m: 0.4957 - val_f1_m: 0.5664\n","Epoch 8/10\n","168/168 [==============================] - 15s 91ms/step - loss: 0.5137 - accuracy: 0.3224 - precision_m: 0.5454 - recall_m: 0.3458 - f1_m: 0.4218 - val_loss: 0.4491 - val_accuracy: 0.4318 - val_precision_m: 0.6636 - val_recall_m: 0.4957 - val_f1_m: 0.5664\n","Epoch 9/10\n","168/168 [==============================] - 15s 91ms/step - loss: 0.5214 - accuracy: 0.3035 - precision_m: 0.5419 - recall_m: 0.3428 - f1_m: 0.4194 - val_loss: 0.4494 - val_accuracy: 0.4318 - val_precision_m: 0.6636 - val_recall_m: 0.4957 - val_f1_m: 0.5664\n","Epoch 10/10\n","168/168 [==============================] - 15s 91ms/step - loss: 0.5191 - accuracy: 0.3074 - precision_m: 0.5369 - recall_m: 0.3288 - f1_m: 0.4059 - val_loss: 0.4586 - val_accuracy: 0.4318 - val_precision_m: 0.6636 - val_recall_m: 0.4957 - val_f1_m: 0.5664\n","Score for fold 1: loss of 0.6472353935241699; accuracy of 16.373397409915924% ;precision_m of 0.5160476565361023 ;recall_m of 0.26589879393577576 ;            f1_m of 0.34966719150543213\n","Epoch 1/10\n","168/168 [==============================] - 19s 95ms/step - loss: 0.6032 - accuracy: 0.2309 - precision_m: 0.5035 - recall_m: 0.1943 - f1_m: 0.2725 - val_loss: 0.4642 - val_accuracy: 0.4318 - val_precision_m: 0.6636 - val_recall_m: 0.4957 - val_f1_m: 0.5664\n","Epoch 2/10\n","168/168 [==============================] - 15s 91ms/step - loss: 0.5804 - accuracy: 0.2344 - precision_m: 0.5419 - recall_m: 0.2620 - f1_m: 0.3513 - val_loss: 0.4851 - val_accuracy: 0.4318 - val_precision_m: 0.6636 - val_recall_m: 0.4957 - val_f1_m: 0.5664\n","Epoch 3/10\n","168/168 [==============================] - 15s 91ms/step - loss: 0.5772 - accuracy: 0.2341 - precision_m: 0.5358 - recall_m: 0.2610 - f1_m: 0.3499 - val_loss: 0.4741 - val_accuracy: 0.4318 - val_precision_m: 0.6636 - val_recall_m: 0.4957 - val_f1_m: 0.5664\n","Epoch 4/10\n","168/168 [==============================] - 15s 92ms/step - loss: 0.5784 - accuracy: 0.2251 - precision_m: 0.5549 - recall_m: 0.2841 - f1_m: 0.3742 - val_loss: 0.4893 - val_accuracy: 0.4318 - val_precision_m: 0.6636 - val_recall_m: 0.4957 - val_f1_m: 0.5664\n","Epoch 5/10\n","168/168 [==============================] - 15s 92ms/step - loss: 0.5784 - accuracy: 0.2322 - precision_m: 0.5428 - recall_m: 0.2799 - f1_m: 0.3677 - val_loss: 0.4833 - val_accuracy: 0.4318 - val_precision_m: 0.6636 - val_recall_m: 0.4957 - val_f1_m: 0.5664\n","Epoch 6/10\n","168/168 [==============================] - 15s 92ms/step - loss: 0.5800 - accuracy: 0.2278 - precision_m: 0.5381 - recall_m: 0.2933 - f1_m: 0.3788 - val_loss: 0.4672 - val_accuracy: 0.4318 - val_precision_m: 0.6636 - val_recall_m: 0.4957 - val_f1_m: 0.5664\n","Epoch 7/10\n","168/168 [==============================] - 16s 93ms/step - loss: 0.5792 - accuracy: 0.2285 - precision_m: 0.5479 - recall_m: 0.3015 - f1_m: 0.3882 - val_loss: 0.4726 - val_accuracy: 0.4318 - val_precision_m: 0.6636 - val_recall_m: 0.4957 - val_f1_m: 0.5664\n","Epoch 8/10\n","168/168 [==============================] - 16s 92ms/step - loss: 0.5794 - accuracy: 0.2301 - precision_m: 0.5435 - recall_m: 0.2944 - f1_m: 0.3812 - val_loss: 0.4745 - val_accuracy: 0.4318 - val_precision_m: 0.6636 - val_recall_m: 0.4957 - val_f1_m: 0.5664\n","Epoch 9/10\n","168/168 [==============================] - 16s 93ms/step - loss: 0.5807 - accuracy: 0.2211 - precision_m: 0.5302 - recall_m: 0.2867 - f1_m: 0.3714 - val_loss: 0.4630 - val_accuracy: 0.4318 - val_precision_m: 0.6636 - val_recall_m: 0.4957 - val_f1_m: 0.5664\n","Epoch 10/10\n","168/168 [==============================] - 16s 92ms/step - loss: 0.5809 - accuracy: 0.2231 - precision_m: 0.5373 - recall_m: 0.2947 - f1_m: 0.3800 - val_loss: 0.4677 - val_accuracy: 0.4318 - val_precision_m: 0.6636 - val_recall_m: 0.4957 - val_f1_m: 0.5664\n","Score for fold 2: loss of 0.5426225662231445; accuracy of 28.511780500411987% ;precision_m of 0.5150595307350159 ;recall_m of 0.33347252011299133 ;            f1_m of 0.40342390537261963\n","Epoch 1/10\n","168/168 [==============================] - 19s 96ms/step - loss: 0.6262 - accuracy: 0.2150 - precision_m: 0.4830 - recall_m: 0.1575 - f1_m: 0.2194 - val_loss: 0.5389 - val_accuracy: 0.3040 - val_precision_m: 0.5332 - val_recall_m: 0.3561 - val_f1_m: 0.4257\n","Epoch 2/10\n","168/168 [==============================] - 15s 92ms/step - loss: 0.5958 - accuracy: 0.2065 - precision_m: 0.5116 - recall_m: 0.1888 - f1_m: 0.2680 - val_loss: 0.5616 - val_accuracy: 0.3040 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00 - val_f1_m: 0.0000e+00\n","Epoch 3/10\n","168/168 [==============================] - 16s 93ms/step - loss: 0.5952 - accuracy: 0.2064 - precision_m: 0.5205 - recall_m: 0.1605 - f1_m: 0.2421 - val_loss: 0.5394 - val_accuracy: 0.3040 - val_precision_m: 0.5332 - val_recall_m: 0.3561 - val_f1_m: 0.4257\n","Epoch 4/10\n","168/168 [==============================] - 15s 92ms/step - loss: 0.5943 - accuracy: 0.1981 - precision_m: 0.5099 - recall_m: 0.2006 - f1_m: 0.2850 - val_loss: 0.5248 - val_accuracy: 0.3040 - val_precision_m: 0.5332 - val_recall_m: 0.3561 - val_f1_m: 0.4257\n","Epoch 5/10\n","168/168 [==============================] - 16s 93ms/step - loss: 0.5940 - accuracy: 0.2083 - precision_m: 0.4989 - recall_m: 0.1991 - f1_m: 0.2799 - val_loss: 0.5272 - val_accuracy: 0.3040 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00 - val_f1_m: 0.0000e+00\n","Epoch 6/10\n","168/168 [==============================] - 16s 93ms/step - loss: 0.5972 - accuracy: 0.2025 - precision_m: 0.5054 - recall_m: 0.1490 - f1_m: 0.2232 - val_loss: 0.5314 - val_accuracy: 0.3040 - val_precision_m: 0.5332 - val_recall_m: 0.3561 - val_f1_m: 0.4257\n","Epoch 7/10\n","168/168 [==============================] - 16s 93ms/step - loss: 0.5957 - accuracy: 0.2093 - precision_m: 0.5186 - recall_m: 0.2285 - f1_m: 0.3121 - val_loss: 0.5330 - val_accuracy: 0.3040 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00 - val_f1_m: 0.0000e+00\n","Epoch 8/10\n","168/168 [==============================] - 16s 93ms/step - loss: 0.5940 - accuracy: 0.2079 - precision_m: 0.4833 - recall_m: 0.1520 - f1_m: 0.2242 - val_loss: 0.5307 - val_accuracy: 0.3040 - val_precision_m: 0.5332 - val_recall_m: 0.3561 - val_f1_m: 0.4257\n","Epoch 9/10\n","168/168 [==============================] - 15s 92ms/step - loss: 0.5941 - accuracy: 0.2042 - precision_m: 0.5175 - recall_m: 0.2214 - f1_m: 0.3056 - val_loss: 0.5284 - val_accuracy: 0.3040 - val_precision_m: 0.5332 - val_recall_m: 0.3561 - val_f1_m: 0.4257\n","Epoch 10/10\n","168/168 [==============================] - 15s 92ms/step - loss: 0.5970 - accuracy: 0.1934 - precision_m: 0.5027 - recall_m: 0.1784 - f1_m: 0.2594 - val_loss: 0.5345 - val_accuracy: 0.3040 - val_precision_m: 0.5332 - val_recall_m: 0.3561 - val_f1_m: 0.4257\n","Score for fold 3: loss of 0.5075380206108093; accuracy of 37.47016787528992% ;precision_m of 0.6107142567634583 ;recall_m of 0.43802905082702637 ;            f1_m of 0.5087757110595703\n","4\n","Epoch 1/10\n","168/168 [==============================] - 27s 141ms/step - loss: 0.5502 - accuracy: 0.2947 - precision_m: 0.5148 - recall_m: 0.2273 - f1_m: 0.3037 - val_loss: 0.4562 - val_accuracy: 0.4318 - val_precision_m: 0.6636 - val_recall_m: 0.4957 - val_f1_m: 0.5664\n","Epoch 2/10\n","168/168 [==============================] - 23s 134ms/step - loss: 0.5224 - accuracy: 0.3040 - precision_m: 0.5412 - recall_m: 0.2768 - f1_m: 0.3616 - val_loss: 0.4457 - val_accuracy: 0.4318 - val_precision_m: 0.6636 - val_recall_m: 0.4957 - val_f1_m: 0.5664\n","Epoch 3/10\n","152/168 [==========================>...] - ETA: 1s - loss: 0.5226 - accuracy: 0.3060 - precision_m: 0.5547 - recall_m: 0.2928 - f1_m: 0.3790"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":163},"id":"GttF3W6cQWXQ","executionInfo":{"status":"error","timestamp":1615319369874,"user_tz":-330,"elapsed":1049,"user":{"displayName":"Shanaka Chathuranga","photoUrl":"","userId":"01381725564551416324"}},"outputId":"adf82be8-4dfc-48d6-a6a0-304eb51245b4"},"source":["accdf"],"execution_count":null,"outputs":[{"output_type":"error","ename":"NameError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-1-7f4eb5522445>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0maccdf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;31mNameError\u001b[0m: name 'accdf' is not defined"]}]}]}